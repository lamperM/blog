<!doctype html><html><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><link rel=stylesheet href=/css/style.css><link rel=stylesheet href=/css/syntax_pastie.css><link rel=stylesheet href=https://gcore.jsdelivr.net/npm/lxgw-wenkai-lite-webfont@1.1.0/style.css><title>课程笔记：cs152（计算机体系结构）</title></head><body><div id=app><div id=sideContainer class=side-container><div class=nav-link-list><div class="a-block nav-link-item"><a href=/posts>最近修改</a></div><div class="a-block nav-link-item"><a href=/categories>分类 Categories</a></div><div class="a-block nav-link-item"><a href=/tags>标签 Tags</a></div><div class="a-block nav-link-item"><a href=/index.xml>RSS Feed</a></div></div></div><div id=extraContainer class=extra-container><div class="a-block nav-link-item" href><div id=fastSearch><input id=searchInput placeholder="Press '/' to focus on me"><ul id=searchResults></ul></div></div><div class="toc animated-visibility" :class="{ invisible: scrollY <= 140 }"><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#cisc-%e7%9a%84%e5%8f%91%e5%b1%95%e5%88%b0-risc-%e8%af%9e%e7%94%9f aria-label="CISC 的发展到 RISC 诞生">CISC 的发展到 RISC 诞生</a></li><li><a href=#%e6%b5%81%e6%b0%b4%e7%ba%bf-pipeline aria-label="流水线 Pipeline">流水线 Pipeline</a><ul><li><a href=#%e6%95%b0%e6%8d%ae%e7%ab%9e%e4%ba%89%e7%9a%84%e4%b8%89%e7%a7%8d%e8%a7%a3%e5%86%b3%e6%96%b9%e6%a1%88 aria-label=数据竞争的三种解决方案>数据竞争的三种解决方案</a></li></ul></li><li><a href=#%e5%bc%82%e5%b8%b8-exception aria-label="异常 Exception">异常 Exception</a></li><li><a href=#%e5%86%85%e5%ad%98-memory aria-label="内存 Memory">内存 Memory</a></li><li><a href=#%e9%a2%84%e5%8f%96-prefetching aria-label="预取 Prefetching">预取 Prefetching</a><ul><li><a href=#%e6%8c%87%e4%bb%a4%e9%a2%84%e5%8f%96 aria-label=指令预取>指令预取</a><ul><li><a href=#basic-schemes%e7%ae%80%e5%8d%95%e5%9c%b0%e9%a2%84%e6%9c%9f-program-order-%e4%b8%8b%e7%9a%84-n-%e8%a1%8c aria-label="Basic Schemes：简单地预期 program order 下的 N 行">Basic Schemes：简单地预期 program order 下的 N 行</a></li><li><a href=#basic-schemes%e5%90%af%e5%8f%91%e5%bc%8f%e7%9a%84%e9%94%99%e8%af%af%e8%b7%af%e5%be%84%e9%a2%84%e5%8f%96 aria-label="Basic Schemes：启发式的错误路径预取">Basic Schemes：启发式的错误路径预取</a></li><li><a href=#%e6%9b%b4%e5%8a%a0%e9%ab%98%e7%ba%a7%e4%b8%8e%e5%88%86%e6%94%af%e9%a2%84%e6%b5%8b%e5%8d%95%e5%85%83%e7%bb%93%e5%90%88%e9%a2%84%e6%9c%9f%e5%88%86%e6%94%af%e9%a2%84%e6%b5%8b%e7%bb%93%e6%9e%9c%e6%96%b9%e5%90%91%e7%9a%84%e6%8c%87%e4%bb%a4 aria-label=更加高级：与分支预测单元结合，预期分支预测结果方向的指令>更加高级：与分支预测单元结合，预期分支预测结果方向的指令</a></li></ul></li><li><a href=#%e4%bd%bf%e7%94%a8-non-blocking-cache-%e6%9d%a5%e5%a2%9e%e5%8a%a0-cache-%e5%b8%a6%e5%ae%bd aria-label="使用 Non-blocking Cache 来增加 Cache 带宽">使用 Non-blocking Cache 来增加 Cache 带宽</a></li></ul></li><li><a href=#567-%e7%9a%84%e6%80%bb%e7%bb%93 aria-label="567 的总结">567 的总结</a></li><li><a href=#89-%e7%9a%84%e6%80%bb%e7%bb%93 aria-label="89 的总结">89 的总结</a><ul><li><a href=#cpu-%e6%b5%81%e6%b0%b4%e7%ba%bf%e5%a6%82%e4%bd%95%e9%80%82%e5%ba%94%e6%9c%89-tlb-%e7%9a%84%e8%99%9a%e6%8b%9f%e5%86%85%e5%ad%98%e7%bf%bb%e8%af%91 aria-label="CPU 流水线如何适应有 TLB 的虚拟内存翻译">CPU 流水线如何适应有 TLB 的虚拟内存翻译</a></li><li><a href=#%e8%99%9a%e6%8b%9f%e5%9c%b0%e5%9d%80-cache aria-label="虚拟地址 Cache">虚拟地址 Cache</a></li><li><a href=#tlb%e5%92%8ccache%e5%b9%b6%e8%a1%8c%e6%9f%a5%e6%89%be aria-label=TLB和Cache并行查找>TLB和Cache并行查找</a></li></ul></li></ul></div></details></div></div></div><script src=/js/fuse.js></script>
<script src=/js/fastsearch.js></script><main class=container><article><header><div class=post-title>课程笔记：cs152（计算机体系结构）</div></header><h2 id=cisc-的发展到-risc-诞生>CISC 的发展到 RISC 诞生</h2><ul><li>1940-1950<ul><li>冯诺依曼架构被提出：以存储器为中心，软件和硬件的设计分离，减少了系统中的硬连接，实现了可编程的计算机！</li><li>用户程序（二进制指令）被存储到存储器中。存储器的容量，几 k 字，不能放下很大的程序。</li><li>存储器有 CRT 磷光线存储器（支持随机存储），磁芯（Core memory）（<a href=https://zhuanlan.zhihu.com/p/144628785>磁芯存储：统治存储领域 20 年 - 知乎</a>）。</li></ul></li><li>1960-1970<ul><li>PDP-6 典型设计，16 个通用寄存器，SP+FP，ISA 逐渐变得复杂</li><li>此时人们用汇编指令写程序，认为每个常见操作都应该实现为一条特殊的指令（三角函数、CRC&mldr;）。<strong>（？？？与 ROM 和 RAM 的速度差异有关吗）</strong></li><li>这么多种类的指令硬连线的方式太复杂 ==> 微码</li><li>微码 ROM 是一张表：ISA 指令和微操作之间的映射，一条指令对应多个微操作</li><li>有了微码，创造一条新的指令很容易，使用不同微操作的组合即可</li></ul></li><li>1980<ul><li>高级语言和编译器来了，不用再手写指令</li><li>编译器很难利用到这么多复杂的指令，生成的汇编代码常用几条指令占 95%，大量的不常用指令占据了微码 ROM。</li><li>发明出基于 Mos 的 SRAM，比原先的快 2-10 倍！<strong>？？？所以呢</strong></li><li>CISC 不适合与流水线<ul><li>decode 时间不一致，边 decode 边取指，不确定的时间段</li><li>寻址模式多，容易引发数据竞争，而且不容易检测</li></ul></li></ul></li></ul><h2 id=流水线-pipeline>流水线 Pipeline</h2><p>RISC 的架构中出现的，旨在提高处理器处理效率，<strong>争取在一个时钟周期中完成一条指令（CPI=1）</strong>。</p><style type=text/css>.notice{--root-color:#444;--root-background:#eff;--title-color:#fff;--title-background:#7bd;--warning-title:#c33;--warning-content:#fee;--info-title:#fb7;--info-content:#fec;--note-title:#6be;--note-content:#e7f2fa;--tip-title:#5a5;--tip-content:#efe}@media(prefers-color-scheme:dark){.notice{--root-color:#ddd;--root-background:#eff;--title-color:#fff;--title-background:#7bd;--warning-title:#800;--warning-content:#400;--info-title:#a50;--info-content:#420;--note-title:#069;--note-content:#023;--tip-title:#363;--tip-content:#121}}body.dark .notice{--root-color:#ddd;--root-background:#eff;--title-color:#fff;--title-background:#7bd;--warning-title:#800;--warning-content:#400;--info-title:#a50;--info-content:#420;--note-title:#069;--note-content:#023;--tip-title:#363;--tip-content:#121}.notice{padding:18px;line-height:24px;margin-bottom:24px;border-radius:4px;color:var(--root-color);background:var(--root-background)}.notice p:last-child{margin-bottom:0}.notice-title{margin:-18px -18px 12px;padding:4px 18px;border-radius:4px 4px 0 0;font-weight:700;color:var(--title-color);background:var(--title-background)}.notice.warning .notice-title{background:var(--warning-title)}.notice.warning{background:var(--warning-content)}.notice.info .notice-title{background:var(--info-title)}.notice.info{background:var(--info-content)}.notice.note .notice-title{background:var(--note-title)}.notice.note{background:var(--note-content)}.notice.tip .notice-title{background:var(--tip-title)}.notice.tip{background:var(--tip-content)}.icon-notice{display:inline-flex;align-self:center;margin-right:8px}.icon-notice img,.icon-notice svg{height:1em;width:1em;fill:currentColor}.icon-notice img,.icon-notice.baseline svg{top:.125em;position:relative}</style><div class="notice tip" id=CPI指标的意义><p class=notice-title><span class="icon-notice baseline"><svg xmlns="http://www.w3.org/2000/svg" viewBox="300.5 134 300 300"><path d="M551.281 252.36c0-3.32-1.172-6.641-3.515-8.985l-17.774-17.578c-2.344-2.344-5.469-3.711-8.789-3.711-3.32.0-6.445 1.367-8.789 3.71l-79.687 79.493-44.141-44.14c-2.344-2.344-5.469-3.712-8.79-3.712-3.32.0-6.444 1.368-8.788 3.711l-17.774 17.579c-2.343 2.343-3.515 5.664-3.515 8.984s1.172 6.445 3.515 8.789l70.704 70.703c2.343 2.344 5.664 3.711 8.789 3.711 3.32.0 6.64-1.367 8.984-3.71l106.055-106.056c2.343-2.343 3.515-5.468 3.515-8.789zM600.5 284c0 82.813-67.188 150-150 150-82.813.0-150-67.188-150-150 0-82.813 67.188-150 150-150 82.813.0 150 67.188 150 150z"/></svg></span><span>CPI指标的意义</span></p><p>CPI 总是衡量大量指令的平均结果，单讨论一两个指令的 CPI 是没有意义的</p><p>Pipeline CPI 计算：从第一条指令结束到最后一条指令结束的周期数/指令数</p><figure><img src=/cs152_cpi.png width=70%></figure><p>￼
PS：为什么不从第一条指令的开始进行计算？==> 因为通常有大量的指令（百万），所以第一条指令开始到结束的时间段没什么实际意义，影响不大。</p></div><p>最经典的当属 MIPS(无内部互锁的流水线处理器)的五级流水线技术。MIPS 体系结构本身就是为了流水线而设计的，每条指令的执行过程都分成五级。每一级成为一个流水线阶段，每个阶段占用固定的时间，通常是一个时钟周期。</p><div class="notice info"><p class=notice-title><span class="icon-notice baseline"><svg xmlns="http://www.w3.org/2000/svg" viewBox="92 59.5 300 300"><path d="M292 303.25V272c0-3.516-2.734-6.25-6.25-6.25H267v-1e2c0-3.516-2.734-6.25-6.25-6.25h-62.5c-3.516.0-6.25 2.734-6.25 6.25V197c0 3.516 2.734 6.25 6.25 6.25H217v62.5h-18.75c-3.516.0-6.25 2.734-6.25 6.25v31.25c0 3.516 2.734 6.25 6.25 6.25h87.5c3.516.0 6.25-2.734 6.25-6.25zm-25-175V97c0-3.516-2.734-6.25-6.25-6.25h-37.5c-3.516.0-6.25 2.734-6.25 6.25v31.25c0 3.516 2.734 6.25 6.25 6.25h37.5c3.516.0 6.25-2.734 6.25-6.25zm125 81.25c0 82.813-67.188 150-150 150-82.813.0-150-67.188-150-150 0-82.813 67.188-150 150-150 82.813.0 150 67.188 150 150z"/></svg></span><span></span></p><p>像是取指、访存阶段都比较耗时，超过了一个时钟周期。</p></div><figure><img src=/cs152_mips.jpg width=90%></figure><p>有的微架构就使用超长的流水线（多级），将指令阶段进一步细分，有助于增加并行度。
但是呢，阶段分的太细，在微架构层面会比较复杂，因为各个阶段之间需要发送信号，会浪费一些时间。</p><h3 id=数据竞争的三种解决方案>数据竞争的三种解决方案</h3><ol><li>等待。其他竞争的指令等着当前指令执行完再执行。</li><li>Bypass。需要额外硬件，</li><li>预测。需要额外硬件，先猜一个值，如果错了再刷新流水线重退。</li></ol><h2 id=异常-exception>异常 Exception</h2><p>流水线的各个阶段都会产生异常，怎么设计？</p><p>难道在每个时钟周期都检测流水线中有无异常吗？显然不行，因为假设指令 B 在 Decode 阶段产生了异常，如果此时就认定指令 B 触发异常。但殊不知上一条指令 A 会在回写阶段也触发异常。
而一般来说，按照程序员的视角我们认为指令一条一条的执行，所以也希望异常按照指令顺序产生。</p><p>进而，就提出了<strong>在流水线的最后【提交】阶段才检查异常</strong>。</p><ul><li>流水线中多了 3 个额外的寄存器用于标记每个阶段是否产生异常。</li><li>前面指令产生的异常标记可以覆盖后面指令。这就使得异常按照指令顺序产生。</li><li>若一条指令在前面阶段已经产生异常，后续阶段 Bubble。</li><li>在最后提交阶段之前，会检查是不是有异常或者异步中断？（如果两者都有，实现定义）之后下一个 PC 就是异常向量。</li></ul><figure><img src=/cs152_pipeline_exception.jpg width=90%></figure><h2 id=内存-memory>内存 Memory</h2><p>Core memory 是首个大标量可靠存储器。</p><ul><li>1940s 被提出</li><li>可靠，比半导体存储器可靠的多</li><li>手工制造，产量低</li><li>访问时间 1 微秒</li></ul><p>半导体内存从 1970s 开始</p><ul><li>英特尔最早的主要产品是半导体存储器</li></ul><p>最早的半导体存储器是静态 RAM，Static RAM</p><ul><li>持续通电，但不需要刷新</li></ul><p>DRAM 最早是 IBM 的一个人发明的，但是由英特尔做到商业化</p><ul><li>电容来存储 bit</li></ul><h2 id=预取-prefetching>预取 Prefetching</h2><p>现代处理器一个时钟周期内可以同时处理多条指令，甚至每个周期执行 ldr/str 操作多次。</p><h3 id=指令预取>指令预取</h3><h4 id=basic-schemes简单地预期-program-order-下的-n-行>Basic Schemes：简单地预期 program order 下的 N 行</h4><p>很简单就不说了，在 1 条指令 miss 的时候，预期下面 N 个 cacheline 长度的指令。</p><h4 id=basic-schemes启发式的错误路径预取>Basic Schemes：启发式的错误路径预取</h4><p>当 decode 到一条条件分支指令后，就立马预取跳转和不跳转两条方向上的指令。</p><ul><li>可能性总>0，每个分支总在某种情况下会发生。</li><li>【Challenge】立即跳转指令来说，可能预取是来不及的。</li><li>【Challenge】某些条件跳转不能支持，例如寄存器间接等，你无法第一时间知道目标地址。</li></ul><h4 id=更加高级与分支预测单元结合预期分支预测结果方向的指令>更加高级：与分支预测单元结合，预期分支预测结果方向的指令</h4><h3 id=使用-non-blocking-cache-来增加-cache-带宽>使用 Non-blocking Cache 来增加 Cache 带宽</h3><ul><li>Non-blocking cache or lockup-free cache 允许 cache 在处理上一个 miss 时继续支持后续指令的 cache 命中。<ul><li>甚至可以维持若干次的 miss（现代处理器一般是 10 几次）</li></ul></li></ul><p>动态加载动态链接在虚拟地址出现之前就已经被广泛使用了，它正是用于解决程序库中的物理内存地址不能写死。</p><p>后面，因为 IO 很慢，只运行一个程序的话 CPU 会一直等待着。这就促使多程序并发思想的诞生。每个用户程序占用物理内存的一部分，只允许访问这些。为每个用户程序分配的内存空间也叫 Segment，如果 OS 检测到超出了，会报 Segment Fault。</p><p>这种分段的方式慢慢显示出了它的问题：外部碎片。为用户程序分配的段必须在物理上是连续的。除此之外，如果程序在运行时想动态的扩大自己的段也是比较困难的。</p><p>段分配的缺点诞生了虚拟内存+分页：</p><ol><li>物理上不需要连续了。</li></ol><p>TLB Miss 的处理分为软件和硬件两种方式：</p><ol><li>软件（MIPS、Alpha）。TLB Miss 触发异常，由 OS 走一个 PTW 来填充 TLB 表项。非常耗时，因为对于 OOO 的处理器，必须刷新 pipeline 去走到异常处理程序中。而且现代的处理器一个周期内可以并行做几个翻译，用软件的方式实在是效率太低。</li><li>MMU 去做 PTW，然后重填 TLB。</li></ol><h2 id=567-的总结>567 的总结</h2><ul><li>首先介绍了内存是怎么回事，物理形态的发展历程。<ul><li>纸带 -> 磁芯存储（Core Mem）-> 半导体存储</li></ul></li><li>随后介绍了 Cache，解决了内存和 CPU 之间数据交换速度差的问题。</li><li>Cache 很好，但是一旦 miss 造成的损耗还是太大。预取 prefetch 可以帮助解决一些问题。既然你已经 Miss 已经要访问内存了，何不根据某种预测算法多取一些，尽量避免以后发生 Miss 的概率。设计好的预取算法是很关键的。<ul><li>预取包括：指令预取和数据预取。</li></ul></li></ul><h2 id=89-的总结>89 的总结</h2><ul><li>之前所有的讨论还是基于单任务的情况</li><li>我们写了很多程序在 CPU 上运行，有些代码段是通用的，程序员们就把他们做成了库封装起来。</li><li>代码直接访问物理地址，所以这些库目标文件中的物理地址不能写死，产生了动态加载动态链接的技术，解决库在不同机器上运行的问题。</li><li>还有一个问题就是 IO 很慢，只运行一个程序的话 CPU 会一直等待着。这就促使多程序并发思想的诞生。每个用户程序占用物理内存的一部分，只允许访问这些。为每个用户程序分配的内存空间也叫 Segment，如果 OS 检测到超出了，会报 Segment Fault。 也就是分段的思想。</li><li>分段有缺点：外部碎片且不能动态扩展。</li><li>分段的缺点引出了虚拟内存+分页的技术，每个应用程序的内存在物理上不再需要连续。</li><li>虚拟内存+分页就要使用页表，最开始的页表是单级的，一个 entry 映射一个页面。如果映射所有的虚拟空间会导致页表很大，但这种单级页表又没办法拆开映射，于是就有了多级页表。</li><li>多级页表查询耗时，在物理上就有了两个优化：<ul><li>TLB 缓存页表的映射信息。</li><li>对大页 Huge page 的支持。</li></ul></li><li>TLB Miss 之后的 refill 一开始是软件实现的，发生 Miss 之后 CPU trap 到特殊的 refill handler，在里面作 pagetable walk，然后用处理器提供的特殊指令重填 TLB。</li><li>然而这种方式随着处理器设计的提升变得影响性能，CPU 可能在一个时钟周期内并行的有多次内存访问，软件处理的效率太低。</li></ul><h3 id=cpu-流水线如何适应有-tlb-的虚拟内存翻译>CPU 流水线如何适应有 TLB 的虚拟内存翻译</h3><p>加入 TLB 虚拟内存之后，在进入访存前 额外多了一些地址翻译的电路连线，在流水线中，我们如何解决这个更加延长的访存阶段呢？</p><ul><li>降低 CPU 时钟频率？时钟周期长了，就延长了访存阶段的时间。但是对性能的影响是无法被接受。</li><li>为地址翻译增加额外的独立流水线阶段？也就是增加流水线的级数，增大了 CPI</li><li>虚拟地址 Cache。在查询 Cache 前就不需要地址翻译了，如果 Cache Miss，才走地址翻译，</li><li>TLB 和 Cache 并行查询，这是现代处理器常用的套路。</li></ul><p>接下来讲就最后两点分别展开介绍。</p><h3 id=虚拟地址-cache>虚拟地址 Cache</h3><figure><img src=/cs152_9_virtcache.jpg width=60%></figure><p>几个特点：</p><ol><li>会带来 aliasing 问题，一个上下文内也会有 多个虚拟地址 映射到 同一个物理地址的共享情况。这时候一旦一个修改了，另一个会不知道。</li><li>更多的Cache coherence问题，多核之间的，一旦一个CPU更新了某个物理地址，不太方便通知到其他核心，要做物理->虚拟的转换，或者是遍历。</li></ol><h3 id=tlb和cache并行查找>TLB和Cache并行查找</h3><p>Cache 存的是物理地址，但是按照page offset来索引（这部分物理和虚拟是一样的）。另外一边TLB去做翻译，最后用Cache中定位的完整tag和TLB翻译的结果对比。</p><p>这种情况我觉得可以称为：page-offset Index, PPN Tag Cache。但是它的统称叫做：Virtual Index Physical Tag Cache。其实也对，因为我们没必要总是拿page-offset去index，VA里的其他bit也可以，只是拿后面的不容易造成冲突吧（根据局部性原理？）。</p><figure><img src=/cs152_9_concur_tlb_cache.jpg width=60%></figure><p>这种VIPT的Cache可以解决 cache coherence 的问题，因为有物理的Tag。</p></article></body><hr width=100% id=EOF><p style=color:#777>创建于: 2024-04-05T19:28:12, Lastmod: 2024-07-29T21:58:50</p></main></div></body></html>