<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Posts on BLOG</title><link>https://wangloo.github.io/posts/</link><description>Recent content in Posts on BLOG</description><generator>Hugo -- gohugo.io</generator><lastBuildDate>Tue, 16 Apr 2024 19:28:12 +0800</lastBuildDate><atom:link href="https://wangloo.github.io/posts/index.xml" rel="self" type="application/rss+xml"/><item><title>课程笔记：NJU ICS2022</title><link>https://wangloo.github.io/posts/course/nju-ics2022/</link><pubDate>Tue, 16 Apr 2024 19:28:12 +0800</pubDate><guid>https://wangloo.github.io/posts/course/nju-ics2022/</guid><description>ISA: RISCV32
构建系统 编译Guest程序流程分析 编译dummy可执行文件的命令如下，很好奇是如何实现的。
cd am-kernels/am-kernels/tests/cpu-tests make ARCH=riscv32-nemu ALL=dummy 既然在当前目录执行make，自然先从 am-kernels/am-kernels/tests/cpu-tests/Makefile开始看起。
ALL默认是所有test的集合，参数指定会覆盖它。 ALL的生成规则属于 静态规则 ，通配符%代表ALL的全称即依赖Makefile.dummy。更多关于静态规则 Makefile.dummy的生成规则也就在下面，这个文件默认是不存在的，需要临时生成 生成的规则是 echo -e &amp;quot;NAME = dummy\nSRCS = tests/dummy.c\ninclude $${AM_HOME}/Makefile&amp;quot; &amp;gt; $@。包含了AM_HOME下的Makefile AM是各个平台版本可执行文件的“制造机”，理念是将平台信息传入，生成指定格式的镜像。运行时库也包含在内。 最后就是执行 make -f 去调用刚才生成的临时Makefile.dummy，传入指定参数 ALL = $(basename $(notdir $(shell find tests/. -name &amp;#34;*.c&amp;#34;))) all: $(addprefix Makefile., $(ALL)) @echo &amp;#34;test list [$(words $(ALL))item(s)]:&amp;#34; $(ALL) $(ALL): %: Makefile.% Makefile.%: tests/%.c latest @/bin/echo -e &amp;#34;NAME = $*\nSRCS = $&amp;lt;\ninclude $${AM_HOME}/Makefile&amp;#34; &amp;gt; $@ @if make -s -f $@ ARCH=$(ARCH) $(MAKECMDGOALS); then \ printf &amp;#34;[%14s] $(COLOR_GREEN)PASS$(COLOR_NONE)\n&amp;#34; $* &amp;gt;&amp;gt; $(RESULT); \ else \ printf &amp;#34;[%14s] $(COLOR_RED)***FAIL***$(COLOR_NONE)\n&amp;#34; $* &amp;gt;&amp;gt; $(RESULT); \ fi -@rm -f Makefile.</description></item><item><title>Linux cmdline 配置</title><link>https://wangloo.github.io/posts/os/linux/cmdline/</link><pubDate>Tue, 16 Apr 2024 10:30:35 +0800</pubDate><guid>https://wangloo.github.io/posts/os/linux/cmdline/</guid><description>内核启动时会打印当前生效的 cmdline。Command Line 相当于外部传给 Linux 内核的参数，内核针对他们做相应处理，并打印无法是被的参数。
如何看当前的cmdline：
内核启动日志会输出 [ 0.000000] Kernel command line: earlycon rw rdinit=/linuxrc root=/dev/vda nokaslr [ 0.000000] Unknown command line parameters: nokaslr cat /proc/cmdline/ 用户有几种方式来注入cmdline：
设备树 bootargs。 linuxkernel的设备树是QEMU生成的，实际就是用的启动参数 --append。
qemu-system-aarch64 \ -nographic -machine virt,secure=on \ -cpu cortex-a53 -smp 2 -m 4G \ -d guest_errors,unimp \ -gdb tcp::1234 \ -bios ./arm-trusted-firmware/build/qemu/debug/bl1.bin \ -kernel ./wupeng/linux/arch/arm64/boot/Image \ -initrd .</description></item><item><title>aptitude修复apt安装依赖</title><link>https://wangloo.github.io/posts/tools/apt_dep/</link><pubDate>Mon, 08 Apr 2024 15:28:12 +0800</pubDate><guid>https://wangloo.github.io/posts/tools/apt_dep/</guid><description>Ubuntu 下用 apt 安装包出现依赖问题： 尝试加-f安装也仍然报相同错误。
在网上查到 aptitude 专用鱼解决 apt 依赖问题，遂尝试。
下载 aptitude
sudo apt install aptitude 用 aptitude 重新安装，aptitude 会给出几种解决方案，第一种是不安装，第二种是将依赖的软件降级消除依赖。我们显然选择第二种方案。
参考：解决Ubuntu下因依赖包而无法安装问题 - soarli博客</description></item><item><title>课程笔记：cs152（计算机体系结构）</title><link>https://wangloo.github.io/posts/course/cs152/</link><pubDate>Fri, 05 Apr 2024 19:28:12 +0800</pubDate><guid>https://wangloo.github.io/posts/course/cs152/</guid><description>CISC的发展到RISC诞生 1940-1950 冯诺依曼架构被提出：以存储器为中心，软件和硬件的设计分离，减少了系统中的硬连接，实现了可编程的计算机！ 用户程序（二进制指令）被存储到存储器中。存储器的容量，几k字，不能放下很大的程序。 存储器有CRT磷光线存储器（支持随机存储），磁芯（Core memory）（磁芯存储：统治存储领域20年 - 知乎）。 1960-1970 PDP-6典型设计，16个通用寄存器，SP+FP，ISA逐渐变得复杂 此时人们用汇编指令写程序，认为每个常见操作都应该实现为一条特殊的指令（三角函数、CRC&amp;hellip;）。（？？？与ROM和RAM的速度差异有关吗） 这么多种类的指令硬连线的方式太复杂 ==&amp;gt; 微码 微码ROM是一张表：ISA指令和微操作之间的映射，一条指令对应多个微操作 有了微码，创造一条新的指令很容易，使用不同微操作的组合即可 1980 高级语言和编译器来了，不用再手写指令 编译器很难利用到这么多复杂的指令，生成的汇编代码常用几条指令占95%，大量的不常用指令占据了微码ROM。 发明出基于Mos的SRAM，比原先的快2-10倍！？？？所以呢 CISC不适合与流水线 decode时间不一致，边decode边取指，不确定的时间段 寻址模式多，容易引发数据竞争，而且不容易检测 流水线 Pipeline RISC的架构中出现的，旨在提高处理器处理效率，争取在一个时钟周期中完成一条指令（CPI=1）。
.notice { --root-color: #444; --root-background: #eff; --title-color: #fff; --title-background: #7bd; --warning-title: #c33; --warning-content: #fee; --info-title: #fb7; --info-content: #fec; --note-title: #6be; --note-content: #e7f2fa; --tip-title: #5a5; --tip-content: #efe } @media (prefers-color-scheme:dark) { .</description></item><item><title>读书笔记：现代Cpu性能分析与优化</title><link>https://wangloo.github.io/posts/reading-notes/perf_analysis/</link><pubDate>Thu, 01 Feb 2024 16:30:35 +0800</pubDate><guid>https://wangloo.github.io/posts/reading-notes/perf_analysis/</guid><description>性能测量 当估计实际程序的性能优化效果时，不建议去除系统中的不确定性行为。 任何性能分析功能——包括采样，都应该在与实际部署最接近的系统下进行。
测量开销是生产环境监控的一个重要问题。由于任何监控都会影响正在运行的服务的性能，因此应该使用尽可能轻量的性能剖析方法。论文（Renet al.，2010）中提到，“如果对正在提供真实服务的服务器进行持续的性能剖析，极低的性能开销是至关重要的”。通常可以接受总体不超过1%的开销，减少监控开销的办法包括限制被监控的机器数量和使用更小的监控时间间隔。
经典的递归计算斐波那契数列，是测量性能的一个好用例。
强烈建议不能只进行一次测试，而是多次运行基准测试，这样基线程序有N个测量值，改动过的程序也有N个测量值。我们需要比较两组测试结果以确定哪一个程序更快。这本身就是一项很难处理的工作，在很多情况下，我们会被测量数据误导而得出错误的结论。如果你向任何数据科学家征求意见， 他们都会告诉你不能依赖单一指标（如最小值、均值、中位数等）， 画出分布图是一种更好的方法。
由于测量的不稳定性，调试性能通常比调试功能更为困难。
Cpu微架构 流水线的灵感来自汽车装配线，将指令的处理分为几个阶段： 取指、译码、执行、访存、回写。几个阶段并行运行。
理想情况下，启用N级流水线后，机器的指令执行效率提升N倍。 实际会存在流水线冒险，包括结构冒险、数据冒险和控制冒险。
乱序执行主要用于避免因依赖引起的停顿而导致CPU资源利用率不足的问题。 指令的动态调整通过硬件结构（如计分板）和诸如寄存器重命名技术实现。
超变量：一个时钟周期内可以发射多条指令。TODO：什么是发射？ 发射宽度是在同一个时钟周期内可以发射的最大指令数。 目前Cpu的典型发射宽度为2~6。
Intel Itanium等架构使用一种称为超长指令字（Very Long InstructionWord，VLIW）的技术， 将调度超标量和多执行单元处理器的负担从硬件转移到编译器。 它的基本原理是要求编译器选择正确的指令组合使得机器被充分利用， 从而简化硬件。编译器可以使用软件流水线、 循环展开等技术来发掘更多的ILP机会， 因为硬件受制于指令窗口长度的限制，而编译器可以获得全局信息。
Cache写操作 在缓存中处理写操作更困难，CPU会使用不同的技术来处理这种复杂情况。 软件开发人员应该特别注意硬件支持的缓存写操作的流程，以确保代码性能最佳。
两种处理Cache写入命中的情况：
写直通（Write-Through）；写入Cache立即同步到低层次的存储结构。 回写（Write-Back）；写Cache当前只修改Cache，设置脏位。 推迟同步操作到该CacheLine被替换出Cache时。 两种处理Cache写入未命中的情况：
写分配（Write-Allocate）；先把该位置的数据加载到Cache， 在执行上方写命中的流程。 写未分配（No-Write-Allocate）；不使用Cache，直接对低层次存储进行修改。 性能分析中的术语 指令和数据都可能发生缓存未命中。根据TMA分析方法（见6.1节）， 指令缓存未命中被归类为前端停滞，数据缓存未命中被归类为后端停滞。 当获取指令时发生指令缓存未命中，会被归类为前端问题。
性能分析方法 程序运行时硬件和软件都可以采集性能数据，这里的硬件是指运行程序的CPU，软件是指操作系统和所有可用于分析的工具。通常软件栈提供上层指标，比如时间、上下文切换次数和缺页次数，而CPU则可以观察缓存未命中、分支预测错误等。根据要解决的问题，各指标的重要程度是不一样的。所以，并不是说硬件指标总能给我们提供更准确的程序执行信息。有些指标是CPU提供不了的，比如上下文切换次数。一般，性能分析工具—比如Linuxperf，可以同时使用来自操作系统和CPU的数据。
代码插桩 代码插桩通过在程序中插入额外的代码来采集运行时信息。 代码清单6展示了最简单的代码插桩例子， 即在函数开头插入printf语句以统计函数的调用次数。
基于插桩的剖析方法常被用在宏观层次，而不是在微观层次。在优化大段代码的场景，使用该方法通常会给出很好的洞察结果，因为你可以自上而下（先在主函数插桩，然后再往被调用函数插桩）地定位性能问题。
代码插桩并不能提供任何关于代码如何从操作系统或CPU角度执行的信息。例如，它不能提供进程调度执行的频率（可从操作系统获得）或发生了多少次分支预测错误（可从CPU获得）的信息。
这种方法的缺点是，每当需要插桩新内容（比如另一个变量）时，都需要重新编译。这可能会成为工程师的负担，增加分析时间。然而，这还不是唯一的缺点。因为通常情况下，你关心的只是应用程序中的热路径，所以你只需要在代码的性能关键部分插桩。在热点代码中插入插桩代码可能会导致整个基准测试的速度降低为原来的1/2[3]。此外，通过插桩代码，你可能改变程序的行为，所以可能无法看到与之前相同的现象。
这就是为什么工程师们现在不经常手动插桩代码了。然而， 自动化代码插桩仍然被编译器广泛使用。编译器能够自动对整个程序进行插桩，并收集与运行相关的统计信息。 最广为人知的用例是代码覆盖度分析和基于剖析文件的编译优化（见7.7节）。
在讨论插桩时，有必要讨论一下二进制插桩方法。二进制插桩背后的思想也类似，不过是在已经构建的可执行文件上完成的，而不是在源代码上完成。二进制插桩有两种类型：静态插桩（提前完成）和动态插桩（在程序执行时按需插入插桩代码）。
跟踪 跟踪在概念上与代码插桩非常相似，但又稍有差别， 代码插桩假设开发者可以掌控程序的代码。然而，跟踪依赖于程序现有的插桩,
负载表征 PMU有两种使用方式：计数和采样。计数模式用于负载表征， 而采样模式用于寻找热点。
人们经常用“剖析”（Profiling）来形容技术上所讲的采样。 剖析是一个更广泛的术语，包括各种收集数据的技术，例如中断、代码插桩和PMU。</description></item><item><title>优秀文章阅读</title><link>https://wangloo.github.io/posts/thinking/post_reading/</link><pubDate>Thu, 01 Feb 2024 10:00:35 +0800</pubDate><guid>https://wangloo.github.io/posts/thinking/post_reading/</guid><description>Cache 伪共享 原地址：Cache伪共享
Cache的操作单位是CacheLine。 当两块内存AB位于同一个CacheLine时，且有两个Cpu核心分别对AB有修改需求， 此时AB都各自被加载到两个Core的Cache中。
伪共享指的是：若其中一个Core对AB进行修改，那另一个Core内的值变不可信， 需要根据一致性协议做出调整（文中举了MESI为例）， 使得两边内容一致。如果两边修改的比较频繁，就会导致一致动作经常发生， 这消耗的时间好似没有Cache存在，具体的时间损耗依据使用的一致性协议决定。</description></item><item><title>2023总结</title><link>https://wangloo.github.io/posts/thinking/2023/</link><pubDate>Wed, 31 Jan 2024 21:30:35 +0800</pubDate><guid>https://wangloo.github.io/posts/thinking/2023/</guid><description>今天刚回东乔老家，也算是折腾收拾了一天。转眼间一年时光已逝， 期间辗转腾挪了四个城市，多多少少也算有一些感悟， 故在此作以记录并对即将到来的2024做出展望。
实习 到了4月份，听到同学们陆陆续续找实习的声音，自己也打算去寻找一份实习。 因为头一次经验不足，投递的时间相对较晚，可能错过了不少好的机会。 最后流程比较长的只有Oppo、华为、特斯拉三家公司， Oppo JD是做基于安卓的Os底层开发，特斯拉车机Os开发， 最终选择了Hr是学长的华为作为主攻方向，当时听说方向还比较匹配。 其中的经历比较坎坷，华为Hr的经典话术：你很匹配，部门很想要-&amp;gt; 卡在公司审批，还需要等等。好在是最终第二批审批通过了， 其实到这已经对华为的招聘流程有些反感了，但毕竟是第一次进入大公司工作， 还是充满了期待，希望能了解华为的开发及项目管理流程， 能为华为的项目贡献自己绵薄之力，也算增加一点成就感。
当天入职遇到了同组的另一位实习生同学：东坡。了解过后发现他之前是做安卓开发， 居然分配我做同样的工作。当时就在想，华为难道不按照个人能力方向进行筛选匹配吗？
事实来看确实如此，依赖于完整的培训体系，华为不指望你进来有什么业务能力， 甚至是该领域完全的小白也Ok，因为初期给你分配的工作都比较简单， 不仅实习生如此，就连校招生进我所在的“芯片仿真组”之前，都不是所在专业的毕业生。
开发工作中的所见所闻也印证了我的观点，我们组的工作是为海思芯片在Qemu上构建仿真平台， 尽可能去模拟所有的寄存器和外设。即便是Hr（目前已经是PL）学长一遍遍的强调我们是核心团队， 在我自己看来这些工作怎么也称不上核心两个字。更何况在工作时偶然间听到小道消息： 这块工作原本是由海思负责完成的，后面海思懒得做，划到了无线下。 在实际工作中我们也和海思需要频繁的拉通对齐，虽然海思不咋愿意搭理我们， 也不想提供涉密资料。在结合我们团队成员普遍在芯片行业的水平， 到底是不是核心团队则不言而喻了。
另外中间比较有意思的一件事是评选优秀实习生，在我们整个小部门有两个实习生： 我和东坡。在这里我不是想自夸，只是说明术业有专攻，在底层软件开发、嵌入式领域我好歹也做了5年至少了， 没想到头衔竟然授予东坡。当然，东坡在自己的学习领域也很优秀我承认， 但是我确实没想到一个从没接触过嵌入式的本科生能比我更有竞争力。 由此我只能得出一个结论：部门或者团队的任务中，不需要你有多NB的嵌入式、芯片知识，99%用不到！ 招你一个硕士的成本比一个本科生大多了，人家也能完成这项工作。 有点意思，这是我最后没选择加入华为的关键原因吧。 和嫉妒真的无关，如果一个专业能力比我强的人，但是这套规则我确实理解不了。
最终校招虽然没能加入华为，但是我想说，我很感谢这段经历。 虽然对工作内容本身有些无聊，但是同组几乎所有的同事都很好相处，与人友善。 大家毕竟在一起工作了三个多月，说没有感情是不可能的，回想起来挺想他们的：
感谢导师宁宁，对我接手新工作的指导，每次问他问题都能准确、通俗易懂的给予解答。 和宁宁聊天有种轻松愉快的感觉，在未来职业规划上给了我许多很有帮助的建议。 感谢组长PL余黎青，组长给我的感觉就是稳重、温文尔雅。让我印象很深刻的是生病时特地 加微信询问身体状况。 感谢吕东坡、罗鑫、郭绍兴，我们四人组天天一起吃饭，一起出去玩， 一起吐槽开发中遇到的各种问题。说到这，后面你们请我吃了两顿饭， 等我到上海一定安排你们！ 感谢芯片仿真组的其他同事们，徐老师、原湛、文栋&amp;hellip; 在我走之前也有幸参加了两次组内和部门的团建活动，部门的氛围真的很不错。 现在也遗憾如果岗位、工作内容合适就好了，不过天下哪有十全十美的事情呢？ 如果我可以定居上海，选择在华为干一辈子也未尝不可， 但问题在于我是一个注定要回家的游子，在华为短暂的技术成长确实较其他公司差些。 唉，真心希望仿真组的同事们能够越来越好。
秋招 大概从7月份开始，就在陆陆续续投递简历，最初并没有太多的消息。 大约在8、9月份的时候感觉好像到达了人生低谷，最自己产生了极大的怀疑。 没遇到合适的公司、岗位和地点。期间在海投但鲜有回复， 因为是偏硬件的底层软件/嵌入式方向，看到传统软件开发方向上的朋友们大批收获着笔试/面试自己不急是假的。一直到10月中旬签署第一个Offer心情才舒缓一些， 12月份又签下理想汽车标志我秋招过程结束。
整个秋招中，令我感触最深的是**战线太长！！**不同公司开始流程的时间段差别太大，早点的像希奥端、中兴微电子都是在8月份左右就开始面试， 而理想汽车确到10月份才进行笔试，11月才开启面试。 令你不得不重复的花时间准备笔试、面试。说起来这半年好像心思都在秋招上， 像在心中的一块石头没有落地。
秋招中一共收获了：希奥端、中兴微电子、中兴、极氪汽车、理想汽车这五个公司的Offer。
希奥端是最先给我Offer的公司，公司的业务是制造提供Arm服务器Cpu。 应聘的岗位是嵌入式软件工程师（OS方向），最终给出的薪资待遇是2415+1.212。面试的内容比较基础， 因为是初创公司，又是第一年招聘应届生，我心里感觉不是非常靠谱。 犹豫再三，接着A25K被拒接的接口拒绝了他们。 中兴微电子同为Arm服务器Cpu解决方案方向，细节应该是性能优化一类。 地点在南京，但工资非常低（18k），差太多也没A就拒了。 中兴公司是成都的OS部门，是陈阔师哥给推荐的，我们组去年有四位师哥在里面。听他们说做的内容还可以，因为与中兴微电子可以有冲突导致谈薪时间一拖再拖就放弃了。当时已经和极氪的Hr谈好了，预估的参考薪资是25*15，属于SSP级别。我个人不喜欢成都，离家太远本身也不是非常想去。 极氪汽车是我第一个签正式三方的公司，岗位是嵌入式软件开发，做的内容应该是车机OS虚拟化这一块。令我印象深刻的是一面面试官对我的肯定，让我后面重新拾回了信心。当时确实正属于过程中还最焦虑的一段时间，感谢极氪也对不起极氪。极氪给出的薪资是24*14，虽然不是很高但已经在这个岗位上算是SSP了。很遗憾最终没有选择极氪， 理想汽车是最晚发的Offer，也是工资开的最高的一个35*14，地点是上海，工作内容是操作系统虚拟化。可以说各个方面都比较符合我的预期，可以说的比较幸运吧，感谢上天的可怜。 情感 2023年是感情及其平淡的一年，与wqq保持着不温不火的关系。 缘由是去年过年时大吵了一架导致我积攒在心中已久的怨恨爆发， 我觉得她不够成熟，总是去计较一些莫须有的事情，让我很累。</description></item><item><title>Vscode Snippets</title><link>https://wangloo.github.io/posts/tools/vscode/snippets/</link><pubDate>Sat, 06 Jan 2024 12:25:12 +0800</pubDate><guid>https://wangloo.github.io/posts/tools/vscode/snippets/</guid><description>Snippets 的含义是代码片段，帮助我们快速补全一段代码。 今天发现这个功能还挺强大的，尤其是写 Markdown 时，关键字写起来麻烦， 加上 Vscode 补全还乱七八糟（代码块的自动匹配不能关闭）。 先解我燃眉之急，先介绍 Markdown 的 Snippest。
全局搜索中找到 snippets 的配置： 全局配置中选择 Insert 还能看到当前所有支持的 Snippets。
以下是我自己添加了一段与 Hugo notice 主题相关的，变量的运用比较关键。 $1 表示插入后光标所在的位置，$2，＄ 3&amp;hellip;依次是按 Tab 键之后的位置， $0 则表示最终将停在哪，不会继续循环。
{ // Place your snippets for markdown here. Each snippet is defined under a snippet name and has a prefix, body and // description. The prefix is what is used to trigger the snippet and the body will be expanded and inserted.</description></item><item><title>Qemu 启动 Linux Kernel(Arm64)</title><link>https://wangloo.github.io/posts/os/arm64-linux-qemu/</link><pubDate>Thu, 04 Jan 2024 19:28:12 +0800</pubDate><guid>https://wangloo.github.io/posts/os/arm64-linux-qemu/</guid><description>最终效果 用的环境和各个软件版本为：
Qemu: 8.1.50 (qemu-system-aarch64 -M virt) linux-4.9.1 u-boot-2023.10 busybox-1.34.0 经过一番折腾，还是没有成功 Qemu+Uboot 来引导 linux 内核， 因为 virt 板级不支持-sd参数，主要的折腾过程见下。 但理论上也可以，只是后面发现没啥必要，用-kernel也能完成目前需求。 -kernel形式下功能没问题，有 Rootfs，可以在 Guest 中读写。
准备 Linux 内核镜像 下载 Linux 内核版本历史 - 维基百科 上海交通大学镜像站 编译 Linux kernel 使用 make 来构建，可以键入make help查看支持的命令：
Cleaning targets: clean - Remove most generated files but keep the config and enough build support to build external modules mrproper - Remove all generated files + config + various backup files distclean - mrproper + remove editor backup and patch files Configuration targets: config - Update current config utilising a line-oriented program nconfig - Update current config utilising a ncurses menu based program menuconfig - Update current config utilising a menu based program xconfig - Update current config utilising a Qt based front-end gconfig - Update current config utilising a GTK+ based front-end 不同 Linux 内核镜像的区别 vmlinux vmlinux 是可引导的、未压缩、可压缩的内核镜像，vm 代表 Virtual Memory。 （表示 Linux 支持虚拟内存，因此得名 vm）它是由用户对内核源码编译得到， 实质是 elf 格式的文件.</description></item><item><title>人像摄影如何引导模特</title><link>https://wangloo.github.io/posts/thinking/photography/</link><pubDate>Thu, 04 Jan 2024 16:21:27 +0800</pubDate><guid>https://wangloo.github.io/posts/thinking/photography/</guid><description>人像摄影如何引导模特 学习链接： https://www.bilibili.com/video/BV1aU4y1t7P2/?spm_id_from=333.788&amp;amp;vd_source=e819378fded474f59b1110fad57bac1b
个人形象 会让模特到你是有审美的 女生最看重 瘦、高、脸好看、皮肤白
平常心态 没有经验的摄影师+没有经验的模特，大概率是翻车， 所以保持平常心，当出去玩一样，最重要的是开心
态度 重视拍摄，提前去到场地选好机位，想好姿势，不要临场才想， 规划一下路线，不要走太多。 尊重模特，说话客气、不要比较 前期准备 和模特商量 服装、妆容、发型 自己准备 灯光、道具 热身阶段 刚开始拍摄的时期，叫热身，一般半个小时。
不要急，边聊边拍 不看照片 姿势 如果模特自己会摆动作，即使不怎么好看，也先不要纠正，先拍， 慢慢找到一个对的感觉的姿势，找到她一个好看的眼神和表情。 慢慢你找到感觉可以开始慢慢调整了，一次只指导一个点，拍几张 然后肯定一下，再调整一下。 对于新人，可以试试她直面镜头，如果她不是很放松，那就不要 先强迫让她看镜头。 针对不会摆姿势的模特，要提前准备好一些样片，给她看一下。 （针对这点我表示怀疑哈哈哈，觉得不太专业） 每一次调整都要按快门，高速连拍 情绪表情不对的时候，要明确告诉模特方向，描述情绪氛围， 可以选择用一个场景对描述这个表情和情绪 夸赞 夸一个具体的细节（耳环、眼线） 不要提当场改不了的意见。（拍着拍着突然说：这件衣服不行啊， 看破不说破，不要毁了心情） 小技巧 跟刚认识的模特，保持舒适距离，2-3米，所以最好买一个85哈哈 直出尽量就拍好看 尽量用屏幕，让人更放松 先拍最差，再拍最好，热身；回放先看最好的，再看最差的；</description></item><item><title>Hugo 引用图片</title><link>https://wangloo.github.io/posts/hugo/hugo_image/</link><pubDate>Wed, 03 Jan 2024 13:39:42 +0800</pubDate><guid>https://wangloo.github.io/posts/hugo/hugo_image/</guid><description>写博文时避免不了插入一些图片，总结了几种方式。
图床 最早在其他平台写博客时，因为 Markdown 格式编辑，不方便内嵌图片（好像听说支持 Base64 编码， 没试过）， 此时想要维护单个 md 文件，最好的方式就是用网络图片， 本地引用必须同时维护图片和文件在同一个目录，而且一些博客平台上传图片太麻烦。
Markdown 插入图像的语法本就支持网络图片，这里防一张图片作为演示：
以前用的 Gitee（码云）搭建图床，后面码云官方禁止这种行为，考虑过换成其他收费的平台， 例如各家云公司的对象存储 OSS。但是仔细想想如果要迁移平台意味着所有的博客都要改动， 未免太麻烦了。
Hugo 使用 Hugo 搭建静态博客页面之后，其实对于远程链接的引用方式的依赖性就消失了。 反正都是用一个 Hugo 工程管理所有笔记，那么也统一管理所有图片也没太大所谓。 以前觉得本地管理很麻烦，需要传图片之类的，但最近用 Latex 写论文发现也还好。 工程放在 Windows 上，传图片直接另存为改下目录就行了，用虚拟机上确实不太方面。 还好 Hugo 对 Windows 的支持还不错。综上，目前就在尝试使用本地的方法管理图片。
Hugo 引用图片有两种方式：
建立一个 Page bundle，图片作为 Page source。通过![](sunset.jpg) 即可访问，Hugo 官方描述。 属于各自 blog 的图片放到各自的目录下，这样的好处是看起啦比较清晰。 但是麻烦的地方就在于需要引用图片的博文都需要建立一个 Page bundle， 而且我不喜欢 index.md 这种文件名，难以搜索。 content/ └── posts/ └── post-1/ &amp;lt;-- page bundle ├── index.md └── sunset.jpg &amp;lt;-- page resource 所有博文的图片都放到的/static目录下，统一管理。 /static可能不是必须存在，可以手动创建。此时的图片通过 !</description></item><item><title>C++ 特性的底层原理</title><link>https://wangloo.github.io/posts/c/cpp/</link><pubDate>Fri, 22 Dec 2023 18:51:49 +0800</pubDate><guid>https://wangloo.github.io/posts/c/cpp/</guid><description>const 修饰成员函数 C++允许将成员函数添加const修饰符，代表此成员函数不会对成员变量进行修改， 否则会发生编译错误。在下面的示例中，set函数用const修饰就会出错， 而get函数用const修饰就能清楚的告诉别人这个函数不会修改类的成员。
对于一个声明为const的类实例，C++规定它只能调用const修饰的成员函数， 也就是说明这个类的成员是不允许被修改的。
class A { int num; public: void set_num(int x) { num = x; } int get_num(void) const { return num; } }; const A a; a.set_num(10); // Compile error a.get_num(); // Success 说起a为什么不允许调用set函数，我这里尝试从C的角度去进行解释， 毕竟C和C++本是同根生。C++定义的成员函数会有一个隐形的参数叫this指针， this总是指向这个类的示例，所以实际上我理解调用成员函数的时候会将成员地址作为参数也传递给成员函数，毕竟这样才能用this指针嘛。然后就说为什么不能调用set函数呢？ 我猜测对于一般的成员函数，规定接受的隐形参数this的类型是 A*， 而const修饰的成员函数接受的this类型为 const A*， 这样做就能限制用const修饰的类实例在将其自身地址传递给普通成员函数的时候出错， 即const A * 不能传递给参数类型为 A* 的函数哦，导致编译错误。
// 猜测C实现C++类 struct A { int num; void (*set_num)(struct A *a, int x){...} void (*get_num)(const struct A *a) {.</description></item><item><title>一些胡思乱想</title><link>https://wangloo.github.io/posts/thinking/growth/</link><pubDate>Sun, 17 Dec 2023 17:19:44 +0800</pubDate><guid>https://wangloo.github.io/posts/thinking/growth/</guid><description>理想校招入职培训感悟 本周作为一个实习生的身份参加了基本都是正式入职的校招生的培训课程， 这个时间段正式入职的都是留学生，经过和他们一周时间的相处，自己感悟也很深，某些方面来看也是认识到了自己的差距吧。另外最重要的是理想汽车的校招培训方案我觉得真的是非常好，PBC、TBP问题解决法、高七都让我到能学到新的知识，不像是常规培训那种纯理论的洗脑。在此我就简单的回顾下本次培训中我的一些具体的感想。
高七培训的内容中，我感受到老师真的用心思想把我们教会。我记得很清楚的一件事是在设定“个人使命宣言时”，老师通过层层递进的方式来帮助我们找到自己的使命宣言，最开始先让我们选择最想共进晚餐的5人，并写出他们的品质和个性，实际上是在挖掘我们内心中敬仰的品性。接着假设来80岁的生日宴，让我们选择邀请的人并写出他们的祝词，目的也是通过期待他人什么样的评判来找到自己的目标。这个过程我觉得层次递进的非常好，真的能更加流畅的确定出我们的使命宣言是什么。
另外我还想说这次培训的分组，以前很多的课程中都会分组，便于讨论或者交流自己的感想。但其实就拿我自己在国内上课的这几年来说，我几乎没遇到过真正有效的小组交流，大家好像都比较抗拒这件事（包括我自己）。但是在这次的小组中，我感受到了不同。首先老师通过若干活动让我们对彼此都快速熟悉破冰，我也意识到我的组员朋友们都是属于积极、阳光的人，所以在后面这几天的培训中，我自认为我们的关系处的都非常好。甚至在今天分别时我产生了一种强烈的不舍，这种心情我说实话已经至少5年没有过了。这种感觉对我的冲击很大，我不禁开始联想原因是什么，完全只是巧合吗？
思考过后，我觉得原因之一是外出留学经历，接受过国外的教育方式可能会对本性中那些可塑性的方面产生影响。俗话说“读万卷书不如行万里路”，见识过一些不同的生活方式、思维方式，你才有机会去主动积极的选择那些你认为好的，而不是被动的接受唯一的选项。第二就是家庭从小的培养方式上，我说农村出身，从小的条件和他们也是没办法比的，当然从小时候的教育上也没办法相提并论，所以这中习惯的养成，或许从出国前就已经慢慢养成。
最后，拿我自己来说，在以后对下一代的培养上，或许传统教育方法中内向的方式也需要改变了，需要让孩子养成大方的性格，但是必须注意谦虚，不能太炫耀自己。
研三寒假和范老师交流 初一给范老师拜年打电话，相约等年后有机会一起聊聊天。 我个人是觉得和范老师交流总是有比较大的收获， 一个是行业方面，因为同样都比较了解嵌入式方向， 在职业发展、个人技术成长方面总是能给到建设性的建议。 二是生活上，作为地地道道的青岛人、即墨人， 我们从个人情感方面或许可以感同身受，我在生活上的一些想法也能得到肯定或者意见。
其实，一直不知道范老师到底希不希望我去拜访。因为说实话， 以我家庭的实力和个人的现状，和范老师的家庭显然是无法相比的。 因为暂时也没有参加工作，没有多少能拿得出手的礼物送给他。 我唯一能做的就是陪他说说话，缓解中老年人子女不在身边的孤独感吧， 暂时想到的也就是这一点。索性就按照这个想法来， 只带一些水果、点心，表达自己的心意即可。
大年初九，怀着忐忑的心情在下午三点给范老师打去了电话， 询问是否有时间可以拜访。范老师的回复也是高兴和欢迎， 暂且不说是否真心，起码我的心情得到了一些缓解。 或许是客气，无法从电话中的语气上判断是否真心愿意， 但是起码回复积极，加上我表示不吃饭后还是留我在吃饭， 这些我觉得足以证明是希望我去的。就这样认为吧， 如果以后不是这样了，可能就说明我不必再去了。
带的礼物是一箱苹果和崂山绿茶，原本是苹果+饼干， 后来由于临时去朋友家，不得已将饼干送了出去。 经过后面的观察，带礼物方面有以下几点需要注意的：
范老师有糖尿病，苹果含糖量不少，后期可以换成猕猴桃、橙子， 这是家里桌子上摆的。 范老师喝红茶会上火，碰巧这次是绿茶，还好一些， 但是据我观察范老师喝的茶叶比较高档（白茶+熟普洱）。 一般的茶叶还是不要再带了。 饼干其实挺好的，因为看到家里也准备了不少点心、甘果之类的， 说明平常也会吃。 因为已经约好了吃中饭，我就不必那么早去，在10：30前开车到达单元楼下。 下午4:30左右才离开，后面看来呆的时间有点长，早些离开比较好。 但是我观察范老师谈话的情绪还比较高，所以也没有主动提出。 想等到范老师什么时候说的不那么兴致勃勃了再离开， 可能这一点也印证了上面说的，总的来说老师还是希望我过去拜访的。
这回交流主要总结了两点：
关于家族成长。自己出身寒门，上天眷顾+父母疼爱得以求学二十载， 有句话说的好族旺留原籍，家贫走他乡。自己手中的牌不能支持我在家里谋得一份顺心的差事， 也不想放弃自己学了六七年的技术。索性只能外走他乡， 向上保证自己以后的结婚生子无需父母操心物质上，向下为孩子提供良好的物质条件和精神教育。 此乃吾辈之大任，不求靠自己寒窗苦读十年超越别人三代努力。 步子是一步步走的，要有目标，但也不能好高骛远。 我们俩都是即墨农村人，对家族的感情很浓重。我每次回到家里看到一大家子人， 心里是格外的亲切和欣慰，打心里希望家族兴旺。之前不管， 从我这里开始就要做好规划，争取给小辈提供一些人生路上的建议。 老师后面又给我发了个视频讲解，关于家族成长的整体规划，我觉得非常有帮助： https://www.douyin.com/video/7334992899735637298。 关于事业规划。基础的技术是很多的，要多了解行业内的知识。 拿这段时间来说，我一开始想的是多补充基础知识，比如研究QEMU的源码等等。 老师给我的建议是先去公司实习，做一些边缘的项目。 为的是在不耽误毕业进度的前提下了解行业内的基础知识， 尽快的入门。不要去做核心业务，会挫败你的积极性，也可能耽误毕业的主任务。 最大的福报 人一生中最大的福报是什么？有人说他当上科长处长，他赚到钱了等等。 我不这么认为，一个人一辈子最大的福报是接受了一套积极向上正确的认知。 活得阳光、活得正派、活得上进、活得积极、活得快乐。
要相信积极向上 徐涛抖音
徐涛：多年轻朋友开始不相信了，不相信风雨之后能见彩虹， 不相信只要努力量变能够达到质变，不相信只要踏踏实实本本分分， 未来就能更好。</description></item><item><title>杂乱的开发日记</title><link>https://wangloo.github.io/posts/thinking/dev_note/</link><pubDate>Sun, 17 Dec 2023 17:19:44 +0800</pubDate><guid>https://wangloo.github.io/posts/thinking/dev_note/</guid><description>零零碎碎的开发笔记，如果思考比较多应该写成单独的博文。
6.828 还能这么拷贝代码 将一段汇编代码从一个地址拷贝到另一个地址，你会怎么做？
我能想到的是利用链接脚本，将该段代码限定在某个段里，然后利用变量来定位代码所在的地址，执行拷贝。
init.c的boot_aps()提供了一种新的思路：在代码的前后定义一个全局变量，就能在外面访问到代码的地址和范围了。
转换函数的一种写法 我们经常会用到两种指代之间的转换，比如用id找到结构体指针（JOS中的envid2env），你会怎么设置函数的参数和返回值？
我以前只能想到：
struct Env *envid2env(envid_t envid) 正常情况下返回转换完成的结构体指针，否则返回NULL。
然而，JOS提供了一种别样的实现方式：
int envid2env(envid_t envid, struct Env **env_store, bool checkperm) { struct Env *e; // If envid is zero, return the current environment. if (envid == 0) { *env_store = curenv; return 0; } e = &amp;amp;envs[ENVX(envid)]; if (e-&amp;gt;env_status == ENV_FREE || e-&amp;gt;env_id != envid) { *env_store = 0; return -E_BAD_ENV; } if (checkperm &amp;amp;&amp;amp; e !</description></item><item><title>Vscode task.json &amp; launch.json</title><link>https://wangloo.github.io/posts/tools/vscode/task_launch/</link><pubDate>Sun, 17 Dec 2023 15:25:12 +0800</pubDate><guid>https://wangloo.github.io/posts/tools/vscode/task_launch/</guid><description>Task.json Vscode中，可以为编译、打包等过程创建自动化任务，避免每次手动敲一些命令。 在我看来，Vscode Task就像是一个强大的、与Vscode联动的Shell脚本。
创建一个Task 创建一个Task很简答，Terminal-Configure Tasks， 然后根据引导就可以创建一个默认的task，对他进行配置的文件是workspace/.vscode/task.json。
展示一下我刚刚创建的一个编译并执行单元测试的任务，关键的参数是label也就是任务的名字， type除了shell不知道还有啥，command就是该任务会执行的shell命令。 更多的参数下面会介绍。
{ // See https://go.microsoft.com/fwlink/?LinkId=733558 // for the documentation about the tasks.json format &amp;#34;version&amp;#34;: &amp;#34;2.0.0&amp;#34;, &amp;#34;tasks&amp;#34;: [ { &amp;#34;label&amp;#34;: &amp;#34;build-ut&amp;#34;, &amp;#34;type&amp;#34;: &amp;#34;shell&amp;#34;, &amp;#34;command&amp;#34;: &amp;#34;bash tools/vscode_build_ut.sh&amp;#34;, &amp;#34;presentation&amp;#34;: { &amp;#34;echo&amp;#34;: true, &amp;#34;reveal&amp;#34;: &amp;#34;always&amp;#34;, &amp;#34;focus&amp;#34;: true, &amp;#34;panel&amp;#34;: &amp;#34;shared&amp;#34;, &amp;#34;showReuseMessage&amp;#34;: true, &amp;#34;clear&amp;#34;: false }, &amp;#34;problemMatcher&amp;#34;: [], } ] } 支持的参数 支持的参数很多，我主要介绍几个，Vscode的官方文档说的非常通俗易懂，修改参数时最好参考一下。
label: 此任务的名字 type：类型 shell：作为shell命令执行 process：创建一个新进程执行 command：任务实际执行的命令 group：任务的分组 presentation：定义如何处理Task的输出 reveal：终端是否显示 echo：任务输出是否到终端中 focus：任务执行时是否聚焦到终端 showReuseMessage：是否显示最后的提示信息 clear：任务运行前是否清理终端输出 options：定义当前目录和一些环境变量 runOptions：定义任务何时运行以及如何运行 problemMatcher: 自定义错误匹配机制，这个应该很强大，我这里单纯是为了运行时不需要再选一次所以用了一个默认值。具体怎么用可以参考: https://code.</description></item><item><title>Dwarf: Stack Unwinding</title><link>https://wangloo.github.io/posts/binary/dwarf/frame/</link><pubDate>Sat, 16 Dec 2023 15:51:49 +0800</pubDate><guid>https://wangloo.github.io/posts/binary/dwarf/frame/</guid><description>前言 栈回溯是调试代码常用的功能之一，Gdb 中对应的命令是bt,info frame等。 这篇文件将介绍利用 Dwarf 生成的调试信息实现栈回溯的方法。
原理 Dwarf v2 开始提供一种叫做 Call Frame Information（简称 CFI）的信息， 它存储在.debug_frame中，调试器可以通过解析这个 Section 完成栈回溯。 .debug_frame里的内容可以看做是一张二维表格，一列是 pc， 另一列是对于此 Pc 如何查找上一个 Frame。
Demo 例如，对于以下的 C 代码和对应的汇编（通过object -S生成)， 汇编代码有一点长，但没关系我们不需要关注每一条汇编指令。 这段代码共有两个函数，main()和fibonacci()， 由 main 函数调用 fibonacci 来计算第 10 个 bibonacci 数。 目前暂时不需要看汇编。
选择 fibonacci()作为例子的原因是模拟一个非叶子函数， 因为 Arm64 下对叶子函数可能不会生成正确的 CFI 信息， 因为这种情况不常见，所以我们先讨论普通的情况。 另外，我知道这个计算 fibonacci 数的算法不是最优的， 但是我们毕竟不是算法优化的主题，所以能够说明问题即可。
int fiboncci(int n) { if (n &amp;lt;= 2) return 1; else return fiboncci(n-1) + fiboncci(n-2); } int main(void) { int result; result = fiboncci(10); return 0; } int fiboncci(int n) { 400594: a9bd7bfd stp x29, x30, [sp, #-48]!</description></item><item><title>GNU 二进制工具集</title><link>https://wangloo.github.io/posts/binary/gnu_binutils/</link><pubDate>Thu, 14 Dec 2023 13:21:27 +0800</pubDate><guid>https://wangloo.github.io/posts/binary/gnu_binutils/</guid><description># 输出 section header table readelf -S xxx.elf # 输出 program header table readelf -l xxx.elf # 输出 ELF header readelf -h xxx.elf # 输出 elf header，section header table，program header table(常用） readelf -e xxx.elf # 输出Elf中的所有符号(基于符号表非调试信息) nm xxx.elf readelf -s xxx.elf # detailed # 打印某个section的内容 readelf -p .strtab xxx.elf # 判断编译时有没有使用-g readelf -n bin # 输出源码和汇编 objdump -DS your_binary # 仅输出汇编, 所有汇编, 不仅仅是代码相关 objdump -D your_binary</description></item><item><title>C/C++ 符号管理的区别</title><link>https://wangloo.github.io/posts/c/linker_symbol/</link><pubDate>Thu, 14 Dec 2023 12:21:27 +0800</pubDate><guid>https://wangloo.github.io/posts/c/linker_symbol/</guid><description>背景 今天在写 C 代码时，遇到一个问题，我忘记 include 头文件而调用某个函数， 一般情况下在编译时会报警告 ⚠，然后也会链接成功，所以我这次就没管它因为只是暂时测试一下。 然而令我费解的是函数的执行结果异常，检查汇编后发现，我声明的函数返回 u64 类型， 而编译后的代码在返回前裁切成了 32 位，就是这里导致的错误！
这与我之前的理解不同，我以为要么就链接找不到符号，要不就成功链接， 为什么会有这种返回类型识别错误呢？
思考 我忽然想起，会不会是因为编译器将返回值识别为了默认的 int 类型， 进而，我的猜想是：
链接时能用符号名找到符号的地址，所以能成功调用 但因为没有参数和返回类型的说明（没有 include），所以导致类型出错 简单验证之后，确实我的猜想是正确的，我调用时多传入一个参数， 还是能够成功编译，汇编只是把参数寄存器赋值，内部用不用得到无法判定。 返回类型则统一认定为默认的int类型。
由此，我又产生了一个想法，既然C语言只使用符号名作为匹配的标准， 那么必然不支持同名函数（参数、返回类型不同）。然而C++明确是支持的， 那么C与C++的符号管理有什么不同吗？
进一步验证 我写了内容相同的C和C++两个文件来尝试解答问题：
// Same code in demo.c/demo.cpp void func(int a, int b) { func(b, a); } 对他们进行编译，查看大小仅相差8字节，猜测是符号的管理有所不同。
$ ls -al total 8 drwxr-xr-x 1 loo loo 512 Dec 14 14:09 . drwxr-xr-x 1 loo loo 512 Dec 14 12:03 .</description></item><item><title>Thinking: Config Linux Network</title><link>https://wangloo.github.io/posts/thinking/cfg_linux_ip/</link><pubDate>Fri, 08 Dec 2023 17:19:44 +0800</pubDate><guid>https://wangloo.github.io/posts/thinking/cfg_linux_ip/</guid><description>起因：今天与一位同学一起尝试去配置Linux静态IP，这中间有不少坎坷，想简单把思考的过程写下来， 复盘一下是不是应该有可以更快的定位到问题并解决的方案。
提出问题 Cl同学想要达到启动Linux后自动设置某个静态Ip的效果， 在我的理解里这并不是一件很复杂的事。
他给我的想法是在Kernel Command Line参数中指定Ip， 我之前没有看到过这种方式配网，但是网上搜了一下确实有这样的例子。 所以他目前已经完成的是:
Linux是通过Uboot起的，要增加Linux Command Line， 可能是在Uboot的bootargs中添加。 但是他在修改完bootargs并重启的时候，发现变量没有成功赋值， 即使已经成功saveenv。所以就邀请我和他一起讨论。
动手实践 了解到问题之后，我先说出了我的想法：
配置静态Ip这个事其实我第一时间想到的是以前修改/etc/network/interfaces文件的方式 但是我愿意陪他先看下为什么命令行参数没有配置上去 这是两条路，因为他的系统里没有真正的文件系统，而是initrd， 所以我提出的方案需要去解包inird的压缩文件，还是尽量先去研究为什么命令行参数没有配置上去。
为什么CMDLINE没有配置上去呢? 首先它说bootargs没有保存成功，这个我也不知道为啥， 可以先不管，即便在每次启动之前在Uboot里设置了Bootargs， 他说在启动之后Kernel的打印也没有输出配置的项目。
Uboot中Bootargs设置的值是和Kernel Command Line配套吗？ 这个我反正是不太确定。
好，那能不能通过别的方式来设置CmdLine呢？ 我们搜索找到了两种方式：
Dts中 Menuconfig中修改 没有尝试Menuconfig是因为他说“目前Menuconfig配置的CmdLine为空， 但是实际Kernel启动后又是有值输出的，那么说明肯定是其他的地方有添加。” 对于这句话我也表示认同，Menuconfig里给的说明是：“默认配置”， 所以即便添加了也无法保证会不会被其他的给冲刷掉。所以，一个根本问题就是： CmdLine配置的顺序，或者说优先级是什么？
先去Dts里改改试试吧，找到了一个chosen结点有关于bootargs的配置， 不管怎么样改了一下，发现并没有生效，和最终Kernel输出的对不上。
所以，看起来修改CmdLine这条路要失败了，只能去修改initrd试试。
修改Initrd达到目的 initrd是打包好的，用的是cpio+lz4的方式。要修改首先要把他解开， 解开到还好说，网上能搜得到命令。 但是重新压缩回去问题很多，前期我就想到了我在华为实习时期遇到的类似的问题， 压缩的算法不对、打包的版本差异都会导致Kernel无法解析重新打包的initrd而panic。
实际也遇到了这个问题，但是这有个小插曲：即便是换回原来的initrd也还是panic。 最终破案是因为需要make clean之后重新make，猜测可能是用了什么中间文件。 不得不感慨Linux Kernel的构建还是相当复杂的。
问题来了：修改/etc/network/interfaces并没有改变静态Ip， 这就使我产生了疑惑，想着可以先在系统启动之后修改试试嘛， 执行ip down和ipup发现确实没有成功修改，这不禁让我想问为什么？
此时，我们突然想到一个问题，既然shell命令能成功修改Ip， 那么就在启动时增加一个脚本去执行设置Ip的行动，不就行了吗？
确实是可以的，所以暂时先不管为什么interfaces不生效。 那就修改有关于/etc/init.d和/etc/inittab相关的知识了， 这一部分我就没参与了，网上的资料的非常全，最终是成功达到目的。
感慨 虽然成功达到了目的，但是消耗了4个小时左右的时间，我觉得这件事并不应该这么复杂。 主要原因是Linux可以配置网络的方式太多了，以至于像我们这种不是非常熟悉的人一时间不知道如何下手。</description></item><item><title>Good Design: 抽象消息参数</title><link>https://wangloo.github.io/posts/c/good_design_proto/</link><pubDate>Sun, 26 Nov 2023 16:21:27 +0800</pubDate><guid>https://wangloo.github.io/posts/c/good_design_proto/</guid><description>在设计一个消息传递类似的子系统时，消息经常需要各种参数， 通常消息的个数和类型是根据消息自身的类型决定的。
void handle_open(..., int flags, int mode); void handle_read(..., size_t len, int offset); // ... 有的消息/命令参数比较多，不想写这么长的参数那就把这些参数封装到struct里
struct arg_open { int flag; int mode; }; struct arg_read { size_t len; int offset; }; // 这里用结构体还是结构体指针都可以，不是重点! void handle_open(..., struct arg_open *arg); void handle_read(..., struct arg_read *arg); 这种方法有什么缺点呢?
不具有通用性；无法用函数指针来实现进一步抽象，即跳表。 &amp;hellip;（暂时没想到） 所以说，一个更好的抽象方式来了，将所有的参数利用union放到一个结构体中。
struct proto_open { int flag; int mode; }; struct proto_read { size_t len; int offset; }; // GOOD DESIGN struct proto { // .</description></item><item><title>Byte/Bit Order</title><link>https://wangloo.github.io/posts/c/byte_bit_order/</link><pubDate>Sat, 25 Nov 2023 16:21:27 +0800</pubDate><guid>https://wangloo.github.io/posts/c/byte_bit_order/</guid><description>字节序与比特序 字节序又称大小段，网络中传输的是大端，在CPU上处理的一般是小端。
字节序与比特序转换 字节序转换 比特序转换 两种方法，一种直接法，另外有一种优化的技巧。
（1）
// Bit reverse unsigned char bit_reverse(unsigned char x) { unsigned char newx = 0; for (int i = 0; i &amp;lt; 8; i++) { newx |= (((x &amp;gt;&amp;gt; i) &amp;amp; 1) &amp;lt;&amp;lt; (7-i)); } return newx; } (2) https://mp.weixin.qq.com/s/KNUH_RmIhUHhuSZLSmN4LQ
// Bit reverse(faster) // 碟式交换法 unsigned char bit_reverse_faster(unsigned char x) { x = (x&amp;lt;&amp;lt;4) | (x&amp;gt;&amp;gt;4); // [ 5678 1234 ] x = ((x&amp;lt;&amp;lt;2)&amp;amp;0xcc) | ((x&amp;gt;&amp;gt;2)&amp;amp;0x33); // [ 78 56 34 12 ] x = ((x&amp;lt;&amp;lt;1)&amp;amp;0xaa) | ((x&amp;gt;&amp;gt;1)&amp;amp;0x55); // [ 8 7 6 5 4 3 2 1 ] return x; } 测试工具函数:</description></item><item><title>Elf 加载器的工作流程</title><link>https://wangloo.github.io/posts/binary/elf_load/</link><pubDate>Fri, 24 Nov 2023 16:21:27 +0800</pubDate><guid>https://wangloo.github.io/posts/binary/elf_load/</guid><description>分析Elf文件 映射 Segments 对栈进行预处理 int main(int argc, char **argv, char **envp) {...} 见到一个main函数的定义，你是否考虑过:
main函数使用这些参数的作用分别是什么? Elf运行前，他们是如何被正确放置的? 我们又如何正确的访问? 内核中的Elf加载器还需要将辅助向量和其他信息(argc,argv,envp)一起放在栈上。 初始化后，进程的堆栈如下所示(64位架构下):
position content size (bytes) + comment ------------------------------------------------------------------------ [ free used for process ] stack pointer -&amp;gt; [ argc = number of args ] 8 [ argv[0] (pointer) ] 8 (program name) [ argv[1] (pointer) ] 8 [ argv[..] (pointer) ] 8 * x [ argv[n - 1] (pointer) ] 8 [ argv[n] (pointer) ] 8 (= NULL) [ envp[0] (pointer) ] 8 [ envp[1] (pointer) ] 8 [ envp[.</description></item><item><title>Vim-YouCompleteMe插件国内安装</title><link>https://wangloo.github.io/posts/tools/vim/ycm/</link><pubDate>Fri, 17 Nov 2023 19:28:12 +0800</pubDate><guid>https://wangloo.github.io/posts/tools/vim/ycm/</guid><description>Vim插件YouCompleteMe国内安装 Update 2023/11/23: vim下现在我不用YCM了，换成Coc.nvim来进行代码补全。 不过在我看来其实没有特别明显的优势，所以YCM的配置注意事项还是留在这吧。
YCM 插件对 python, vim 的版本均有要求。
下载 可以使用 vim-plug 等工具下载, 也可以下载源码然后拷贝到.vim目录下
编译 编译用到 python3, 这里是问题最多的一步
# 编译并添加对C的提示支持 python3 install.py --clangd-completer --verbose Searching Python 3.8 libraries... ... Downloading Clangd from https://github.com/ycm-core/llvm/releases/download/13.0.0/clangd-13.0.0-x86_64-unknown-linux-gnu.tar.bz2... 使用--clangd-completer参数时, 脚本会去下载 clangd-14.0.0-x86_64-unknown-linux-gnu.tar.bz2 文件, 比较慢. 也可以提前根据提示的网站自己手动下载压缩包.
下载完成后, 放到本地目录下:
:~/.vim/plugged/YouCompleteMe/third_party/ycmd/third_party/clangd/cache$ ls clangd-14.0.0-x86_64-unknown-linux-gnu.tar.bz2 还需对脚本YouCompleteMe/third_party/ycmd/build.py进行修改, 防止重新下载.
def DownloadClangd( printer ): ... MakeCleanDirectory( CLANGD_OUTPUT_DIR ) if not p.exists( CLANGD_CACHE_DIR ): os.makedirs( CLANGD_CACHE_DIR ) # 注释下面的语句 # elif p.exists( file_name ) and not CheckFileIntegrity( file_name, check_sum ): # printer( &amp;#39;Cached Clangd archive does not match checksum.</description></item><item><title>Linux mmap 函数</title><link>https://wangloo.github.io/posts/os/linux/addrspace/mmap/</link><pubDate>Fri, 06 Oct 2023 14:51:49 +0800</pubDate><guid>https://wangloo.github.io/posts/os/linux/addrspace/mmap/</guid><description>在进程的地址空间中，栈和堆直接夹着的区域为文件映射区。 它的空间是动态的，和堆空间一起实现动态内存的分配与释放。
文件映射区中包含了一段段的虚拟内存区域（也称线性区），代码里标识符是struct vm_area_struct。其中包含文件映射和匿名映射。
匿名映射是malloc()的底层实现之一，当请求大块内存时，移动brk可能带来大碎片， 不如用匿名mmap()来的灵活。
下图就展示了一个进程地址空间中即存在文件映射，又存在匿名映射的情况：
Linux 地址空间线性区组织形式 不只是文件映射区包含线性区，所有其他的区域（代码段、数据段等）都可以用线性区来描述， 统一进行维护。代码里用struct vm_area_struct描述一个线性区，其中重要的成员有:
vm_mm(struct mm_struct *): 指向所属的地址空间描述符 vm_start(unsigned long): 此线性区的开始 vm_end(unsigned long): 下一个线性区的开始(此线性区结束地址+1） vm_next(struct vm_area_struct *): 指向进程线性区的 next vm_rb(struct rb_node): 此线性区对应红黑树中的节点 此线性区的大小就可以表示为: vm_end - vm_start.
双向链表和红黑树 进程虚拟内存空间中的所有 VMA 在内核中有两种组织形式：一种是双向链表，用于高效的遍历进程 VMA，这个 VMA 双向链表是有顺序的，所有 VMA 节点在双向链表中的排列顺序是按照虚拟内存低地址到高地址进行的。 第一个区在mm_struct-&amp;gt;mmap, 下一次通过vm_area_struct-&amp;gt;vm_next找到，依次类推。并且，mmstruct-&amp;gt;map_count成员记录了进程所有线性区的数量。
另一种则是用红黑树进行组织，用于在进程空间中高效的查找 VMA， 正常来说，想要查找某个地址是否存在于进程的地址空间，遍历上述链表的效率是 O(n)。
通常一个进程地址空间的文件映射区会有非常多的线性区。因此，Linux2.6 引入红黑树来优化查找速度， 所有线性区同时组织成一个红黑树， 首部通过mm_struct.mm_rb指向。 然后每个线性区的vm_area_struct.vm_rb 存储节点的颜色和双亲信息。
现在，当需要插入/删除一个线性区描述符时，用红黑树查找前后元素，再操作链表进行插入。
mmap()的使用方式 mmap()用于在文件映射区创建一个真实的文件映射或者匿名映射。
void* mmap(void* addr, size_t length, int prot, int flags, int fd, off_t offset); 参数prot 通过 mmap 系统调用中的参数 prot 来指定其在进程虚拟内存空间中映射出的这段虚拟内存区域 VMA 的访问权限，它的取值有如下四种, 组合使用：</description></item><item><title>Linux Buddy 内存分配器</title><link>https://wangloo.github.io/posts/os/linux/mem/buddy/</link><pubDate>Mon, 18 Sep 2023 17:51:49 +0800</pubDate><guid>https://wangloo.github.io/posts/os/linux/mem/buddy/</guid><description>伙伴系统的优势 作为一个页分配器，伙伴系统主要解决外部碎片过多的问题， 保证系统中尽可能有大的连续空间可以使用。
这也正是伙伴系统要设计成相邻内存块合并的原因。</description></item><item><title>ARMv8 内存模型</title><link>https://wangloo.github.io/posts/armv8/memory_model_and_barrier/</link><pubDate>Sun, 10 Sep 2023 18:02:04 +0800</pubDate><guid>https://wangloo.github.io/posts/armv8/memory_model_and_barrier/</guid><description>为什么要关心内存模型 内存模型是一个约定或者规则, 是体系结构决定的，定义了内存的某些属性和行为。 一般各个架构之间有所不同，比如 ARM 会做合并访存、乱序执行这类优化方法。
所以，某些情况下，指令的执行顺序可能不与你程序设计的一模一样，只是为你呈现的结果相同罢了。 当然这里边还有编译器来优化（捣乱 hh）。
一般程序无需关心内存模型带来的差异，除非你从事底层软件开发（嵌入式开发）这种需要和寄存器打交道， 涉及系统底层机制的实现时，你必须按照内存模型来合理的规划你的程序。
各种内存模型 不同的处理器架构有不同的内存模型.
例如, ARM 架构可能优化内存读写指令的顺序, 但是 X86/64 架构通常不会这样做. X86 架构的每次内存加载指令都带有 acquire 语义, 每次写内存都带有 release 语义. ARM 架构就不一定, 拿 ARMv8 来说, 仅有LDRA/STRL指令带有此含义. 我们称类似 ARM 架构行为的内存模型为 Relaxed Memory Model
将 X86/64 上稳定运行的 Lock-free 的代码搬到 ARM 上, 就不一定是可行的.
顺序一致性模型 Sequential Consistency Model 指令的执行顺序总是和可执行文件一致.不论是否存在内存访问指令重排等优化操作.
举个例子,
先写后读内存的模型中, 总是能实现读内存时值是新的(不会被优化成先读后写). 多条ldr指令的执行顺序也是严格按照程序所写 多处理器环境下, 每个核的执行顺序都是可执行文件中的指令顺序. 多核之间的同步需要程序员来保证.
宽松一致性模型 Relaxed Consistency Model 各种优化 buff 叠满，一般加载/存储指令的执行顺序不能保证，需要程序员自行维护。</description></item><item><title>Linux 进程间通信概述</title><link>https://wangloo.github.io/posts/os/linux/ipc/linux-ipc/</link><pubDate>Fri, 08 Sep 2023 16:21:27 +0800</pubDate><guid>https://wangloo.github.io/posts/os/linux/ipc/linux-ipc/</guid><description>SystemV IPC Linux 引入了 SystemV 中 IPC 的集中实现方式，包括：信号量、共享内存、消息队列。
共享内存 共享内存基于文件实现，用操作文件的方式来操作共享内存区。
原理是对一块物理内存做多个映射，用引用计数来维护，只有引用计数为0时，才能释放。
共享内存的特点是：
速度快，但自身没有同步功能，需要配合外部的同步机制。 信号量 为什么说信号量也是一种通信机制?
其实通信并不一定就是要发送数据，只要能够相互感知，通知到对方，就算是一种通信。 类比抛媚眼也算是通信的一种。
消息队列 并非基于文件，由自己的一套API，使用起来不方便。 消息队列是面向消息的（并非字节流），消息由类型。 消息队列有自己的同步机制，无需外部添加。 信号 常用于父子之间通信，只要你知道了对方的PID，就可以给对方发信号。
用kill(pid, signal)来发送信号。</description></item><item><title>QEMU 工作原理</title><link>https://wangloo.github.io/posts/qemu/1/</link><pubDate>Fri, 08 Sep 2023 16:21:27 +0800</pubDate><guid>https://wangloo.github.io/posts/qemu/1/</guid><description>Qemu 的工作方式 Qemu有两种工作方式：全系统模拟（Full-system emulation）和用户模拟（User-mode emulation）。
用户模拟仅仅对目标格式的Elf文件进行指令翻译并执行， 在遇到需要使用系统资源的命令（通过系统调用）时， 就转换成实际host的系统调用来完成，将执行完的结果返回。 Elf就是一个用户态的应用，不能直接操作硬件。 总之，用户模式下Qemu仅仅实现了讲Guest指令翻译为Host指令并执行， 不模拟资源。
全系统模拟的方式下，Qemu在用户态模拟了完整的一套Guest硬件资源， 包括Cpu、内存、外设等，此时Qemu更像是一个虚拟机管理器。 Guest Elf可以直接对硬件进行操作。
指令翻译 在 host 上运行 guest 架构代码的能力由 QEMU TCG 模块提供。
TCG 做指令翻译的思路是 “边翻译边执行”， 并且将翻译工作分为前后端，中间会有一层中间指令， 这样能够方便添加对新指令的支持。这个有点类似于现代编译器，也是由类似间结果的流程，称为 IR。
TCG 执行一次翻译的单位是 Translation Block，以分支跳转、页边界为划分条件。
Qemu 全系统模拟启动内核 &amp;ndash;kernel选项后面接一个Elf格式的系统镜像，Qemu内部用seaBios来实现引导Elf， 所以我们可以不关心如何引导Elf的问题。</description></item><item><title>操作系统：相关名词汇总</title><link>https://wangloo.github.io/posts/os/abbreviation/</link><pubDate>Fri, 08 Sep 2023 16:21:27 +0800</pubDate><guid>https://wangloo.github.io/posts/os/abbreviation/</guid><description> 名词 含义解释 Unix 起源于BELL实验室的一个操作系统家族, 指代一类OS。
这些OS共同遵守Unix特性，但各个分支在实现上有所不同。
包括SystemV、BSD等分支 SystemV 是Unix的特殊版本，由AT&amp;amp;T公司开发 GNU 目标是开发一个完全自由、开源的OS，借鉴Unix Linux OS内核，借鉴了Linux。后与GNU工具集结合，称为GNU/Linux</description></item><item><title>Cortex-A53 PMU介绍</title><link>https://wangloo.github.io/posts/armv8/pmu/</link><pubDate>Sat, 02 Sep 2023 22:02:04 +0800</pubDate><guid>https://wangloo.github.io/posts/armv8/pmu/</guid><description>关于PMU PMU是一个独立的单元，不和体系结构绑定。而是每个SOC都可以不同。比如说Cortex-A53实现了PMUv3架构，但别的基于ARMv8架构的Soc可能实现PMUv4或者其他版本。
PMU内部有六个计数器，所以可以记录六个事件的发生次数。计数器的数值不一定绝对的正确，因为管道的存在，所以一般来说还是通过长时间计数来减弱影响。
PMU和ETM的区别 1. 记录的事件不同 PMU：Cache Miss、分支预测失败、TLB Miss等 ETM：记录分支指令、内存屏障指令等所有指令的执行，包括地址、结果等。 另外还可以记录数据读写的地址、结果（可选）。 2. 记录的粒度不同 PMU：仅用计数器来记录事件发生的次数 ETM：指令的类型、地址、执行结果等。数据访问也类似。 所以说，ETM的信息量大，需要专门的缓存机制。而PMU只需在定时器结束时记录发生的次数就行， 不需要什么缓存，没有实际的数据流。</description></item><item><title>Hugo 主题创建(7): footer</title><link>https://wangloo.github.io/posts/hugo/new_theme_7/</link><pubDate>Sat, 02 Sep 2023 18:39:42 +0800</pubDate><guid>https://wangloo.github.io/posts/hugo/new_theme_7/</guid><description>footer属于 partial模板之一, 创建一个新文件footer.html, 然后在baseof模板中, 指定footer内容显示的位置.
&amp;lt;body&amp;gt; &amp;lt;div id=&amp;#34;app&amp;#34;&amp;gt; {{- partial &amp;#34;sidebar.html&amp;#34; . -}} &amp;lt;main class=&amp;#34;container&amp;#34;&amp;gt; {{- block &amp;#34;main&amp;#34; . }} {{- end }} {{- partial &amp;#34;footer.html&amp;#34; . -}} &amp;lt;/main&amp;gt; {{- partial &amp;#34;script.html&amp;#34; . -}} &amp;lt;/div&amp;gt; &amp;lt;/body&amp;gt; 下面将按照功能划分, 添加各种内容到footer模板中.
文件创建和lastmode时间 commit: https://github.com/wangloo/hugo-theme-puer/commit/d263d9af65808ff03b2307abfb4db397ae1bcc2a
文件创建时间是获取的footer中的变量, lastmod其实也可以通过这种方式获取, 但是这样每次修改都要手动更新太复杂, 我们可以借助git追踪的文件的修改时间来作为lastmod, 默认不是这样的, 需要在config.toml中指定.
[frontmatter] lastmod = [&amp;#39;lastmod&amp;#39;, &amp;#39;:git&amp;#39;, &amp;#39;:fileModTime&amp;#39;, &amp;#39;date&amp;#39;, &amp;#39;publishDate&amp;#39;] 然后就是在footer.html中引用这两个变量即可:
&amp;lt;HR width=&amp;#34;100%&amp;#34; id=&amp;#34;EOF&amp;#34;&amp;gt; {{- if not .Lastmod.IsZero -}} &amp;lt;p style=&amp;#34;color:#777;&amp;#34;&amp;gt;创建于: {{ .Date.Format &amp;#34;2006-01-02T15:04:05&amp;#34;}}, Lastmod: {{ .</description></item><item><title>一道题搞定二分法的细节</title><link>https://wangloo.github.io/posts/algorithm/bsearch/</link><pubDate>Sun, 20 Aug 2023 20:30:35 +0800</pubDate><guid>https://wangloo.github.io/posts/algorithm/bsearch/</guid><description>实际上我做过的二分搜索的题目并不少，但是一直以来没有静下心去研究它的 【循环条件】【边界调整】【返回值】的细节，通过这个题目希望自己能完整、 清晰的了解二分搜索。
题目 https://leetcode.cn/problems/find-first-and-last-position-of-element-in-sorted-array
给你一个按照非递减顺序排列的整数数组 nums，和一个目标值 target。请你找出给定目标值在数组中的开始位置和结束位置。
如果数组中不存在目标值 target，返回 [-1, -1]。
你必须设计并实现时间复杂度为 O(log n) 的算法解决此问题。
示例 1：
输入：nums = [5,7,7,8,8,10], target = 8 输出：[3,4]
解答(python): def searchRange(self, nums: List[int], target: int) -&amp;gt; List[int]: if nums == []: return [-1, -1] # 第一次二分，确定右边界 left, right = 0, len(nums)-1 while left &amp;lt;= right: mid = (left + right) // 2 if nums[mid] &amp;lt;= target: left = mid+1 else: right = mid-1 end = right # 第二次二分，确定左边界 left, right = 0, len(nums)-1 while left &amp;lt;= right: mid = (left + right) // 2 if nums[mid] &amp;lt; target: left = mid+1 else: right = mid-1 sta = left print(sta, end) if end &amp;lt; 0 or sta &amp;gt; len(nums)-1 or nums[sta] !</description></item><item><title>Hugo 主题创建(6): shortcode</title><link>https://wangloo.github.io/posts/hugo/new_theme_6/</link><pubDate>Sun, 20 Aug 2023 18:39:42 +0800</pubDate><guid>https://wangloo.github.io/posts/hugo/new_theme_6/</guid><description>shortcode 可以当成是一些对 html 代码块封装的函数，在写 markdown 的时候就会方便一些， 举个例子来说，我有时需要往 post 中插入图片，并调整它的大小，这时候每次都手动写一些 html 简直是太麻烦了，使用 shortcode 就像是调用函数一样，告诉它函数名和必要的参数， 它会在生成网页时自动转换为对应的 html 语法。
shortcode 分为两种：Hugo 默认和自定义的。Hugo 默认支持的 shortcode 有这些 https://gohugo.io/content-management/shortcodes/ ，这里面同时包含了告诉我们如果使用 shortcode 的基本语法。
figure 插入图片 ref/relref 引用本地文档 当然hugo支持创建自定义 shortcode，详细的使用方法可以看这里， https://gohugo.io/templates/shortcode-templates/ ，我会大概说一下。
定义一个新的shortcode，即在layouts/shortcodes/下创建一个新的xxx.html文件，文件名就是你的函数名 这个shortcode会做什么事，就是在这个html中进行实现 插入链接图片 remoteFigure，参考的是diary主题的实现支持调整图片大小、填充样式、对齐、添加图片描述等。
puer 主题的 Github commit
Reference 中文介绍Shortcode</description></item><item><title>C/python: cmp函数应该怎么写</title><link>https://wangloo.github.io/posts/c/cmp-func/</link><pubDate>Sun, 20 Aug 2023 17:59:22 +0800</pubDate><guid>https://wangloo.github.io/posts/c/cmp-func/</guid><description>C 中的qsort, python 中的sorted()很多时间需要自己构造比较的规则，也就是告诉排序函数怎么衡量两个值的大小关系？
TL;DR 升序的写法(C-qsort):
int cmp(const void *a, const void *b) { return *(int *)a - *(int *)b; } int main(void) { int nums[] = {2, 1, 3, 5, 4}; qsort(nums, 5, sizeof(int), cmp); return 0; } 升序的写法(python-sorted()):
from functools import cmp_to_key nums = [2, 3, 1, 4, 5] nums = sorted(nums, key=cmp_to_key(lambda x,y: x-y)) print(nums) python3 丢弃了sorted()中的cmp选项， 全部用 key 选项进行指定， 所以需要cmp_to_key进行转换
升序的写法(C++-sort()):
// sort()原型 void sort (RandomAccessIterator first, RandomAccessIterator last, Compare comp); bool cmp(int a, int b){ return a &amp;lt; b; } int main(){ int a[10]={8 ,3 ,10 ,9 ,5}; sort(a,a+10,cmp); return 0; } 详解 正如上面所说，cmp 函数的作用是给排序函数一个比较的依据。</description></item><item><title>Python 做机试题目技巧</title><link>https://wangloo.github.io/posts/python/algo/</link><pubDate>Sat, 19 Aug 2023 10:30:35 +0800</pubDate><guid>https://wangloo.github.io/posts/python/algo/</guid><description>排序 使用sorted()来做, 不修改原来的变量, 而是返回一个新的。 自定义cmp函数的例子
被排序的类型必须是iterable的。
字符串 无重复字符的最长子串 def lengthOfLongestSubstring(self, s: str) -&amp;gt; int: mp = {} left, right = 0, 0 max_len = 0 while right &amp;lt; len(s): if s[right] not in mp: mp[s[right]] = 1 else : mp[s[right]] += 1 while mp[s[right]] &amp;gt; 1: mp[s[left]] -= 1 left += 1 max_len = max(max_len, right-left+1) right += 1 return max_len 牛客网处理输入 https://blog.nowcoder.net/n/0632a788b94b4923976b7c82c45eca95
写递归 遇到需要用递归的题目中, 常常需要传值出来. 比如写一个求 sum(1..n)的函数</description></item><item><title>Hugo 主题创建(5): Tag 分类支持</title><link>https://wangloo.github.io/posts/hugo/new_theme_5/</link><pubDate>Tue, 15 Aug 2023 18:39:42 +0800</pubDate><guid>https://wangloo.github.io/posts/hugo/new_theme_5/</guid><description>通过 tag 可以实现对post进行分类，用到的支持是 HUGO Taxonomy Template（分类模板）
原理 实现tag的功能需要完成两类页面的设计： /tags/ 和 /tags/&amp;lt;one-tag&amp;gt;
前者属于 Taxonomy Terms（分类术语）页面，用分类术语模板实现， 后者属于 Taxonomy List （分类列表）页面，用分类列表模板实现，他们都属于 Taxonomy 模板。
不难推测出，分类术语模板规定了如何展现某个分类方式，比如说用云图来展示tag分类方法。 而分类list模板的作用是展示选中某一类之后的页面，比如说在云图中选中了某个tag。
更加详细的描述可以看官方文档: https://gohugobrasil.netlify.app/templates/taxonomy-templates/
设计 正与文档中所说，分类terms模板可以有多个查找的优先级：
/layouts/taxonomy/&amp;lt;SINGULAR&amp;gt;.terms.html /layouts/_default/terms.html /themes/&amp;lt;THEME&amp;gt;/layouts/taxonomy/&amp;lt;SINGULAR&amp;gt;.terms.html /themes/&amp;lt;THEME&amp;gt;/layouts/_default/terms.html 这样的好处是，比如说我有两种terms，tag和categories，我想在分类术语页面对这两种分类展示不用的页面， 就可以定义tag.terms.html和category.terms.html，注意是单数形式。参考Commit：拆分tag和category样式
分类list模板也是，使用最通用的list.html, 和其他的list公用，并没有对分类list做单独的页面。
对应的 commit: https://github.com/wangloo/hugo-theme-puer/commit/63d8bb762b16a3d4657ba3523d6b6fb38cf5f9ca
上面的commit不小心提交了menu.html, 实际不属于taxonomy的目的，所以在这纠正: https://github.com/wangloo/hugo-theme-puer/commit/0af07f66807b540fd9d3be84e8d7faca7f962c4b
References 中文博客介绍Taxonomy(1): https://hugo-in-action.foofun.cn/zh/docs/part1/chapter4/4/ 中文博客介绍Taxonomy(2): https://note.qidong.name/2017/10/hugo-taxonomy/</description></item><item><title>ARMv8: cache相关知识</title><link>https://wangloo.github.io/posts/armv8/cache/</link><pubDate>Mon, 14 Aug 2023 22:02:04 +0800</pubDate><guid>https://wangloo.github.io/posts/armv8/cache/</guid><description>之前在特斯拉面试的时候被问到了 cache 的 maintain 操作有哪些, 一时间竟想不起一个准确的词来, 这里就再学习一下, 把这个坑填上吧。
可能不会说的很细，目的只是把一些概念复习，做到心中大致有数。
cache 是个硬件 cache 的本质是一种 SRAM, 容量很小, 速度很快(ns 级)。
拿 Cortex-A53 来说，共有三级 Cache：
L1 cache 是 Core 单独的，分为数据 cache 和指令 cache，容量是 KB 级 L2 cache 一般是 cluster 内共享，容量是 MB 级 L3 cache 是所有 core 共享，容量是 MB 级 cache 控制器 单独的 cache 就是一个存储设备，得有一个控制器告诉它存什么以及什么时候存。
cache 控制器的任务举个例子说：比如 cache miss 的时候，需要从主存向 cache 回填数据，然而此时 CPU 那边记着要数据，我们都知道 cache 操作的单位 是 cache line 嘛，但这是 cache 控制器会有限填充一个 cache line 中 CPU 要的那一条（或几条），最后在后台默默填充完剩下的。</description></item><item><title>前端学习: display</title><link>https://wangloo.github.io/posts/html-css/display/</link><pubDate>Fri, 11 Aug 2023 22:02:04 +0800</pubDate><guid>https://wangloo.github.io/posts/html-css/display/</guid><description>display 是规定元素排列方式的属性，总的来说，元素的排列方式可分两种：block 和 inline。
block 的含义是，该元素默认情况下的 width 表现为充满整个父元素，height 表现为根据内容决定。 inline 的含义是，该元素的 width 和 height 都是必须根据内容决定，不能使用显示的width和height来改变。 即便 block 可以去设置 width, 比如为 50%, 但是它永远必须独占一行，下面的元素也不会排到它的空白处， 这就是 block 称之为 block 的原因。
细分来说，其实 display 这个属性共有五种取值： block, inline, inline-block, flex, grid。 我们将依次介绍。
block 默认 display 方式为 block 的标签有: p, h1-h6, div, li 等
inline 默认 display 方式为 inline 的标签有: span, a, strong
inline-block inline-block 是结合了 block 和 inline 的优势：既不必独占一行，又可以调整 width 和 height。
一些 button 经常使用的 display 就是 inline-block。</description></item><item><title>前端学习: position</title><link>https://wangloo.github.io/posts/html-css/position/</link><pubDate>Fri, 11 Aug 2023 21:02:04 +0800</pubDate><guid>https://wangloo.github.io/posts/html-css/position/</guid><description>position 属性决定了一个元素在页面中的排放方式, 通过与 top、bottom、left、right 结合可以决定任一元素在页面中应该在什么位置上。
position 的取值可以是: static/absolute/relative/fixed/sticky ，下面我将依次对他们的使用方法和场景进行介绍。
static static 是元素默认的 position，它使得元素按照顺序排列（什么样的顺序取决于display)。
它不能与 top、bottom 等属性结合，就是最简单的依次排布。
relative relative 与 static 相比，支持了 tom、bottom 这些属性，使得元素在依次排布的同时 能调整相对于上一个元素的位置变化。
据我所知，relative 并不常见。
absolute absolute 也就是我们常称的&amp;quot;绝对定位&amp;quot;， 产生的效果相对于父元素做了一些偏移，而不是上面所说的上一个元素，只有父元素的位置改变，它才按照偏移数值进行改变。 偏移数值的指定通过 top、bottom 来实现。
absolute 可以与 fixed 进行对比，两者相差很小。
absolute 无视 static。上面说 absolute 是基于父元素进行调整，仅当父元素是 static 时例外，absolute 会跳过这一层，找它的爷爷元素。
fixed fixed的含义是使元素的排列始终固定在页面的某个位置，换句话也可以说它总是基于body做relative的 排列。当然，偏移是通过top、bottom给出的。
一些页面的小广告用的排列就是fixed。
sticky sticky像默认的static，但它也有top、bottom等属性值，这些值有特殊含义： 当元素随着页面滚动变化，而使元素的页面绝对位置（相对于body）达到top、bottom值时， 便固定在那不会再移动，使元素永远不会被移动出页面。
看起来就好像是用页面的外框对sticky元素画了一个笼子，它永远跑不出页面之外。
sticky目前被广泛应用与导航栏，只要设置top=0
sticky是新增的属性，某些浏览器支持的可能不是很好</description></item><item><title>Hugo 主题创建(4): 样式打磨</title><link>https://wangloo.github.io/posts/hugo/new_theme_4/</link><pubDate>Fri, 11 Aug 2023 18:39:42 +0800</pubDate><guid>https://wangloo.github.io/posts/hugo/new_theme_4/</guid><description>字体替换 commit: https://github.com/wangloo/hugo-theme-puer/commit/861ca01617c06c83b701506c9a574cc2726d36d8
修改的参考：
一般文字用最近很火的【霞鹜文楷】 代码使用一些比较通用的代码字体，注意用!important提高优先级</description></item><item><title>Hugo 主题创建(3): 站内搜索</title><link>https://wangloo.github.io/posts/hugo/new_theme_3/</link><pubDate>Fri, 11 Aug 2023 16:39:42 +0800</pubDate><guid>https://wangloo.github.io/posts/hugo/new_theme_3/</guid><description> commit:
为什么选择fast search? hugo本身是不支持站内搜索功能的, 如果你写的文章较多就只能按照tag去检索分类. 这样至少也需要三次点击操作, 如果每个页面的边栏或者顶栏有一个搜索框, 能够 搜索文章的内容或者标题、Tag这些，对我来说效率就能得到显著提升。
fast search 是我检索到的目前比较简单、成熟的方案，它的亮点：
最小外部依赖（无需jQuery） 支持实现键盘唤出 无需NPM, grunt等外部工具 无需额外的编译步骤，你只需要像往常一样执行hugo 可以方便地切换到任意可使用json索引的客户端搜索工具 集成 集成的步骤我是参照的这篇文章 , fast search官方也有说明类似的步骤，过程不难，大概可分为：
Add index.json file to layouts/_default Add JSON as additional output format in config.toml Add search.js and fuse.js (downloaded from fusejs.io) to static/js Add searchbox html 到你想布局的位置 对searchbox添加样式文件 具体的步骤看博文或者官方文档就行，这里不赘述。
改动 做了一些让自己舒服的改动：
让搜索框常驻，只是搜索结果可以隐藏(ESC) /聚焦搜索框，和vim相同 简化样式，贴合我的主题 搜索结果只显示title就够 这样以后不论在哪，想要切换到一篇文章只需要两次鼠标（或者两次键盘）就能精准定位并打开，不必使用鼠标的方式可能更有作用哈哈。
TODO 只能搜索标题，不能搜索内容、tag？</description></item><item><title>Hugo 主题创建(2): 添加侧边栏</title><link>https://wangloo.github.io/posts/hugo/new_theme_2/</link><pubDate>Fri, 11 Aug 2023 15:39:42 +0800</pubDate><guid>https://wangloo.github.io/posts/hugo/new_theme_2/</guid><description>commit: https://github.com/wangloo/hugo-theme-puer/commit/32abfccc6bafd3763e07b751f0315a5403c6eaff
与顶栏相比，我更喜欢侧边栏，现在的屏幕纵向空间很宝贵。
本文创建了侧边栏模板的框架，预留了未来实现各种功能的布局，这个过程也是第一次接触partials/ 下的文件的作用——页面的某个组成部分。而_default/下的模板则是描述不同类型的页面。
布局 基于hugo模板的分类思想，侧边栏属于页表的一个部分，所以侧边栏的模板需要放在partials/下， 同理的还有footer、toc、comment等。我们给侧边栏模板起一个名字sidebar.html。
因为想在站点所有的页面（section、single、list）都显示侧边栏， 所以在baseof.html中需要引入sidebar模板：
&amp;lt;!DOCTYPE html&amp;gt; &amp;lt;html&amp;gt; &amp;lt;head&amp;gt; {{- partial &amp;#34;head.html&amp;#34; . -}} &amp;lt;title&amp;gt; {{ block &amp;#34;title&amp;#34; . }} {{ .Site.Title }} {{ end }} &amp;lt;/title&amp;gt; &amp;lt;/head&amp;gt; &amp;lt;body&amp;gt; &amp;lt;div id=&amp;#34;app&amp;#34;&amp;gt; {{- partial &amp;#34;sidebar.html&amp;#34; . -}} &amp;lt;main class=&amp;#34;container&amp;#34;&amp;gt; {{- block &amp;#34;main&amp;#34; . }} {{- end }} &amp;lt;/main&amp;gt; &amp;lt;/div&amp;gt; &amp;lt;/body&amp;gt; &amp;lt;/html&amp;gt; sidebar.html的内容就比较简单了，目前的计划是添加首页、TAG和一个搜索框， 不着急，先展位，以后再实现这些功能，本次先实现框架。
&amp;lt;div id=&amp;#34;sideContainer&amp;#34; class=&amp;#34;side-container&amp;#34;&amp;gt; &amp;lt;div class=&amp;#34;nav-link-list&amp;#34;&amp;gt; {{/* TODO: 回到首页 */}} &amp;lt;div class=&amp;#34;a-block nav-link-item &amp;#34; href=&amp;#34;&amp;#34;&amp;gt; BACK &amp;lt;/div&amp;gt; {{/* TODO: articles.</description></item><item><title>Hugo 主题创建(1): 内置样式</title><link>https://wangloo.github.io/posts/hugo/new_theme_1/</link><pubDate>Fri, 11 Aug 2023 07:39:42 +0800</pubDate><guid>https://wangloo.github.io/posts/hugo/new_theme_1/</guid><description>本次对应的commit，应该属于站点的仓库，因为仅修改 config.toml
代码高亮 hugo 内置一套highlight引擎, 参见官网的描述 , 所以我们只需要对站点的配置文件(注意不是模板的配置文件)进行修改, 就能最简单的实现代码高亮.
如果你需要对其进行自定义, 且将其固化到你的主题中, 那么就可能需要使用highlight.js来完成, 遵循&amp;quot;提前优化是万恶之源&amp;quot;的理论, 暂时使用hugo提供的高亮支持就能符合我们的目标.
这是我的配置文件config.toml中关于代码高亮的启用:
[markup] [markup.highlight] anchorLineNos = false # 行号格式化为&amp;lt;span&amp;gt; codeFences = true # 代码围栏, 不启用高亮无效 guessSyntax = true # 自动推断高亮语言 hl_Lines = &amp;#39;&amp;#39; # 突出显示某些特定的行 hl_inline = false # 高亮 inline code, ver&amp;gt;=0.101.0 lineAnchors = &amp;#39;&amp;#39; #　与 anchorLineNos 配合 lineNoStart = 1 # 行号开始 lineNos = true # 是否显示行号 lineNumbersInTable = true # 生成html中分开行号和代码 noClasses = true noHl = false style = &amp;#39;vs&amp;#39; tabWidth = 4 参考 hugo代码高亮引擎描述引导页: https://gohugo.</description></item><item><title>Hugo 主题创建(0): 脚手架</title><link>https://wangloo.github.io/posts/hugo/new_theme_0/</link><pubDate>Thu, 10 Aug 2023 17:39:42 +0800</pubDate><guid>https://wangloo.github.io/posts/hugo/new_theme_0/</guid><description>commit: https://github.com/wangloo/hugo-theme-puer/commit/c014d1fae09eea1fcc44e03c69b6dd4d185f91fd
背景交代 到现在为止我使用hugo也一年多了, 记了几十条的博客，对于使用频率如此高的工具来说， 有一个顺眼的外观、方便的功能布局简直是梦寐以求。
然而，试过了这么多的现有主题，始终没有一个让我觉得满意，可能我的要求过于苛刻：
搜索；我经常需要翻阅之前的博客/笔记，期望可以检索Tag，且不需要二次点击（ 上方直接是一个搜索框而不是一个按钮）。 TOC；要求可是展开显示三级的目录，且布局好看些。 外观；简洁，不花里胡哨，代码高亮看起来舒服。 xxx 所以，既然Hugo是一个开源的、社区环境较好的工具，那么为什么不尝试打造一款属于自己主题呢。
我是一名嵌入式开发工程师，对于前端的知识生疏，希望在良好的社区环境下能帮助我早日完成满足我个人需求的主题。
计划 搭建框架 制作模板，熟悉模板的概念，各个模板负责的区域 在上面的了解过程中逐渐加入对布局的调整，这一块可能需要学习css的知识 观摩学习前人的代码，结合百家之长，磨合出适合自己的布局和功能 开始动手：搭建脚手架 创建的过程可以参考这个博客 , 我主要想按照我的理解对整个框架进行详细的介绍。
目录结构 . ├── layouts │ ├── 404.html │ ├── _default &amp;lt;--- 此次重点研究 │ │ ├── baseof.html │ │ ├── section.html │ │ ├── single.html │ │ └── list.html │ ├── index.html &amp;lt;--- 此次重点研究 │ └── partials │ ├── footer.html │ ├── header.</description></item><item><title>openwrt 开发日记</title><link>https://wangloo.github.io/posts/embedded/openwrt/</link><pubDate>Sat, 05 Aug 2023 19:28:12 +0800</pubDate><guid>https://wangloo.github.io/posts/embedded/openwrt/</guid><description>构建 openWRT 我在此步骤失败了，后面项目没有依赖完整的编译过程， 所以可能对你不构成参考
过程可参考官方教程, 编译过程非常长，使用到的工具非常多，这里提供两个优化的思路:
提前安装本地依赖，忘了./scripts/feeds update -a还是./scripts/feeds install -a时需要检查系统的各种依赖, 可以提前统一安装一波.
sudo apt install g++ sudo apt install libncurses5-dev sudo apt install zlib1g-dev sudo apt install bison sudo apt install flex sudo apt install unzip sudo apt install autoconf sudo apt install gawk sudo apt install make sudo apt install gettext sudo apt install gcc sudo apt install binutils sudo apt install patch sudo apt install bzip2 sudo apt install libz-dev sudo apt install asciidoc sudo apt install subversion sudo apt install python sudo apt install git 提前下载dl, dl是默认在编译时下载的一些工具源码, 你可以将他们提前下载好 放到dl/下, 即可省去下载的时间, 特别当你不能翻墙时.</description></item><item><title>工具&amp;&amp;博客站点集合</title><link>https://wangloo.github.io/posts/tools/useful_sites/</link><pubDate>Sat, 05 Aug 2023 19:28:12 +0800</pubDate><guid>https://wangloo.github.io/posts/tools/useful_sites/</guid><description>博客站 向优秀的前辈们学习~
hitzhangjie
腾讯 一本有关Dwarf的gitbook: https://www.hitzhangjie.pro/debugger101.io/ Blog也是基于Hugo构建，风格很好，移动端体验不错。https://www.hitzhangjie.pro/blog/ stdcc
上海交大 IPADS Blog风格很好，https://stdrc.cc/ Slides一定得学习，https://stdrc.cc/slides/write-os-in-rust-2.0/slides.html 用notion整理表格 https://stdrc.notion.site/c93719166f094ac187dfba6fc199b566 &amp;hellip; 工具站 Armv8 寄存器、指令速查：http://hehezhou.cn/a64/ Emoji cheat sheet https://www.webfx.com/tools/emoji-cheat-sheet/ Windows10搭建局域网FTP服务器 跟我一起写Makefile https://seisman.github.io/how-to-write-makefile/Makefile.pdf 网络调试工具 http://free.cmsoft.cn/download/cmsoft/assistant/netassist5.0.3.zip Gnu gcc 内联汇编官方手册: https://gcc.gnu.org/onlinedocs/gcc/Using-Assembly-Language-with-C.html#Using-Assembly-Language-with-C 交叉编译工具 Linaro: 经常用来编译armv7架构的一些项目。 https://releases.linaro.org/components/toolchain/binaries/
Gnu: https://developer.arm.com/tools-and-software/open-source-software/developer-tools/gnu-toolchain/gnu-a/downloads
目前我组织的ARM64项目都使用 aarch64-none-linux-gnu- 作为交叉编译工具集, 直达链接: https://armkeil.blob.core.windows.net/developer/Files/downloads/gnu-a/10.3-2021.07/binrel/gcc-arm-10.3-2021.07-x86_64-aarch64-none-linux-gnu.tar.xz</description></item><item><title>开发环境构建指南</title><link>https://wangloo.github.io/posts/tools/dev_env/</link><pubDate>Mon, 17 Jul 2023 19:28:12 +0800</pubDate><guid>https://wangloo.github.io/posts/tools/dev_env/</guid><description>前言 写这篇博客的背景是我实在忍受不了每次换新的开发机器都得费好大的劲来完全恢复以前的环境， 而且，我平常喜欢搜集各种有用的工具、好看的主题，字体这些，如果零零散散的记录，大概率会忘记或者记不得某些细节。
所以，最后期望达到的是能够使我每次在新机器上搭建环境只需要看这一篇文章就可以了。因此这里会记录：
帮助提升开发效率的小工具 好看的字体、主题 配置某些环境的要点及注意事项 🥀 到目前为止，我还未发现一种方式能够完全达到“一键式布置”，这也不是本文的目的。 付出至少半天的时间的一定的，希望未来能发现一种好的方法。
字体 Fira Code 这款字体适合做编程字体，蛮好看的。我在 vscode 和 terminal 下都使用了这款字体。
详情及安装参考github
霞鹜文楷 开源的中文字体，做博客、PPT 不错。
详情及安装参考github
vscode vscode的所有配置通过其内置的sync功能实现, 目前用的是Github账号同步。
Command+Shift+o 或者搜索框中输入@ ==&amp;gt; 搜索outline 搜索框中输入% ==&amp;gt; 全局快速搜索quick search vscode多个窗口群组（Group）可以有两种排列方式：自由排布和放大某一个。 使用Toggle Editor Group Sizes命令来切换。
vscode常用快捷键 Remote SSH 连接失败 使用Remote SSH插件总是连接失败，但终端使用指令可以连接成功。这种情况下是插件挂了，解决方法参考链接：
VS Code Remote SSH Connection not working - Stack Overflow 删除服务器上的~/.vscode-server目录，并重试连接 Release 1.88.0 内置终端中按Ctrl+Alt+R执行历史命令。选择时按住Alt可以不自动执行 // #MARK：在minimap中标记region Quick search中按Command+⬆️/⬇️来在一次跳转文件 Ubuntu2004源 新版本的Clangd Clangd用15+才能用vscode的inlay hint功能。</description></item><item><title>课程学习：cs61a</title><link>https://wangloo.github.io/posts/course/cs61a/</link><pubDate>Mon, 17 Jul 2023 19:28:12 +0800</pubDate><guid>https://wangloo.github.io/posts/course/cs61a/</guid><description>学习日历 - 激励自己学习 因为最近在写论文，所以每两天能学习一次，并记录每次学习的事件
2024年1月4日22点09分 配置环境
lab00目录的组成：
lab00.py: The template file you&amp;rsquo;ll be adding your code to ok: A program used to test and submit assignments lab00.ok: A configuration file for ok What Would Python Do? (WWPD)
python3 ok -q python-basics -u --local 结尾的--local避免输入伯克利邮箱。
解释一个函数的组成：
The lines in the triple-quotes &amp;quot;&amp;quot;&amp;quot; are called a docstring, which is a description of what the function is supposed to do.</description></item><item><title>Linux SLAB 内存分配器(3): SLUB/SLOB</title><link>https://wangloo.github.io/posts/os/linux/mem/slab3/</link><pubDate>Fri, 26 May 2023 18:51:49 +0800</pubDate><guid>https://wangloo.github.io/posts/os/linux/mem/slab3/</guid><description>slub 和 slob 是基于 slab 思想针对某些场景下的优化实现。
SLUB 当 slab 分配器面对过多的申请需求时，cache 中就会有多个 slab (struct slab), 在以前的 slab 分配器设计中， slab 描述符是放在物理页中的，即物理页的结构为： （slab 描述符+freelist+对象 s）,管理数据结构的开销就比较大。后期 SLUB 首先将 slab 描述符与struct page共用（通过 union 实现）。后面该思想被 SLAB 采纳。 SLAB 中每个 cache node 有三个 list: free, partial, full， 管理起来很麻烦， SLUB 中只有一个 partial 链表。 放弃着色，效果不明显 SLOB SLOB 的设计更加简洁，只有 600 行左右代码（SLAB，SLUB 都是 4000+），适合小内存的嵌入式设备。
SLOB 中没有对象的概念，每个 slab 中分配的小块内存大小可以是不同的， 通过长度+偏移来记录下一个小块内存的位置。
另外，SLOB 基本上放弃了 cache 的思想，系统中通过创建三个全局的链表: small, medium, large, 分别应对&amp;lt;256b, &amp;lt;1k, &amp;lt;PAGESIZE 的请求， slab 直接挂在这三个链表上，因为 slab 中的内存分配大小可以不同， 用三个链表可以加速查找。</description></item><item><title>Linux SLAB 内存分配器(2): 算法</title><link>https://wangloo.github.io/posts/os/linux/mem/slab2/</link><pubDate>Sat, 20 May 2023 18:51:49 +0800</pubDate><guid>https://wangloo.github.io/posts/os/linux/mem/slab2/</guid><description>上一篇介绍了数据结构，这一篇主要介绍 slab 分配器的分配和释放算法。
最外层接口: kmalloc()/kfree() 最上层的接口是kmalloc(size, flag)。
slab 分配器维护了多个不同大小的 kmem_cache，放在数组kmem_caches[]中, 其对应的 object 大小和该 kmem_cache 的 name 在另一个数组kmalloc_info[] 中，它们的下标是对应的。使得我们能根据请求分配的大小来找到对应的struct kmem_cache结构。 【代码】
专用的&amp;quot;cache&amp;quot; 上面的结构，会遍历系统初始化创建的一些内存池，来寻找一个大小满足要求的 object， 但是通常不能找到大小相等的，如果系统中存在的固定 cache 中 object 的大小太稀疏， 就容易发生空间浪费的问题。
因此，我们可以为某个特定大小的内存请求再创建一个单独的 cache，仅仅用于满足这一类 结构体的申请，也是符合 slab 分配器关于面向对象的设计思想。
slab 分配器提供的相关接口是:
kmem_cache_create(): 创建一个专用 cache kmem_cache_alloc()： 从指定的 cache 里分配 object kmem_cache_free(): 释放对象到指定的 cache kmem_cache_destory(): 销毁某个 cache Reference https://blog.csdn.net/u010923083/article/details/116518646?spm=1001.2014.3001.5502</description></item><item><title>Linux SLAB 内存分配器(1): 概述</title><link>https://wangloo.github.io/posts/os/linux/mem/slab1/</link><pubDate>Sat, 20 May 2023 17:51:49 +0800</pubDate><guid>https://wangloo.github.io/posts/os/linux/mem/slab1/</guid><description>参考的 linux kernel 代码版本 4.12
slab 是什么 slab 属于 linux 内核内存分配器的一种，满足细粒度的小块内存的请求。 内核中还有其他的内存分配器例如伙伴系统，它是满足页为单位的分配请求。 因为内核中大部分的分配请求都用不到一个页那么大，所以 slab 的出现能够减小 内存碎片的出现。
另外，非常重要的是，除了基本的小块内存分配， slab 的最初设计开始就基于 对象缓存的思想，加速分配和初始化的过程，下面将详细介绍缓存的设计思想。
slab 分配器的实现在 linux 中是基于伙伴系统的，slab 管理的内存来源 就是伙伴系统，只是进行“二次管理”， 。
slab 的设计思想 对象缓存特性 经常会在 slab 接口中看到kmem_cache这个前缀，我最初也有疑问说 slab 不就是一个内存分配算法，和 cache 扯上什么关系呢？
slab 一般用于分配一些结构的内存，拿struct task来举例，我们通常会为 struct task创建一个内存池，里面包含了若干大小为sizeof(struct task) 的内存块，用的时候从里面取，释放之后回归池子里即可。这是 slab 分配小块内存的 基本思想。
内核中的很多数据结构，我们在申请完空间之后立马做的一件事，就是初始化对象的成员 为某些特定的值，可以称这个过程为结构体(类)的构造函数，意为所有对象都会 做的那些相同的事。比如说，多核环境下很多结构中会有锁，或者链表，那么申请完空间 之后都会做锁或链表做初始化，这是固定的。实际上这些操作消耗的时间甚至大于申请 一块内存。
基于以上事实，slab 分配器做的缓存优化是：为每个类别的内存池都绑定一个构造函数 和析构函数，当用完的对象空间被释放时，调用析构函数将某些成员的值恢复为默认状态 ，这样下次申请的时候，直接拿就行了，省略了重复的初始化流程。而构造函数被调用的 情况仅仅是当该小块内存第一次被申请时。
由于这个思想，整个内存池也就被声明结构 struct kmem_cache, 它是整个 slab 算法的顶层数据结构，其中包含了许多相同大小的小内存块，slab 通过一些算法对其进行 管理。
整体数据结构的规划 上面说了整个系统的顶层结构是struct kmem_cache, 其中可以再划分为多个&amp;quot;slab&amp;quot;, 这个 slab 就能代表一个或多个连续的物理页嘛，从 buddy 申请来的。</description></item><item><title>Linux 中断管理: 软中断/tasklet/工作队列</title><link>https://wangloo.github.io/posts/os/linux/interrupt/softirq/</link><pubDate>Sat, 13 May 2023 20:51:49 +0800</pubDate><guid>https://wangloo.github.io/posts/os/linux/interrupt/softirq/</guid><description>软中断、tasklet、工作队列都是中断上下部分离的具体实现方案。
软中断 我们可以将某些中断配置为软中断，相当于建立一张 INTID 到软中断的映射表，这样在 中断到来时就能判断是否为软中断。
这张“表”的建立是静态的，即编译时确定的。key 为 INTID，value 为描述一个软中断 的数据结构，在下面会介绍。
软中断的服务函数必须是可重入的，即多个 CPU 可以同时执行同一个 softirq 的处理函数，涉及到的全局结构可以用 spinlock 钳制。
表示 softirq 的数据结构 struct softirq_action代表一个软中断，系统中所有支持的软中断组成一个数据 softirq_vec[], 所有的软中断按照优先级来分配下标。
struct softirq_action { // 指向softirq的处理函数 void (*action)(struct softirq_action *); }; softirq 的中断流程 在中断的上部，如果识别到当前中断是一个 softirq， 那么系统会标记一个软中断发生， 即raise_softirq()函数。其做的事情包括:
标记某个软中断发生，记录的结构是irq_cpustate_t.__softirq_pending (这个字段使loca_softirq_pending()访问) 唤醒ksoftirqd内核线程，之后介绍 光标记不行，那么什么时候执行它们的服务函数呢？
几个可能的检查点:(1) 中断退出前 (2)ksoftirq被唤醒时
如果在检查点发现有标记挂起的 softirq(local_softirq_pending() != 0), 内核调用do_softirq()处理它们：
如何in_interrupt()返回非 0， 直接返回。此时代表要么禁用了 softirq，要么当前是 在中断嵌套的环境下，也可能正在执行do_softirq()时中断嵌套的，而do_softirq() 函数是不能嵌套执行的。 调用__dosoft_irq(), 对于local_softirq_pending()的每一位都调用其 softirq_vec[nr]-&amp;gt;action() 这里有个重要的问题，此时处于中断下部，即开中断的情况，所以在处理 softirq 时会有新的 softirq 到来，这里就有两种策略：</description></item><item><title>Linux 内核数据结构 hlist</title><link>https://wangloo.github.io/posts/os/linux/data_struct/hlist/</link><pubDate>Thu, 11 May 2023 20:51:49 +0800</pubDate><guid>https://wangloo.github.io/posts/os/linux/data_struct/hlist/</guid><description>linux 内核为创建【用单链表解决冲突的哈希表】设计了专门的数据结构 hlist。
hlist 整体来说是带头结点的双向链表，头结点的类型为hlist_head, 普通节点 的类型为hlist_node. 为什么要区别两种类型？节约空间， 因为哈希表的 表项类型可以是hlist_head, 它其实不需要prev指针, 比起一般的结点，一个 哈希表能节约一半的空间。
所以一个哈希表和头结点的结构可表示为:
struct hlist_head { struct hlist_node *first; }; struct hlist_head table[TALBE_SZ]; 二象性 任何事物都具有二象性，区分两种类型节约空间的空间，也带了一个问题： 首个hlist_node结点的prev指向哪呢？
正常情况下肯定毫不犹豫的指向头结点，即hlist_head，但注意此时类型是 不同的，prev不能同时是struct hlist_head*和struct hlist_node *。
解决方案有两个，首先可以使首个结点的prev=NULL, 这样虽然避免了类型引发的 问题，也能保证功能正确，但是却破坏了一致性，使得操作的复杂度上升，增加了许多 判断分支。
// delelt a node void del_node(struct hlist_head *head, struct hlist_node *node) { // 这个if 本来是不需要的，甚至参数的head 也不需要传， // 更好的处理方式见解决方案2 if (node == head-&amp;gt;first) { head-&amp;gt;first = node-&amp;gt;next; } else { node-&amp;gt;prev-&amp;gt;next = node-&amp;gt;next; } if (node-&amp;gt;next) { node-&amp;gt;next-&amp;gt;prev = node-&amp;gt;prev; } } // insert a node void add_node_before(struct hlist_head *head, struct hlist_node *new struct hlist_node *next) { // 这个if 本来是不需要的，参数head也是不需要传递的 if (next == head-&amp;gt;first) { new-&amp;gt;prev = NULL; head-&amp;gt;first = new; } else { new-&amp;gt;prev = next-&amp;gt;prev; new-&amp;gt;prev-&amp;gt;next = new; } new-&amp;gt;next = next; next-&amp;gt;prev = new; 更好的解决方案: **prev 改变struct hlist_node的构成，使用二级指针:</description></item><item><title>Linux 进程间通信(1): 管道</title><link>https://wangloo.github.io/posts/os/linux/ipc/pipe/</link><pubDate>Thu, 11 May 2023 20:51:49 +0800</pubDate><guid>https://wangloo.github.io/posts/os/linux/ipc/pipe/</guid><description>管道属于实现进程间通信的一种方式，正如其名，一个进程在一头读，另一个进程在一头写。
管道被看做是打开的文件，但在已安装的文件系统中没有相应的实体，即并不是一个 真正的文件。
管道的创建和使用 可以使用pipe()系统调用来创建一个管道(后面会介绍另一个方式)，其返回一对文件 描述符，一个用来写一个用来读。必须返回两个描述符的原因是： POSIX 只定义了半双工 的管道，所以读写需要两个端口。
POSIX 另外要求使用一个描述符前需要关闭另一个描述符。 但 Linux 中则可以不关闭， 可以实现全双工，但为了可移植性， 一般还是将另一个先关闭。
用ls | more组合命令来解释如何使用pipe()实现通信:
shell 调用pipe(), 返回 fd3(对应读通道),fd4(对应写通道) 两次调用 fork() 创建两个子进程，由于属于不同的地址空间， 所以操作自己的文件描述符不会影响其他进程，但都指向同一个管道 父进程调用close()关闭这两个文件描述符 第一个子进程执行ls程序，其操作如下，
调用dup2(fd4, stdout), 执行文件描述符的拷贝，从此stdout 就代表管道的写通道 由于stdout代表写通道，所以可将 fd3 和 fd4 均关闭 exec()执行ls程序，默认情况下，其输出结果到 stdout， 当下即管道的写通道，即向管道中写了数据 第二个子进程执行more程序，其操作如下：
调用dup2(fd3, stdin), 从此stdin代表管道的读通道 同样可以将 fd3 和 fd4 关闭 exec()执行more程序，由于现在stdin就是管道的读通道, 上面的子进程向管道中写了数据，所以stdin现在有数据，more 可以正常输出 popen(): 更简单的 API 当管道的使用是单向的，即某个进程仅仅想知道另一个进程的执行输出，或者 某个进程想把数据灌入到另一个进程的输入。
此时 Linux C 库中的popen()和pclose()简化使用pipe()中 调用dup2(), close()这些繁琐的步骤。</description></item><item><title>Linux 进程与线程的关系</title><link>https://wangloo.github.io/posts/os/linux/process/thread/</link><pubDate>Wed, 10 May 2023 20:51:49 +0800</pubDate><guid>https://wangloo.github.io/posts/os/linux/process/thread/</guid><description>Linux 中其实并不区别进程和线程，都用task_struct来描述，可以说 它们之间的联系大于区别。
创建进程的接口是fork()， 创建线程的接口是pthread_create()， 但是它们最终都是调用的clone()系统调用， 只是参数不同而已。
当一个进程/线程发起创建线程的请求时，不像创建进程那样重新申请mm_struct 和打开的文件等结构， 而是直接将指针赋值为父进程的值，所以它和父进程共享同一个 地址空间这些。
上面说的父进程，因为没有父线程的概念，如果创建线程的task_struct也是一个 线程，那么它的地址空间也是最终指向某个进程的，所以父亲和新的线程就是同等 地位了。
再说说 PID，PID 能够唯一的标识一个进程，一个进程下所有的线程的 PID 都与父进程 相同，那么问题来了，如何标识线程的从属关系呢？
task_struct.tgid标识自己所归属的进程 ID，或者叫主线程 ID，反正就是地址空间 的真正来源。 而进程如何知道自己创建了哪些线程呢？， 通过task_struct.children 链表来查找，但这里面即有子进程又有线程，需要过滤。
有的地方会使用一个名词 管理线程， 其实就是线程共享的地址空间这些的原主。
内核线程 内核线程是一种特殊的进程，当然也是用task_struct来描述，内核线程的特殊点：
mm成员=NULL，没有用户空间的数据，不能访问用户空间 每个内核线程有私有数据，用set_child_tid成员指向， 是一个struct kthread结构，用to_kthread()来访问私有数据 内核线程也像普通线程一样参与调度，其创建的地方在内核，使用kthread_create() 创建，不能由用户态创建。
内核线程一般负责执行一些内核任务，比如软中断 就有一个内核线程，来专门执行到来中断的服务函数中不着急的部分。</description></item><item><title>ARMv8 基础概念</title><link>https://wangloo.github.io/posts/armv8/introduce/</link><pubDate>Tue, 09 May 2023 21:19:01 +0800</pubDate><guid>https://wangloo.github.io/posts/armv8/introduce/</guid><description>指令执行的过程：取指、译码、执行和写回。 根据这个将Core分为两部分：
前端：指令从内存预取到Cpu，解码，发射。在Arm中， 前端的流程是顺序的。一个cycle里最多可以解码4条指令给后端。 后端：后端的作用是执行指令。后端一般包含几个执行单元， 整数、浮点数、Load/Store、Branch相关的执行单元。 后端中，如果指令之间没有依赖，支持乱序执行。 Core中的Cache分布：Icache在前端，Dcache属于后端。
Core中的Tlb分布：ITlb在前端，DTlb在后端
指令执行完后，到达Retire，指令退役。
程序性能的分析方法 性能的问题可能出在前端，称为前端Stall，在后端时则称为后端Stall。
性能指标：
IPC：IPC=INST_RETIRED / CPU_CYCLES，IPC并不能单独判断 是否性能比较好，比如说在某个处理器上，前端最多一个Cycle发射4 条指令，那么IPC是不是越接近4越好呢？其实不是，还要结合CPU 此时正在做什么事情，如果是死循环，那么就不代表什么。 Pipeline Stalls Stall Front-end rate=STALL_FRONTEND/CPU_CYCLES Stall Back-end rate=STALL_BACKEND/CPU_CYCLES Frontend Bound ITLB events I-Cache events Backend Bound DTLB events Memory System related events D-Cache events Retiring Instruct Mix Bad Speculation Branch Effectiveness events 程序性能的分析工具 Linux Perf # Counting perf stat -e &amp;lt;event list&amp;gt; # Event based sampling perf record -e &amp;lt;event list&amp;gt; # SPE sampling perf record -e árm_spe_0/ts_enable=1&amp;#39; 与 ARMv7 相比的改动 指令集： 新增 A64 指令集， 但也兼容原来的 A32 指令集 权限等级： AArch64 下新增 EL0-EL3 异常等级，对应 V7 的特权等级 通用寄存器：31 个通用寄存器，V7 15 个 虚拟地址长度：64 位的地址长度，理论支持 256TB 的寻址范围 Arm 处理器的架构与微架构 架构可以理解为由指令集、内存模型等组成的一个行为规范， 或叫做 specification。相当于一种标准，会定义 Cpu 工作行为的预期， 并不会限制具体是如何实现。</description></item><item><title>C 和 C++ 的区别与联系</title><link>https://wangloo.github.io/posts/c/c_and_cpp/</link><pubDate>Tue, 09 May 2023 20:51:49 +0800</pubDate><guid>https://wangloo.github.io/posts/c/c_and_cpp/</guid><description>C++几乎是 C 的超集，只有很少的 C 的特性在 C++中不支持
C++增加了需要方便实现面向对象特性的语法和封装，当然这些用 C 应该也能实现， 只不过 C++使其实现起来更简单。
C++ 改进了一些 C 中的缺点，比如 new 自动计算大小避免出错 C++ 增加一些语法糖，比如迭代器等 C++ 原生支持一些方便的库文件，比如 STL 库</description></item><item><title>Dwarf(2): basetype类型</title><link>https://wangloo.github.io/posts/binary/dwarf/1_basetype/</link><pubDate>Tue, 09 May 2023 16:51:49 +0800</pubDate><guid>https://wangloo.github.io/posts/binary/dwarf/1_basetype/</guid><description>想要描述一个变量，必须知道它类型信息，才能知道变量的大小、输出的格式等。
Dwarf 为 C 语言定义了一些描述数据类型的 DIE，包括 basetype, array,pointer, structure&amp;hellip;
basetype 今天我们先介绍最简单的 basetype。
basetype 是指那些 C 语言自身定义的基础类型，像int, double这些。
basetype 类型的 DIE 通常有属性:
DW_AT_name: basetype 的名称 DW_AT_byte_size: 该 basetype 占空间大小 下面给出描述int和double的 DIE 展示(还是通过objdump工具输出）：
&amp;lt;1&amp;gt;&amp;lt;43&amp;gt;: Abbrev Number: 3 (DW_TAG_base_type) &amp;lt;44&amp;gt; DW_AT_byte_size : 4 &amp;lt;45&amp;gt; DW_AT_encoding : 5 (signed) &amp;lt;46&amp;gt; DW_AT_name : int &amp;lt;1&amp;gt;&amp;lt;60&amp;gt;: Abbrev Number: 4 (DW_TAG_base_type) &amp;lt;61&amp;gt; DW_AT_byte_size : 8 &amp;lt;62&amp;gt; DW_AT_encoding : 4 (float) &amp;lt;63&amp;gt; DW_AT_name : (indirect string, offset: 0x9): double Array 数组表示为 DW_TAG_array 的 DIE，通常含有属性:</description></item><item><title>Dwarf(1): 基础</title><link>https://wangloo.github.io/posts/binary/dwarf/0_basic/</link><pubDate>Tue, 09 May 2023 15:51:49 +0800</pubDate><guid>https://wangloo.github.io/posts/binary/dwarf/0_basic/</guid><description>Dwarf 把源文件中每个可描述的模块（例如函数，变量，结构体的声明等）描述为一个 DIE (Debugging Information Entry)，所以每个源文件可以描述为若干 DIE 的组合。
每个 DIE 由一个 tag 和若干 attribute-val 键值对构成:
tag: 描述此 DIE 的类型 attribute-val: 描述此 DIE 的一些细节属性，项目根据 DIE 的类型不同而有差别 各个 DIE 之间会相互联系，一个 DIE 可能含有 parent，若干的 child 和 sibling， 它们之间组成树的结构。
查看一个 ELF 的所有 DIE ELF 文件中的所有 DIE 存储在.debug_info section 中，通过 GNU utils 中的objdump工具 可以解析为可阅读的结构:
objdump --dwarf=info &amp;lt;file&amp;gt; 若我们有一个 demo.c 如下:
void func(void) { int var_local; } 编译为可执行文件后， 执行上述的objdump命令， 可以得到如下的输出（节选）：
&amp;lt;1&amp;gt;&amp;lt;68&amp;gt;: Abbrev Number: 5 (DW_TAG_subprogram) &amp;lt;69&amp;gt; DW_AT_external : 1 &amp;lt;69&amp;gt; DW_AT_name : (indirect string, offset: 0x32): func &amp;lt;6d&amp;gt; DW_AT_decl_file : 1 &amp;lt;6e&amp;gt; DW_AT_decl_line : 3 &amp;lt;6f&amp;gt; DW_AT_decl_column : 6 &amp;lt;70&amp;gt; DW_AT_prototyped : 1 &amp;lt;70&amp;gt; DW_AT_low_pc : 0x1129 &amp;lt;78&amp;gt; DW_AT_high_pc : 0xb &amp;lt;80&amp;gt; DW_AT_frame_base : 1 byte block: 9c (DW_OP_call_frame_cfa) &amp;lt;82&amp;gt; DW_AT_GNU_all_call_sites: 1 &amp;lt;2&amp;gt;&amp;lt;82&amp;gt;: Abbrev Number: 6 (DW_TAG_variable) &amp;lt;83&amp;gt; DW_AT_name : (indirect string, offset: 0x28): var_local &amp;lt;87&amp;gt; DW_AT_decl_file : 1 &amp;lt;88&amp;gt; DW_AT_decl_line : 4 &amp;lt;89&amp;gt; DW_AT_decl_column : 9 &amp;lt;8a&amp;gt; DW_AT_type : &amp;lt;0x43&amp;gt; 上述例子中节选了两个 DIE，分别是函数func()和局部变量var_local, 可以看到它们的 tag 是不同的，且都具有一系列属性。</description></item><item><title>C 语言的内存对齐要求</title><link>https://wangloo.github.io/posts/c/alignment/</link><pubDate>Mon, 08 May 2023 17:19:44 +0800</pubDate><guid>https://wangloo.github.io/posts/c/alignment/</guid><description>内存对齐为何被需要 架构规定了数据类型大小的同时，也规定了对这些类型的变量合法访问的对齐要求。 也就是说，变量不能随便的放在内存的任意位置，起始地址必须满足特定的对齐要求， 对不满足要求的变量强行访问就叫做非对齐访问， 非对齐访问通常会触发异常。
一般数据类型的对齐要求 对于一般的数据类型，比如 int, long, char 这些，要求其变量地址对齐到自身大小， 比如 ARM64 中，int 变量的地址必须对齐到 4 字节，long 变量地址必须对齐到 8 字节等等。
那么对于*(int *)0x1001 = 1234;, 这类的内存访问就叫非对齐的内存访问。
即 （变量 addr % 变量 size) ！= 0, 就称为非对齐内存访问。
结构体的对齐要求 上面说的还都是一般的数据类型，对于结构体这种复杂的类型，对齐的要求也复杂些。
首先是结构体成员，每个成员都必须满足其自身的对齐要求 然后是结构体变量自身的起始地址的对齐要求是其所有成员的最大对齐要求。 然而两个要求均满足有时候根本不可能，比如一个结构体声明为:
struct foo { char mem1; int mem2; short mem3; }; 不可能同时做到 foo 变量和其成员 mem2 同时满足对齐到 4 字节，所以编译器会依据 上面的两条要求在成员之间添加 padding。
除了变量中间添加 padding 外，在末尾也会添加，使得结构体数组容易满足对齐需求。
最后 foo 变量在内存中的样子可能是:
struct foo { char mem1; char _pad1[3]; // 保证结构体和成员均对齐正确 int mem2; short mem3; char _pad2[2]; // 保证【结构体数组】对齐正确 }; 若结构体的成员还是一个结构体，嵌套操作就可以了，编译器可以 handle。</description></item><item><title>Linux 进程地址空间 堆的管理</title><link>https://wangloo.github.io/posts/os/linux/addrspace/heap/</link><pubDate>Mon, 08 May 2023 10:51:49 +0800</pubDate><guid>https://wangloo.github.io/posts/os/linux/addrspace/heap/</guid><description>当进程被创建时，就预留了一块特殊的线性区，其开始地址和结束地址单独保存在 mm_struct.start_brk和mm_strcut.brk成员中，并不由vm_area_struct 链接，这块特殊的线性区就叫堆。
进程使用的malloc()和free()等相关 API 都是操纵的堆空间。
修改堆空间的接口 对用户态进程来说，提供brk()系统调用来修改自身的堆空间。
brk(): 参数addr, 效果是修改mm_struct.brk到 addr，即修改一个堆的结束地址。
brk() 系统调用的实现，在内核态是调用do_mmap()扩充堆，或者do_unmap()缩小堆。 并且移动mm_struct.brk的值而已，这是 brk()的实现。
用户态进程还有一个接口: sbrk(), 参数是字节，代表扩充的字节数。 其下层还是调用的 brk()。
malloc()的实现 进程刚创建时，堆空间的大小为 0， 即bkr==start_brk。
调用malloc()，即对堆空间扩充，上面介绍了修改堆空间的接口， 所以我们可以使用brk()来实现malloc().
对于进程本身来说，只能通过brk()简单的增加/减少堆的总大小，这样做的效率是比较低的。 比如连续执行了三次malloc(), 如果要将中间的地址 free 掉，其实是无法实现的。
而且这种最简单的情况下，每次malloc()都要使用brk()系统调用，效率也是很低的。
所以，通常在 C 库则一层，即malloc()和brk()之间，会有一层对堆内存的管理， 包含碎片回收，内存池等算法来避免频繁的使用系统调用。</description></item><item><title>Linux 进程地址空间 写时复制</title><link>https://wangloo.github.io/posts/os/linux/addrspace/cow/</link><pubDate>Mon, 08 May 2023 09:51:49 +0800</pubDate><guid>https://wangloo.github.io/posts/os/linux/addrspace/cow/</guid><description>当前存在的问题 未启用写时复制时，fork()创建子进程地址空间的流程如下:
动态申请子进程的页表 动态申请子进程的物理页面，大小和父进程的相同 创建父进程虚拟地址-新物理页的映射到子进程页表 memcpy()将父进程所有页面拷贝到子进程地址空间下 这样做有什么问题呢？ 在fork()的常规调用环境下，fork()之后 接的一般是exec()类函数，即载入一个新的可执行文件，继续用父进程 的情况不多。
这样的话，上述过程中memcpy()父进程的页面就是多余的，而且如果 父进程比较大，会非常耗时。
写时复制的优化 执行 fork() 时，不给子进程分配新的物理页，而是将父进程的页表项 完全的拷贝到子进程中，结果就是父子进程的虚拟地址指向同一个物理地址。
换句话说，这样做就不需要memcpy()父进程所有的页面，仅仅是memcpy()一份 父进程的页表，给子进程用。
那么是否连新页表都不申请，直接用父进程的页表？
显然是不行的，因为本质上父子进程拥有不同的地址空间， 最后都要分隔开（无论是否执行exec()），所以没必要 推迟页表的申请，本身不怎么耗时。
但是创建线程时，确实使用同一张页表。
当然，仅设计到这步是不行的，因为按理来说父子进程是独立的，对子进程的 修改不应该影响父进程的地址空间。
所有，在 copy 完页表后，会将父子进程的所有地址空间（实际是页表项）设置 为只读属性，当父/子进程尝试修改地址空间时，触发异常，配合特定的 异常处理机制，为其创建一个新的屋里也，拷贝原来的+执行修改。
下图是对上述情况的描述，仅给出一个页面的示例，可以推广到整个地址空间：
VMA VMA ┌───────┐ │ ┌───────┐ Parent │ │ │ Parent │ │ │ │ │ │ │ ├───────┤ │ ├───────┤ │ ├────┐ │ │ ├────┐ ├───────┤ │ PMA Write │ ├───────┤ │ PMA │ │ │ ┌───────┐ ────┼───► │ │ │ ┌───────┐ │ │ │ │ │ │ │ │ │ │ │ │ │ │ │ │ │ │ │ │ │ │ └───────┘ │ ├───────┤ │ └───────┘ │ ├───────┤ ├────►│ │ Read │ └────►│ │ RW ┌───────┐ │ ├───────┤ only │ ┌───────┐ ├───────┤ Child │ │ │ │ │ │ Child │ │ │ │ │ │ │ │ │ │ │ │ ├───────┤ ├───────┤ │ │ │ │ ├───────┤ ┌─►│ │ RW │ ├────┘ └───────┘ │ │ ├───────┘ ├───────┤ ├───────┤ │ ├───────┤ │ │ │ │ │ │ │ └───────┘ │ │ │ │ │ │ │ │ │ │ └───────┘ │ └───────┘ │ 这样就完美了吗 实际上不是的，拷贝父进程的页表和vm_area_struct就不占内存了吗？</description></item><item><title>Libdwarf 函数介绍及其实现方法</title><link>https://wangloo.github.io/posts/binary/dwarf/libdwarf_func/</link><pubDate>Sun, 07 May 2023 14:51:49 +0800</pubDate><guid>https://wangloo.github.io/posts/binary/dwarf/libdwarf_func/</guid><description>Function dwarf_alloc.c _dwarf_get_alloc() char * _dwarf_get_alloc(Dwarf_Debug dbg, Dwarf_Small alloc_type, Dwarf_Unsigned count) 函数功能: 根据类型申请一块空间
注意, 申请时大小会多DW_RESERVE, 此函数返回的地址是 mem_alloc()返回的地址+DW_RESERVE
_dwarf_error() void _dwarf_error(Dwarf_Debug dbg, Dwarf_Error * error, Dwarf_Sword errval) 函数功能 错误处理的函数
函数流程 判断传入参数error是否为空, 如果为空则跳转到 step 4. 分配一个新的Dwarf_Error空间 将传入的错误信息存入Dwarf_Error, 并将其作为指针返回 error为空时, 一般要在出错时执行一些方法,即 dbg-&amp;gt;de_errhand() 所以, 此时dbg 和 dbg-&amp;gt;de_errhand 必须非空. dwarf_elf_access.c dwarf_elf_object_access_init() int dwarf_elf_object_access_init(u64 elf_base_addr, int libdwarf_owns_elf, Dwarf_Obj_Access_Interface** ret_obj, int *err) 函数功能 初始化 Dwarf_Obj_Access_Interface 结构
函数流程 初始化其成员object, 使用的是dwarf_elf_object_access_internals_init方法 申请空间 为成员赋值 为全局变量_dwarf_get_elf_flags_func_ptr赋值, 为获取elf section flags的方法 _dwarf_get_elf_flags_func() static int _dwarf_get_elf_flags_func( void* obj_in, Dwarf_Half section_index, Dwarf_Unsigned *flags_out, Dwarf_Unsigned *addralign_out, int *error) 函数功能 获取elf指定section的flags</description></item><item><title>Linux 进程地址空间 概述</title><link>https://wangloo.github.io/posts/os/linux/addrspace/addrspace/</link><pubDate>Sun, 07 May 2023 14:51:49 +0800</pubDate><guid>https://wangloo.github.io/posts/os/linux/addrspace/addrspace/</guid><description>何为进程地址空间? 进程地址空间的含义是进程能访问的所有虚拟地址, 一般来说可以划分为若干线性地址区域(也称&amp;quot;虚拟内存区域&amp;quot;)。
每个线性区域由起始地址、长度和属性来描述。
在进程刚创建时，其地址空间仅包含 4 个线性区，分别是：代码段、数据段、栈区和堆区， 其中堆区的初始大小为 0，栈有一个默认大小。
栈区对用户是透明的，所以我们一般将其归于内核管理，并非进程本身。
线性区增加的典型情况:
使用mmap()为一个文件映射内存空间 创建一个 IPC 共享线性区与其他进程协作 调用malloc()扩张自己的堆区 Linux 描述地址空间的数据结构 在进程的 tcb 中，描述地址空间相关的结构都保存在成员mm中，其类型为struct mm_struct, 其中重要的成员有：
mmap(struct vm_area_struct*): 指向所有线性区的链表头 mm_rb(struct rb_root): 指向所有线性区对象红黑树的根 pgd(pgd_t *): 指向进程的页表 mmlist(struct list_head): 指向下一个地址空间描述符(所有进程的地址空间描述符 被链接起来) Linux 描述线性区的数据结构 进程地址空间所有线性区的组织 进程拥有的所有线性区通过单链表串联（按地址排序），
红黑树优化查找 正常来说，想要查找某个地址是否存在于进程的地址空间，遍历上述链表的效率是 O(n).
因此，Linux2.6 引入红黑树来优化查找速度， 所有线性区同时组织成一个红黑树， 首部通过mm_struct.mm_rb指向。 然后每个线性区的vm_area_struct.vm_rb 存储节点的颜色和双亲信息。
现在，当需要插入/删除一个线性区描述符时，用红黑树查找前后元素，再操作链表进行插入。
分配一个线性区 接口是do_mmap(), 参数为:
file, offset; 如果有文件映射 addr, len prot; 该线性区的权限 步骤大致包含:</description></item><item><title>操作系统：信号的由来和实现原理</title><link>https://wangloo.github.io/posts/os/linux/signal/</link><pubDate>Fri, 05 May 2023 20:51:49 +0800</pubDate><guid>https://wangloo.github.io/posts/os/linux/signal/</guid><description>Linux 为什么要引入信号? 信号是用户进程感知外部事件的一种方式。内核可以发送信号给用户程序，当然用户程序之间也可以互相发送信号，进程通过对某个信号绑定Handler实现对信号的响应。
所以说信号也属于进程通信的一种方式，但是这种通信比较简单直接，目标进程只能知道信号来源的PID，无法直接附带其他数据。
信号传递的原理 每个进程的TCB里都有一条链表存该进程等待的所有信号，给某个进程发送信号就表示为挂一个节点到目标进程的此链表上，内核发送信号当然可以直接操作，进程之间的话会转换成系统调用间接完成。当目标进程被调度时会检查并处理等待的所有信号。
目标进程只能同时有一个同种类型的信号处于挂起状态，也就是说，如果上一个同种信号没有被处理，那么之后到来的同类信号会被忽略。
更详细的说，这个信号的队列（链表）不止一条，分为进程组共享和进程私有的挂起队列。 才能实现某些信号是发送给整个进程组的，比如kill()，而一些是指定某个进程的， 比如tkill().
信号被处理 对目标进程来说，它可以提前设置自定义的handler，所以在其TCB中还需要记录对于每个信号的处理方式。可能有三种：ignore, default handler, user-defined handler。
当进程被调度获得CPU时，在返回用户态执行代码之前会检查是否有挂起的信号。如果有则执行对应的handler。
这个过程对应内核函数do_signal()。
有一个问题是，自定义的信号处理函数是在用户态的, 而do_signal()是发生在 内核态，所以内核要做一些特殊的操作：
创建一个临时的用户栈，不能破坏保存的原来用户态环境 ELR(返回地址) = 自定义处理程序，和其他的用户态环境构建 返回用户态，CPU 会执行处理函数 执行完毕后，通过之前对用户栈的特殊构建，使得程序接下来会运行一个 syscall (sys_sigreturn), 返回内核态 如上述操作检查完所有挂起的信号 当所有信号都被处理完成后，则恢复用户进程的原有环境，继续执行</description></item><item><title>操作系统：同步互斥机制</title><link>https://wangloo.github.io/posts/os/linux/sync/</link><pubDate>Thu, 04 May 2023 20:51:49 +0800</pubDate><guid>https://wangloo.github.io/posts/os/linux/sync/</guid><description>为何需要同步互斥机制 同步互斥存在的意义只针对多个任务都会修改同一块内存的场景。这块内存也叫临界区， 要求是必须各个任务独占访问的。比如说许多线程都会往 ringbuffer 中填数据， 必须使用同步互斥机制才能保证数据的正确性。
所以说，在以下的场景中，无需考虑同步互斥：
如果你只有1个CPU，该CPU上只运行1一个线程 如果会存在多个线程（可能是多个core或者一个core上的多线程环境），但是他们不会涉及同一块内存 即便是多个线程访问了同一块内存，但是都是读操作 需要同步互斥的场景在OS内核和用户态程序中都很常见：
内核中常见的临界资源包括：对内存区域的引用计数操作，或者对调度队列的修改操作等。 用户态那就更不用说了，同步互斥的场景很多，比如典型的读者写者问题(Buffer) 因为OS内核和用户态程序的权限不同，所以实现同步互斥的方案也不太相同。
同步互斥的常见方案 per-cpu 变量 OS 内核里有些数据结构如果不需要CPU之间共享，可以定义成per-cpu形式。
比如说调度队列，每个CPU只关心自己核上队列的情况，如果想要访问其他CPU的， 比如进程迁移请通过核间通信IPI来做，并不能直接访问。
per-cpu 变量通常被安排在不同的 cache line，避免 cache 的频繁刷新
优点：多 CPU 之间互不干扰 缺点： 要求逻辑独立， 极少数临界资源可以实现为 per-CPU 形式 需要考虑内核抢占的影响，如果OS内核修改percpu变量时被调度，新的进程也可能修改这个变量。 如果在中断服务函数中可能修改，还需要另外关闭内核中断。 原子操作 如果临界资源只是一个基础类型变量，比如说一个Flag或者引用计数。那么实现同步互斥的逻辑就比较简单。
我们知道，如果多个CPU同时对一个变量做修改(flag++)，结果是不可知的。这是因为一次修改其实在处理器来看分为三步:
load mem =&amp;gt; register update register store register =&amp;gt; mem ISA 会提供一些原子操作的指令，将这三步绑定在一起，一旦有一个core执行了写动作，会对该内存总线独占， 只有此次写入完成后，其他core才能发起写入请求。</description></item><item><title>Linux Trace(1): Tracepoint</title><link>https://wangloo.github.io/posts/os/linux/trace/tracepoint/</link><pubDate>Sun, 23 Apr 2023 23:51:49 +0800</pubDate><guid>https://wangloo.github.io/posts/os/linux/trace/tracepoint/</guid><description>tracepoint 是 Linux trace system 中 data source 之一， 其 trace 的对象是 kernel，属于一种静态的插桩方法。
添加和删除需要手动修改内核源码 可以向上提供接口，可以通过 frontend 来开启或者关闭，也可以自定义数据处理方式 在 disable 时， 仅有一次 if 判断的损耗，所以效率还算高。但缺点是不够灵活。 tracepoint 的组成 看其源码struct tracepoint就能知道它的组成结构：
struct tracepoint { const char *name; #define TP_STATE_DISABLE 0 #define TP_STATE_ENABLE 1 int state; // 并非用于注册hook的函数，而是注册hook时的hook int (*reghook)(void); void (*unreghook)(void); // 在tracepoint触发时将调用的hook struct tracepoint_hook *hooks; }; name: 是该 tracepoint 的名称 state: 用于控制其开关状态 hooks: 是一系列的函数指针，当 tracepoint hit 时，这些函数会被依次调用 reghook/unreghook: 在注册/注销 hook 时将被调用，可以用来输出一些提示信息 为了提供对 tracepoint 操作的接口，定义一个 tracepoint 时，会同时定义一系列功能函数, 包括：</description></item><item><title>ARMv8 中断管理(3): 中断服务程序</title><link>https://wangloo.github.io/posts/armv8/gicv3/3/</link><pubDate>Thu, 13 Apr 2023 23:51:49 +0800</pubDate><guid>https://wangloo.github.io/posts/armv8/gicv3/3/</guid><description>从进入 IRQ/FIQ 中断向量开始，中断处理的完整流程:
保存上下文 切换中断栈，为进入“真正的”中断服务程序做准备 执行真正的中断服务程序 恢复之前的上下文 “真正的”中断服务程序 “真正的”意为不算那些对于所有异常、中断来说都相同的“套话” ，只讨论对于中断特有的行为。
承认一个中断 真正的中断服务程序从接受 CPU Interface 传来的中断 开始算起，这一步的实现通过读取ICC_IAR1_EL1, 返回当前 中断的 INTID。
拿到 INTID 后，就根据不同的 ID 调用各自对应场景下的服务函数， 比如若 INTID 是对应与时钟中断，那么此步需要清楚状态寄存器、 重新开启时钟定时器。
标记中断处理完毕 做完相干的事情后，需要将该中断标记为已完成，方便后面的中断进来， 也就是上一节说的优先级下降和中断失效过程。
GICv3 支持将这两步合为一次操作，实际我们也是这样做的，通过写入 ICC_EOI1_EL1寄存器来完成标记处理完成。此中断的状态也就从 active-&amp;gt;inactive.
中断服务程序中，承认中断和标记完成两步操作应该是用 while 循环 包裹起来的。
反复的读取 IAR、标记中断已完成&amp;hellip; 如果此时该 CPU 上已经没有 中断待处理了，读取 IAR 会返回特殊 INTID: 1023
中断的上下部机制 中断服务函数的停留时间应该越短越好，否则影响其他任务占用 CPU，这是老生常谈的。
以上观点存在的原因是：中断服务函数中是关闭中断的，CPU 只有串行的处理完当前 中断后， 才能继续做下一件事情，即便是高优先级任务也得等待，因为时钟中断被关闭！
所以 Linux 在 2.6 引入了中断的上下部机制，将整个中断服务函数拆分为上部和下部:
上部：那些不能被打断的步骤，比如保存上下文，承认和标记中断完成等 下部：宽松的管理方式，执行过程就算被打断也没关系，指的就是上面说的对应各自中断 应用场景下的服务函数，比如一个按键触发代表的实际行为 ARMv8 如何支持中断上下部 ARMv8 中，进入异常向量是自动关中断的，可执行msr DAIFClr, #imm来手动开启。</description></item><item><title>Linux 内核抢占</title><link>https://wangloo.github.io/posts/os/linux/schedule/kernel_preempt/</link><pubDate>Thu, 13 Apr 2023 23:51:49 +0800</pubDate><guid>https://wangloo.github.io/posts/os/linux/schedule/kernel_preempt/</guid><description>抢占的含义 抢占指的是强制使一个任务让出 CPU 给其他任务。
抢占是调度器做的，每次执行schedule()就可能发生一次抢占，所以 抢占发生的地点是内核，也就是schedule()的执行环境。
用户抢占 与内核抢占相对应的是用户抢占，用户抢占不是指抢占发生的地点，因为 上面说了抢占发生的地点一定是内核。
所以用户抢占的含义是：抢占的时机是用户态，换句话说就是抢占发生之前， 系统正处于用户态。
用户抢占的经典场景是时钟中断，用户进程 1 执行的好好地，被时钟中断打断 然后中断返回时执行重调度，选择了新的用户进程 2。其他的可能用户抢占的场景 还有系统调用返回时， 总之是内核返回用户态时都会发生用户抢占。
内核抢占 启用内核抢占增加了系统中发生抢占的点，即抢占前系统正处于内核。
当一个进程正处于内核态执行任务时，比如执行mmap()系统调用的任务，在 未开启内核抢占的情况下，中断返回时只可能继续执行当前进程的任务，不会 发生调度。
当启用内核抢占时，上述情况下若发生中断，系统在退出中断后，即使此时不是 返回用户态，也可以执行schedule()，即可以发生抢占。此之谓内核抢占。
抢占发生的条件 启用内核抢占之后，其实抢占的过程也不区分用户态和内核态，只要满足条件都会 执行schedule()。
执行重调度的条件有两个:
是否需要重调度? 是否可以重调度? 是否需要重调度也就是何时执行schedule()的问题，大概包含以下的场景:
时钟中断 新进程创建 修改进程的 nice 值 中断返回内核态 内核恢复为可抢占(下面会介绍) 然而有一些情况不可以重新调度，比如内核中一些关键的步骤，那些不能被打断的 原子操作。
在关键步骤之前，需要调用preempt_disable()，此时 linux 会在 tcb 中会改变 preempt_count的值，这个操作不是关闭中断，而是在中断返回时即使有更高优先级的其他进程， 只要该值不符合要求，重调度也不会发生。
关键步骤执行完，调用preempt_enable()，此时为了去满足关键区域内可能 有新加入的高优先级进程，会调用一次重调度，这也正是上面所说需要重调度的场景之一。</description></item><item><title>ARMv8 中断管理(2): 中断的生命周期</title><link>https://wangloo.github.io/posts/armv8/gicv3/2/</link><pubDate>Wed, 12 Apr 2023 23:51:49 +0800</pubDate><guid>https://wangloo.github.io/posts/armv8/gicv3/2/</guid><description>一个中断完整的生命周期大概包括:
产生中断 中断分发: by Distributor or Redistributor 中断传递: deliver to CPU Interface 中断激活: pending-&amp;gt;active 优先级下降: priority drop 中断失效: active-&amp;gt;inactive 中断的产生 外设传来中断信号，或者处理器触发 SGI， GIC 此时将该中断标记为pending状态。
中断的分发 中断生命周期中的重要部分，根据中断的类型不同可能由 Distributor 和 Redistributor 负责分发工作。
分发器查配置得到此中断的优先级，目的 CPU 等信息。此时可能有多个中断想要发往同一 CPU， 优先级决定先分发哪个中断。将其顺利分发目的 CPU 的 CPU Interface
中断传递 CPU Interface 做最后一步检查，是否满足优先级屏蔽? 是否符合抢占条件?
如果条件都满足，给 CPU 一个信号，CPU 准备激活中断
TODO: 关于running priority 和 highest pending priority的解释
中断激活 CPU 此时将触发 IRQ/FIQ，执行对应的中断服务程序。
中断服务程序中需要显式的执行一些操作将中断状态由 pending 置为 active。
异常向量（中断处理函数）的详细步骤见下一节
优先级下降和中断失效 优先级下降和中断的失效可以配置为同时发生，实际中我们也是这么使用的。</description></item><item><title>ARMv8 中断管理(1): 架构与GICv3</title><link>https://wangloo.github.io/posts/armv8/gicv3/1/</link><pubDate>Wed, 12 Apr 2023 21:51:49 +0800</pubDate><guid>https://wangloo.github.io/posts/armv8/gicv3/1/</guid><description>ARMv8 中断系统的架构 GIC 的输入为许多的中断线，但输出到 CPU 的只有 IRQ 和 FIQ 两种， 所以就要由 GIC 做中断的分发和过滤工作。
总体来说，整个中断系统架构从底向上可分为三部分:
硬件接口；外设的引脚 中断控制器；桥梁，向下提供引脚连接外设，向上连接 CPU 在合适的时间 触发中断信号，充当中断系统的主管 中断处理函数；GIC 将中断信号传递到 CPU 后，CPU 执行中断处理函数 +-----------+ +-----------+ | Process | | Process | +---------+-+ ++----------+ | | +-+--------+----+ | | | GIC | | | +-------+-------+ | +-------------+----------+ | Peripheral Device | +------------------------+ 中断控制器 GICv3 GIC 的有许多版本，本文皆以 GIC version3 为例介绍, 简称为 GICv3
如上所述，GIC 在中断系统中充当“管家”的作用。如果将 CPU 比作老板， 到来的中断比作约见老板的员工，那么 GIC 就是秘书，统筹安排何人何时 与老板谈话。</description></item><item><title>AArch64 内存属性与内存类型</title><link>https://wangloo.github.io/posts/armv8/memory_attr/</link><pubDate>Wed, 12 Apr 2023 08:01:33 +0800</pubDate><guid>https://wangloo.github.io/posts/armv8/memory_attr/</guid><description>有了虚拟内存系统之后，MMU 可以抽象出一些可配置的内存属性。
例如，配置某个虚拟内存区域为不可执行、不被 cache 等，不可执行的属性 有助于防范攻击，不进入 cache 经常划分给外设 Memory-mapped 区域。
内存属性和内存类型 首先，我们没法直接设置内存类型，我们能设置的是一些细粒度的内存属性字段， 比如说权限(WRX)、cacheable、shareable 等。
我们说的内存类型也就是某些有意义的属性字段相互组合，ARM 给出了两种内存类型: 普通内存和设备内存。
普通内存会启用架构提供的所有优化技术，例如合并访存、乱序执行等。所以 普通内存有最高的性能，但同时不是那么的“安全”，需要底层人员手动使用 内存屏障等手段保证某些情况下的顺序性要求。
设备内存，顾名思义，常映射到外设的 Memory-mapped 区域。对于设备来说， 那些提高性能的技术会造成一些问题，例如某些寄存器的配置必须按照顺序， 这时就不能使用乱序执行。设备内存就牺牲了性能，优先保证正确性。
配置内存类型也是通过页表项中的其中一个属性字段: AttrIndx[2:0], 它与系统寄存器MAIR_EL1配合实现。
具体表现为: mair_el1寄存器被划分为 8 个字段，我们为每个字段写入 不同的值可代表不同的内存类型和一些配套属性，具体的真值表可以参见 mair_el1寄存器的描述。
mair_el1中内存类型配套属性只是属性的一部分，是和设备类型绑定的那部分。
cacheable&amp;amp;shareable 傻傻分不清 先说 cacheable，一段内存被设置为 non-cacheable 属性说明不会进入 cache， inner-cacheable 是实现定义的，可能指进 L1 cache/L2 cache， outer-cacheable 说明会进入 L3 cache。
要注意，只有普通内存才支持配置是否进入 cache，所有的设备内存需要 non-cacheable。
内存支持配置为是否被 cacheable，这在mair_el1的字段中配置。
shareable 说的是一块内存的外部可见性，外部不可见并不是真的看不到，只是说不保证值的正确性。
shareable 属性和 cacheable 其实是有关联的，他们俩比如配合使用，不能随便设置:</description></item><item><title>Python 基础知识</title><link>https://wangloo.github.io/posts/python/basic/</link><pubDate>Sat, 01 Apr 2023 10:30:35 +0800</pubDate><guid>https://wangloo.github.io/posts/python/basic/</guid><description>为什么写 因为平常的工作中很少用到python, 但是不得不承认 python是一门优秀的语言, 对于我目前要准备秋招的情况来看, 有的公司做题如果支持python那会简单很多, 同样的代码,用C写要100行, 换到python最多30搞定.
有人说C++也可以啊,而且对于常用C的人来说学习门槛更低, 但是我实在是受不了 C++的语法, 包括但不限于模板、迭代器，STL操作，感觉有点四不像的味道。 当然，这只是我的个人习惯，使用C++的人也是很多的，还是根据自己的习惯 选择一套趁手的工具比较好。
因为我其他时间基本都在用C，所以在本篇文章中我会更多拿C来进行比较，这样更好记忆。
我学习 Python 的知识点来源:
《Python 学习手册 第 4 版》李军等 UCB CS61A 列表 list 列表支持下标索引，所以它就像C语言中的“数组”，列表支持大小动态增长，所以更像“数组plus”，类似C++中的vector吧（不太确定）。
列表支持定长声明或变长声明，像创建一些flag列表，用下标进行查找时，定长创建就是必要的。
相关操作 创建一个列表 以下的创建操作都是支持的:
# 创建一个空列表 lst = [] # 创建一个带有初值的列表 lst = [1, 2] # 创建二维空列表 # 应用的场景是: 按照索引来修改list, 此时如果单纯的初始化list=[], # 那么对list[1].append()会提示超出范围. 所以我们要提前规定list的长度, # 即将list声明为目标长度的二维list. lst = [[] for _ in range(5)] # 创建定长列表并附初值 lst = [0 for _ in range(5)] # 创建二维定长列表并附处置0 lst = [[0 for _ in range(5)] for _ in range(5)] 以下的方式是错误的!</description></item><item><title>Linux Kconfig 概述</title><link>https://wangloo.github.io/posts/os/linux/kconfig/</link><pubDate>Tue, 28 Mar 2023 16:15:03 +0800</pubDate><guid>https://wangloo.github.io/posts/os/linux/kconfig/</guid><description>Kconfig 介绍 Kconfig 是一个通用的配置系统，最初由 Linux 开发，提供了一种简单的可扩展的配置语言， 实现工程的模块化和可定制需求。
在简单的工程中，或许我们使用简单的 C 语言宏就能解决问题，不必用到 Kconfig。 但对于大型项目，并不只是一个选项的开启和关闭，并不只是影响到源代码，还有基于 Makefile 的编译工作。并且，当可配置的选项增加时，开发者手动管理这些配置选项就显得不那么智能了。
Kconfig 的出现使得上述工作变得轻松：
在 build 前，我们可以使用图形化界面来选择此次构建启用了哪些编译选项, (menuconfig) 对于不同的厂商驱动，可以有不同的配置文件，厂商可以为我们提供一个默认的 config 文件，我们可以方便的应用这些默认选项进行编译, 或者基于这些默认选项进行改动，保存为自己的配置项文件(defconfig) 选项之间可以建立依赖关系，例如，只有 A 启用时，BCD 选项才有意义。对此 Kconfig 提供了一套简单上手的编辑语言 Kconfig 的使用必须配合 Makefile 进行，应该说，Kconfig 与 Makefile 结合是简化了 Kconfig 的使用步骤。
Kconfig 的使用方法 我们常用的功能大概包括：
使用一些默认配置文件来构建项目 自定义配置构建项目 将某套配置选项保存下来，方便下次使用 在分别介绍这些功能的使用方法之前，先得说明这些 Kconfig 中各种配置文件的用途了，还是比较容易混淆的。
Kconfig: Kconfig 不仅在根目录，还可能存在于各级子目录下。里面的内容是整个 Kconfig 系统的所有配置项，以及每个配置项的默认值、描述等。如果想要添加、删除配置项，需要改动这个文件 xxxdefconfig: xxx 可以替换为任意字符，这些都是默认的配置项，通常由开发人员提供给使用者 .config: 这个文件存在于根目录下，我们可以叫他当前配置。可以把他当为服务与一次构建的“临时文件”，每次构建都是基于当前配置进行的 autoconfig.h: 由 Kconfig 系统根据当前构建使用的配置自动生成的头文件，C 源代码可以通过它来知道当前的配置情况 其实它们之间的关系不是那么复杂，到底是谁根据谁生成的谁，下面将要说明。</description></item><item><title>C 语言enum的使用</title><link>https://wangloo.github.io/posts/c/enum/</link><pubDate>Thu, 09 Mar 2023 17:18:57 +0800</pubDate><guid>https://wangloo.github.io/posts/c/enum/</guid><description>枚举类型的优势 枚举类型完全可被宏定义替代，类如
enum Furniture { DOOR = 1, DESK, LOCK, } 与下面的代码等效
#define DOOR 1 #define DESK 2 #define LOCK 3 那么我们如何在两种设计方法中选择呢？在我看来某些情况下使用 enum 会有以下优势：
提高代码键入效率；仅适用于所需变量的值是连续的整数，就像上面的情况，可以只给第一个 DOOR 赋值，其余的值累加。如果首个变量的值要求是 0，甚至每一个都无需显式赋值 提高代码的可维护性；可以划定范围，编译器也会检查类型是否正确，偶尔会有用 提高代码的可读性；例如 DOOR, DESK, LOCK&amp;hellip; 都属于家具，均定义在 Furniture 中 枚举类型所占的大小 枚举类型所占内存的大小，即枚举变量的大小。
由于枚举变量的赋值，一次只能存放枚举结构中的某个常数。所以 枚举变量的大小，实质是常数所占内存空间的大小（常数为 int 类型，当前主流的编译器中一般是 32 位机器和 64 位机器中 int 型都是 4 个字节），枚举类型所占内存大小也是这样。
所以默认情况下，无论枚举变量的值是多少，都是占用 4 个字节。即执行：
printf(&amp;#34;sizeof(enum Furniture) = %d\n&amp;#34;, sizeof(enum Furniture)); 输入的结果是 4。
编译选项：-fshort-enums GCC 下关于这个编译选项的介绍：
-fshort-enums Allocate to an enum type only as many bytes as it needs for the declared range of possible values.</description></item><item><title>C 语言的特点与难点</title><link>https://wangloo.github.io/posts/c/feature/</link><pubDate>Thu, 09 Mar 2023 17:18:57 +0800</pubDate><guid>https://wangloo.github.io/posts/c/feature/</guid><description>函数指针 指针的数组 or 指向数组的指针? &amp;gt;&amp;gt; int (*p)[10] p是指针, 指向长度为10的数组. 加括号是为了强调p是一个指针, 区别包含10个指针的array. &amp;gt;&amp;gt; int *(p[10]) p是数组, 它的元素类型是int *, 加括号是为了强调p是数组. &amp;gt;&amp;gt; int *p[10] 等效于int *(p[10]) 程序的内存分布 我们写的高级语言代码最终会被编译成可执行文件被操作系统加载、执行。 ELF文件是由一个个section组成的，那么程序里的变量、指令都是如何排布的呢？
地址空间各部分 内容 是否与可执行文件相对应 代码段 所有的可执行代码, 属性一般为只读 是, 加载时直接映射 数据段 初始化非0的全局变量和局部static变量 是, 加载时直接映射 bss段 未初始化或初始化0的全局变量和局部static变量 是, 加载时需要清空 栈 局部变量, 参数传递等 无, OS分配空间, 编译器维护 堆 动态申请的空间 无, OS分配空间 常量区 定义的常量字符串等 是, 有时和代码段合并到一起 有的人喜欢说“静态区”这个概念，我也一直被忽悠不理解什么叫静态区。实际上就是表示 存储函数内部static变量的区域，本质上属于数据段的一部分。</description></item><item><title>C 语言程序设计的一些经验</title><link>https://wangloo.github.io/posts/c/experience/</link><pubDate>Mon, 27 Feb 2023 19:20:20 +0800</pubDate><guid>https://wangloo.github.io/posts/c/experience/</guid><description>头文件的引用形式 C 中引用一个头文件有两种形式 #include &amp;lt;&amp;gt;和#include &amp;quot;&amp;quot;，在应用开发中，需要引用一些系统库文件，我们通常使用&amp;lt;&amp;gt;，对于自己定义的头文件，我们会使用&amp;quot;&amp;quot;。
然而对于底层软件的开发，比如说操作系统，用到的库都是自己工程中的文件，那么此时用&amp;quot;&amp;quot;和&amp;lt;&amp;gt;有时都能 work，那么它们的区别是什么呢？
搜索相关关键词得到的结论是: 两种方式的区别是搜索文件的优先级， &amp;quot;&amp;quot;优先搜索的当前目录，而&amp;lt;&amp;gt;优先搜索系统库文件目录。对于这个系统库，即那些使用gcc -I&amp;lt;dir&amp;gt;参数指定的路径。 当然，如果第一优先级位置没有被找到，也会到另一个目录中搜索。这么两种方式均可，实际工程中也有部分人混合使用，毫不在意规则。但是有时会导致一些细节问题，比如说我们经常会用到-MMD或者类似选项生成目标文件的依赖，方便实现增量编译。此时就可能会产生一些问题。
假设你有一个头文件inc/father.h, 它里面会引用inc/child.h, 对于根目录下的源文件main.c，其引用语句该如何写呢？以下列出的几种形式都可以，任意的排列组合
// 编译参数: -I. -MMD // main.c #include &amp;#34;inc/father.h&amp;#34;#include &amp;lt;inc/father.h&amp;gt; // father.h #include &amp;#34;inc/child.h&amp;#34;#include &amp;lt;inc/child.h&amp;gt;#include &amp;#34;child.h&amp;#34;#include &amp;lt;child.h&amp;gt; 如果 main.c 是使用系统库路径(-I.)来找到的 father.h, 即上面 main.c 的第 2 种情况，那么其生成依赖文件的形式内容都是绝对路径，包括 father.h 中的引用（因为即便 child.h 是相对路径找到的，相对的也是 father.h，其基准就是绝对路径）。例如:main.o: main.c /home/xx/father.h /home/xx/child.h 否则即以相对路径找到 father.h,即上说 main.c 的第 1 种，那么生成 father.h 依赖的方式一定是相对路径，但 child.h 的形式却取决于其本身. 也就是说，如果 child.h 的寻找方式是绝对的（上面的第 1,2,4 种），那么依赖文件的形式就是main.o: main.c inc/father.h /home/xx/child.h. 如果 child.h 的寻找方式是相对的(上面的第 3 种)，那么依赖文件的形式是main.</description></item><item><title>Sed/Awk/Grep 三剑客</title><link>https://wangloo.github.io/posts/tools/sed_awk_grep/</link><pubDate>Tue, 03 Jan 2023 19:28:12 +0800</pubDate><guid>https://wangloo.github.io/posts/tools/sed_awk_grep/</guid><description>Sed Sed stands for Stream Editor.
Basic sed syntax:
sed [options] {sed-commands} {input-file} Sed reads one line at a time from the {input-file} and executes the {sed-commands} on that particular line
The input 并非必须是文件
echo &amp;quot;Some string&amp;quot; | sed '' 当然也是支持的.
Option: -n 通常sed是按照行来处理文本的, 然后打印处理后的结果. 然而并不是符合匹配的行被打印, 所有的行都会被打印. 例如sed 's/t/T/'会输出所有的行, 并且替换其中某些行的t.
这样的结果不是我们想见的(大多数情况下), 所以, 我们可以添加-n option 来 禁止自动打印所有内容, 例如sed -n 's/t/T/' 不会输出任何结果.
如果想要将匹配的结果单独打印, 则sed为我们提供了p命令. 例如, sed -n 's/t/T/p' 只会打印替换后的行.</description></item><item><title>行结束符在windows和linux的区别</title><link>https://wangloo.github.io/posts/os/linux/end-of-line/</link><pubDate>Sat, 24 Dec 2022 01:35:24 +0800</pubDate><guid>https://wangloo.github.io/posts/os/linux/end-of-line/</guid><description>使用VIM 打开一个文件时, 有时会看到例如 ^M 这类字符出现. 下面我会挖一下其出现的原因.
EOL 字符 EOL 或者说 end-of-line 表示一个新行的开始.
EOL 字符在不同的操作系统中是不同的. 本文中仅以 Linux 和 Windows 为例说明.
Windows中是以读到回车&amp;lt;CR&amp;gt;和换行&amp;lt;LF&amp;gt; 表示 EOL. Linux 中仅以换行作为EOL 回车&amp;lt;CR&amp;gt; : Carriage return. 将光标回到行首, 对应C语言中的 \r 换行&amp;lt;LF&amp;gt; : Line feed. 将光标下移一行, 对应C语言中的 \n 在 Linux 中打开 Windows 下的文件将多余的回车通常显示成 ^M 或者 Control-M
Ref End Of Line Characters</description></item><item><title>操作系统：浅谈 errno 的线程安全问题</title><link>https://wangloo.github.io/posts/os/errno_thread_safe/</link><pubDate>Wed, 21 Dec 2022 19:08:22 +0800</pubDate><guid>https://wangloo.github.io/posts/os/errno_thread_safe/</guid><description>我始终以为，C库中常用的 errno 仅是一个全局变量，使用了全局变量就无法保证线程安全了，因为全局变量在所有线程中都是共享的。
要实现线程安全的errno 就必须将其设置为线程私有的变量，下面就来看看GCC是如何巧妙的实现的。
正文 现在的errno定义并非一个全局变量, 而是一个宏定义, 以下是在usr/include/errno中的声明:
extern int *__errno_location (void); # define errno (*__errno_location ()) 这种方式下其实现原理大概是: __errno_location 函数返回一个int指针, 而这个函数的实现中, 返回的就恰好是实际的errno 变量(与宏同名)的地址, 所以对其解引用就相当于对其值进行操作. 所以, 这种定义规则下, 左值和右值表达式均成立.
errno = 10; // *__errno_location () = 10 int x = errno; // x = *__errno_location (); __errno_location 的实现就至关重要, 因为如果其返回的变量地址不包含任何技巧的话, 就和原先直接定义全局变量的方式没差了, 说到底能否实现线程安全, 还得看实际保存errno的变量是否为线程独有的. 目前还没有发掘到其精髓, 只是套壳而已.
以下给出/csu/errno-loc.c中__errno_location 的实现, 与我们预期一致, 返回变量的地址. 而同名变量errno则定义在/csu/errno.c中, 决定了能够实现errno的线程安全.
int * __errno_location (void) { return &amp;amp;errno; } __thread int errno; &amp;ldquo;__thread&amp;rdquo; 是GCC提供的扩展前缀, 表示该变量将被库处理为线程私有的, 注意这一步是C库完成的, 对程序员透明.</description></item><item><title>git 宝典</title><link>https://wangloo.github.io/posts/tools/git/git/</link><pubDate>Tue, 13 Dec 2022 17:39:42 +0800</pubDate><guid>https://wangloo.github.io/posts/tools/git/git/</guid><description>合并操作: git merge merge行为的语义是将其他分支的修改合并到当前分支。由此就产生了两种内部的实现原理， 以下均假设当前分支为main，其他分支为dev：
fast-forward： three-way merger： Fast-forward Merge main是dev的某个直接祖先，或者说他们之间是一条线的关系。此时将dev的修改合并进来相当于移动main指针指向dev的最新commit(F1)。此时merge称为 fast-forward.
例如, 当前在 main, 执行git merge dev的过程如下:
main main | | M1 --- M2 ===&amp;gt; M1 --- M2 -- F1 \ | \--- F1 dev | dev three-way Merge 合并的两者不构成直接的祖先-孩子关系，也就意味着main和dev分别位于两个分叉上（见下图左）。此时merge的步骤就相对复杂：
找到main和dev的公共祖先M2 列出main和dev分别基于公共祖先来说做了哪些修改 如果两条分叉的修改不冲突，完美合并 经常出现的是，两个分叉难免对同一片段做了不同修改，此时标记为冲突，等待用户解决 因为main和dev位于两个分叉，合并会新建一个节点（M4），commit的信息是“Merge dev into main”。如果步骤2中产生冲突了，那么解决冲突的行为就被记录到M4的diff。没有冲突时diff是空的。 main main | | M1 --- M2 --- M3 ===&amp;gt; M1 --- M2 --- M3 --- M4 \ \ / \--- F1 \--- F1 --- | | dev dev 因为此时merge需要借助三个 commit(main, dev, 公共祖先)，这种操作就叫做 three-way merge。</description></item><item><title>电子电路基础笔记</title><link>https://wangloo.github.io/posts/ee/</link><pubDate>Wed, 07 Dec 2022 10:30:35 +0800</pubDate><guid>https://wangloo.github.io/posts/ee/</guid><description>铜厚常规的1盎司，盎司是重量单位，1盎司的铜平铺到1平方米的面积上， 其厚度就是35μm。
整流电路 整流：交流转直流，最简单的整流电路就是串联一个二极管。 逆变：直流转交流。 倍压整流 没有变压器的情况下，220V经过阻容降压+倍压整流给芯片供电。
桥式整流电路 220V交流电先经过变压器变为12V左右交流电 整流器将其转为直流电 16V左右 滤波电容滤波 7812稳压12V 再滤波（大电解+小无极） 先整流再变压 现代开关电源的工作大致是：整流&amp;mdash;经过开关电路&amp;mdash;变成高频交流&amp;mdash;经高频变压器变压&amp;mdash;整流、滤波&amp;mdash;直流。 因为市电是50Hz低频，220V直接变压的话，频率低导致变压器绕线要长，从而使得变压器体积会很大。 所以都是要两次整流操作。
PWM 占空比 占空比: 高电平持续的时间占整个周期的百分比
输出的平均电压 = 高电压 x 占空比
所以通过调整占空比就能调整输出的平均电压.
频率 仅通过调整占空比, 只能完成高电平时电机全速转动, 低电平时停止转动的效果. 不能达到我们的预期, 所以还需要PWM的另一个参数: 频率
通过提高频率使得电机还未停下来时就又到达下一个高电平.
稳压二极管 特性 稳压二极管反向接入电路是能够实现两端电压恒定, 工作时的状态是反向击穿, 能一直稳定在这个状态不会坏.
稳压二极管的参数有两个: 稳压值和功率. 如果输入的电压小于其稳压值, 那么稳压作用消失, 如果大于稳压值, 那么稳压二极管两端的电压总是等于稳压值. 由于稳压二极管两端的电压是恒定的, 其功率的含义就是最大通过的电流.
由于有功率的限制, 所以必须要串联限流电阻使用, 避免电流太大烧坏稳压管,
限流电阻的计算 首先, 稳压二极管有最小工作电流, 通常为3-5mA, 规定了限流电阻的最大值.
其次, 限流电阻需要确保二极管工作在规定的功率内, 因为当负载过大(极限状态下是空接)时, 所有的电流都通过稳压二极管. 按照其功率的1/2, 除以其稳压值就是工作电流.</description></item><item><title>Makefile 一些技巧</title><link>https://wangloo.github.io/posts/c/make/makefile_tricks/</link><pubDate>Sat, 03 Dec 2022 19:08:22 +0800</pubDate><guid>https://wangloo.github.io/posts/c/make/makefile_tricks/</guid><description>make命令参数 # 仅输出所有命令，不实际执行，调试用 make -nB 伪目标的依赖关系 Makefile 中的依赖关系指的是目标和依赖之间建立的关系，目标对应规则中的语句是否执行取决于依赖的状态。
最简单的依赖关系可以拿两个文件来举例:
# gcc语句执行当前仅当 main.c 新于 main.elf main.elf: main.c gcc main.c -o main.elf make 在执行main.elf的规则时，会先判断依赖关系。拿上面的例子来说， gcc 语句是否执行取决于main.c 和 main.elf的修改时间，只有当 依赖新与目标时，规则语句才会执行。
然而许多情况下，目标或者依赖并不是一个文件，而是虚拟目标。虚拟目标 并不是一个文件，即它没有修改时间这个属性，此时 make 就不能作比较，结果就是 如果目标是伪目标，那么不管依赖如何都执行规则语句；如果依赖是伪目标， 那么目标的规则语句也永远被执行。下面是两个例子：
# 伪目标作为目标文件出现 # build finish总是输出， 而gcc语句仅当main.c比main.elf新时才执行 .PHONY : all all: main.elf @echo &amp;#39;build finish&amp;#39; main.elf: main.c gcc $&amp;lt; -o $@ # 伪目标作为依赖文件中出现 # 不管main.c是否比main.elf更新，因为pre-work是伪目标 # 所以gcc语句总是执行 .PHONY : pre-work main.elf: main.c pre-work gcc $&amp;lt; -o $@ 上面的代码的效果是：两条规则中的语句都会执行，即使你并没有对 main.</description></item><item><title>Uboot: 常用命令</title><link>https://wangloo.github.io/posts/os/uboot/commands/</link><pubDate>Sun, 27 Nov 2022 22:03:48 +0800</pubDate><guid>https://wangloo.github.io/posts/os/uboot/commands/</guid><description>..
环境变量相关 内存操作 网络操作 EMMC和SD卡 BOOT操作指令 bootm go 其他命令 启动相关
md
mmcinfo
cp</description></item><item><title>常用的 shell 命令</title><link>https://wangloo.github.io/posts/shell/shell-commands/</link><pubDate>Sun, 27 Nov 2022 14:45:58 +0800</pubDate><guid>https://wangloo.github.io/posts/shell/shell-commands/</guid><description>开发 mkfs.ext4 格式化文件为ext4分区
mkfs.ext4 &amp;lt;file&amp;gt; # 将file格式化为ext4 dd https://www.runoob.com/linux/linux-comm-dd.html
mount sudo mount [file] [dir] # 挂载file到dir sudo umount [dir] sudo mount # 输出当前已经挂载的分区 find # 查找24小时内修改过的文件 find . -mtime 0 # 查找2小时内修改过的文件 find . -mmin -$((2*60)) # 查找24小时内访问过的文件 find . -atime 0s 通用 执行cp命令时，如果目录下有链接文件，拷贝源文件而不是链接文件，这在链接文件指向相对地址时非常有用。
cp -rL /path/to/ /path/from 搜索目录文件内容包含关键字
# n: print line number # r: recursive search grep -nr &amp;#34;pattern&amp;#34; 查看当前用的是哪个shell:
echo $0 which 查看可执行文件的位置，whereis 除了可执行文件还能搜索其他类型的文件, 不常用, 详见 man whereis</description></item><item><title>C 语言工具宏</title><link>https://wangloo.github.io/posts/c/c-macros/</link><pubDate>Thu, 24 Nov 2022 01:35:24 +0800</pubDate><guid>https://wangloo.github.io/posts/c/c-macros/</guid><description>计算数组元素的个数 #define nelem(array) sizeof(array)/sizeof(array[0])</description></item><item><title>C语言 "inline" 关键字</title><link>https://wangloo.github.io/posts/c/inline/</link><pubDate>Thu, 24 Nov 2022 01:35:24 +0800</pubDate><guid>https://wangloo.github.io/posts/c/inline/</guid><description>TODO: inline 的发展历程: Myth and reality about inline in C99 – Jens Gustedt&amp;rsquo;s Blog (wordpress.com)
GNU89: 函数的实现之前添加不同的关键字:
inline: 表明这个函数可能被优化. 如果没有被优化, 编译器就会视为一个常规函数的定义.
extern inline: 表明这个函数可能被优化. 如果没有被优化, 编译器就将这个函数的定义转换为该函数的声明, 即 extern inline func(); 因此当此函数被调用时, 可以调用一个外部的函数来替代. 如果没有函数调用它, 那么也可以没有外部的替代函数实现.
static inline: 表明这个函数可能被优化. 如果没有被优化, 编译器就会视为一个常规静态函数.
C99: 函数的实现之前添加不同的关键字:
inline: 等效于gnu89中的extern inline extern inline: 等效于gnu89中的inline static inline: 与gnu89相同含义. C++: 只有inline一个关键字, 如果不能优化就定义为普通函数
Ref:
c++ - What does extern inline do?</description></item><item><title>AArch64/X86 函数调用约定</title><link>https://wangloo.github.io/posts/armv8/function-call-conventions/</link><pubDate>Mon, 21 Nov 2022 10:30:35 +0800</pubDate><guid>https://wangloo.github.io/posts/armv8/function-call-conventions/</guid><description>符合调用约定使得调用函数能够正常获取参数, callee结束之后能够回到原来位置继续执行.
X86 调用约定 函数调用 x86架构中, 函数调用以一条call指令为分界.
在call指令执行之前, 所有的参数必须都躺在栈中, 参数入栈的规则是: 第一个参数最后入栈.
另外, 执行call指令之前, 必须确保栈指针esp是16-byte对齐. 这项工作是编译器完成的, 如果它判断参数入栈之后的esp 不满足对齐条件, 则会手动调整esp使之对齐. 实现方式见下面例子.
call 指令的语义是:
push pc+1 ;push next insttuction mov pc, func ;set pc = new function call 指令之后的下一条指令就是callee的内容了, 至此就算是进入新函数的地盘.
但是在执行新的任务之前, callee还需要完成栈的转换, 因为此时使用的栈还是caller的.
push ebp ;preserve location of caller&amp;#39;s stack mov ebp, esp ;new ebp is old esp 此时esp也就是栈指针等于ebp, 这是callee栈的初始条件. 万事俱备, 可以开始执行callee的实际任务了.
ebp在整个函数执行过程中是固定的, 好处是: 能够快速的或者函数参数, 返回地址.
函数返回 callee执行完毕后, 需要返回到caller继续执行. 刚才说过, callee的返回地址在栈中, 所以我们要做的是找到返回地址所在的位置, 然后使pc = 返回地址.</description></item><item><title>二级指针操作链表技巧</title><link>https://wangloo.github.io/posts/c/pointers-pointers-list/</link><pubDate>Sun, 20 Nov 2022 23:40:30 +0800</pubDate><guid>https://wangloo.github.io/posts/c/pointers-pointers-list/</guid><description>问题源于我在知乎刷到的一个回答: 能分享你C指针用得最灵活（飘）的一次吗?
文中提到了Linus关于无头节点单项链表的删除操作给出的一种新的思路, 我觉得对理解指针非常有帮助, 所以在这里详细描述一下这件事.
从我学习数据结构起, 对不含头节点的单向链表的删除操作, 做法常是: 借用pre指针搜索. 这种情况下避免不了对于链表中第一个节点的特判(第一个节点没有pre).
Linus提到了一种借助二级指针避免该分支的方法.
void remove_if(node ** head, remove_fn rm) { for (node** curr = head; *curr; ) { node * entry = *curr; if (rm(entry)) { *curr = entry-&amp;gt;next; free(entry); } else curr = &amp;amp;entry-&amp;gt;next; } } 指针的内容就是地址, int *p = a 也就意味着变量p 中保存着变量a的地址. 所以参数head在内存中的含义为:
假如要删除node2, 那么改变*curr实际上就是改了node1的next成员.</description></item><item><title>操作系统：大小端问题</title><link>https://wangloo.github.io/posts/os/big-little-endian/</link><pubDate>Thu, 17 Nov 2022 10:30:35 +0800</pubDate><guid>https://wangloo.github.io/posts/os/big-little-endian/</guid><description>大小端问题的由来 为什么计算机世界需要区分大小端? 内存里存取的单位是字节, 如果所有的数据类型长度都是一个字节, 那就完全不需要大小端了, 每个变量都仅占据单独一个字节.
例如, 三个变量 a=10, b=20, c=30, 在内存中的布局可能就是:
┌────────────┐ │ │ │ 10 │ a ├────────────┤ │ │ │ 20 │ b ├────────────┤ │ │ │ 30 │ c ├────────────┤ │ │ │ │ │ │ │ │ │ │ └────────────┘ 但是我们最常使用的数据类型肯定有超过一个字节的, int类型在64位的系统中就占4个字节. 例如变量a=0xaabbccdd
一个变量的大小一旦超过4个字节, 内存的存取又是以字节位单位的, 那么要把它塞到内存里就必然会产生两种不同存放方式: 先放0xaa还是先放0xdd
首先, 0xdd是变量a的低8位, 0xaa是最高8位, 这是确定的.
如果先放0xaa, 即低地址放高位, 就叫做大端, 如左图;
如果先放0xdd, 即低地址放低位, 就叫小端, 如右图.
startaddrof`a`startaddrof`a`┌────────────┐┌────────────┐│││││aa││dd│├────────────┤├────────────┤│││││bb││cc│├────────────┤├────────────┤│││││cc││bb│├────────────┤├────────────┤│││││dd││aa│├────────────┤├────────────┤││││││││└────────────┘└────────────┘什么情况?</description></item><item><title>操作系统：上下文切换</title><link>https://wangloo.github.io/posts/os/context/</link><pubDate>Mon, 14 Nov 2022 22:13:06 +0800</pubDate><guid>https://wangloo.github.io/posts/os/context/</guid><description>本文基于AArch64执行环境, 介绍现代操作系统中上下文切换的相关内容.
何为上下文 我们正在看一本书的时候如果被其他的事情打断, 返回时为了能够从上次被打断的位置继续读, 就要在被打断的时候记下来当前是读到了哪个第几页的第几行.
操作系统对待线程也是如此, 需要保存的用于恢复线程执行的信息就称为线程的上下文.
那么对于线程来说需要记下的内容有什么呢? 寄存器和栈即可. 拿 AArch64 架构来距离, 线程的上下文就是:
通用寄存器x0-x29: 函数调用的参数, 某些计算过程的中间值, 都要用到这些寄存器. 线程的执行流可能在任何时候被打断, 当然这些内容也不能丢. 通用寄存器lr(x30): lr 保存着返回地址, 即当前函数结束之后该返回到哪执行. 栈顶指针 sp: 栈的重要性无需多言. 程序计数器 pc: 被打断的线程如果再次执行, 从哪里执行呢? 显然是被打断指令的下一条(或者重新执行当前). 这个指令的地址当然也需要被保存好. PSTATE: 想一下, 有了以上的内容就能够保证线程完整的恢复之前的环境吗? 其他的例如中断是开还是关, 有哪些标志位(NZCV)被设置了. 这些信息在 AArch64 中是保存在 PSTATE 的各个字段中. ttbr0：保存着进程的页表 上下文保存和恢复 TODO
协程的上下文 协程是用户级别的线程,
协程之间的切换不进入内核 切换协程只能是某个协程主动放弃控制权 我们在这里讨论一下协程切换时需要保存的上下文是否与线程有所不同.
首先, PC 一定属于, 这个毋庸置疑. 其次是栈顶指针 sp, 每个协程都有单独的栈, 如果不保存栈的位置, 那么协程内部定义局部变量就没法访问了(局部变量的访问指令都是以 sp 为 base 的偏移来做的).
另外, 关于通用寄存器, 由于协程的切换需要主动调用某个函数(通常叫做yield()), 在函数的最后将 PC 设置为新协程的上下文 PC.</description></item><item><title>ARM64 上实现 setjmp/longjmp</title><link>https://wangloo.github.io/posts/c/setjmp_and_longjmp/</link><pubDate>Tue, 01 Nov 2022 23:38:54 +0800</pubDate><guid>https://wangloo.github.io/posts/c/setjmp_and_longjmp/</guid><description>介绍 setjmp() and longjmp() 是一对组合使用的函数, 可以实现全局的goto.
setjmp() 构造一个运行环境, 调用longjmp() 则将执行流切换到该环境.
/* setjmp() 保存当前的运行环境(上下文)到 env 参数中 */ int setjmp(jmp_buf env); /* longjmp() 将控制流切换到 env 指定的运行环境 */ void longjmp(jmp_buf env, int val); 使用方法 #include &amp;lt;setjmp.h&amp;gt;#include &amp;lt;stdio.h&amp;gt; jmp_buf e; void foo() { longjmp(e, 1); } int main(void) { int ret; /* After calling longjmp(), the execution flow back to setjmp(), and setjmp() will return not 0. */ ret = setjmp(e); if (ret == 0) { printf(&amp;#34;Return from setjmp\n&amp;#34;); foo(); } else { printf(&amp;#34;Return from longjmp\n&amp;#34;); } return 0; } 基于 AArch64 的实现 .</description></item><item><title>Armv8 Kernel Monitor</title><link>https://wangloo.github.io/posts/os/monitor/</link><pubDate>Fri, 28 Oct 2022 22:56:19 +0800</pubDate><guid>https://wangloo.github.io/posts/os/monitor/</guid><description>Kernel Monitor 是什么 Kernel Monitor 是一个适配我们微内核操作系统的 Kernel 调试和监控系统. 它能实现内核的动态调试和监控. 同时, 它还接管内核的同步异常和系统错误, 使开发者能够了解发生异常时系统的状态.
Kernel Monitor 具有一定的可扩展性, 例如通过统计内核中存储的 TCB 来实时监控系统中所有线程的状态. 可根据开发者的需求添加统计的对象, 如 Endpoint, Capability等.
 Kernel Monitor 总体设计 Kernel Monitor 系统包含 Clinet 和 Server 两个部分. 简单来说, Client 负责处理用户输入, 并将输入进行解析, 封装为 一系列基础命令. 发送给 Server. Server 负责执行这些 基础的命令, 如设置断点, 查看某个地址的值等.
整个系统有两种架构: 本地 Monitor 和远程 Monitor.
本地monitor 和远程 monitor 的区别是: Monitor Client 的位置在哪, 是否与 Server 在同一个机器上.
先说 Monitor Server, 它必须嵌入要调试的 Kernel 中, 位于一个地址空间, 方便操作 Kernel 的内存.</description></item><item><title>AArch64 MMU介绍</title><link>https://wangloo.github.io/posts/armv8/mmu/</link><pubDate>Thu, 29 Sep 2022 08:01:33 +0800</pubDate><guid>https://wangloo.github.io/posts/armv8/mmu/</guid><description>Introduction MMU: 专用于将虚拟地址转换为物理地址. 通常配合分页机制来工作.
页表: 页表中的表项包含提供虚拟地址和物理地址之间的映射.
MMU就是直接访问页表, 并且通过将频繁使用的映射缓存到TLB中.
MMU 的结构 MMU是一种硬件, 可以通过在适当的安全状态下对其进行配置. 每个Core都有自己的MMU, 每个MMU包括:
一个TLB, 缓存最近访问的映射. 一个Table Walk Unit, 从内存中查询页表, 得到最终的虚拟地址-物理地址的映射. MMU 控制着整个系统的缓存策略, 内存属性和访问权限. MMU开启后, 软件发出的所有内存访问都使用虚拟地址, 要求MMU为每次访问进行地址转换.
MMU 的配置 在启用MMU前, 必须告知其页表存放的位置.
MMU 地址转换的过程 对于每个转换请求, MMU首先检查TLB是否已经对该地址缓存, 如果该地址未缓存, 则需要遍历页表.
页表遍历单元在页表中搜索相关的映射表项.
一旦找到映射, MMU就会检查权限和属性. 决定允许本次访问, 或者发出故障信号. 若未找到映射, 则触发缺页异常. 页表的工作原理 页表的工作方式是将虚拟地址空间和物理地址空间划分为大小相等的块, 称为页面.
页表中的每个表项对应着一块虚拟地址空间中的块, 表项的值就是这块虚拟地址空间对应的物理地址块, 以及访问物理地址时要使用的属性.
在查表过程中, 将虚拟地址分为两部分:
高阶位用作页表的索引. 用来找到对应的物理块 低地址是块内的偏移量, 不会因为映射而改变. 页表项中的物理地址与该偏移组合形成用于访问内存的物理地址. 多级页表 实际实现中, 多采用多级页表的方案, 各级页表自定向下组成树的形式, 协作实现虚拟到物理地址的转换.
树中的分支成为页目录, 页目录中的表项不是直接存储目标物理地址, 而是下一级页表的地址; 最后一级页表的表项中保存着目标物理地址.</description></item><item><title>AArch64 异常等级切换</title><link>https://wangloo.github.io/posts/armv8/exception_return/</link><pubDate>Sat, 24 Sep 2022 21:19:01 +0800</pubDate><guid>https://wangloo.github.io/posts/armv8/exception_return/</guid><description>ARMv8 异常返回指令 当异常处理程序结束后，需要执行异常返回指令恢复进入异常之前的状态.
具体要做的事情包括:
恢复发生异常前的PC
从SPSR中恢复PSTATE寄存器(现场)
异常返回的指令根据当前执行状态为AArch32还是AArch64有所不同.
AArch32 AArch32的异常返回指令在不同的模式下也有所不同:
若异常是在Hyp模式下处理: 仅可执行ERET指令从异常返回.
若异常是在其他模式下处理, AArch32提供了以下的异常返回指令:
ERET 指令
使用带S后缀的数据处理指令直接操作PC(例如, MOVS, PC, LR), 恢复PSTATE
RFE 指令: RFE &amp;lt;Rn&amp;gt;. 从基址寄存器指向的地址依次加载PC和PSTATE
LDM 指令: LDM &amp;lt;Rn&amp;gt; {pc..}. 若目标寄存器中包含PC, 则会同时恢复PSTATE
AArch64 AArch64下统一使用 ERET 指令进行异常返回.
指令格式及用法参考 ERET ERET指令完成了:
从ELR_ELx中恢复PC指针
从SPSR_ELx中恢复PSTATE寄存器的状态.
LDM(Load Multiple) 格式: LDM &amp;lt;Rn&amp;gt; {registers}
含义: 从基址寄存器&amp;lt;Rn&amp;gt;指向的地址开始依次加载多个寄存器值.</description></item><item><title>GNU C 内联汇编学习</title><link>https://wangloo.github.io/posts/c/inline-asm/</link><pubDate>Sat, 24 Sep 2022 16:48:58 +0800</pubDate><guid>https://wangloo.github.io/posts/c/inline-asm/</guid><description>语句结构 asm asm-qualifiers ( AssemblerTemplate : OutputOperands : InputOperands : Clobbers : GotoLabels) The asm keyword is a GNU extension. 当使用编译选项 -ansi 或 -std 时, 使用 __asm__代替 asm.
Qualifiers volatile: 向编译器说明禁止内敛的语句与其他语句 reorder。但不能保证内部 reorder，那是内存屏障的任务 goto inline Parameters AssemblerTemplate: 字符串, 汇编代码的模板
OutputOperands: 输出操作数; 指令将会修改的变量集合
InputOperands: 输入操作数; 指令将读取的变量集合
Clobbers: ???TODO
GotoLabels: 仅当 qualifiers 使用goto时, 声明label集合.
The total number of input + output + goto operands is limited to 30.
 Param #1: AssemblerTemplate 多条语句可以放在一个asm字符串中, 但是更常见的是每条汇编语句使用一个字符串, 并在结束时使用换行符和制表符(\n, \t)来表示换行.</description></item><item><title>Shellscript</title><link>https://wangloo.github.io/posts/shell/shell-script/</link><pubDate>Wed, 20 Jul 2022 11:54:13 +0800</pubDate><guid>https://wangloo.github.io/posts/shell/shell-script/</guid><description>ℹ️ 如未特殊说明，以下的命令在bash和zsh中都能正确生效。
变量的定义和引用 # 何时变量赋值要加&amp;#34;&amp;#34;? # =&amp;gt; 包含分隔符，空格或tab时 qemu_opt=&amp;#34;-machine raspi3b&amp;#34; # 引用变量时为什么加{}? ${var} # 引用变量时为什么加&amp;#34;&amp;#34;? &amp;#34;$var&amp;#34; # 变量赋值为什么$()? # =&amp;gt; ()里面是shell命令时用 qemu_ver=$($qemu --version | head -n 1) 常用Shell命令的注意事项 echo的参数 # echo不自动换行 echo -n &amp;#34;some-string&amp;#34; # echo转义特殊字符 echo &amp;#34;some-string\n&amp;#34; # 不转义\ echo -e &amp;#34;some-string\n&amp;#34; # 正确转义换行 Zsh中，echo默认带-e，bash中则不是。 所以说，如果输出的字符串有转义字符，不管要不要转义，都显式指定一下。
-e 强制转义 -E 强制不转义 sort 应付多种场景 # 对版本号进行排序(x.y.z) echo -ne &amp;#34;1.2.3\n4.5.6\n3.4.5&amp;#34; | sort -V shift 操作参数 shift命令将参数左移，应用场景:</description></item><item><title>C 语言位操作技巧</title><link>https://wangloo.github.io/posts/c/bitops/</link><pubDate>Sun, 03 Jul 2022 09:44:13 +0800</pubDate><guid>https://wangloo.github.io/posts/c/bitops/</guid><description>连续内存取n bit #include &amp;lt;stdio.h&amp;gt;#include &amp;lt;stdint.h&amp;gt;#include &amp;lt;assert.h&amp;gt; #define bitmask(n) ((1ul &amp;lt;&amp;lt; (n)) - 1) /* * 从ptr指向的内存开始，抽取第start个bit开始的连续n个bit * 限制: n &amp;lt; 32 */ uint32_t extract_bits(uint8_t *ptr, uint32_t start, uint32_t n) { uint32_t start_byte = start / 8; uint32_t start_offset = start % 8; uint32_t *pstart = (uint32_t *)(ptr + start_byte); uint32_t end = start + n - 1; uint32_t end_byte = end / 8; uint32_t end_offset = end % 8; uint32_t *pend = (uint32_t *)(ptr + end_byte); uint32_t data = *pstart &amp;gt;&amp;gt; start_offset; if (n &amp;gt; 32 - start_offset) { /* 由于n &amp;lt; 32, 所以补齐*pend一定就够了， * end_offset对齐到最后一位(n-1).</description></item><item><title>Stack and Heap</title><link>https://wangloo.github.io/posts/os/stack-and-heap/</link><pubDate>Tue, 28 Jun 2022 16:41:54 +0800</pubDate><guid>https://wangloo.github.io/posts/os/stack-and-heap/</guid><description> 堆的含义 我们都知道malloc动态申请的变量是存放在堆中. 所以相比栈来说, 堆是动态的.
堆占据进程虚拟地址空间的大部分, 我们可能通过堆来申请1GB的数组, 但是栈通常不行 , 大多也就几兆的空间.
 堆空间的管理 进程中堆空间的管理是运行库负责的, 在Linux中是GLIBC.
运行库在初始化时会像操作系统申请一大块的堆空间, 再为每个进行分别分配需求. 当然, 如果某些程序的需求过大, 运行库也可以使用mmap系统调用直接向操作系统申请, 然后 返回给用户进程.
GLIBC的malloc函数的处理方式是: 对于小于128KB的申请, 会从运行库&amp;quot;批发的&amp;quot;堆空间 里分出一块来; 但若申请的空间过大, 则使用mmap系统调用来创建匿名空间分配给用户.
Linux中虚拟地址块(VMA)的管理使用了红黑树, 可以用于运行库管理自己向操作系统 &amp;ldquo;批发&amp;quot;的堆空间. 使得用户程序动态申请和释放内存性能提高.</description></item><item><title>操作系统：动态链接/动态加载</title><link>https://wangloo.github.io/posts/os/dynamic-link/</link><pubDate>Sun, 26 Jun 2022 19:50:45 +0800</pubDate><guid>https://wangloo.github.io/posts/os/dynamic-link/</guid><description>静态链接带来的问题 像是libc这种几乎每个程序都要用到的库, 如果是静态的, 那么不仅意外着每个程序的 可执行文件很大, 浪费磁盘空间. 并且当程序加载到内存时, 可能许多程序都会用到printf , 使得内存中会存在好多份的printf源码.
维护和更新难. 一旦静态链接的其中一个目标文件更新, 所有的可执行程序都要重新链接.
不满足局部性原理. 上面提到, 内存中同时存在多份的printf源码会破坏局部性原理的. 显然如果所有的程序共享一份printf源码的想法更好. 即动态加载.
可移植性差. 静态链接, 只要有一个依赖目标文件的实现不同, 软件厂商就得专门发布一个 版本. 而动态链接则信赖客户电脑上的动态库, 相当于一个中间层.
动态链接的过程 对比静态链接使用ld链接器在编译后即执行链接, 动态链接则是将链接过程推迟到运行时, 即装载到内存时.
这样, 链接器在链接产生可执行文件时就有两种做法:
对于静态符号, 按照静态链接的规则进行地址引用重定位 对于动态符号, 链接器则仅标记其为动态链接中的符号, 不进行处理. 而是等到装载时由 专门的动态链接器来完成动态符号的链接工作. ⁉️ 链接器如何确定一个符号是静态的 or 动态的?
在动态共享对象(.so)中保存了完整的动态符号表*, 表中存在的符号即为动态的, 否则为静态.
Linux 的 C 语言运行库glib的动态链接版本叫libc.so. 它在外存上只保存一份, 所有的程序 都可以在运行时使用它. 所以千万不要删掉它.
动态链接有一定的性能损失, 因为每次运行程序时都要重新链接, 并不像静态链接是一劳永逸的.</description></item><item><title>Elf 文件的链接与加载</title><link>https://wangloo.github.io/posts/binary/elf-format/</link><pubDate>Mon, 20 Jun 2022 16:21:27 +0800</pubDate><guid>https://wangloo.github.io/posts/binary/elf-format/</guid><description>ELF是什么 ELF（Executable Linkable Format）可执行文件格式不止是单指“可以被执行的文件”， 动态链接库、静态链接库都按照可执行文件格式来存储。
ELF标准里把采用ELF格式的文件分为四类：
Type description 实例 Relocatable File 这些文件包含了代码和data, 可以被用来链接成可执行文件或共享目标文件. .o, .a Executable File 直接可执行的文件 /bin/ls Shared Object File Including code and data. 链接器可将其与其他Relocatable File或Shared Object File结合, 生成新的目标文件. 动态链接器可将其与Executable File结合, 作为进程映像的一部分来运行. .so Core Dump File Restore critical infomation when process is terminated unexpectedly core dump 📌 file command in Linux can output the format of a file.</description></item><item><title>写高质量的C语言工程的规范</title><link>https://wangloo.github.io/posts/c/improve_quality/</link><pubDate>Tue, 14 Jun 2022 17:59:22 +0800</pubDate><guid>https://wangloo.github.io/posts/c/improve_quality/</guid><description>添加更多的编译选项(comiler options)来防止bug 对于我常用的GCC, 推荐开启一下的compiler options:
-Wall: enable a lot of common warnings
-Wno-format-truncation: warns about the snprintf output buffer not being large enough for a corresponding “%s” in the format string.
-Werror: turn warnings into errors.
 动态申请的空间到底要不要释放 When using a barebones embedded OS, you absolutely need to tightly manage your memory.
但是, 如果你是写应用业务的代码, 特别是在内存足够的场景下. 最好不要手动释放内存, 因为当线程/进程退出时, 操作系统会自动帮我们释放. 某些情况下, 释放内存的操作会很大程度上增加逻辑的复杂度.
如果你是一个内核程序员, 则必须手动的释放.</description></item><item><title>操作系统：SeL4 基础概念</title><link>https://wangloo.github.io/posts/os/sel4/</link><pubDate>Sat, 04 Jun 2022 11:52:51 +0800</pubDate><guid>https://wangloo.github.io/posts/os/sel4/</guid><description>seL4 Capabilities In seL4, capabilities are stored in C-space. C-space is a hierarchical data structure very similar to page table.
page table is a mapping from virtual address to physical address. C-space is a mapping from object ID to capability. Kernel object is made up of several C-nodes, just like a page table made up of individual page tables. Each C-nodes is an array of cap slots, which contain capability.</description></item><item><title>Hugo 基础概念</title><link>https://wangloo.github.io/posts/hugo/basic/</link><pubDate>Sat, 21 May 2022 17:39:42 +0800</pubDate><guid>https://wangloo.github.io/posts/hugo/basic/</guid><description>本章将解答Hugo是什么, 以及Hugo是如何工作的. 只有了解Hugo的工作机制之后, 才能发挥想象力进行DIY.
本章内容大多来自官方手册或者搜索引擎提供的结果.
Hugo 项目结构 一个hugo 项目通常包含以下内容:
. ├── archetypes ├── config.toml ├── content ├── data ├── layouts ├── public ├── static └── themes 这里面有些是必须的, 有些是可选的.
archetypes
定义新创建post时, header的格式.
asserts
Note: assets directory is not created by default.
config
Hugo uses the config.toml, config.yaml, or config.json (if found in the site root) as the default site config file.
The user can choose to override that default with one or more site config files using the command-line --config switch.</description></item><item><title>2019 Stanford Commencement Timcook</title><link>https://wangloo.github.io/posts/motivation/2019-stanford-commencement-timcook/</link><pubDate>Wed, 18 May 2022 19:32:38 +0800</pubDate><guid>https://wangloo.github.io/posts/motivation/2019-stanford-commencement-timcook/</guid><description>Content Fourteen years ago, Steve stood on this stage and told your predecessors &amp;ldquo;Your time is limited. So don&amp;rsquo;t waste is living someone else&amp;rsquo;s life.&amp;rdquo;
So what is true then is true now. Don&amp;rsquo;t waste your time living someone else&amp;rsquo;s life. Don&amp;rsquo;t try to emulate the people who came before you to the exclusion of everything else, contorting into a shape that doesn&amp;rsquo;t fit.
Graduates, the fact is, when your time comes, and it will, you will never be ready.</description></item><item><title>Html Css Learning note (0)</title><link>https://wangloo.github.io/posts/html-css/0/</link><pubDate>Tue, 17 May 2022 11:02:04 +0800</pubDate><guid>https://wangloo.github.io/posts/html-css/0/</guid><description>Get start What is HTML&amp;amp;CSS? HTML is resonsible for the content of the page. That&amp;rsquo;s the text, images, buttons, etc.
CSS is resonsible for the presentation of the content. That&amp;rsquo;s the color, layout, etc.
Web designers create the overall look and fell of a website.
Web developers implement the design using HTML, CSS and JavaScript code.
Configure VIM as HTML code-editor Finally in the arms of vscode 🙉</description></item><item><title>我的 vim 调教随笔</title><link>https://wangloo.github.io/posts/tools/vim/basic/</link><pubDate>Mon, 09 May 2022 19:28:12 +0800</pubDate><guid>https://wangloo.github.io/posts/tools/vim/basic/</guid><description>Search a word quickly: put cursor on the word, press / and press &amp;lt;C-R&amp;gt; &amp;lt;C-W&amp;gt;.
 Vim 启动参数 view &amp;lt;file&amp;gt; 只读方式打开 vim -u NONE -N 可以不加载vim配置和插件打开vim vim --startuptime vim.log 生成vim启动的log 缩写的含义(Meaning of abbreviations) Operation
d - delete y - yank(copy, 因为c被占了) c - change r - replace v - visual select Scope or location
i - inside a - around f - forward t - to Object</description></item><item><title>reveal.js Tutorial</title><link>https://wangloo.github.io/posts/revealjs/</link><pubDate>Sun, 08 May 2022 19:34:44 +0800</pubDate><guid>https://wangloo.github.io/posts/revealjs/</guid><description>Change code theme Default use monokai.css. see 官方文档
修改需要下载新的css放到plugin/highlight/目录下.
其他可用的css在highlight.js仓库中下载.
Align Slide Align 取消center对齐方式:
Reveal.initialize({ ... center: false, ... }) 所有slide左对齐: https://github.com/hakimel/reveal.js/issues/1897
用markdown写的方式下使某一幻灯片左对齐: https://github.com/hakimel/reveal.js/issues/890#issuecomment-129735291</description></item><item><title>AArch64 A64 指令集</title><link>https://wangloo.github.io/posts/armv8/a64/</link><pubDate>Sat, 07 May 2022 21:19:01 +0800</pubDate><guid>https://wangloo.github.io/posts/armv8/a64/</guid><description>Load/Store 指令 寻址模式 Base register - w0=[x1]
ldr w0, [x1] Offset addressing mode - w0=[x1+12]
ldr w0, [x1, 12] Pre-index addressing mode - x1+=12; w0=[x1]
ldr w0, [x1, 12]! Post-index addressing mode - w0=[x1]; x1+=12
ldr w0, [x1], 12 更多示例 // load a byte from x1 ldrb w0, [x1] // load a signed byte from x1 ldrsb w0, [x1] // store a 32-bit word to address in x1 str w0, [x1] // load two 32-bit words from stack, then add 8-byte to sp ldp w0, w1, [sp], 8 // Store two 64-bit regs in [sp-96] and subtract 96-byte from sp.</description></item><item><title>AArch64 寄存器</title><link>https://wangloo.github.io/posts/armv8/register/</link><pubDate>Sat, 07 May 2022 20:19:44 +0800</pubDate><guid>https://wangloo.github.io/posts/armv8/register/</guid><description>寄存器分类 通用寄存器 x0-x7 参数寄存器: Restore function parameters and return vaule. x9-x15 caller-saved 临时寄存器: callee 默认可以直接使用来保存临时变量, 不需要保存和恢复. 如果 caller 在里面存储了非临时信息, 那么在函数调用之前应当由 caller 负责保存. x19-x28 callee-saved 寄存器: callee 应该避免使用. 如果必须要使用，那么在返回前必须恢复. special registers: x8 restore indirect result. Commonly used when returning a struct. x18 platform reserved register. x29 frame pointer register(FP). x30 link register(LR). All general-purpose register xN is 64-bit width. They all have corresponding wN register using the lower 32-bit of xN.</description></item><item><title>Numberical Analysis Exam</title><link>https://wangloo.github.io/posts/numberical-analysis/</link><pubDate>Sat, 07 May 2022 18:04:58 +0800</pubDate><guid>https://wangloo.github.io/posts/numberical-analysis/</guid><description>考试大纲 🎯 To Reader:
This blog is JUST FOR EXAMINATION! If you are interested in numberical analysis, please quit this web. I try to sort out the knowledge points of the course, just to pass the exam.
Based on the course of Professor Zhong Erjie of UESTC.
💢 I hate mathematics!
 第二章 非线性方程/方程组的求解 1. 二分法及迭代 二分法误差估计定理 2. 不动点迭代 不动点及不动点迭代的概念 迭代格式的选择? 是否收敛? 迭代的初值是否合适? 3. 牛顿法解非线性方程 背景: 如果函数f(x)是线性的, 那么它的求根问题就会简化.</description></item><item><title>LaTeX Vim Tutorial</title><link>https://wangloo.github.io/posts/tools/vim/latex_vim/</link><pubDate>Wed, 04 May 2022 17:07:51 +0800</pubDate><guid>https://wangloo.github.io/posts/tools/vim/latex_vim/</guid><description>Use plugin vimtex Vim build-in support of LaTeX files is just OK. When we need more excellent exprience, good plugins is very recommended.
vimtex is a nice and modern vim plugin for LaTeX files.
Useful Futures of vimtex IMO
&amp;lt;leader&amp;gt;ll Complier. By default, it will auto-complier when you type :w. &amp;lt;leader&amp;gt;lt Open content tree as a sidebar. &amp;lt;leader&amp;gt;lv View PDF with configured PDF viewer. &amp;lt;leader&amp;gt;li File information. cse Change surrounding \begin \end environment.</description></item><item><title>Portability Issues</title><link>https://wangloo.github.io/posts/reading-notes/expert_c_programming/portability_issues/</link><pubDate>Sun, 01 May 2022 16:41:35 +0800</pubDate><guid>https://wangloo.github.io/posts/reading-notes/expert_c_programming/portability_issues/</guid><description>When reading C standard documents, we usually see phrases like &amp;ldquo;Implementation-defined&amp;rdquo;, &amp;ldquo;Unspecified&amp;rdquo;,.etc.
So, what do they really mean?
术语 我们将这些难以直接理解的词汇称为术语，在ANSI C中，术语可以分为描述不可移植代码(unportable), 坏代码(bad), 可移植的代码(portable)三类.
unportable code Implementation-defined
需要由编译器设计者决定采取何种行为，他们可能不同，但都不能说是错误的.
例如：当整型数右移时，是否需要扩展符号位. 右移代替除法可能导致的灾难.
unspecified
在某些正确情况下的做法，标准并未明确规定应该怎样做.
例如：参数求值的顺序.
bad code undefined
在某些不正确情况下的做法，但标准并未规定应该怎样做。意味着你可以采取任何行动，可以什么都不做，也可以发出一条警告信息, 或者终止CPU重启等等. 你甚至可以发射核导弹(只要你安装了能发射核导弹的硬件系统).
例如：当一个有符号整数溢出时该采取什么行动.
constraint
这是一个必须遵守的限制或要求. 如果你不遵守, 那么你的程序的行为就会变成如上所说的undefined. 这出现了一种很有意思的情况: 分辨某种东西是否是一个constaint是很容易的, 因为每个标准的主题都附有一个constraint小节, 列出了所有的约束条件。
例如: %操作符的操作数必须为整型. 所以,在非整型数据上使用%操作符肯定会导致undefined.
portable code strictly conforming
严格遵守标准的. 符合该条件的程序应当是:
只使用已确定的特性 不突破任何由编译器实现(Implementation-defined)的限制. 不使用unspecified和undefined特性 这样规定的目的是最大程序保证代码的可移植性. 但符合该术语的代码并不常见, 例如INT_MAX的值在不同架构的机器上结果可能不同.
comforming
遵循标准的; 一个遵循标准的程序可以依赖一些对于某种编译器特有的不可移植的特性. 这样一个程序对于某个编译器可能是遵循标准的, 但对于另外一个编译器又是不遵循标准的.</description></item><item><title>Third Blog</title><link>https://wangloo.github.io/posts/third-blog/</link><pubDate>Sun, 01 May 2022 16:41:35 +0800</pubDate><guid>https://wangloo.github.io/posts/third-blog/</guid><description/></item><item><title>"GCC -M" 选项在Makefile中的使用</title><link>https://wangloo.github.io/posts/c/make/gcc_-m_related/</link><pubDate>Tue, 26 Apr 2022 19:08:22 +0800</pubDate><guid>https://wangloo.github.io/posts/c/make/gcc_-m_related/</guid><description>As we all know, there are huge number of parameters for GCC. With them, we can make many things possible. Now we talk about -M and related ones. After reading this article, you will know the meaning of there magic parameters. And I will put some little demos follows. Finally, we will see what can they do in really project. Let&amp;rsquo;s go ahead.
实例规则 以下的分析都是基于这样一个生成目标文件的规则, 应该来说具有一定的通用性。
build/obj/main.o: src/main.c $(CC) $(CFLAGS) $(INCLUDES) -c $&amp;lt; -o $@ main.</description></item><item><title>Second Blog</title><link>https://wangloo.github.io/posts/second-blog/second-blog/</link><pubDate>Tue, 26 Apr 2022 15:32:11 +0800</pubDate><guid>https://wangloo.github.io/posts/second-blog/second-blog/</guid><description>This is my second blog.
Wish you have a good life.
happy smile sunset</description></item><item><title>First Blog</title><link>https://wangloo.github.io/posts/first-blog/first-blog/</link><pubDate>Tue, 26 Apr 2022 15:13:07 +0800</pubDate><guid>https://wangloo.github.io/posts/first-blog/first-blog/</guid><description>This is my first blog. This is my first blog. This is my first blog. This is my first blog. This is my first blog. This is my first blog. This is my first blog. This is my first blog. This is my first blog. This is my first blog. This is my first blog. This is my first blog. This is my first blog. This is my first blog. This is my first blog.</description></item><item><title/><link>https://wangloo.github.io/posts/os/linux/trace/ftrace/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://wangloo.github.io/posts/os/linux/trace/ftrace/</guid><description>Reference Measuring Function Duration with Ftrace Finding Origins of Latencies Using Ftrace Slides: Ftrace Slides: Ftrace Kernel Hooks:More than just tracing 介绍 ftrace功能 ：帮助了解Linux内核的运行时行为，可以查看系统调用情况，以及某个函数的调用流程。 2.6内核之后引入内核的。以便进行故障调试或性能分析。
Ftrace 跟踪工具由性能分析器（profiler）和跟踪器（tracer）两部分组成，
性能分析器：用来提供追踪数据的解析和图形化作战时（需要 CONFIG_FUNCTION_PROFILER=y）
函数性能分析 直方图 跟踪器：负责不同追踪事件的实现，数据的来源
函数跟踪（function） 点跟踪（tracepoint） kprobe uprobe 函数调用关系（function_graph） hwlat等 Debugfs提供用户层控制接口 ftrace的目录：/sys/kernel/debug/tracing/ ，常用文件介绍：
dynamic tracing，动态trace进行过滤的接口，是需要在编译时支持该功能，需要打开对应的宏开关： available_events available_filter_functions: 可追对函数的完整列表 available_tracers，当前内核中可用的插件追踪器。 buffer_size_kb，以KB为单位指定各个CPU追踪缓冲区的大小。系统追踪缓冲区的总大小就是这个值乘以CPU的数量。设置buffer_size_kb时，必须设置current_tracer为nop追踪器。 buffer_total_size_kb current_tracer，通过该接口指定当前ftrace要使用的tracer，也就是要追踪的函数/时间。 dyn_ftrace_total_info: enabled_functions: max_graph_depth: printk_formats: saved_cmdlines: saved_cmdlines_size: set_event: set_event_pid: set_ftrace_filter，指定要追踪的函数名称，函数名称仅可以包含一个通配符。 set_ftrace_notrace，指定不要追踪的函数名称。 set_ftrace_pid，指定作为追踪对象的进程的PID号。 set_graph_function: set_graph_notrace: trace，以文本格式输出内核中追踪缓冲区的内容，是查看trace日志的接口。 trace_clock: trace_marker: trace_marker_raw: trace_options: trace_pipe，与trace相同，但是运行时像管道一样，可以在每次事件发生时读出追踪信息，但是读出的内容不能再次读出 tracing_cpumask，以十六进制的位掩码指定要作为追踪对象的处理器，例如，指定0xb时仅在处理器0、1、3上进行追踪。 tracing_on，启用/禁用向追踪缓冲区写入功能。1为启用，0为禁用。 tracing_thresh: uprobe_events: uprobe_profile: 支持的tracer包括:</description></item><item><title/><link>https://wangloo.github.io/posts/os/trace/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://wangloo.github.io/posts/os/trace/</guid><description>名词解释 probe 一个probe是一个位置或者活动, 动态追踪工具可以在probe上绑定一些action. 例如记录栈帧位置, 查看参数等.
probe就像是一个可编程的传感器, 你可以为他设定触发的事件或者指令. 当probe 触发时, 可以执行你提前绑定的函数, 了解此时系统的状态</description></item><item><title/><link>https://wangloo.github.io/posts/photo/50%E8%AE%B2/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://wangloo.github.io/posts/photo/50%E8%AE%B2/</guid><description>涉猎要广 要摄影, 其他的方面也要广泛涉猎.
安塞尔·亚当斯（Ansel Adams）曾经说过：“我们不只是用相机在拍照，我们带到摄影中去的是所有我们读过的书、看过的电影、听过的音乐、爱过的人。”
拍出来的照片跟你的经历有非常大的关系, 不要拍不在自己经历范畴之内的东西.
能够说明拍照与后期的关系的电影: 再次出发之纽约遇见你 (豆瓣) (douban.com)</description></item><item><title/><link>https://wangloo.github.io/posts/python/process-run.py/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://wangloo.github.io/posts/python/process-run.py/</guid><description>源文件 模拟了一个调度器的行为，支持输入多个进程，每个进程可以包含一部分CPU计算指令和IO指令，IO指令可以设置等待时间。
http://pages.cs.wisc.edu/~remzi/OSTEP/Homework/HW-CPU-Intro.tgz
运行参数解析 利用python OptionParser 模块
from optparse import OptionParser 生成实例，添加支持的参数列表：
parser = OptionParser() # -s ==&amp;gt; 短参数 # --seed ==&amp;gt; 长参数 # default ==&amp;gt; 默认值 # type ==&amp;gt; type of option value # action=&amp;#39;store&amp;#39; ==&amp;gt; store option value to dest # action=&amp;#39;store_true&amp;#39; ==&amp;gt; 无需携带参数，只要出现就认为True # dest ==&amp;gt; member of parser for storing value # help ==&amp;gt; description of this option, -h时会输出 parser.add_option(&amp;#39;-s&amp;#39;, &amp;#39;--seed&amp;#39;, default=0, help=&amp;#39;the random seed&amp;#39;, action=&amp;#39;store&amp;#39;, type=&amp;#39;int&amp;#39;, dest=&amp;#39;seed&amp;#39;) parser.</description></item><item><title/><link>https://wangloo.github.io/posts/thinking/poetry/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://wangloo.github.io/posts/thinking/poetry/</guid><description>长征 《清平乐·会昌》近现代·毛泽东
东方欲晓，莫道君行早。踏遍青山人未老，风景这边独好。会昌城外高峰，颠连直接东溟。战士指看南粤，更加郁郁葱葱。
1933年下半年蒋介石发动第五次“围剿”。中共此时听取国产国际而实行“御敌于国门之外”的错误方针，与敌硬拼，致使红军连吃败仗，毛泽东此时被雪藏。1934年4月，毛泽东在被冷遇三个月后，重新工作，前往中央苏区南部的会昌视察并指导工作，准备开展新的根据地。
哪怕是在这种情境下，我们还是能从这首词中读出一种乐观、积极的态度。</description></item><item><title/><link>https://wangloo.github.io/posts/tools/clang/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://wangloo.github.io/posts/tools/clang/</guid><description>Clang是个啥 Clang与LLVM llvm有两种含义：llvm框架和llvm Core
llvm框架定义了一个编译器的组成架构，此时Clang可以作为框架中针对C/C++语言的前端。 当然llvm框架也并不只是包含这一个前端，也可以有其他的前端。 llvm Core是除了前端之外的其他构成编译器的部分，包括中端优化和后端。 Clang与Gcc Clang是一个编译器前端，Clang+llvm Core=编译器，Gcc也是一个编译器 Clang的代码结构更好，扩展性强 Clangd clangd是llvm项目推出的C/C++语言服务器，通过LSP(Language Server Protocal)协议向编辑器如vscode/vim/emacs提供语法补全、错误检测、跳转、格式化等等功能。C++的LSP曾经是cquery, ccls, clangd三足鼎立。但是clangd支持clang-tidy实时检查的功能是另外两者不具备的，而且cquery和ccls都是单个开发者主导的项目，clangd背后则是有llvm的背书。
一般写C代码，在vscode中用C/C++这个插件来进行自动补全，这类插件在复杂工程中效果不太好因为它是基于代码进行分析，理论上不能准确的区别同名函数到底是调用谁的情况。而且在实践中也经常产生莫名其妙找不到定义的情况。
而Clangd则是支持基于编译的分析做代码补全， 通过解析一个调用数据库文件compile_commands.json 来提供错误检查和补全等功能。
生成 compile_commands.json 一般采用make工具构建的工程，通过bear工具可以在编译中自动分析并生成compile_commands.json。
特别对于Linux kernel，有专门的工具scripts/clang-tools/gen_compile_commands.py，在编译后执行该脚本即可在根目录生成compile_commands.json。
VSCode配置Clangd补全 安装clangd插件 clangd插件与c/c++插件冲突，目前的方法时禁用C/C++插件。 配置clangd服务的路径，可以在User或者Workspace。 如果有其他参数需求，可以按需添加。 .notice { --root-color: #444; --root-background: #eff; --title-color: #fff; --title-background: #7bd; --warning-title: #c33; --warning-content: #fee; --info-title: #fb7; --info-content: #fec; --note-title: #6be; --note-content: #e7f2fa; --tip-title: #5a5; --tip-content: #efe } @media (prefers-color-scheme:dark) { .notice { --root-color: #ddd; --root-background: #eff; --title-color: #fff; --title-background: #7bd; --warning-title: #800; --warning-content: #400; --info-title: #a50; --info-content: #420; --note-title: #069; --note-content: #023; --tip-title: #363; --tip-content: #121 } } body.</description></item><item><title/><link>https://wangloo.github.io/posts/tools/gtest/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://wangloo.github.io/posts/tools/gtest/</guid><description>Googletest 移植 Arm64 交叉编译 Download source code
git clone https://github.com/google/googletest.git -b v1.14.0 编写适用于Arm64平台的规则，指定交叉编译器的位置。此文件放在项目的根目录下。
set(CMAKE_CROSSCOMPILING TRUE)set(CMAKE_FIND_ROOT_PATH ~/tools/gcc-arm-10.3-2021.07-x86_64-aarch64-none-linux-gnu/)# Cross compiler SET(CMAKE_C_COMPILER aarch64-none-linux-gnu-gcc)SET(CMAKE_CXX_COMPILER aarch64-none-linux-gnu-g++)set(CMAKE_LIBRARY_ARCHITECTURE aarch64-none-linux-gnu)# Search for programs in the build host directories SET(CMAKE_FIND_ROOT_PATH_MODE_PROGRAM NEVER)# Libraries and headers in the target directories set(CMAKE_FIND_ROOT_PATH_MODE_LIBRARY ONLY)set(CMAKE_FIND_ROOT_PATH_MODE_INCLUDE ONLY)set(CMAKE_FIND_ROOT_PATH_MODE_PACKAGE ONLY)编译，这里没有编译Googlemock
#!/bin/bash rm -rf build mkdir build &amp;amp;&amp;amp; cd build cmake .. -DCMAKE_TOOLCHAIN_FILE=../toolchain_arm64.cmake -DGTEST_HAS_PTHREAD=0 -DBUILD_GMOCK=OFF # check file: lib/libgtest_main.a and lib/libgtest.a</description></item><item><title/><link>https://wangloo.github.io/posts/tools/regex/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://wangloo.github.io/posts/tools/regex/</guid><description>正则表达式常用:
匹配一个或多个以上的空格: [ \t]{1,}</description></item></channel></rss>