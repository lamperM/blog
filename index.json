[{"categories":["Operating System"],"contents":"Rootfs 定义和存在的问题 Linux 启动后用到的文件都存储在“根文件系统”中，也叫 rootfs，里面存放着一些系统程序和用户文件。因此，rootfs 一般是存储在块设备中，比如 UFS、EMMC 等。\n所以说，要想访问这些文件，执行这些系统程序需要先 初始化块设备的驱动程序，我理解这个过程是很慢的，相当于所有的任务都会被这个驱动初始化给 delay。\n 消耗的时间包括：块设备驱动初始化+文件系统格式初始化 我们可能会有一些任务比如说展示开机动画这些，本身是不依赖块设备，但却都堵塞在这。  为了解决这个问题，先后有两种策略：\n initrd initramfs  “initrd” based on “Ramdisk” initrd 的提出就是为了解决上述问题，initrd=init ramdisk，本质上属于一个 ramdisk 设备，所以这里需要先对 ramdisk 进行介绍。\nramdisk 是一个用内存模拟的块设备，就和 EMMC、UFS（这俩都属于 SCSI）类似。既然作为块设备，在它之上需要一个文件系统格式（例如 ext4、f2fs）才能使用。 ramdisk 可能有其他的用处，ramdisk 的使用 不需要那么复杂的设备驱动程序。\nLinux 在加载时，除了内核和设备树文件同时加载了一个带有文件系统格式的镜像到内存中，然后在内核初始化 ramdisk 后，就去把这个镜像挂载到一个特殊的 ramdisk 设备上，也称为 init ramdisk。尽早的进入了用户态，完成一些需要先执行的任务后（/linuxrc ），可以慢慢加载其他物理的块设备，挂载真正的 rootfs， 执行里面的/sbin/init。\n“initramfs” based on “ramfs、tmpfs” ramdisk 作为一个内存中模拟的块设备，自身占用一部分内存。同时文件系统格式的缓冲区又占用一块内存，一个文件的读写需要先到文件系统的缓冲，合适的时候会同步到块设备的存储区域中。\n 这种方式对于一般的物理块设备是很正常的，但对于 ramdiks 来说，两个缓冲都是在内存，互相拷贝就没什么必要。  于是 linux 在 2.6 引入了一个特殊的文件系统格式：ramfs，这种文件格式的操作不需要下级的物理设备，修改仅仅保存在内存中。\n tmpfs 是在 ramfs 的基础上做了一些优化，本质相同。  initramfs 就是基于 tmpfs 对 initrd 进行优化，省去了创建 ramdisk 的必要性，更加方便，速度也更快。\n 用户引导时直接传入一个 cpio gz 或者 lz4 的压缩文件，内核启动时将其格式化为 tmpfs 文件系统。  总结 系统启动过程的最后一个阶段：挂载根文件系统、执行根文件系统中的 init 程序完成到用户空间的切换。然而根文件系统可能是在不同的硬件设备上，如 SCSI 硬盘、SATA 硬盘、Flash 设备等，后续会出现更多的硬件设备；根文件系统可以是 xfs、ext4、NFS 等不同的文件系统；为了成功挂载根文件系统，内核需要具备相应的设备驱动、文件系统驱动，如果为了兼容所有的根文件系统，将所有相关驱动编译进内核，会增大内核大小，并在实际环境中引入一些无用的驱动。\ninitramfs 作为一个过渡文件系统解决了挂载根文件系统的兼容性。其中包含了必要的硬件设备、文件系统驱动以及驱动的加载工具及其运行环境。initramfs 可以编译进内核也可以作为单独文件由 bootloader 加载入内存，在内核初始化的最后阶段，会解压 initramfs，运行其中的 init 程序完成根文件系统挂载，并执行根文件系统中的 init 程序，完成内核空间到用户空间的切换。\n ramdisk：使用内存模拟的特殊的块设备，像是 EMMC、UFS 这种 ramfs、tmpfs：文件系统格式，像是 EXT4、F2FS 这种 initrd：init ramdisk，一个启动阶段专用的 ramdisk，存放第一级“临时 rootfs” initramfs：基于 tmpfs 的、专门用于启动阶段，同样存放第一级“临时 rootfs” rootfs：不是一种文件系统格式，而是一堆文件的统称。系统启动后，指那些真正的用户文件和系统程序，一般来说 rootfs 使用的文件系统可能是 EXT4 或 f2fs，底层的块设备是 EMMC 或 UFS。  通过使用 initramfs，Linux 可以逐渐将早期引导功能的执行从内核空间转移到用户空间，为处理复杂的启动要求提供了更可定制和可扩展的环境。\n启动阶段分析 对 initrd 的处理函数主要有两个：populate_rootfs()和 prepare_namespace()，针对不同的格式，处理情况各不相同。\n  优先处理 initramfs 被编译到内核的情况，__initramfs_start 就是起始地址。如果__initramfs_end - __initramfs_start等于 0，那么 unpack_to_rootfs 函数不会做任何事情，直接退出。系统认为该 initrd 不是 initramfs 文件，所以需要到后面去处理。\n  initrd_start 是从 uboot 得到的，如果 uboot 没有传 cpio-initrd 或 image-initrd，或者 CONFIG_INITRAMFS_FORCE 使能强制忽略 uboot 传来的，则直接跳转到 (5)。\n  按照 cpio-initrd 的格式去解包 uboot 传来的，如果 uboot 传来的是 image-initrd，则此步骤会失败。\n  到这里的情况只有 uboot 传来的 image-initrd 情况，这也是为什么要检查 CONFIG_BLK_DEV_RAM （是否支持 ram 作为块设备，即 ramdisk）。这里面的函数就不进去了，大概的行为就是：首先在前面挂载的根目录 rootfs 上创建一个 /initrd.image 文件，再把 initrd_start 到 initrd_end 的内容写入到/initrd.image 中。剩下的处理过程在 prepare_namespace()。\n  最后处理的关于 uboot 传来的 cpio-initrd/image-initrd 占用内存释放的过程。kexec_free_initrd() 中去做了判断，只释放不在 crashkernel 范围内的内存。我理解如果是内置的 initramfs(gz)或者 cpio-initrd(gz)，都会有解压的过程。会解压出这个=范围。而一般的情况，都会优先被放到 crashkernel 范围中，不会超出，减少释放的时间损耗。\n  static int __init populate_rootfs(void) { /* Load the built in initramfs */ // (1) \tchar *err = unpack_to_rootfs(__initramfs_start, __initramfs_size); if (err) panic(\u0026#34;%s\u0026#34;, err); /* Failed to decompress INTERNAL initramfs */ if (!initrd_start || IS_ENABLED(CONFIG_INITRAMFS_FORCE)) // (2) \tgoto done; if (IS_ENABLED(CONFIG_BLK_DEV_RAM)) printk(KERN_INFO \u0026#34;Trying to unpack rootfs image as initramfs...\\n\u0026#34;); else printk(KERN_INFO \u0026#34;Unpacking initramfs...\\n\u0026#34;); err = unpack_to_rootfs((char *)initrd_start, initrd_end - initrd_start); // (3) \tif (err) { #ifdef CONFIG_BLK_DEV_RAM \tpopulate_initrd_image(err); // (4) #else \tprintk(KERN_EMERG \u0026#34;Initramfs unpacking failed: %s\\n\u0026#34;, err); #endif \t} done: /* * If the initrd region is overlapped with crashkernel reserved region, * free only memory that is not part of crashkernel region. */ if (!do_retain_initrd \u0026amp;\u0026amp; initrd_start \u0026amp;\u0026amp; !kexec_free_initrd()) // (5) \tfree_initrd_mem(initrd_start, initrd_end); initrd_start = 0; initrd_end = 0; flush_delayed_fput(); return 0; } image-initrd 的解包 prepare_namespace()： 对于 image-initrd 来说，上一步 populate_rootfs() 还没有最终完成解包（挂载到/），只是写入到一个文件/initrd.image ，剩下的步骤就是在这里完成。\n参考   深入理解 Linux 2.6 的 initramfs 機制\n  【转载】linux2.6 内核 initrd 机制解析 - 玩意儿 - 博客园\n  启动过程分析\u0026ndash;initramfs 阶段 - Just Hack Fun\n  ","date":"2024-08-18T10:51:49+08:00","permalink":"https://wangloo.github.io/posts/os/linux/rootfs/","section":"posts","tags":["Operating System","Linux"],"title":"Linux 易混淆的 ramdisk/ramfs/tmpfs/initrd/initramfs/rootfs"},{"categories":["Virtualization"],"contents":"探究中断虚拟化的方案，按照 GIC 的不同版本架构进行说明。\n带有 Hypervisor 的架构来说，如何处理外部物理设备的中断就变得更加复杂：\n 有些中断是给 Hypervisor 处理的 有些中断是给 VM 处理的 甚至，当分配给这个 VM 处理的中断到来的时候，这个 VM 没有被调度  在引入虚拟化之后，这些条件都是需要被考虑的。所以说，在设计中断虚拟化时，我们要从以下两个部分进行实现。分块也更加便于我们逐步理解中断虚拟化实现中软件/硬件的任务界限划分。\n 一套能在 EL2 处理 Hypervisor 中断的机制 一套能将部分中断映射转发到 VM 的机制  中断虚拟化的历史 知道历史才能更加清楚一个技术的巧妙。GIC 硬件支持虚拟化是从 GICv2 开始引入的，GICv3 又增加了和虚拟化相关的更多新功能。\n软件做\u0026ndash;性能太差/实现太复杂\u0026ndash;硬件做\n中断虚拟化的相关配置 vFIQ/vIRQ 是新加入的两条中断线，也就是说现在连接到 CPU 上共有四条中断线（IRQ/FIQ/vIRQ/vFIQ）。vFIQ/vIRQ 的特点是只能在 EL0 和 EL1 触发，而且只能在 NSecure 状态触发。\n To recap, support for virtualization in Secure state was introduced in Armv8.4A. For a virtual interrupt to be signaled in Secure EL0/1, Secure EL2 needs to be supported and enabled. Otherwise virtual interrupts are not signaled in Secure state.\n 触发 vIRQ/vFIQ 的两种方式 There are two mechanisms for generating virtual interrupts:\n  Internally by the core, using controls in HCR_EL2. HCR.VI = Setting this bit registers a vIRQ.HCR_VF = 触发 vFIQ。缺点是只提供了触发 vIRQ 的方式，但是没有其他的模拟啊，比如说怎么配置优先级？怎么 ACK、EOI 中断这些。所有 VM 对 GIC 的操作都需要 Trap 到 EL2 来模拟（emulate），性能太差。\n  这种软件的方法由于性能迟早被硬件方法代替，Using a GICv2, or later, interrupt controller. From Arm GICv2, the GIC can signal both physical and virtual interrupts。The advantage of this approach is that the hypervisor only needs to set up the virtual interface, and does not need to emulate it. This approach reduces the number of times that the execution needs to be trapped to EL2, and therefore reduces the overhead of virtualizing interrupts.\n  接收到一个物理中断并处理的流程：\n 物理设备产生中断信号，到达 GIC CPU 读到 HCR.IMO/FMO 是 1，该中断会强制路由到 EL2 Hypervior 首先判断这个中断是谁处理的，如果是自己那就自己处理完默默回去 如果是 VM 的中断，将 vINTID 和路由到哪个 vCPU 决定好 按照 vINTID 更新 LR，也就是 GIC virtual interface control registers，比如说 vINTID 写入 vGICC_IAR。包括中断所属的 Group 信息。 如果有多个 VM，最好调度到处于中断目标 vCPU 的 VM，减少中断延迟 写完之后，物理 Interface 就可以写 EOI 了，根据 pGICC.EOImode，这个 EOI 不会 deactivate 中断，只是降低优先级而已。使得其他中断能够到达，即便 VM 还没有 ack 这个。但是这个 INTID 的中断不会到，所以不影响当前中断处理。 因为是发送给 VM 的中断，需要由 GIC virtual interface 来发出中断信号，也就是 vIRQ/vFIQ。 Hypervisor 将控制权切换到 VM，VM 进入处理函数，在 VM 中读 GICC 其实读的就是 GICV。 VM 处理完中断后，写 EOI，根据 EOImode 配置，最好是将 lower running priority 和 deactivate 一步完成。此时才算真正处理完一个中断。  相关：中断直通 ","date":"2024-08-08T19:28:12+08:00","permalink":"https://wangloo.github.io/posts/virtualization/intr_virt/","section":"posts","tags":["Virtualization","ARM"],"title":"虚拟化：中断虚拟化"},{"categories":["Architecture"],"contents":"  NS Group 1： 想给 REE 处理的中断 S Group 1：想给 TEE 处理的中断 Group 0：想给 ATF 处理的中断  IRQ 和 FIQ 的含义 FIQ 并不是以前意义上的快速中断，而是 Forward 中断，需要被转发的中断。IRQ 和 FIQ 的优先级是相同的。\n中断分组产生的原因？ 怎么就能做到上述的约定？ 根据 3 种当前环境（REE、TEE、ATF）和 3 种中断分组，总共有 9 种可能得情况，依次进行分析。ATF 在这里也就等价于 BL31。\n.notice { --root-color: #444; --root-background: #eff; --title-color: #fff; --title-background: #7bd; --warning-title: #c33; --warning-content: #fee; --info-title: #fb7; --info-content: #fec; --note-title: #6be; --note-content: #e7f2fa; --tip-title: #5a5; --tip-content: #efe } @media (prefers-color-scheme:dark) { .notice { --root-color: #ddd; --root-background: #eff; --title-color: #fff; --title-background: #7bd; --warning-title: #800; --warning-content: #400; --info-title: #a50; --info-content: #420; --note-title: #069; --note-content: #023; --tip-title: #363; --tip-content: #121 } } body.dark .notice { --root-color: #ddd; --root-background: #eff; --title-color: #fff; --title-background: #7bd; --warning-title: #800; --warning-content: #400; --info-title: #a50; --info-content: #420; --note-title: #069; --note-content: #023; --tip-title: #363; --tip-content: #121 } .notice { padding: 18px; line-height: 24px; margin-bottom: 24px; border-radius: 4px; color: var(--root-color); background: var(--root-background) } .notice p:last-child { margin-bottom: 0 } .notice-title { margin: -18px -18px 12px; padding: 4px 18px; border-radius: 4px 4px 0 0; font-weight: 700; color: var(--title-color); background: var(--title-background) } .notice.warning .notice-title { background: var(--warning-title) } .notice.warning { background: var(--warning-content) } .notice.info .notice-title { background: var(--info-title) } .notice.info { background: var(--info-content) } .notice.note .notice-title { background: var(--note-title) } .notice.note { background: var(--note-content) } .notice.tip .notice-title { background: var(--tip-title) } .notice.tip { background: var(--tip-content) } .icon-notice { display: inline-flex; align-self: center; margin-right: 8px } .icon-notice img, .icon-notice svg { height: 1em; width: 1em; fill: currentColor } .icon-notice img, .icon-notice.baseline svg { top: .125em; position: relative }     以下所有的 Case 描述都基于一个前提：\n BL31 非安全上下文中 SCR_EL3.IRQ=0,SCR_EL3.FIQ=1 安全上下文中 SCR_EL3.IRQ=0,SCR_EL3.FIQ=0。  这是 BL31 初始化时的默认配置，2022 年前大部分厂家也是用的这种配置。但是现在随着功能的不断演进，已经有的厂家开始修改这种路由规则了。但是我感觉，只要你了解底层原理，也能快速地理解他们这样配置的理由。\nTODO：EHF？\n Case 1：REE 时收到 NSG1  这是最简单的情况：\n 因为 REE 处于 NS 状态，根据 GICv3 上述的真值表，NSG1 会触发 IRQ。 由于此时 SCR_EL3.IRQ=0，所以 IRQ 并不会 Trap 到 EL3，就是默认的情况在 Linux Kernel 处理。  Case 2：TEE 收到 NSG1  这种情况就相对来说比较复杂，但是很经典：\n 由于当前在 S 状态，NSG1 会触发为 FIQ 大部分的 TEE 对 FIQ 没有做任何操作，特别是没有 ack 这个中断，直接执行 smc 下去。 到了 BL31，切换安全状态，进入 REE。（猜测由于是 SMC 懈怠的参数识别了这种情况？） 由于中断没有 ack，所以还处于 pendding 状态，但切换到 NS 状态后，触发的就是 IRQ 了。 在 REE linux kernel 处理后，回到 BL31，准备返回 TEE。（猜测是由于设置了某种标志才知道 IRQ 处理完是要返回 BL31 的） BL31 返回 TEE 继续执行。  Case 3：BL31 收到 NSG1  这种情况其实最终会转化成以上两种： BL31 有两种 context，安全和非安全，NSG1 在 EL3 会触发为 FIQ，两种状态下默认 FIQ 都是被 MASK 的，所以根据你之前是从哪里陷入的就会再哪里去处理这个 NSG1 中断。\nCase 4：TEE 收到 SG1 也是比较简单的情况，当前是 S 状态，收到 SG1，触发 IRQ，直接在 TEE 里被处理，不涉及异常等级的切换。\nCase 5：REE 收到 SG1   当前执行环境为 NS，SG1 被触发为 FIQ。因为 SCR_EL3.FIQ=1，所以中断直接到 BL31 FIQ handler。 BL31 实际不做处理，只是将 ELR 设置成 TEE 的处理函数，进行异常返回。（为什么没有在 TEE 重新被触发，而是在 EL3 被触发，因为 BL31 切换到 TEE 时就 MASK 所有的中断，所以用的配置 ELR 的方式进入异常处理函数） TEE 处理完成后，返回 BL31 BL31 返回 REE  Case 6：ATF 收到 SG1 和 ATF 收到 NSG1 情况类似，最后都是转成上面的两种 case，因为 BL31 中无论是 NSG1 还是 SG1 触发的都是 FIQ，而 FIQ 被 MASK，所以最后怎么处理还是看 BL31 返回时到 REE 还是 TEE。\nCase 7：TEE 收到 G0   TEE 属于 S 状态，G0 被触发为 FIQ。因为 SCR.FIQ=0，所以 FIQ 在 TEE 触发。 TEE 不会对 FIQ 做任何处理，也不会 ack 中断，直接 smc 进入 BL31。 这个 BL31 不是 FIQ 的处理函数，而是一个 SMC 处理函数，因为此时中断是 MASK 的，所以不会在 BL31 再次出发。BL31 的做法是切换安全状态，回到 REE。 在 REE，G0 会再次触发，根据真值表来看仍然是 FIQ，而此时因为 SCR.FIQ=1，所以 BL31 可以直接进入中断处理函数。  Case 8：REE 收到 G0 比较简单，REE 时 G0 触发为 FIQ，因为 SCR_EL3.FIQ=1，所以中断在 BL31 触发，直接被处理。再返回 REE。\nCase 9：BL31 收到 G0 默认 BL31 屏蔽，所以不会被触发。一直处于 pending 状态，直到返回 REE 或者 TEE，就又回到了 Case7 和 Case8 的情况。\nTODO：EHF？\n","date":"2024-08-02T23:51:49+08:00","permalink":"https://wangloo.github.io/posts/arch/armv8/gicv3/intr_grp/","section":"posts","tags":["armv8","gic"],"title":"ARMv8 中断管理(4): 中断分组"},{"categories":["Operating System"],"contents":"PSCI PSCI, Power State Coordination Interface，由 ARM 定义的电源管理接口规范。 目前 PSCI 最新规格为 v1.1，《POWER STATE COORDINATION INTERFACE (PSCI) System Software on ARM® Systems》。\n为什么要有 PSCI 协议？ 以前，ARM 中设备的电源管理由 OS 内核负责，随着多 OS、虚拟化技术的发展，电源管理需要有一个单独统一的组件去完成。ARMv8 引入 PSCI 协议，OS 内核里的所有电源管理行为通过 smc/hvc 下陷到 hypervisor/EL3 完成，通常在 EL3。ATF 里那就是 BL31 去做这件事。\nPSCI 规定了 OS 内核发送 smc 指令的标准电源管理请求格式，BL31 会按照这个格式去实现具体的方案。所以，只要 OS 是遵循 PSCI 协议的，就能使得 OS 和 BL31 解绑，通用性更好。\nSCP BL31 接收到 PSCI SMC 消息，然后呢？这一块又是解耦的设计，电源管理具体是要一个单独的硬件控制器去做，BL31 的任务就是将 PSCI SMC 请求转化为具体电源控制器的控制指令。\nSCP, System Control Processor，是一个控制电源的硬件，里面运行的固件叫 SCP Firmware。BL31 需要想办法和 SCP 通信。\nSCMI SCMI（System Control and Management Interface），是 BL31 和 SCP 的通信接口。当然，有了 SCMI 标准接口，SOC 中的其他 IP 也可以通过 SCMI 接口与 SCP 通信控制电源。\n热插拔 Hotplug echo 0 \u0026gt; /sys/devices/system/cpu/cpu1/online //拔核操作 echo 1 \u0026gt; /sys/devices/system/cpu/cpu1/online //插核操作 CPU 热插拔是在不关闭系统电源的情况下，根据需求动态“关闭”任意 non-boot CPU，可避免因为 CPU 空转造成的能源浪费。\n AP：将要被拔掉的 cpu。 BP：处理拔核流程的 cpu。  CPU Down Linux 侧行为 // 如果config中启用了hotplug功能，则定义回调函数 cpu_subsys_online/cpu_subsys_offline struct bus_type cpu_subsys = { .name = \u0026#34;cpu\u0026#34;, .dev_name = \u0026#34;cpu\u0026#34;, .match = cpu_subsys_match, #ifdef CONFIG_HOTPLUG_CPU \t.online = cpu_subsys_online, .offline = cpu_subsys_offline, #endif }; // 如果config中启用了hotplug功能 const struct cpu_operations cpu_psci_ops = { .name\t= \u0026#34;psci\u0026#34;, .cpu_init\t= cpu_psci_cpu_init, .cpu_prepare\t= cpu_psci_cpu_prepare, .cpu_boot\t= cpu_psci_cpu_boot, #ifdef CONFIG_HOTPLUG_CPU \t.cpu_can_disable = cpu_psci_cpu_can_disable, .cpu_disable\t= cpu_psci_cpu_disable, .cpu_die\t= cpu_psci_cpu_die, .cpu_kill\t= cpu_psci_cpu_kill, #endif  cpu_subsys_offline() =\u0026gt; cpu_down(cpu = dev-\u0026gt;id, CPUHP_OFFLINE) cpu_down(cpu, target) =\u0026gt; cpuhp_kick_ap_work(cpu) // 使AP放弃手头工作，进入CPUHP_TEARDOWN_CPU状态  =\u0026gt; wake_up_process(ap-\u0026gt;thread); =\u0026gt; wait_for_ap_thread(); =\u0026gt; cpuhp_down_callbacks() // 进一步 clean AP  =\u0026gt; takedown_cpu(cpu) takedown_cpu(cpu) =\u0026gt; stop_cpus() =\u0026gt; queue_stop_cpus_work() // !! 将die自己的线程加入AP的运行队列，  // 等待AP自己die，而不是BP完全帮他  =\u0026gt; __cpu_die() // 见下  // ====== 切换到 AP 的执行视角 take_cpu_down() =\u0026gt; __cpu_disable() // 设置CPU状态为OFFLINE，一旦如此，IDLE线程里就会 call idle_dead()  =\u0026gt; set_cpu_online(cpu, false); =\u0026gt; irq_migrate_all_off_this_cpu()// 中断迁移  =\u0026gt; // 任务迁移 idle_dead() // PSCI 接口，切换到BL31执行实际电源管理。  =\u0026gt; cpu_die() // ====== 返回 BP 的执行视角 // 等待 BP 完成自己的die =\u0026gt; __cpu_die(cpu) =\u0026gt; cpu_wait_death(cpu) =\u0026gt; op_cpu_kill(cpu) =\u0026gt; cpu_kill(cpu) // cpu_psci_cpu_kill() 总结来看：\n 用户输入echo 0 \u0026gt; /sys/devices/system/cpu/cpu1/online 唤醒 AP per_cpu 线程，完成手头的工作 设置 AP cpu 的状态为 OFFLINE，AP 的 idle 线程会自己调用 psci 接口 die 做 AP 上的任务迁移和中断迁移 BP 会等到 AP 自杀完成  BL31 侧行为 CPU UP 唤醒后执行哪里的代码？是 warm boot 还是 cold boot？\n系统休眠唤醒 echo mem \u0026gt; /sys/power/state 关机重启 ","date":"2024-08-02T19:28:12+08:00","permalink":"https://wangloo.github.io/posts/os/bl31_pm/","section":"posts","tags":["Operating System"],"title":"ATF 解读：电源管理"},{"categories":["Python"],"contents":"jinja2 要了解jinja2，那么需要先理解模板的概念。 python中自带一个简单的模板，就是string提供的。\n\u0026gt;\u0026gt;\u0026gt; import string \u0026gt;\u0026gt;\u0026gt; a = string.Template(\u0026#39;$who is $role\u0026#39;) \u0026gt;\u0026gt;\u0026gt; a.substitute(who=\u0026#39;daxin\u0026#39;,role=\u0026#39;Linux\u0026#39;) \u0026#39;daxin is Linux\u0026#39; \u0026gt;\u0026gt;\u0026gt; a.substitute(who=\u0026#39;daxin\u0026#39;,role=\u0026#39;cat\u0026#39;) \u0026#39;daxin is cat\u0026#39; \u0026gt;\u0026gt;\u0026gt; Python自带的模板功能极其有限，如果我们想要在模板中使用控制语句，和表达式，以及继承等功能的话，就无法实现了。\n目前主流的模板系统，最常用的就是jinja2和mako\njinja2是Flask作者开发的一个模板系统，之所以被广泛使用是因为它具有以下优点：\n 相对于Template，jinja2更加灵活，它提供了控制结构，表达式和继承等。 相对于Mako，jinja2仅有控制结构，不允许在模板中编写太多的业务逻辑。 相对于Django模板，jinja2性能更好。 Jinja2模板的可读性很棒。  ","date":"2024-07-30T19:28:12+08:00","permalink":"https://wangloo.github.io/posts/python/libs/","section":"posts","tags":["Python"],"title":"Python：三方库"},{"categories":["Operating System"],"contents":"CI/CD  CI 全名(Continuous Integration)持续集成， CD 全名是(Continuous Deployment)，是持续部署。CD 还有个小号，叫持续交付，英文全称是 Continuous delivery，缩写也是 CD。  现在很多公司都有做持续集成，Jenkins 就是一个持续集成的工具，开源的，基于 JAVA 语言的。\nCI 是持续集成，意思是让多个开发者，能够共同在同个代码库中开发不同的新功能，然后能够持续整合到某个分支上面。之所要持续做这件事，是因为开发不同功能时，代码可能会有冲突，而持续地整合就能及早化解冲突。在 CI 的流程中，也会有自动化测试与建构，来避免等要上线前一次合并才发现有测试跑不过，或者建构有错误。\nCD 则是持续交付/部署，在整合完后有自动化的部署流程。最理想的状况，是当开发者把代码合并后，就会开始整合、测试，最终部署，整个流程不需用有人工介入，一切自动化完成，新的功能就会到最端使用者手上。\n .notice { --root-color: #444; --root-background: #eff; --title-color: #fff; --title-background: #7bd; --warning-title: #c33; --warning-content: #fee; --info-title: #fb7; --info-content: #fec; --note-title: #6be; --note-content: #e7f2fa; --tip-title: #5a5; --tip-content: #efe } @media (prefers-color-scheme:dark) { .notice { --root-color: #ddd; --root-background: #eff; --title-color: #fff; --title-background: #7bd; --warning-title: #800; --warning-content: #400; --info-title: #a50; --info-content: #420; --note-title: #069; --note-content: #023; --tip-title: #363; --tip-content: #121 } } body.dark .notice { --root-color: #ddd; --root-background: #eff; --title-color: #fff; --title-background: #7bd; --warning-title: #800; --warning-content: #400; --info-title: #a50; --info-content: #420; --note-title: #069; --note-content: #023; --tip-title: #363; --tip-content: #121 } .notice { padding: 18px; line-height: 24px; margin-bottom: 24px; border-radius: 4px; color: var(--root-color); background: var(--root-background) } .notice p:last-child { margin-bottom: 0 } .notice-title { margin: -18px -18px 12px; padding: 4px 18px; border-radius: 4px 4px 0 0; font-weight: 700; color: var(--title-color); background: var(--title-background) } .notice.warning .notice-title { background: var(--warning-title) } .notice.warning { background: var(--warning-content) } .notice.info .notice-title { background: var(--info-title) } .notice.info { background: var(--info-content) } .notice.note .notice-title { background: var(--note-title) } .notice.note { background: var(--note-content) } .notice.tip .notice-title { background: var(--tip-title) } .notice.tip { background: var(--tip-content) } .icon-notice { display: inline-flex; align-self: center; margin-right: 8px } .icon-notice img, .icon-notice svg { height: 1em; width: 1em; fill: currentColor } .icon-notice img, .icon-notice.baseline svg { top: .125em; position: relative }    补充说明: CI/CD 与 DevOps 的关系？  可能有读者会问 CI/CD 与 DevOps 的关系。在爬梳这段历史时，看到 DevOps 约是 2008 - 2009 年左右被提出；而 CI/CD 则是更早之前就有，只是后来才逐渐在业界普及。目前 CI/CD 是 DevOps 中的重要元素。可以在 Atlassian 这篇介绍看到，建置 CI/CD 流程是 DevOps 工程师的重要能力之一 ，但要成为 DevOps 工程师，还需要有其他技能。\n Footprint 程序波及的范围，这个范围可以是多个层面的，比如说内存访问的局部性强，也就是footprint小。\nBanner Banner 表示旗帜或者标志物。\n","date":"2024-07-30T19:28:12+08:00","permalink":"https://wangloo.github.io/posts/os/glossary/","section":"posts","tags":["Operating System"],"title":"名词解释"},{"categories":["Operating System"],"contents":"配置 # 下载源代码 git clone https://gitee.com/coollh/zephyr.git # 下载SDK wget https://github.com/zephyrproject-rtos/sdk-ng/releases/download/v0.16.8/zephyr-sdk-0.16.8_linux-x86_64.tar.xz # 进入 sdk 目录，setup tar xvf zephyr-sdk-0.16.8_linux-x86_64.tar.xz cd zephyr-sdk-0.16.8/ ./setup.sh # 加入环境变量到 zephyr-env.sh export ZEPHYR_GCC_VARIANT=zephyr export ZEPHYR_SDK_INSTALL_DIR=../zephyr-sdk-0.16.8 ## Zephyr SDK 安装路径 export ZEPHYR_BASE=. ## Zephyr 源码路径 # source 环境变量文件 source zephyr-env.sh # 安装依赖的库 pip3 install --user -r ~/zephyr/scripts/requirements.txt 编译并在qemu-x86上仿真运行 hello-world cd zephyr/samples/hello_world/ mkcd build cmake -GNinja -DBOARD=qemu_x86 .. ninja # build ninja run # build and run Ref  《嵌入式系统 – Zephyr开发笔记》 第2章 Zephyr 编译环境搭建（Linux） - BruceOu的博客  ","date":"2024-07-29T19:28:12+08:00","permalink":"https://wangloo.github.io/posts/os/zephyr-01/","section":"posts","tags":["Operating System"],"title":"Zephry：编译"},{"categories":["Operating System"],"contents":"设备树是一种描述硬件信息的文件格式。\n设备树实现了驱动代码与硬件设备信息的分离，驱动代码可以有很多，但是不一定每个设备都要用。在设备树中配置了启用哪些设备，和一些关于设备的配置，比如说中断号是多少、内存地址是哪里。就能与驱动代码分离开，即便是不用板子的外设，只要型号一致就能用同一份驱动。其他的尽量做成可配置的。\n设备树的加载流程 Uboot将设备树的地址传给 Linux内核\nbootm \u0026lt;uImage_addr\u0026gt; \u0026lt;initrd_addr\u0026gt; \u0026lt;dtb_addr\u0026gt; start_kernel是内核进入C环境调用的第一个函数，不久后便会调用dtb的解析。\nstart_kernel() =\u0026gt; setup_arch(\u0026amp;command_line); =\u0026gt; setup_machine_fdt(__fdt_pointer); __fdt_pointer 是在汇编中赋值的，存储由Uboot传来的fdt地址。\n/* * Preserve the arguments passed by the bootloader in x0 .. x3 */ SYM_CODE_START_LOCAL(preserve_boot_args) mov\tx21, x0\t// x21=FDT adr_l\tx0, boot_args\t// record the contents of stp\tx21, x1, [x0]\t// x0 .. x3 at kernel entry stp\tx2, x3, [x0, #16]  dmb\tsy\t// needed before dc ivac with // MMU off mov\tx1, #0x20\t// 4 x 8 bytes \tb\t__inval_dcache_area\t// tail call SYM_CODE_END(preserve_boot_args) ... str_l\tx21, __fdt_pointer, x5\t// Save FDT pointer TBD：继续分析 setup_machine_fdt() ？\n设备树调试 查看原始的dtb文件\nls /sys/firmware/fdt hexdump -C /sys/firmware/fdt 查看设备树信息。以目录结构程现的dtb文件, 根节点对应base目录, 每一个节点对应一个目录, 每一个属性对应一个文件 /proc/device-tree 是链接文件, 指向 /sys/firmware/devicetree/base\nls /sys/firmware/devicetree ls /proc/device-tree 查看所有硬件信息。系统中所有的platform_device, 有来自设备树的, 也有来有.c文件中注册的。\nls /sys/devices/platform ","date":"2024-07-26T19:28:12+08:00","permalink":"https://wangloo.github.io/posts/os/devicetree/","section":"posts","tags":["Operating System"],"title":"设备树 Device Tree"},{"categories":["Operating System"],"contents":"BL31 位于 EL3 安全世界， 提供运行时服务，并不像 BL1 和 BL2 一样 boot 后就释放空间，其他的子系统通过 SMC 调用向 BL31 发送请求，包括安全世界的切换。\nBL31 不是必须得，如果实际没有实现 EL3，或者不需要 Secure Monitor，则可以不用 BL31.\nGIC 初始化 默认配置 GIC，其中 GIC 有一些配置在 secure state 才能配置，所以在这里配一下。\nBL31 中，每个 platform 都有一个分配中断分组的全局变量qemu_interrupt_props（以 QEMU 为例），在 BL31 中可以将一些中断划分为 G1S 或 G0。当然，我猜测 BL32 也可以重设，毕竟 BL32 也要设定一些特殊中断，比如说安全 uart。\nEHF 配置完 GIC 后，紧接着就是可选的 EHF 功能。 默认 ATF 中关中断，这个我们可以想想，EL31 负责安全世界的切换，有点像处于异常处理上下文中，也没有什么中断需要触发，所以关中断也是合理的。\nEHF 通过编译选项 EL3_EXCEPTION_HANDLING 控制开关，EHF 的功能就是让 EL3 能处理其他中断（除了原本的 SMC），原本的情况是直接返回，让上面的 EL 处理。开启 EHF 后，其他的应用可以注册一些中断处理函数到 EL3，并设置 SCR_EL3.IRQ/FIQ，置 1 之后，IRQ/FIQ 会被路由到 EL3，调用之前注册好的 handler。\nEHF 的全称是 Exception Handling Framework，既然是 Framework，一个框架，就是提供注册的接口。 其他的子模块填充一个 intr_type_descs 成员，它是一个数组\n 下标 type 代表想要运行在哪个状态的中断 Trap 到 EL3？是 SEL1？EL3？还是 Non-secure 我们知道，每种 type 下，都有三种类型的中断（G0、G1S、G1NS），有时我们只想让 EL3 handle 其一，或者都。 EHF 提供的粒度是 IRQ 和 FIQ。知道当前运行的 type，和你想要 trap EL3 的中断分组，就能唯一得到中断是 IRQ/FIQ。 所以你可以单独设计这个 IRQ/FIQ 是否 Trap，来达到你想要只 trap 一种分组的目的。当然这不是一一对应的，IRQ 可能对应多个中断分组，这是没办法的事情。只能人为做更加严格的中断分组。 配置完成后，框架会将 IRQ 和 FIQ 置位的情况（成员 scr_el3[2]) 汇总，存到上下文中，返回时到该 type 时恢复。  typedef struct intr_type_desc { interrupt_type_handler_t handler; u_register_t scr_el3[2]; // 2 =\u0026gt; 两种安全状态下的scr_el3  uint32_t flags; // bit[0]: routing model for interrupt from not EL3 but secure state  // bit[1]: routing modul for interrupt from not EL3 but non-secure state  // \u0026#39;1\u0026#39; =\u0026gt; this interrupt will be routed to EL3  // \u0026#39;0\u0026#39; =\u0026gt; this interrupt will be routed to current EL } intr_type_desc_t; #define INTR_TYPE_S_EL1\tU(0) #define INTR_TYPE_EL3\tU(1) #define INTR_TYPE_NS\tU(2) #define MAX_INTR_TYPES\tU(3) #define INTR_TYPE_INVAL\tMAX_INTR_TYPES  static intr_type_desc_t intr_type_descs[MAX_INTR_TYPES]; ATF 中中断的注册(这三种类型的 handler 程序的注册)，以 INTR_TYPE_S_EL1 为例：\n在开机 bl32_main 调用 opteed_setup()时，将 opteed_sel1_interrupt_handler()函数注册成了 INTR_TYPE_S_EL1 类型中断，同时也会将 REE(Linux)使用的 SCR_EL3.FIQ 配置成 1,也意味着当 CPU 运行在 REE 时，来了一个 secure group1 的中断，此中断在 REE 中被标记 FIQ 后将被 target 到 EL3，进入 EL3(ATF)的中断处理函数，也就是刚才注册的 opteed_sel1_interrupt_handler()函数，在该函数中，会将 cpu 切换到 TEE 中，去处理这个中断。这就是 REE 切换到 TEE 的一种方式。\n 由此我们再看 EHF 的实现原理。\n/* The ``flags`` field stores the routing model for the interrupt type in bits[1:0]. Bit[0] stores the routing model when execution is in the secure state. Bit[1] stores the routing model when execution is in the non-secure state. As mentioned in Section `Routing model`_, a value of ``0`` implies that the interrupt should be targeted to the FEL. A value of ``1`` implies that it should be targeted to EL3. The remaining bits are reserved and SBZ. The helper macro ``set_interrupt_rm_flag()`` should be used to set the bits in the ``flags`` parameter. */ // EL3 不是要处理中断吗，当SCR_EL3.IRQ/FIQ打开时，会进入EL3的异常处理函数， // ehf_init()做的就是初始化好这个框架，使得EL3在接收到FIQ、IRQ后不会直接返回， // 为其注册了一个大的 handler，在里面根据情况调用其他type的处理函数。 ehf_init() =\u0026gt; set_interrupt_rm_flag(flags, NON_SECURE); // flag | (1 \u0026lt;\u0026lt; 1)  =\u0026gt; if SPMC is not present in S-EL2 =\u0026gt; set_interrupt_rm_flag(flags, SECURE); // flag | (1 \u0026lt;\u0026lt; 0)  =\u0026gt; register_interrupt_type_handler(type=INTR_TYPE_EL3,,flags=flags) register_interrupt_type_handler() =\u0026gt; set_routing_model(INTR_TYPE_EL3, flags) set_routing_model() =\u0026gt; intr_type_descs[INTR_TYPE_EL3].flags = flags; // 两次调用分别将FIQ和IRQ的情况汇总到最终上下文中的SCR寄存器  =\u0026gt; set_scr_el3_from_rm(type=INTR_TYPE_EL3, flags, SECURE); =\u0026gt; set_scr_el3_from_rm(type=INTR_TYPE_EL3, flags, NON_SECURE); set_scr_el3_from_rm() // 看传入secure state在flag中对应的bit是1还是0  =\u0026gt; flag = get_interrupt_rm_flag(flags, security_state); // 计算SCR_ELx中对应secure state（FIQ/IRQ）的控制 bit  =\u0026gt; bit_ops = plat_interrupt_type_to_line(INTR_TYPE_EL3, security_state); =\u0026gt; intr_type_descs[type].scr_el3[security_state] = (u_register_t)flag \u0026lt;\u0026lt; bit_pos; /* * Update scr_el3 only if there is a context available. If not, it * will be updated later during context initialization which will obtain * the scr_el3 value to be used via get_scr_el3_from_routing_model() */ =\u0026gt; cm_write_scr_el3_bit(security_state, bit_pos, flag); /******************************************************************************* * This function updates a single bit in the SCR_EL3 member of the \u0026#39;cpu_context\u0026#39; * pertaining to the given security state using the value and bit position * specified in the parameters. It preserves all other bits. ******************************************************************************/ cm_write_scr_el3_bit() =\u0026gt; ctx = cm_get_context(security_state); scr_el3 = read_ctx_reg(state, CTX_SCR_EL3); scr_el3 \u0026amp;= ~(1UL \u0026lt;\u0026lt; bit_pos); scr_el3 |= (u_register_t)value \u0026lt;\u0026lt; bit_pos; write_ctx_reg(state, CTX_SCR_EL3, scr_el3); SDEI SDEI: Software Delegated Exception Interface，软件委派异常接口。\n其实就是在 EL1(或 EL2)能够注册 SDEI 中断，其实就是切换到 EL3 中将该中断注册成 group0 中断，然后当事件到来时，中断将直接 target 到 EL3，在 EL3 的处理程序中会 dispatcher 到 EL1(EL2)中再处理。\n  用图来表示就是上述的过程，大概分为以下几步：\n Linux/hyperv 注册一个中断为 SDEI 中断，调用 SDEI API SDEI API 准备好参数，调用 smc 指令陷入 EL3，EL3 将这个中断号配置为Group0分组，并设置好 SCR_EL3.IRQ/FIQ 当运行在 EL1/2 时，来了一个注册为 SDEI 的中断，因为是 Group0 且 SCR_EL3.FIQ 被置位，所以直接路由到 EL3 处理。 EL3 fiq handler 识别到这是一个注册为 SDEI 的中断，则返回上层注册的 hangler 去执行，处理完后再返回。  SDEI 和 EHF 的关系 结论：SDEI 依赖 EHF。\n没有开 EHF 的情况下，BL31 是不处理 FIQ、IRQ 的，没有 dispatch 的行为。\nSDEI 的应用 Hypervisor 引入 Hypervisor 后，如果开启了中断直通，那么 hostVM 就不能控制 guestVM 了，这里的”控制“的含义是将其拉到 EL2 hypervisor。为什么呢？\n 因为没有中断直通的情况下，hostVM 发送 IPI 给 guestVM，Hypervisor 会拦截 IPI，识别到这是一个控制 guestVM 的行为，就会停在 Hypervisor 完成相应的服务。 但是，如果开启了中断直通，这个 IPI 不会被 Hypervisor 拦截，而是直接到了 GuestVM 里，GuestVM 并不一定会选择陷入 Hypervisor，这取决于 guestVM 的实现，所以说不能保证。  此时可以通过把某个 IPI 注册为 SDEI 中断，使得发送 IPI 首先被 EL3 拦截，通过注册 Hypervisor 对应的处理函数，就使得 guestVM 一定进入 EL2。\nNMI NMI 的含义是不可屏蔽中断，如果某个中断我们想让其快速触发，通过注册为 SDEI 中断，即便是在 EL1/2 是屏蔽中断的环境下，这个中断也能直接到达 EL3，dispatch 到 EL1/2 完成处理，不受中断屏蔽上下文的影响。\n运行时服务 ","date":"2024-07-22T19:28:12+08:00","permalink":"https://wangloo.github.io/posts/os/bl31/","section":"posts","tags":["Operating System"],"title":"ATF 解读：中断"},{"categories":["Architecture"],"contents":"作为一个 OS 开发者，到底什么时候需要维护 Cache ？\nCache alias（别名）问题 Cache 的组织方式 如何检索 Cache 表项，因为访问地址/数据时有虚拟地址转物理地址的过程，所以检索可能以虚拟地址为索引，或者是先翻译，再以物理地址为索引去查找 Cache。Cache 检索时的行为取决与 Cache 的组织方式，这是由硬件决定的。\n?I?T，I 代表 Index，即以哪种地址去索引。T 代表 Tag，即索引到表项后以什么地址去检查。因为 Cache 支持多路的原因，同一个 Index 可能对应多个表项，需要依次的和 Tag 比对，直到匹配成功或者 Cache Miss。\nVIVT(Virtual Index Virtual Tag) 早期的 ARM 处理器一般采用这种方式，全使用虚拟地址，这种方式会导致 cache 别名(cache alias)问题。\nVIPT(Virtual Index Physical Tag) 使用虚拟地址做索引，物理地址做 Tag。在利用虚拟地址索引 cache 同时，同时会利用 TLB/MMU 将虚拟地址转换为物理地址。然后将转换后的物理地址，与虚拟地址索引到的 cache line 中的 Tag 作比较，如果匹配则命中。\n这种方式要比 VIVT 实现复杂，当进程切换时，不在需要对 cache 进行 invalidate 等操作(因为匹配过程中需要借物理地址)。但是这种方法仍然存在 cache 别名的问题，但是可以通过一定手段解决。\nPIPT(Physical Index Physical Tag) 使用物理地址做索引，物理地址做 Tag。现代的 ARM Cortex-A 大多采用 PIPT 方式，由于采用物理地址作为 Index 和 Tag，所以不会产生 cache alias 问题。不过 PIPT 的方式在芯片的设计要比 VIPT 复杂得多，而且需要等待 TLB/MMU 将虚拟地址转换为物理地址后，才能进行 cache line 寻找操作。\n Data cache invalidate on reset\n  The Armv8-A architecture does not support an operation to invalidate the entire data cache. If software requires this function, it must be constructed by iterating over the cache geometry and executing a series of individual invalidate by set/way instructions.\n outof-order and speculative execution\nMemory Barriers（内存屏障） 指令流水线，指令预取，Store buffer 等很多优化为了提高性能。然而，有时候一些前后的依赖微架构自身并不能保证，所以 ARM 指令集提供了一些显式的或者说强制的 barrier 来保证一些指令执行顺序/数据读写顺序。\nInstruction Synchronization Barrier Instruction Synchronization Barrier(ISB) 指令确保后续指令在 isb 执行之后重新 fetch，即起到了刷新 pipeline 的效果。 用到 isb 的地方一般与内存、Cache 操作相关。确保ISB之前的context-changing操作会被之后的指令看到。\nMRS X1, CPACR_EL1 // Copy contents of CPACR to X1 ORR X1, X1, #(0x3 \u0026lt;\u0026lt; 20) // Write to bit 20 of X1. (Enable FPU and SIMD) MSR CPACR_EL1, X1 // Write contents of X1 to CPACR ISB // enable FPU 和 SIMD 后，后续指令执行的方式就会发生变化， // 所以当前流水线上的指令必须重新fetch // Linux kernel: arch/arm64/kernel/head.S // 其他的指令后面会介绍到，这个例子中可以仅关注isb msr\tsctlr_el1, x19\t// re-enable the MMU isb // 开启MMU后，流水线上按照原来页表取得的指令就可能不对 // 需要重新按照新的mapping来fetch ic\tiallu\t// 改变了mapping，Icache上的映射需要invalid dsb\tnsh\t// 确保前面icache invalid操作执行完毕 isb // 确保后面预取的指令不受 ICache old value 的影响 // ，后续之行必须重新 Fetch Data Synchronization Barrier(DSB) 当处理器执行 DSB 指令时，会 block 后面指令执行，直到 DSB 前面的指令执行完成。\nDSB, DMB 携带参数 OSHLD Operation that waits only for loads to complete, and only to the outer shareable domain\nISH | Inner SHareable | Operation only to the Inner Shareable domain.\nDC 指令 IC 指令 IC \u0026lt;ic_op\u0026gt;, {\u0026lt;Xt\u0026gt;}  IC IALLU: Invalidate ALL to PoU，无效化所有到 PoU 的指令缓存行。 IC IALLUIS: 表示 Invalidate all to PoU, Inner Shareable，无效化所有到 PoU 的，内部可共享（Inner Shareable）的指令缓存行。 IC IVAU: 表示 Invalidate Virtual Address to PoU，无效化虚拟地址到 PoU 的指令缓存行。  案例 1 assembly - Does AArch64 need a DSB after creating a page table entry? - Stack Overflow\n填充一个空的页表，然后立马用虚拟地址去访问，这之间需要什么 fence 类指令吗？\nstr x1, [x0] ;x1 is phy addr for pte, x0 is pte_entry ; \u0026lt;\u0026lt; need any fence? ldr x2, [x3] ;x3 has VA that is mapped by above instruction ARMv8 requires what they call a \u0026ldquo;break-before-make\u0026rdquo; procedure when 更新页表项。 This procedure is described in G5.9.1 in the ARMv8 ARM:\n A break-before-make sequence on 修改页表项 requires the following steps:\n Replace the old translation table entry with an invalid entry, and execute a DSB instruction. Invalidate the translation table entry with a broadcast TLB invalidation instruction, and execute a DSB instruction to ensure the completion of that invalidation. Write the new translation table entry, and execute a DSB instruction to ensure that the new entry is visible. This sequence ensures that at no time are both the old and new entries simultaneously visible to different threads of execution, and therefore the problems described at the start of this subsection cannot arise.   对于该问题来说，因为原来已经是无效的表项，所以可以直接跳过 1、2 步，直接执行第三步即可。 同时，针对这种情况，DSB 可以规定为 SH 参数来优化性能。DSB 之后的 ISB 也是必须的，使后面的 ldr 指令重新 fetch，因为页表已经更新，可能更新了下一条指令地址的页表项，使得新的 fetch 对应不同的指令，所以加一个 isb 比较安全。\n案例 2 Linux Kernel __enable_mmu()\nSYM_FUNC_START(__enable_mmu) ... msr\tttbr0_el1, x2\t// load TTBR0 offset_ttbr1 x1, x3 msr\tttbr1_el1, x1\t// load TTBR1 isb msr\tsctlr_el1, x0 isb // 开了MMU以后，后面根据PC预取的指令可能对应别的指令地址，需要重新fetch /* * Invalidate the local I-cache so that any instructions fetched * speculatively from the PoC are discarded, since they may have * been dynamically patched at the PoU. */ ic\tiallu dsb\tnsh // 充当一个barrier，确保上面icache clean完毕后，isb才commit isb // 后面的指令可能之前从icache中fetch的，在icache clean后需要重新fetch ret SYM_FUNC_END(__enable_mmu) 案例 3 自己做的项目中，修改当前 TTBR 寄存器后，没有做相应的处理。 正常来说，在 MMU 和 Cache 都 Enable 时，修改 TTBR 后，需要做几件事：\ndsb st ; Ensure writes to tables have completed  msr ttbr0_el2, x0 ; Set the root table  tlbi vmalle2 ; Invalidate TLB entry dsb sy ; Ensure TLB invalidation has completed ic iallu ; Clean Icache if VIVT or aliasing VIPT dsb sy ; Ensure Icache clean has completed isb ; Refetch following instructions using 正确的 pagetable 和 cache、TLB 案例 4 .macro\t__idmap_cpu_set_reserved_ttbr1, tmp1, tmp2 adrp\t\\tmp1, empty_zero_page phys_to_ttbr \\tmp2, \\tmp1 offset_ttbr1 \\tmp2, \\tmp1 msr\tttbr1_el1, \\tmp2 isb // 必须吗？ tlbi\tvmalle1 dsb\tnsh isb .endm ","date":"2024-07-14T22:02:04+08:00","permalink":"https://wangloo.github.io/posts/arch/armv8/cache2/","section":"posts","tags":["armv8"],"title":"ARMv8: cache相关知识2"},{"categories":["Operating System"],"contents":"查看内核的符号\ncat /proc/kallsyms | grep tracepoint 查看内核启动log\ndmesg | more 运行时查看内核的设备输\n在 /sys/fireware 下是关于Linux内核运行时的设备信息，其中fdt是dtb格式。而devicetree/ 按照层级目录的形式展现dts。\n查看内核的.config\n# zcat 快速预览压缩文件内容 zcat /proc/config.gz ","date":"2024-05-17T14:51:49+08:00","permalink":"https://wangloo.github.io/posts/os/linux/devel_kern/","section":"posts","tags":["Operating System","Linux"],"title":"Linux 内核开发经验技巧"},{"categories":["Thinking"],"contents":"长征 《清平乐·会昌》近现代·毛泽东\n东方欲晓，莫道君行早。踏遍青山人未老，风景这边独好。会昌城外高峰，颠连直接东溟。战士指看南粤，更加郁郁葱葱。\n 1933年下半年蒋介石发动第五次“围剿”。中共此时听取国产国际而实行“御敌于国门之外”的错误方针，与敌硬拼，致使红军连吃败仗，毛泽东此时被雪藏。1934年4月，毛泽东在被冷遇三个月后，重新工作，前往中央苏区南部的会昌视察并指导工作，准备开展新的根据地。\n哪怕是在这种情境下，我们还是能从这首词中读出一种乐观、积极的态度。\n 李白 使寰区大定，海县清一。是李白的政治抱负。\n李白当时在唐玄宗手下做待诏翰林， “但用东山谢安石，为君谈笑静胡沙。”《永王东巡歌十一首》。 我李白就是像东山谢安那样的人物，你只要好好的任用我，千秋大业唾手可得。\n.notice { --root-color: #444; --root-background: #eff; --title-color: #fff; --title-background: #7bd; --warning-title: #c33; --warning-content: #fee; --info-title: #fb7; --info-content: #fec; --note-title: #6be; --note-content: #e7f2fa; --tip-title: #5a5; --tip-content: #efe } @media (prefers-color-scheme:dark) { .notice { --root-color: #ddd; --root-background: #eff; --title-color: #fff; --title-background: #7bd; --warning-title: #800; --warning-content: #400; --info-title: #a50; --info-content: #420; --note-title: #069; --note-content: #023; --tip-title: #363; --tip-content: #121 } } body.dark .notice { --root-color: #ddd; --root-background: #eff; --title-color: #fff; --title-background: #7bd; --warning-title: #800; --warning-content: #400; --info-title: #a50; --info-content: #420; --note-title: #069; --note-content: #023; --tip-title: #363; --tip-content: #121 } .notice { padding: 18px; line-height: 24px; margin-bottom: 24px; border-radius: 4px; color: var(--root-color); background: var(--root-background) } .notice p:last-child { margin-bottom: 0 } .notice-title { margin: -18px -18px 12px; padding: 4px 18px; border-radius: 4px 4px 0 0; font-weight: 700; color: var(--title-color); background: var(--title-background) } .notice.warning .notice-title { background: var(--warning-title) } .notice.warning { background: var(--warning-content) } .notice.info .notice-title { background: var(--info-title) } .notice.info { background: var(--info-content) } .notice.note .notice-title { background: var(--note-title) } .notice.note { background: var(--note-content) } .notice.tip .notice-title { background: var(--tip-title) } .notice.tip { background: var(--tip-content) } .icon-notice { display: inline-flex; align-self: center; margin-right: 8px } .icon-notice img, .icon-notice svg { height: 1em; width: 1em; fill: currentColor } .icon-notice img, .icon-notice.baseline svg { top: .125em; position: relative }    待诏翰林  唐代开始作为官及官署名，最初的性质是“天下以艺能技术见召者之所处也”，文学、经术、僧道、书画、琴棋等各色人士以其专长听候君主召见，称“待诏翰林”。\n 这时候唐玄宗就让他天天写诗，比如“云想衣裳花想容，春风拂槛露华浓。“ 久而久之李白肯定不乐意，跟唐玄宗辞职，李白走的时候唐玄宗就给他一大笔钱。历史上这件事被称作”赐金放还“。\n去好朋友丹丘生家里做客，做了《将进酒》\n 三人要喝个尽兴（会须一饮三百杯）， 让丹丘生不用担心没酒，我李白有的是钱（五花马，千金裘，呼儿将出换美酒）。 在长安在皇帝身边虽好，但是看不上（锦城虽云乐，不如早还家）  后面李白不做官就去访道了，李白说“仙人抚我顶，结发受长生”，“紫阳之真人，邀我吹玉笙“。 但再后面因缘聚会，去给永王做幕僚去了，被平定后李白就被流放了。李白有一首“两岸猿声啼不住，轻舟已过万重山”，是当时皇帝大赦天下，李白得知自己被释放后，就写下了这首《早发白帝城》。\n李白走的两条路都是非常艰难的：\n “十五游神仙，仙游未曾歌”，成为神仙，长生不老 “十五观奇书，作赋凌相如”，当人间做宰相，权力之巅  李白的一生都围绕这两个方向，这两条路都是非常艰难的，所以李白才常常感叹事与愿违，“欲渡黄河冰塞川，将登太行雪满山”，我想成就一番事业，但有人从中作梗，但李白无所谓啊，他觉得自己雄才满腹、良略在怀。所以又有最后的感慨“长风破浪会有时，直挂云帆济沧海”。\n   《行路难》  李白第一次北上入长安，壮志酬筹，通过干谒权门去投赠玉真公主，想使自己的仕途上再有所进展。结果被小人所排挤，没能成功，所以才写了《行路难》。\n 杜甫和李白在仕途的远景上是有一定共性的，这是也为什么40多岁的李白遇上30多岁的杜甫能够成为好朋友。 李白写过“鲁酒不可醉，齐歌空复情。”\n参考  大伙最爱李白哪句诗？ #好兄台君儿不见黄河之水天上来 - 抖音 如果能重来？-李白：我会一条道走到黑！-杜甫：我想要早活11岁！【韩潇老师】_哔哩哔哩_bilibili  ","date":"2024-05-13T19:30:35+08:00","permalink":"https://wangloo.github.io/posts/thinking/poetry/","section":"posts","tags":["poetry"],"title":"诗词笔记"},{"categories":null,"contents":"指令执行过程  指令执行的过程：取指、译码、执行和写回。 根据这个将 Core 分为两部分：\n 前端：指令从内存预取到 Cpu，解码，发射。在 Arm 中， 前端的流程是顺序的。一个 cycle 里最多可以解码 4 条指令给后端。 后端：后端的作用是执行指令。后端一般包含几个执行单元， 整数、浮点数、Load/Store、Branch 相关的执行单元。 后端中，如果指令之间没有依赖，支持乱序执行。  Core 中的 Cache 分布：Icache 在前端，Dcache 属于后端。\nCore 中的 Tlb 分布：ITlb 在前端，DTlb 在后端\n指令执行完后，到达 Retire，指令退役。\nArm 处理器的架构与微架构   架构可以理解为由指令集、内存模型等组成的一个行为规范， 或叫做 specification。相当于一种标准，会定义 Cpu 工作行为的预期， 并不会限制具体是如何实现。\n  微架构就是整个流水线的设计，包括前端和后端具体的设计与实现， 由芯片厂商自行开发。\n  CS152 课程 CS152 课程笔记\n","date":"2024-05-11T21:19:01+08:00","permalink":"https://wangloo.github.io/posts/arch/arch/","section":"posts","tags":["arch"],"title":"计算机体系结构基础"},{"categories":["Virtualization"],"contents":"从最近开始接触虚拟化的基础知识，一直不太理解设备虚拟化的理念。然而通过最近对 Virtio 的了解，可能稍微有一些见解，在这里记录下。\nVirtio 是干啥的 虚拟化中，设备的虚拟化是很复杂、很关键的一点，Linux 代码中大量的设备驱动，如何对这些驱动的行为进行模拟成为了一个很难解决的问题。 Virtio 提供了一种高性能的设备虚拟化方案。\n以前的设备虚拟化为什么性能低 最早，虚拟化技术刚刚提出的时候，实现虚拟化的是的方案是\u0026ndash;设备“全虚拟化”。关键的点是：VM 不必知道自己运行在 Hypervisor 之上，也不用修改任何的代码，直接就能实现设备的访问。\n实现这种方案的关键是：对所有的设备访问都要 Trap 到 Hypervisor 处理。OS 和设备交互的方式是 MMIO 和中断，以串口举例，我们要发送一个字符到串口中，就需要不断的读 busy 寄存器，直到空闲然后写 data 寄存器。\n 不能直接把设备 MMIO 地址给 VM 操作，因为 hypervisor 之上运行着多个 VM，他们不知道其他人是否在占用设备，会造成冲突。 所以唯一的方法就是：每一次 MMIO 的访问，都 Trap 到 Hypervisor，它能看到所有 VM 的状态，在合适的时候将这个请求转发给物理设备。中断也是如此，Hypervisor 拦截所有的中断。  这种做法显然造成了频繁的 Trap，性能很差！！\n Virtio 如何提高性能 Virtio 的设计原则是：放弃一部分设备全虚拟化的优势，VM 得知道自己运行在 Hypervisor 之上。然后，在 VM 上运行“改良过的”设备驱动，来提高性能。\n这个改良做的是什么呢？\n Virtio 分为前后端，前端在 VM 中，替换原来的设备驱动。 后端在 Hypervisor/HostVM 中，相当于是原来对物理设备实际操作的代码。  原来的全虚拟化，不是每次寄存器操作都要 Trap 吗？现在的方案是，\n 在前后端之间（不论后段在 Hypervisor 还是 HostVM），有一个 ringbuf，两个端口可以分别将数据放到 ringbuf 中，甚至是两个分离的 ringbuf。 加以合适的通知机制，在数据准备好后通知后段进行处理，或者后段通知前端，原理是相同的。  这种方案能提高性能主要在于：\n GuestVM 和直接驱动硬件设备的代理方（可能是 Hypervisor/HostVM）通信不需要每次都 Trap，直接等到某个条件下通过中断告之，去 ringbuf 取就可以了。你可能会问，全虚拟化中，也可以做缓存啊？但问题是，因为 VM 不知道自己运行在虚拟机上，所以缓存不能做成共享内存的形式（或者难做、不通用），而 VirtIO 中的 ringbuf 是完全的共享内存的形式，零拷贝，速度快。  另外，Virtio 前后端分离的设计，也解决了一部分通用性问题。前后端在设备初始化时会握手，只要满足某种约束就行相互配合，可以独立设计实现。\n 站在 Hypervisor/HostVM 的角度，不用对所有的设备驱动都分别做代理判断了，而是划分为了几种类别（Virtio-blk、Virtio-console 等）。不管你是什么设备，只要 VM 有 virtio 驱动，Hypervisor/HostVM 就不用更改，直接支持。  几种 Virtio 的经典实现 后端在 Hypervisor  VM 驱动通过 hvc 调用来通知 hyperv Hypervisor 通过中断注入来通知 VM   后端在 HostVM  VM 后端是 HostVM 里的一个用户线程，专门处理前端请求 VM 如何通知 HostVM，我理解只有 Host 能主动发起通知，难道还是 hvc 吗？ VM 和 HostVM 之间的 virtqueue 通过共享内存来实现，可以承载于 uio 设备 HostVM 专门用于处理请求的，所以它可以直接操作硬件，Hypervisor 不需要 Trap 吧  TODO： 展示一个完整的数据流程，假设 GusetVM 要操作硬件，比如说写入数据\n 首先 GuestVM 用户程序调用驱动 write()， 驱动将数据写入到 virtqueue 里，hvc 通知 virtio 后端？ hypervisor 负责通知 Hostvm 处理 virtio 请求，中断注入到 Hostvm HostVM 在收到 virtio 请求中断时，调度 EL0 的后端线程，在此之前后端线程已经打开了/dev 下的 virtio 设备，所以要做的就是判断 guestVM 此次是写哪个设备，做一下代理转换。 目的地（设备）决定好后，向 virtio device 写入数据即可。 写完之后，怎么通知 hypervisor，再最终通知到 guestVM？   进一步提升性能：Vhost 在 HostVM 作为后端的模式下，因为 virtio 后端原本是用户线程，在准备处理请求时还得先陷入到 HostVM Kernel 中，请求完毕还得返回 HostVM EL0.\nVhost 就是把后端放在 HostVM 的内核中，避免 HostVM 处理请求时多次的内核陷入。\nvhost：一种 virtio 高性能的后端驱动实现 - bakari - 博客园\nVirtio QEMU 进一步提升性能：VHE VHE 适用于 QEMU KVM 吧。\n启用 ARM VHE 特性，VM Kernel 运行在 EL2\n我是一个 VMM 开发者，如何支持 Virtio 我是一个 Linux 驱动开发者，如何支持 Virtio ","date":"2024-04-19T19:28:12+08:00","permalink":"https://wangloo.github.io/posts/os/virt/virtio/","section":"posts","tags":["Virtualization","Virtio"],"title":"虚拟化：Virtio"},{"categories":["Course"],"contents":"ISA: RISCV32\n编译一个客户程序 内存布局 貌似所有的格式，所有的平台都使用同一个链接脚本。\n 栈空间在ELF中预留，好处是统一，缺点是增加了ELF的大小。 bss跟在数据段后面，导致数据段的filesz和memsz可能不同。NanOS是加载APP的时候，load segment时直接清零，而不是需要单独遍历一下bss，更加方便。  ENTRY(_start) PHDRS { text PT_LOAD; data PT_LOAD; } SECTIONS { /* _pmem_start and _entry_offset are defined in LDFLAGS */ . = _pmem_start + _entry_offset; .text : { *(entry) *(.text*) } : text etext = .; _etext = .; .rodata : { *(.rodata*) } .data : { *(.data) } : data edata = .; _data = .; .bss : { /* bss段跟在.data的后面，会被放入同一个segment，所以加载时需要清零 */ _bss_start = .; *(.bss*) *(.sbss*) *(.scommon) } /* 栈空间在ELF中定义 */ _stack_top = ALIGN(0x1000); . = _stack_top + 0x8000; _stack_pointer = .; end = .; _end = .; _heap_start = ALIGN(0x1000); } Difftest 的设计理念 揭开Difftest的魔法。\n进行DiffTest需要提供一个和DUT(Design Under Test, 测试对象) 功能相同但实现方式不同的REF(Reference, 参考实现), 然后让它们接受相同的有定义的输入, 观测它们的行为是否相同.\n拿NEMU作为DUT，Spike作为REF来说，Difftest的原理就是：\n 微调REF，使得两者初始化环境相同，同时输入的客户机程序也相同。 DUT执行一条指令 发送信号让REF执行一条指令。 拷贝REF的运行环境（寄存器）到DUT中 在DUT中检查是否一致。 DUT和REF继续执行指令，直至客户程序结束  // (1) 如何保证两者初始环境相同？ init_difftest() // NEMU  =\u0026gt; dlopen() // 打开REF的动态链接库（Spike）  =\u0026gt; dlsym() // 过动态链接对动态库中的上述API符号进行符号解析和重定位  // 返回REF中函数的地址，可以在DUT里强制调用  =\u0026gt; ref_difftest_init() // REF初始化，等待DUT的命令  // Spike怎么做的不清楚，但是QEMU是用Gdb监听，DUT给Gdb发命令  =\u0026gt; ref_difftest_memcpy() // 将DUT的guest memory拷贝到REF中  =\u0026gt; ref_difftest_regcpy() // 将DUT的寄存器状态拷贝到REF中 // (2) DUT执行一条指令 exec_once() // (3) 并让REF也执行指令，比较结果 difftest_step() =\u0026gt; ref_difftest_exec(1) // REF执行一条指令，QEMU来说就是让Gdb发送一条si命令  =\u0026gt; ref_difftest_regcpy(DIFFTEST_TO_DUT); // 将REF的寄存器拷贝过来，准备比较  =\u0026gt; checkregs(); // 比较DUT和REF的寄存器值 NEMU的简化会导致某些指令的行为与REF有所差异, 因而无法进行对比。 Difftest支持跳过对比某些指令，大概的过程如下：\n// (1) 情况1: NEMU执行一条指令，但是QEMU如果也执行会发生差异， // 所以让QEMU跳过执行这条指令。 difftest_skip_ref() // 在执行NEMU指令的任意阶段调用  =\u0026gt; is_skip_ref = true // 标记跳过下次REF指令执行阶段  =\u0026gt; skip_dut_nr_inst = 0 // 与情况2有关，下面再介绍  difftest_step() { if (is_skip_ref) { ref_difftest_regcpy(DIFFTEST_TO_REF); // 同步DUT到REF，相当于跳过  is_skip_ref = false; return; // 跳过REF，直接返回到下一条指令  } } // (2) 情况2: NEMU跳过执行，让REF执行 difftest_skip_dut() // 在执行NEMU指令的任意阶段调用  =\u0026gt; skip_dut_nr_inst += 1 =\u0026gt; ref_difftest_exec(1) // REF先执行一次，更新了REF上下文  difftest_step() { if (skip_dut_nr_inst \u0026gt; 0) { ref_difftest_regcpy(DIFFTEST_TO_DUT); // 不管NEMU此次的结果，同步REF到DUT  if (ref_r.pc == npc) { skip_dut_nr_inst = 0; checkregs(\u0026amp;ref_r, npc); return; } skip_dut_nr_inst --; return; } } 构建系统 编译Guest程序并追加参数 make ARCH=$ISA-nemu run mainargs=I-love-PA 编译Guest程序流程分析 编译dummy可执行文件的命令如下，很好奇是如何实现的。\ncd am-kernels/am-kernels/tests/cpu-tests make ARCH=riscv32-nemu ALL=dummy 既然在当前目录执行make，自然先从 am-kernels/am-kernels/tests/cpu-tests/Makefile开始看起。\n ALL默认是所有test的集合，参数指定会覆盖它。 ALL的生成规则属于 静态规则 ，通配符%代表ALL的全称即依赖Makefile.dummy。更多关于静态规则 Makefile.dummy的生成规则也就在下面，这个文件默认是不存在的，需要临时生成 生成的规则是 echo -e \u0026quot;NAME = dummy\\nSRCS = tests/dummy.c\\ninclude $${AM_HOME}/Makefile\u0026quot; \u0026gt; $@。包含了AM_HOME下的Makefile AM是各个平台版本可执行文件的“制造机”，理念是将平台信息传入，生成指定格式的镜像。运行时库也包含在内。 最后就是执行 make -f 去调用刚才生成的临时Makefile.dummy，传入指定参数  ALL = $(basename $(notdir $(shell find tests/. -name \u0026#34;*.c\u0026#34;))) all: $(addprefix Makefile., $(ALL)) @echo \u0026#34;test list [$(words $(ALL))item(s)]:\u0026#34; $(ALL) $(ALL): %: Makefile.% Makefile.%: tests/%.c latest @/bin/echo -e \u0026#34;NAME = $*\\nSRCS = $\u0026lt;\\ninclude $${AM_HOME}/Makefile\u0026#34; \u0026gt; $@ @if make -s -f $@ ARCH=$(ARCH) $(MAKECMDGOALS); then \\ \tprintf \u0026#34;[%14s] $(COLOR_GREEN)PASS$(COLOR_NONE)\\n\u0026#34; $* \u0026gt;\u0026gt; $(RESULT); \\ \telse \\ \tprintf \u0026#34;[%14s] $(COLOR_RED)***FAIL***$(COLOR_NONE)\\n\u0026#34; $* \u0026gt;\u0026gt; $(RESULT); \\ \tfi -@rm -f Makefile.$* 目前为止大概的思路还算比较清晰：\n 生成 Makefile.dummy 执行它，传递命令行参数（$(MAKECMDGOALS)）  Makefile.dummy 是一个临时文件，编译命令执行后会被删除。注销删除命令，直接打开看它的内容。\nNAME = dummy SRCS = tests/dummy.c include /home/soben/ics2023/abstract-machine/Makefile 需要结合AM_HOME下的Makefile去理解了。 这么来看AM的构建系统像是一个“加工厂”，在软件设计术语叫“模板“。\n 外部传入加工零件的要求（ARCH、NAME、SRCS\u0026hellip;） 输出对应需求的产品（可执行文件）。 既可以要求它将我们传入的源文件编译成native架构下可执行文件，或者是NEMU、QEMU这类模拟器上。  AM的构建思路 .notice { --root-color: #444; --root-background: #eff; --title-color: #fff; --title-background: #7bd; --warning-title: #c33; --warning-content: #fee; --info-title: #fb7; --info-content: #fec; --note-title: #6be; --note-content: #e7f2fa; --tip-title: #5a5; --tip-content: #efe } @media (prefers-color-scheme:dark) { .notice { --root-color: #ddd; --root-background: #eff; --title-color: #fff; --title-background: #7bd; --warning-title: #800; --warning-content: #400; --info-title: #a50; --info-content: #420; --note-title: #069; --note-content: #023; --tip-title: #363; --tip-content: #121 } } body.dark .notice { --root-color: #ddd; --root-background: #eff; --title-color: #fff; --title-background: #7bd; --warning-title: #800; --warning-content: #400; --info-title: #a50; --info-content: #420; --note-title: #069; --note-content: #023; --tip-title: #363; --tip-content: #121 } .notice { padding: 18px; line-height: 24px; margin-bottom: 24px; border-radius: 4px; color: var(--root-color); background: var(--root-background) } .notice p:last-child { margin-bottom: 0 } .notice-title { margin: -18px -18px 12px; padding: 4px 18px; border-radius: 4px 4px 0 0; font-weight: 700; color: var(--title-color); background: var(--title-background) } .notice.warning .notice-title { background: var(--warning-title) } .notice.warning { background: var(--warning-content) } .notice.info .notice-title { background: var(--info-title) } .notice.info { background: var(--info-content) } .notice.note .notice-title { background: var(--note-title) } .notice.note { background: var(--note-content) } .notice.tip .notice-title { background: var(--tip-title) } .notice.tip { background: var(--tip-content) } .icon-notice { display: inline-flex; align-self: center; margin-right: 8px } .icon-notice img, .icon-notice svg { height: 1em; width: 1em; fill: currentColor } .icon-notice img, .icon-notice.baseline svg { top: .125em; position: relative }    帮助理解AM的Makefile  AM_HOME/Makefile 有命令转化makefile为html文件，帮助理解。\n### *Get a more readable version of this Makefile* by `make html` (requires python-markdown) html: cat Makefile | sed \u0026#39;s/^\\([^#]\\)/ \\1/g\u0026#39; | markdown_py \u0026gt; Makefile.html .PHONY: html  上面说过，AM的构建系统是一个模版，将源文件编译，使其能运行在指定的平台上。 甚至，运行时库也是集成到AM中的，最大程度上减少重复劳动。\n下面是Makefile的源代码，我们选取关键的部分进行拆解。\n 提前说明，传入的参数有ARCH、NAME、SRCS，剩余参数在$(MAKECMDGOALS) 环境检查（clean、html命令跳过） 从参数ARCH中分离出ISA和PLATFORM 设置编译器和编译选项 引入和ISA、Platform相关的一些规则，include scripts/$ARCH.mk，下面会详细分析 一些通用的编译目标规则，比如.c/.S如何生成.o  ## 1. Basic Setup and Checks  ### Default to create a bare-metal kernel image ifeq ($(MAKECMDGOALS),) MAKECMDGOALS = image .DEFAULT_GOAL = image endif ### Override checks when `make clean/clean-all/html` ifeq ($(findstring $(MAKECMDGOALS),clean|clean-all|html),) # 其他的检查暂时省略...  ### Extract instruction set architecture (`ISA`) and platform from `$ARCH`. Example: `ARCH=x86_64-qemu -\u0026gt; ISA=x86_64; PLATFORM=qemu` ARCH_SPLIT = $(subst -, ,$(ARCH)) ISA = $(word 1,$(ARCH_SPLIT)) PLATFORM = $(word 2,$(ARCH_SPLIT)) ### Check if there is something to build ifeq ($(flavor SRCS), undefined) $(error Nothing to build) endif ### Checks end here endif ## 2. General Compilation Targets  ### Compilation targets (a binary image or archive) IMAGE_REL = build/$(NAME)-$(ARCH) IMAGE = $(abspath $(IMAGE_REL)) ARCHIVE = $(WORK_DIR)/build/$(NAME)-$(ARCH).a ### Collect the files to be linked: object files (`.o`) and libraries (`.a`) OBJS = $(addprefix $(DST_DIR)/, $(addsuffix .o, $(basename $(SRCS)))) LIBS := $(sort $(LIBS) am klib) # lazy evaluation (\u0026#34;=\u0026#34;) causes infinite recursions ## 3. General Compilation Flags # 省略：编译器和编译选项  ## 4. Arch-Specific Configurations  ### Paste in arch-specific configurations (e.g., from `scripts/x86_64-qemu.mk`) -include $(AM_HOME)/scripts/$(ARCH).mk ### Fall back to native gcc/binutils if there is no cross compiler ifeq ($(wildcard $(shell which $(CC))),) $(info # $(CC) not found; fall back to default gcc and binutils) CROSS_COMPILE := endif ## 5. Compilation Rules  ### Rule (compile): a single `.c` -\u0026gt; `.o` (gcc) $(DST_DIR)/%.o: %.c @mkdir -p $(dir $@) \u0026amp;\u0026amp; echo + CC $\u0026lt; @$(CC) -std=gnu11 $(CFLAGS) -c -o $@ $(realpath $\u0026lt;) # 省略：一些其他的通用规则  ### Rule (recursive make): build a dependent library (am, klib, ...) $(LIBS): %: @$(MAKE) -s -C $(AM_HOME)/$* archive ### Rule (link): objects (`*.o`) and libraries (`*.a`) -\u0026gt; `IMAGE.elf`, the final ELF binary to be packed into image (ld) $(IMAGE).elf: $(OBJS) $(LIBS) @echo + LD \u0026#34;-\u0026gt;\u0026#34; $(IMAGE_REL).elf @$(LD) $(LDFLAGS) -o $(IMAGE).elf --start-group $(LINKAGE) --end-group ### Rule (archive): objects (`*.o`) -\u0026gt; `ARCHIVE.a` (ar) $(ARCHIVE): $(OBJS) @echo + AR \u0026#34;-\u0026gt;\u0026#34; $(shell realpath $@ --relative-to .) @$(AR) rcs $(ARCHIVE) $(OBJS) ### Rule (`#include` dependencies): paste in `.d` files generated by gcc on `-MMD` -include $(addprefix $(DST_DIR)/, $(addsuffix .d, $(basename $(SRCS)))) ## 6. Miscellaneous  ### Build order control image: image-dep archive: $(ARCHIVE) image-dep: $(OBJS) $(LIBS) @echo \\# Creating image [$(ARCH)] .PHONY: image image-dep archive run $(LIBS) ### Clean a single project (remove `build/`) clean: rm -rf Makefile.html $(WORK_DIR)/build/ .PHONY: clean ### Clean all sub-projects within depth 2 (and ignore errors) CLEAN_ALL = $(dir $(shell find . -mindepth 2 -name Makefile)) clean-all: $(CLEAN_ALL) clean $(CLEAN_ALL): -@$(MAKE) -s -C $@ clean .PHONY: clean-all $(CLEAN_ALL) $ARCH.mk 文件规定一些架构、运行平台相关的选项：\n 架构相关的：比如说交叉编译器是啥，和特殊的CFLAGS(-march) 平台相关的：因为命令行参数可以添加如run，编译完后直接运行，此时需要提前将平台准备好，编译好NEMU。  include $(AM_HOME)/scripts/isa/riscv.mk include $(AM_HOME)/scripts/platform/nemu.mk CFLAGS += -DISA_H=\\\u0026#34;riscv/riscv.h\\\u0026#34; COMMON_CFLAGS += -march=rv32im_zicsr -mabi=ilp32 # overwrite LDFLAGS += -melf32lriscv # overwrite AM_SRCS += riscv/nemu/start.S \\  riscv/nemu/cte.c \\  riscv/nemu/trap.S \\  riscv/nemu/vme.c ","date":"2024-04-16T19:28:12+08:00","permalink":"https://wangloo.github.io/posts/course/nju-ics2022/","section":"posts","tags":["Course"],"title":"课程笔记：NJU ICS2022"},{"categories":null,"contents":"内核启动时会打印当前生效的 cmdline。Command Line 相当于外部传给 Linux 内核的参数，内核针对他们做相应处理，并打印无法是被的参数。\n如何看当前的cmdline：\n 内核启动日志会输出 [ 0.000000] Kernel command line: earlycon rw rdinit=/linuxrc root=/dev/vda nokaslr [ 0.000000] Unknown command line parameters: nokaslr  cat /proc/cmdline/  用户有几种方式来注入cmdline：\n  设备树 bootargs。 linuxkernel的设备树是QEMU生成的，实际就是用的启动参数 --append。\nqemu-system-aarch64 \\  -nographic -machine virt,secure=on \\  -cpu cortex-a53 -smp 2 -m 4G \\  -d guest_errors,unimp \\  -gdb tcp::1234 \\  -bios ./arm-trusted-firmware/build/qemu/debug/bl1.bin \\  -kernel ./wupeng/linux/arch/arm64/boot/Image \\  -initrd ./rootfs.cpio.gz \\  -append \u0026#34;earlycon rw rdinit=/linuxrc nokaslr\u0026#34; \\  -serial mon:stdio \\  -semihosting-config enable=on,target=native   uboot boot_args\nsetenv bootargs \u0026#39;init=xx\u0026#39;   Linux menuconfig\n   优先级：设备树 \u0026gt; uboot \u0026gt; linux kconfig\n","date":"2024-04-16T10:30:35+08:00","permalink":"https://wangloo.github.io/posts/os/linux/cmdline/","section":"posts","tags":["Linux"],"title":"Linux cmdline 配置"},{"categories":["DevTools"],"contents":"Ubuntu 下用 apt 安装包出现依赖问题：  尝试加-f安装也仍然报相同错误。\n在网上查到 aptitude 专用鱼解决 apt 依赖问题，遂尝试。\n  下载 aptitude\nsudo apt install aptitude   用 aptitude 重新安装，aptitude 会给出几种解决方案，第一种是不安装，第二种是将依赖的软件降级消除依赖。我们显然选择第二种方案。\n    参考：解决Ubuntu下因依赖包而无法安装问题 - soarli博客\n ","date":"2024-04-08T15:28:12+08:00","permalink":"https://wangloo.github.io/posts/tools/apt_dep/","section":"posts","tags":["tools"],"title":"aptitude修复apt安装依赖"},{"categories":["C"],"contents":"数据结构和 API 介绍 // 信号配置中最关键的数据结构 struct sigaction { void (*sa_handler)(int); // 信号触发钩子函数（简单版）  void (*sa_sigaction)(int, siginfo_t *, void *); // 信号触发钩子函数（复杂版）  sigset_t sa_mask; int sa_flags; // 一些标识位，下面会介绍  void (*sa_restorer)(void); }; // 几种常用的sa_flags: // SA_SIGINFO ==\u0026gt; 触发信号后会调用更强大的 sa_sigaction() // SA_ONSTACK ==\u0026gt; 使用单独的栈运行handler，避免函数太大撑爆原来程序栈 // SA_RESTART ==\u0026gt; 使信号触发可以打断阻塞状态（如read()等待）， // 此时errno将被置为 EINTR  // 为某个信号自定义触发handler，以及某些配置项 int sigaction(int signum, const struct sigaction *act, struct sigaction *oldact); // 在当前进程中触发一个信号 int raise(int sig); // 向pid进程发送一个信号（本案例中用不到） int kill(pid_t pid, int sig); 信号从触发到被捕获的过程  简单版 Demo 只有一个进程\n 为 SIGUSR1 设置 handler while(1)循环接受用户输入字符 当输入 q 时为当前进程触发信号 进入设定的信号 handler，设置进程退出标志 进程退出，终止  #include \u0026lt;stdio.h\u0026gt;#include \u0026lt;string.h\u0026gt;#include \u0026lt;signal.h\u0026gt;#include \u0026lt;assert.h\u0026gt; static int need_exit; static void sig_handler(int sig) { assert (sig == SIGUSR1); printf(\u0026#34;SIGUSR1 triggered! Set need_exit, program will exit\\n\u0026#34;); need_exit = 1; } static void install_signal_handler() { struct sigaction s; int ret; memset(\u0026amp;s, 0, sizeof(s)); s.sa_handler = sig_handler; // 重设信号的处理函数  // struct sigaction 的其他参数暂不关心  ret = sigaction(SIGUSR1, \u0026amp;s, NULL); assert(ret == 0); } int main(void) { char c; pid_t pid; install_signal_handler(); while ((c = getchar())) { // printf(\u0026#34;char: %c:\\n\u0026#34;, c);  if (c == \u0026#39;q\u0026#39;) { raise(SIGUSR1); } if (need_exit) break; } return 0; } 高级版 Demo  设置 SA_SIGINFO 标志，即启用参数更多的 handler 实现简易的批处理系统？  info.si_addr 来判断发生的地址，    重新注册了三个信号的 handler，分别有不同的作用\n SIGUSR1 模拟用户态程序发送 IO 请求 SIGUSR2 模拟用户态程序调用 yield()主动让出 CPU SIGVTALRM 模拟 timer 中断 SIGSEGV 不是显式触发，程序执行出错自动触发被捕捉。  出错可能有多种原因，利用 hangler 中的 siginfo_t 参数区分不同情况 siginfo_t 的结构和成员说明在下方 主要用到 si_addr, si_code 来区分 syscall、iret、page_fault 行为    static void sig_handler(int sig, siginfo_t *info, void *ucontext) { thiscpu-\u0026gt;ev = (Event) {0}; thiscpu-\u0026gt;ev.event = EVENT_ERROR; switch (sig) { case SIGUSR1: thiscpu-\u0026gt;ev.event = EVENT_IRQ_IODEV; break; case SIGUSR2: thiscpu-\u0026gt;ev.event = EVENT_YIELD; break; case SIGVTALRM: thiscpu-\u0026gt;ev.event = EVENT_IRQ_TIMER; break; case SIGSEGV: if (info-\u0026gt;si_code == SEGV_ACCERR) { switch ((uintptr_t)info-\u0026gt;si_addr) { case 0x100000: thiscpu-\u0026gt;ev.event = EVENT_SYSCALL; break; case 0x100008: iret(ucontext); return; } } if (__am_in_userspace(info-\u0026gt;si_addr)) { assert(thiscpu-\u0026gt;ev.event == EVENT_ERROR); thiscpu-\u0026gt;ev.event = EVENT_PAGEFAULT; switch (info-\u0026gt;si_code) { case SEGV_MAPERR: thiscpu-\u0026gt;ev.cause = MMAP_READ; break; // we do not support mapped user pages with MMAP_NONE  case SEGV_ACCERR: thiscpu-\u0026gt;ev.cause = MMAP_WRITE; break; default: assert(0); } thiscpu-\u0026gt;ev.ref = (uintptr_t)info-\u0026gt;si_addr; } break; } if (thiscpu-\u0026gt;ev.event == EVENT_ERROR) { thiscpu-\u0026gt;ev.ref = (uintptr_t)info-\u0026gt;si_addr; thiscpu-\u0026gt;ev.cause = (uintptr_t)info-\u0026gt;si_code; thiscpu-\u0026gt;ev.msg = strsignal(sig); } setup_stack(thiscpu-\u0026gt;ev.event, ucontext); } // signal handlers are inherited across fork() static void install_signal_handler() { struct sigaction s; memset(\u0026amp;s, 0, sizeof(s)); s.sa_sigaction = sig_handler; s.sa_flags = SA_SIGINFO | SA_RESTART | SA_ONSTACK; __am_get_intr_sigmask(\u0026amp;s.sa_mask); int ret = sigaction(SIGVTALRM, \u0026amp;s, NULL); assert(ret == 0); ret = sigaction(SIGUSR1, \u0026amp;s, NULL); assert(ret == 0); ret = sigaction(SIGUSR2, \u0026amp;s, NULL); assert(ret == 0); ret = sigaction(SIGSEGV, \u0026amp;s, NULL); assert(ret == 0); } .notice { --root-color: #444; --root-background: #eff; --title-color: #fff; --title-background: #7bd; --warning-title: #c33; --warning-content: #fee; --info-title: #fb7; --info-content: #fec; --note-title: #6be; --note-content: #e7f2fa; --tip-title: #5a5; --tip-content: #efe } @media (prefers-color-scheme:dark) { .notice { --root-color: #ddd; --root-background: #eff; --title-color: #fff; --title-background: #7bd; --warning-title: #800; --warning-content: #400; --info-title: #a50; --info-content: #420; --note-title: #069; --note-content: #023; --tip-title: #363; --tip-content: #121 } } body.dark .notice { --root-color: #ddd; --root-background: #eff; --title-color: #fff; --title-background: #7bd; --warning-title: #800; --warning-content: #400; --info-title: #a50; --info-content: #420; --note-title: #069; --note-content: #023; --tip-title: #363; --tip-content: #121 } .notice { padding: 18px; line-height: 24px; margin-bottom: 24px; border-radius: 4px; color: var(--root-color); background: var(--root-background) } .notice p:last-child { margin-bottom: 0 } .notice-title { margin: -18px -18px 12px; padding: 4px 18px; border-radius: 4px 4px 0 0; font-weight: 700; color: var(--title-color); background: var(--title-background) } .notice.warning .notice-title { background: var(--warning-title) } .notice.warning { background: var(--warning-content) } .notice.info .notice-title { background: var(--info-title) } .notice.info { background: var(--info-content) } .notice.note .notice-title { background: var(--note-title) } .notice.note { background: var(--note-content) } .notice.tip .notice-title { background: var(--tip-title) } .notice.tip { background: var(--tip-content) } .icon-notice { display: inline-flex; align-self: center; margin-right: 8px } .icon-notice img, .icon-notice svg { height: 1em; width: 1em; fill: currentColor } .icon-notice img, .icon-notice.baseline svg { top: .125em; position: relative }    siginfo_t  从 siginfo_t 中截取了某些关键成员，对他们的含义进行说明：\n// [si_code] indicating why this signal was sent. // 需要 man sigaction 才能找到对应与某个信号的所有si_code。 // [si_addr] the address of the fault. siginfo_t { int si_signo; /* Signal number */ int si_errno; /* An errno value */ int si_code; /* Signal code */ int si_trapno; /* Trap number that caused hardware-generated signal (unused on most architectures) */ pid_t si_pid; /* Sending process ID */ uid_t si_uid; /* Real user ID of sending process */ int si_status; /* Exit value or signal */ union sigval si_value; /* Signal value */ void *si_addr; /* Memory location which caused fault */ int si_fd; /* File descriptor */ }  参考  南京大学 AM 中 native 实现 CTE 的方案  ","date":"2024-04-05T20:51:49+08:00","permalink":"https://wangloo.github.io/posts/c/posix-signal/","section":"posts","tags":["C"],"title":"A Demo of Posix Signal"},{"categories":["Course"],"contents":"CISC 的发展到 RISC 诞生  1940-1950  冯诺依曼架构被提出：以存储器为中心，软件和硬件的设计分离，减少了系统中的硬连接，实现了可编程的计算机！ 用户程序（二进制指令）被存储到存储器中。存储器的容量，几 k 字，不能放下很大的程序。 存储器有 CRT 磷光线存储器（支持随机存储），磁芯（Core memory）（磁芯存储：统治存储领域 20 年 - 知乎）。   1960-1970  PDP-6 典型设计，16 个通用寄存器，SP+FP，ISA 逐渐变得复杂 此时人们用汇编指令写程序，认为每个常见操作都应该实现为一条特殊的指令（三角函数、CRC\u0026hellip;）。（？？？与 ROM 和 RAM 的速度差异有关吗） 这么多种类的指令硬连线的方式太复杂 ==\u0026gt; 微码 微码 ROM 是一张表：ISA 指令和微操作之间的映射，一条指令对应多个微操作 有了微码，创造一条新的指令很容易，使用不同微操作的组合即可   1980  高级语言和编译器来了，不用再手写指令 编译器很难利用到这么多复杂的指令，生成的汇编代码常用几条指令占 95%，大量的不常用指令占据了微码 ROM。 发明出基于 Mos 的 SRAM，比原先的快 2-10 倍！？？？所以呢 CISC 不适合与流水线  decode 时间不一致，边 decode 边取指，不确定的时间段 寻址模式多，容易引发数据竞争，而且不容易检测      流水线 Pipeline RISC 的架构中出现的，旨在提高处理器处理效率，争取在一个时钟周期中完成一条指令（CPI=1）。\n.notice { --root-color: #444; --root-background: #eff; --title-color: #fff; --title-background: #7bd; --warning-title: #c33; --warning-content: #fee; --info-title: #fb7; --info-content: #fec; --note-title: #6be; --note-content: #e7f2fa; --tip-title: #5a5; --tip-content: #efe } @media (prefers-color-scheme:dark) { .notice { --root-color: #ddd; --root-background: #eff; --title-color: #fff; --title-background: #7bd; --warning-title: #800; --warning-content: #400; --info-title: #a50; --info-content: #420; --note-title: #069; --note-content: #023; --tip-title: #363; --tip-content: #121 } } body.dark .notice { --root-color: #ddd; --root-background: #eff; --title-color: #fff; --title-background: #7bd; --warning-title: #800; --warning-content: #400; --info-title: #a50; --info-content: #420; --note-title: #069; --note-content: #023; --tip-title: #363; --tip-content: #121 } .notice { padding: 18px; line-height: 24px; margin-bottom: 24px; border-radius: 4px; color: var(--root-color); background: var(--root-background) } .notice p:last-child { margin-bottom: 0 } .notice-title { margin: -18px -18px 12px; padding: 4px 18px; border-radius: 4px 4px 0 0; font-weight: 700; color: var(--title-color); background: var(--title-background) } .notice.warning .notice-title { background: var(--warning-title) } .notice.warning { background: var(--warning-content) } .notice.info .notice-title { background: var(--info-title) } .notice.info { background: var(--info-content) } .notice.note .notice-title { background: var(--note-title) } .notice.note { background: var(--note-content) } .notice.tip .notice-title { background: var(--tip-title) } .notice.tip { background: var(--tip-content) } .icon-notice { display: inline-flex; align-self: center; margin-right: 8px } .icon-notice img, .icon-notice svg { height: 1em; width: 1em; fill: currentColor } .icon-notice img, .icon-notice.baseline svg { top: .125em; position: relative }    CPI指标的意义  CPI 总是衡量大量指令的平均结果，单讨论一两个指令的 CPI 是没有意义的\nPipeline CPI 计算：从第一条指令结束到最后一条指令结束的周期数/指令数\n ￼ PS：为什么不从第一条指令的开始进行计算？==\u0026gt; 因为通常有大量的指令（百万），所以第一条指令开始到结束的时间段没什么实际意义，影响不大。\n 最经典的当属 MIPS(无内部互锁的流水线处理器)的五级流水线技术。MIPS 体系结构本身就是为了流水线而设计的，每条指令的执行过程都分成五级。每一级成为一个流水线阶段，每个阶段占用固定的时间，通常是一个时钟周期。\n    像是取指、访存阶段都比较耗时，超过了一个时钟周期。\n  有的微架构就使用超长的流水线（多级），将指令阶段进一步细分，有助于增加并行度。 但是呢，阶段分的太细，在微架构层面会比较复杂，因为各个阶段之间需要发送信号，会浪费一些时间。\n数据竞争的三种解决方案  等待。其他竞争的指令等着当前指令执行完再执行。 Bypass。需要额外硬件， 预测。需要额外硬件，先猜一个值，如果错了再刷新流水线重退。  异常 Exception 流水线的各个阶段都会产生异常，怎么设计？\n难道在每个时钟周期都检测流水线中有无异常吗？显然不行，因为假设指令 B 在 Decode 阶段产生了异常，如果此时就认定指令 B 触发异常。但殊不知上一条指令 A 会在回写阶段也触发异常。 而一般来说，按照程序员的视角我们认为指令一条一条的执行，所以也希望异常按照指令顺序产生。\n进而，就提出了在流水线的最后【提交】阶段才检查异常。\n 流水线中多了 3 个额外的寄存器用于标记每个阶段是否产生异常。 前面指令产生的异常标记可以覆盖后面指令。这就使得异常按照指令顺序产生。 若一条指令在前面阶段已经产生异常，后续阶段 Bubble。 在最后提交阶段之前，会检查是不是有异常或者异步中断？（如果两者都有，实现定义）之后下一个 PC 就是异常向量。   内存 Memory Core memory 是首个大标量可靠存储器。\n 1940s 被提出 可靠，比半导体存储器可靠的多 手工制造，产量低 访问时间 1 微秒  半导体内存从 1970s 开始\n 英特尔最早的主要产品是半导体存储器  最早的半导体存储器是静态 RAM，Static RAM\n 持续通电，但不需要刷新  DRAM 最早是 IBM 的一个人发明的，但是由英特尔做到商业化\n 电容来存储 bit  预取 Prefetching 现代处理器一个时钟周期内可以同时处理多条指令，甚至每个周期执行 ldr/str 操作多次。\n指令预取 Basic Schemes：简单地预期 program order 下的 N 行 很简单就不说了，在 1 条指令 miss 的时候，预期下面 N 个 cacheline 长度的指令。\nBasic Schemes：启发式的错误路径预取 当 decode 到一条条件分支指令后，就立马预取跳转和不跳转两条方向上的指令。\n 可能性总\u0026gt;0，每个分支总在某种情况下会发生。 【Challenge】立即跳转指令来说，可能预取是来不及的。 【Challenge】某些条件跳转不能支持，例如寄存器间接等，你无法第一时间知道目标地址。  更加高级：与分支预测单元结合，预期分支预测结果方向的指令 使用 Non-blocking Cache 来增加 Cache 带宽  Non-blocking cache or lockup-free cache 允许 cache 在处理上一个 miss 时继续支持后续指令的 cache 命中。  甚至可以维持若干次的 miss（现代处理器一般是 10 几次）    动态加载动态链接在虚拟地址出现之前就已经被广泛使用了，它正是用于解决程序库中的物理内存地址不能写死。\n后面，因为 IO 很慢，只运行一个程序的话 CPU 会一直等待着。这就促使多程序并发思想的诞生。每个用户程序占用物理内存的一部分，只允许访问这些。为每个用户程序分配的内存空间也叫 Segment，如果 OS 检测到超出了，会报 Segment Fault。\n这种分段的方式慢慢显示出了它的问题：外部碎片。为用户程序分配的段必须在物理上是连续的。除此之外，如果程序在运行时想动态的扩大自己的段也是比较困难的。\n段分配的缺点诞生了虚拟内存+分页：\n 物理上不需要连续了。  TLB Miss 的处理分为软件和硬件两种方式：\n 软件（MIPS、Alpha）。TLB Miss 触发异常，由 OS 走一个 PTW 来填充 TLB 表项。非常耗时，因为对于 OOO 的处理器，必须刷新 pipeline 去走到异常处理程序中。而且现代的处理器一个周期内可以并行做几个翻译，用软件的方式实在是效率太低。 MMU 去做 PTW，然后重填 TLB。  567 的总结  首先介绍了内存是怎么回事，物理形态的发展历程。  纸带 -\u0026gt; 磁芯存储（Core Mem）-\u0026gt; 半导体存储   随后介绍了 Cache，解决了内存和 CPU 之间数据交换速度差的问题。 Cache 很好，但是一旦 miss 造成的损耗还是太大。预取 prefetch 可以帮助解决一些问题。既然你已经 Miss 已经要访问内存了，何不根据某种预测算法多取一些，尽量避免以后发生 Miss 的概率。设计好的预取算法是很关键的。  预取包括：指令预取和数据预取。    89 的总结  之前所有的讨论还是基于单任务的情况 我们写了很多程序在 CPU 上运行，有些代码段是通用的，程序员们就把他们做成了库封装起来。 代码直接访问物理地址，所以这些库目标文件中的物理地址不能写死，产生了动态加载动态链接的技术，解决库在不同机器上运行的问题。 还有一个问题就是 IO 很慢，只运行一个程序的话 CPU 会一直等待着。这就促使多程序并发思想的诞生。每个用户程序占用物理内存的一部分，只允许访问这些。为每个用户程序分配的内存空间也叫 Segment，如果 OS 检测到超出了，会报 Segment Fault。 也就是分段的思想。 分段有缺点：外部碎片且不能动态扩展。 分段的缺点引出了虚拟内存+分页的技术，每个应用程序的内存在物理上不再需要连续。 虚拟内存+分页就要使用页表，最开始的页表是单级的，一个 entry 映射一个页面。如果映射所有的虚拟空间会导致页表很大，但这种单级页表又没办法拆开映射，于是就有了多级页表。 多级页表查询耗时，在物理上就有了两个优化：  TLB 缓存页表的映射信息。 对大页 Huge page 的支持。   TLB Miss 之后的 refill 一开始是软件实现的，发生 Miss 之后 CPU trap 到特殊的 refill handler，在里面作 pagetable walk，然后用处理器提供的特殊指令重填 TLB。 然而这种方式随着处理器设计的提升变得影响性能，CPU 可能在一个时钟周期内并行的有多次内存访问，软件处理的效率太低。  CPU 流水线如何适应有 TLB 的虚拟内存翻译 加入 TLB 虚拟内存之后，在进入访存前 额外多了一些地址翻译的电路连线，在流水线中，我们如何解决这个更加延长的访存阶段呢？\n 降低 CPU 时钟频率？时钟周期长了，就延长了访存阶段的时间。但是对性能的影响是无法被接受。 为地址翻译增加额外的独立流水线阶段？也就是增加流水线的级数，增大了 CPI 虚拟地址 Cache。在查询 Cache 前就不需要地址翻译了，如果 Cache Miss，才走地址翻译， TLB 和 Cache 并行查询，这是现代处理器常用的套路。  接下来讲就最后两点分别展开介绍。\n虚拟地址 Cache  几个特点：\n 会带来 aliasing 问题，一个上下文内也会有 多个虚拟地址 映射到 同一个物理地址的共享情况。这时候一旦一个修改了，另一个会不知道。 更多的Cache coherence问题，多核之间的，一旦一个CPU更新了某个物理地址，不太方便通知到其他核心，要做物理-\u0026gt;虚拟的转换，或者是遍历。  TLB和Cache并行查找 Cache 存的是物理地址，但是按照page offset来索引（这部分物理和虚拟是一样的）。另外一边TLB去做翻译，最后用Cache中定位的完整tag和TLB翻译的结果对比。\n这种情况我觉得可以称为：page-offset Index, PPN Tag Cache。但是它的统称叫做：Virtual Index Physical Tag Cache。其实也对，因为我们没必要总是拿page-offset去index，VA里的其他bit也可以，只是拿后面的不容易造成冲突吧（根据局部性原理？）。\n 这种VIPT的Cache可以解决 cache coherence 的问题，因为有物理的Tag。\n","date":"2024-04-05T19:28:12+08:00","permalink":"https://wangloo.github.io/posts/course/cs152/","section":"posts","tags":["Course"],"title":"课程笔记：cs152（计算机体系结构）"},{"categories":["ReadingNotes"],"contents":"性能测量 当估计实际程序的性能优化效果时，不建议去除系统中的不确定性行为。 任何性能分析功能——包括采样，都应该在与实际部署最接近的系统下进行。\n测量开销是生产环境监控的一个重要问题。由于任何监控都会影响正在运行的服务的性能，因此应该使用尽可能轻量的性能剖析方法。论文（Renet al.，2010）中提到，“如果对正在提供真实服务的服务器进行持续的性能剖析，极低的性能开销是至关重要的”。通常可以接受总体不超过1%的开销，减少监控开销的办法包括限制被监控的机器数量和使用更小的监控时间间隔。\n经典的递归计算斐波那契数列，是测量性能的一个好用例。\n强烈建议不能只进行一次测试，而是多次运行基准测试，这样基线程序有N个测量值，改动过的程序也有N个测量值。我们需要比较两组测试结果以确定哪一个程序更快。这本身就是一项很难处理的工作，在很多情况下，我们会被测量数据误导而得出错误的结论。如果你向任何数据科学家征求意见， 他们都会告诉你不能依赖单一指标（如最小值、均值、中位数等）， 画出分布图是一种更好的方法。\n 由于测量的不稳定性，调试性能通常比调试功能更为困难。\nCpu微架构 流水线的灵感来自汽车装配线，将指令的处理分为几个阶段： 取指、译码、执行、访存、回写。几个阶段并行运行。\n理想情况下，启用N级流水线后，机器的指令执行效率提升N倍。 实际会存在流水线冒险，包括结构冒险、数据冒险和控制冒险。\n乱序执行主要用于避免因依赖引起的停顿而导致CPU资源利用率不足的问题。 指令的动态调整通过硬件结构（如计分板）和诸如寄存器重命名技术实现。\n超变量：一个时钟周期内可以发射多条指令。TODO：什么是发射？ 发射宽度是在同一个时钟周期内可以发射的最大指令数。 目前Cpu的典型发射宽度为2~6。\nIntel Itanium等架构使用一种称为超长指令字（Very Long InstructionWord，VLIW）的技术， 将调度超标量和多执行单元处理器的负担从硬件转移到编译器。 它的基本原理是要求编译器选择正确的指令组合使得机器被充分利用， 从而简化硬件。编译器可以使用软件流水线、 循环展开等技术来发掘更多的ILP机会， 因为硬件受制于指令窗口长度的限制，而编译器可以获得全局信息。\nCache写操作 在缓存中处理写操作更困难，CPU会使用不同的技术来处理这种复杂情况。 软件开发人员应该特别注意硬件支持的缓存写操作的流程，以确保代码性能最佳。\n两种处理Cache写入命中的情况：\n 写直通（Write-Through）；写入Cache立即同步到低层次的存储结构。 回写（Write-Back）；写Cache当前只修改Cache，设置脏位。 推迟同步操作到该CacheLine被替换出Cache时。  两种处理Cache写入未命中的情况：\n 写分配（Write-Allocate）；先把该位置的数据加载到Cache， 在执行上方写命中的流程。 写未分配（No-Write-Allocate）；不使用Cache，直接对低层次存储进行修改。  性能分析中的术语 指令和数据都可能发生缓存未命中。根据TMA分析方法（见6.1节）， 指令缓存未命中被归类为前端停滞，数据缓存未命中被归类为后端停滞。 当获取指令时发生指令缓存未命中，会被归类为前端问题。\n性能分析【指标】 性能指标：\n IPC：IPC=INST_RETIRED / CPU_CYCLES，IPC并不能单独判断 是否性能比较好，比如说在某个处理器上，前端最多一个Cycle发射4 条指令，那么IPC是不是越接近4越好呢？其实不是，还要结合CPU 此时正在做什么事情，如果是死循环，那么就不代表什么。 Pipeline Stalls  Stall Front-end rate=STALL_FRONTEND/CPU_CYCLES Stall Back-end rate=STALL_BACKEND/CPU_CYCLES   Frontend Bound  ITLB events I-Cache events   Backend Bound  DTLB events Memory System related events D-Cache events   Retiring  Instruct Mix   Bad Speculation  Branch Effectiveness events    性能分析方法 性能的问题可能出在前端，称为前端Stall，在后端时则称为后端Stall。\n程序运行时硬件和软件都可以采集性能数据，这里的硬件是指运行程序的CPU，软件是指操作系统和所有可用于分析的工具。通常软件栈提供上层指标，比如时间、上下文切换次数和缺页次数，而CPU则可以观察缓存未命中、分支预测错误等。根据要解决的问题，各指标的重要程度是不一样的。所以，并不是说硬件指标总能给我们提供更准确的程序执行信息。有些指标是CPU提供不了的，比如上下文切换次数。一般，性能分析工具—比如Linuxperf，可以同时使用来自操作系统和CPU的数据。\n代码插桩 代码插桩通过在程序中插入额外的代码来采集运行时信息。 代码清单6展示了最简单的代码插桩例子， 即在函数开头插入printf语句以统计函数的调用次数。\n基于插桩的剖析方法常被用在宏观层次，而不是在微观层次。在优化大段代码的场景，使用该方法通常会给出很好的洞察结果，因为你可以自上而下（先在主函数插桩，然后再往被调用函数插桩）地定位性能问题。\n代码插桩并不能提供任何关于代码如何从操作系统或CPU角度执行的信息。例如，它不能提供进程调度执行的频率（可从操作系统获得）或发生了多少次分支预测错误（可从CPU获得）的信息。\n这种方法的缺点是，每当需要插桩新内容（比如另一个变量）时，都需要重新编译。这可能会成为工程师的负担，增加分析时间。然而，这还不是唯一的缺点。因为通常情况下，你关心的只是应用程序中的热路径，所以你只需要在代码的性能关键部分插桩。在热点代码中插入插桩代码可能会导致整个基准测试的速度降低为原来的1/2[3]。此外，通过插桩代码，你可能改变程序的行为，所以可能无法看到与之前相同的现象。\n这就是为什么工程师们现在不经常手动插桩代码了。然而， 自动化代码插桩仍然被编译器广泛使用。编译器能够自动对整个程序进行插桩，并收集与运行相关的统计信息。 最广为人知的用例是代码覆盖度分析和基于剖析文件的编译优化（见7.7节）。\n在讨论插桩时，有必要讨论一下二进制插桩方法。二进制插桩背后的思想也类似，不过是在已经构建的可执行文件上完成的，而不是在源代码上完成。二进制插桩有两种类型：静态插桩（提前完成）和动态插桩（在程序执行时按需插入插桩代码）。\n跟踪 跟踪在概念上与代码插桩非常相似，但又稍有差别， 代码插桩假设开发者可以掌控程序的代码。然而，跟踪依赖于程序现有的插桩,\n负载表征 PMU有两种使用方式：计数和采样。计数模式用于负载表征， 而采样模式用于寻找热点。\n人们经常用“剖析”（Profiling）来形容技术上所讲的采样。 剖析是一个更广泛的术语，包括各种收集数据的技术，例如中断、代码插桩和PMU。\n采样 采样可以在两种不同的模式下进行，即用户模式采样和基于硬件事件的采样（Event-ased Sampling，EBS）。 用户模式采样是一种纯软件方法，它将代理库嵌入被分析的应用程序中。 代理库为应用程序中的每个线程设置OS计时器，在计时器计时完成时， 应用程序会接收到SIGPROF信号，该信号由收集器处理。 EBS使用硬件PMC触发中断。\n用户模式采样比EBS产生更多的运行时开销。当使用10ms的默认采样间隔时，用户模式采样的平均开销约为5%。当采用1ms的采样间隔时，EBS的平均开销约为2%。因为可以以更高的频率收集样本，所以通常EBS更准确。\n静态性能分析 静态性能分析器不运行实际代码而是模拟代码运行。静态准确地预测性能几乎是不可能的，因此这种类型的分析有很多限制。\n 首先，不可能静态分析C/C++代码的性能，因为我们不知道它将被编译成什么样的机器码。因此，静态性能分析更适用于汇编代码。 其次，静态分析工具模拟负载而不是执行负载。这个过程显然会很慢，所以我们不可能静态分析整个程序。用户只能选择一些特定的汇编指令（通常是小循环）进行分析，所以静态性能分析的应用范围很窄。  静态分析工具的输出相当底层，有时会将执行过程分解到CPU周期。开发者通常利用这些信息对关键代码区域（与CPU周期相关性比较强）进行细粒度调整。\n这种工具的好处是不需要拥有真正的硬件就可以模拟不同CPU代系的代码。另一个好处，是无须担心结果的一致性：静态分析工具将始终提供稳定的输出，因为模拟不会有任何偏差（与在真实硬件上执行时相比）。静态工具的缺点是它们通常无法预测和模拟现代CPU中的所有内容：它们使用的某些模型中可能存在错误和限制。静态性能分析工具有IACA[23]和llvm-ca[24]。\n编译器优化报告 编译器提供了性能优化报告，开发者可以使用这些报告进行性能分析。 有时，我们想知道某个函数是否被内联，或者某个循环是否被向量化、展开等。如果循环被展开，展开因子是多少？一种比较困难的分析方法是分析生成的汇编指令。但是，并不是所有人都喜欢阅读汇编代码。如果函数比较大，这可能会特别困难，因为可能会调用其他函数或者包含许多同样被向量化的循环，甚至包含编译器创建的同一循环的多个版本。幸运的是，包括GCC、ICC和Clang在内的大多数编译器都提供了优化报告，供开发者检查编译器对特定代码段做了哪些优化。\n性能分析工具 Perf # Counting perf stat -e \u0026lt;event list\u0026gt; # Event based sampling perf record -e \u0026lt;event list\u0026gt; # SPE sampling perf record -e árm_spe_0/ts_enable=1\u0026#39; ","date":"2024-02-01T16:30:35+08:00","permalink":"https://wangloo.github.io/posts/reading-notes/perf_analysis/","section":"posts","tags":["ReadingNotes"],"title":"读书笔记：现代Cpu性能分析与优化"},{"categories":["Thinking"],"contents":"Cache 伪共享  原地址：Cache伪共享\n Cache的操作单位是CacheLine。 当两块内存AB位于同一个CacheLine时，且有两个Cpu核心分别对AB有修改需求， 此时AB都各自被加载到两个Core的Cache中。\n 伪共享指的是：若其中一个Core对AB进行修改，那另一个Core内的值变不可信， 需要根据一致性协议做出调整（文中举了MESI为例）， 使得两边内容一致。如果两边修改的比较频繁，就会导致一致动作经常发生， 这消耗的时间好似没有Cache存在，具体的时间损耗依据使用的一致性协议决定。\n","date":"2024-02-01T10:00:35+08:00","permalink":"https://wangloo.github.io/posts/thinking/post_reading/","section":"posts","tags":["Thinking"],"title":"优秀文章阅读"},{"categories":["Thinking"],"contents":"今天刚回东乔老家，也算是折腾收拾了一天。转眼间一年时光已逝， 期间辗转腾挪了四个城市，多多少少也算有一些感悟， 故在此作以记录并对即将到来的2024做出展望。\n实习 到了4月份，听到同学们陆陆续续找实习的声音，自己也打算去寻找一份实习。 因为头一次经验不足，投递的时间相对较晚，可能错过了不少好的机会。 最后流程比较长的只有Oppo、华为、特斯拉三家公司， Oppo JD是做基于安卓的Os底层开发，特斯拉车机Os开发， 最终选择了Hr是学长的华为作为主攻方向，当时听说方向还比较匹配。 其中的经历比较坎坷，华为Hr的经典话术：你很匹配，部门很想要-\u0026gt; 卡在公司审批，还需要等等。好在是最终第二批审批通过了， 其实到这已经对华为的招聘流程有些反感了，但毕竟是第一次进入大公司工作， 还是充满了期待，希望能了解华为的开发及项目管理流程， 能为华为的项目贡献自己绵薄之力，也算增加一点成就感。\n当天入职遇到了同组的另一位实习生同学：东坡。了解过后发现他之前是做安卓开发， 居然分配我做同样的工作。当时就在想，华为难道不按照个人能力方向进行筛选匹配吗？\n事实来看确实如此，依赖于完整的培训体系，华为不指望你进来有什么业务能力， 甚至是该领域完全的小白也Ok，因为初期给你分配的工作都比较简单， 不仅实习生如此，就连校招生进我所在的“芯片仿真组”之前，都不是所在专业的毕业生。\n开发工作中的所见所闻也印证了我的观点，我们组的工作是为海思芯片在Qemu上构建仿真平台， 尽可能去模拟所有的寄存器和外设。即便是Hr（目前已经是PL）学长一遍遍的强调我们是核心团队， 在我自己看来这些工作怎么也称不上核心两个字。更何况在工作时偶然间听到小道消息： 这块工作原本是由海思负责完成的，后面海思懒得做，划到了无线下。 在实际工作中我们也和海思需要频繁的拉通对齐，虽然海思不咋愿意搭理我们， 也不想提供涉密资料。在结合我们团队成员普遍在芯片行业的水平， 到底是不是核心团队则不言而喻了。\n另外中间比较有意思的一件事是评选优秀实习生，在我们整个小部门有两个实习生： 我和东坡。在这里我不是想自夸，只是说明术业有专攻，在底层软件开发、嵌入式领域我好歹也做了5年至少了， 没想到头衔竟然授予东坡。当然，东坡在自己的学习领域也很优秀我承认， 但是我确实没想到一个从没接触过嵌入式的本科生能比我更有竞争力。 由此我只能得出一个结论：部门或者团队的任务中，不需要你有多NB的嵌入式、芯片知识，99%用不到！ 招你一个硕士的成本比一个本科生大多了，人家也能完成这项工作。 有点意思，这是我最后没选择加入华为的关键原因吧。 和嫉妒真的无关，如果一个专业能力比我强的人，但是这套规则我确实理解不了。\n最终校招虽然没能加入华为，但是我想说，我很感谢这段经历。 虽然对工作内容本身有些无聊，但是同组几乎所有的同事都很好相处，与人友善。 大家毕竟在一起工作了三个多月，说没有感情是不可能的，回想起来挺想他们的：\n 感谢导师宁宁，对我接手新工作的指导，每次问他问题都能准确、通俗易懂的给予解答。 和宁宁聊天有种轻松愉快的感觉，在未来职业规划上给了我许多很有帮助的建议。 感谢组长PL余黎青，组长给我的感觉就是稳重、温文尔雅。让我印象很深刻的是生病时特地 加微信询问身体状况。 感谢吕东坡、罗鑫、郭绍兴，我们四人组天天一起吃饭，一起出去玩， 一起吐槽开发中遇到的各种问题。说到这，后面你们请我吃了两顿饭， 等我到上海一定安排你们！ 感谢芯片仿真组的其他同事们，徐老师、原湛、文栋\u0026hellip;  在我走之前也有幸参加了两次组内和部门的团建活动，部门的氛围真的很不错。 现在也遗憾如果岗位、工作内容合适就好了，不过天下哪有十全十美的事情呢？ 如果我可以定居上海，选择在华为干一辈子也未尝不可， 但问题在于我是一个注定要回家的游子，在华为短暂的技术成长确实较其他公司差些。 唉，真心希望仿真组的同事们能够越来越好。\n秋招 大概从7月份开始，就在陆陆续续投递简历，最初并没有太多的消息。 大约在8、9月份的时候感觉好像到达了人生低谷，最自己产生了极大的怀疑。 没遇到合适的公司、岗位和地点。期间在海投但鲜有回复， 因为是偏硬件的底层软件/嵌入式方向，看到传统软件开发方向上的朋友们大批收获着笔试/面试自己不急是假的。一直到10月中旬签署第一个Offer心情才舒缓一些， 12月份又签下理想汽车标志我秋招过程结束。\n整个秋招中，令我感触最深的是**战线太长！！**不同公司开始流程的时间段差别太大，早点的像希奥端、中兴微电子都是在8月份左右就开始面试， 而理想汽车确到10月份才进行笔试，11月才开启面试。 令你不得不重复的花时间准备笔试、面试。说起来这半年好像心思都在秋招上， 像在心中的一块石头没有落地。\n秋招中一共收获了：希奥端、中兴微电子、中兴、极氪汽车、理想汽车这五个公司的Offer。\n 希奥端是最先给我Offer的公司，公司的业务是制造提供Arm服务器Cpu。 应聘的岗位是嵌入式软件工程师（OS方向），最终给出的薪资待遇是2415+1.212。面试的内容比较基础， 因为是初创公司，又是第一年招聘应届生，我心里感觉不是非常靠谱。 犹豫再三，接着A25K被拒接的接口拒绝了他们。 中兴微电子同为Arm服务器Cpu解决方案方向，细节应该是性能优化一类。 地点在南京，但工资非常低（18k），差太多也没A就拒了。 中兴公司是成都的OS部门，是陈阔师哥给推荐的，我们组去年有四位师哥在里面。听他们说做的内容还可以，因为与中兴微电子可以有冲突导致谈薪时间一拖再拖就放弃了。当时已经和极氪的Hr谈好了，预估的参考薪资是25*15，属于SSP级别。我个人不喜欢成都，离家太远本身也不是非常想去。 极氪汽车是我第一个签正式三方的公司，岗位是嵌入式软件开发，做的内容应该是车机OS虚拟化这一块。令我印象深刻的是一面面试官对我的肯定，让我后面重新拾回了信心。当时确实正属于过程中还最焦虑的一段时间，感谢极氪也对不起极氪。极氪给出的薪资是24*14，虽然不是很高但已经在这个岗位上算是SSP了。很遗憾最终没有选择极氪， 理想汽车是最晚发的Offer，也是工资开的最高的一个35*14，地点是上海，工作内容是操作系统虚拟化。可以说各个方面都比较符合我的预期，可以说的比较幸运吧，感谢上天的可怜。  情感 2023年是感情及其平淡的一年，与wqq保持着不温不火的关系。 缘由是去年过年时大吵了一架导致我积攒在心中已久的怨恨爆发， 我觉得她不够成熟，总是去计较一些莫须有的事情，让我很累。\n但是当身在他乡，你会觉得能认识这样一个知根知底， 同时了解你的过去和现在的人真的很困难。所以我在心底也不想轻易放下， 我觉得，给她一点时间成长吧，这一年来确实成长了许多， 该肯定确实实话实说。\n新的一年 东隅已逝，桑榆非晚。\n2024 希望能买上属于自己的一辆代步车， 不过我感觉自己在上海工作的话确实是没必要买， 如果要买也是年底时开回家，前提是在家里我爸开或者上海停车方便。 说实话自己一个人在外也没太有用车的必要。 如果不能买就年底前长租一个，花个3000左右租一个假期吧。\n","date":"2024-01-31T21:30:35+08:00","permalink":"https://wangloo.github.io/posts/thinking/2023/","section":"posts","tags":["Thinking"],"title":"2023总结"},{"categories":["DevTools"],"contents":"Snippets 的含义是代码片段，帮助我们快速补全一段代码。 今天发现这个功能还挺强大的，尤其是写 Markdown 时，关键字写起来麻烦， 加上 Vscode 补全还乱七八糟（代码块的自动匹配不能关闭）。 先解我燃眉之急，先介绍 Markdown 的 Snippest。\n全局搜索中找到 snippets 的配置：  全局配置中选择 Insert 还能看到当前所有支持的 Snippets。\n以下是我自己添加了一段与 Hugo notice 主题相关的，变量的运用比较关键。 $1 表示插入后光标所在的位置，$2，＄ 3\u0026hellip;依次是按 Tab 键之后的位置， $0 则表示最终将停在哪，不会继续循环。\n{ // Place your snippets for markdown here. Each snippet is defined under a snippet name and has a prefix, body and  // description. The prefix is what is used to trigger the snippet and the body will be expanded and inserted. Possible variables are:  // $1, $2 for tab stops, $0 for the final cursor position, and ${1:label}, ${2:another} for placeholders. Placeholders with the  // same ids are connected.  // Example:  // \u0026#34;Print to console\u0026#34;: {  // \u0026#34;prefix\u0026#34;: \u0026#34;log\u0026#34;,  // \u0026#34;body\u0026#34;: [  // \u0026#34;console.log(\u0026#39;$1\u0026#39;);\u0026#34;,  // \u0026#34;$2\u0026#34;  // ],  // \u0026#34;description\u0026#34;: \u0026#34;Log output to console\u0026#34;  // }  \u0026#34;Hugo notice\u0026#34;: { \u0026#34;prefix\u0026#34;: \u0026#34;notice\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;Add hugo notice snip\u0026#34;, \u0026#34;body\u0026#34;: [\u0026#34;{{\u0026lt; notice $1 \u0026gt;}}\u0026#34;, \u0026#34;$0\u0026#34;, \u0026#34;{{\u0026lt; /notice \u0026gt;}}\u0026#34;] } } 注意，需要在 editor 配置中插入对 Markdown 语言启用建议的配置。 部分情况下如果上下文中有和 snippet 重复的关键字，默认 snippet 的优先级较低， 所以添加了升高优先级的配置。\n\u0026#34;[markdown]\u0026#34;: { \u0026#34;editor.quickSuggestions\u0026#34;: { // 开启markdown中的智能提示建议  \u0026#34;other\u0026#34;: \u0026#34;on\u0026#34;, \u0026#34;comments\u0026#34;: \u0026#34;off\u0026#34;, \u0026#34;strings\u0026#34;: \u0026#34;off\u0026#34; }, \u0026#34;editor.snippetSuggestions\u0026#34;: \u0026#34;top\u0026#34;, // 提高snippet在所有提示中的优先级  }, ","date":"2024-01-06T12:25:12+08:00","permalink":"https://wangloo.github.io/posts/tools/vscode/snippets/","section":"posts","tags":["tools"],"title":"Vscode Snippets"},{"categories":["Qemu"],"contents":"最终效果 用的环境和各个软件版本为：\n Qemu: 8.1.50 (qemu-system-aarch64 -M virt) linux-4.9.1 u-boot-2023.10 busybox-1.34.0  经过一番折腾，还是没有成功 Qemu+Uboot 来引导 linux 内核， 因为 virt 板级不支持-sd参数，主要的折腾过程见下。 但理论上也可以，只是后面发现没啥必要，用-kernel也能完成目前需求。 -kernel形式下功能没问题，有 Rootfs，可以在 Guest 中读写。\n准备 Linux 内核镜像 下载  Linux 内核版本历史 - 维基百科 上海交通大学镜像站  编译 Linux kernel 使用 make 来构建，可以键入make help查看支持的命令：\nCleaning targets: clean - Remove most generated files but keep the config and enough build support to build external modules mrproper - Remove all generated files + config + various backup files distclean - mrproper + remove editor backup and patch files Configuration targets: config - Update current config utilising a line-oriented program nconfig - Update current config utilising a ncurses menu based program menuconfig - Update current config utilising a menu based program xconfig - Update current config utilising a Qt based front-end gconfig - Update current config utilising a GTK+ based front-end 不同 Linux 内核镜像的区别 vmlinux vmlinux 是可引导的、未压缩、可压缩的内核镜像，vm 代表 Virtual Memory。 （表示 Linux 支持虚拟内存，因此得名 vm）它是由用户对内核源码编译得到， 实质是 elf 格式的文件.也就是说 vmlinux 是编译出来的最原始的内核文件，未压缩。\n vmlinuz vmlinuz 是可执行 的 Linux 内核，它位于/boot/vmlinuz， 它一般是一个软链接，比如是 vmlinuz-3.13.0-32-generic 的软链接。 vmlinuz 是 vmlinux 的压缩文件。vmlinuz 的建立有两种方式。 一是编译内核时通过“make zImage”创建，二是内核编译时通过命令 make bzImage 创建。\nImage Image 是经过 objcopy 处理的只包含二进制数据的内核代码，它已经不是 elf 格式了，但这种格式的内核镜像还没有经过压缩.\nzImage zImage 是 ARM linux 常用的一种压缩镜像文件，它是由 vmlinux 经过 objcopy ， objcopy 实现由 vmlinux 的 elf 文件拷贝成纯二进制数据文件加上解压代码经 gzip 压缩而成， 命令格式是#make zImage.这种格式的 Linux 镜像文件多存放在 NAND 上。 适用于小内核的情况，它的存在是为了向后的兼容性。\n bzImage bzImage 不是用 bzip2 压缩的，bz 表示 big zImage,其格式与 zImage 类似， 但采用了不同的压缩算法，注意，bzImage 的压缩率更高 ，是压缩的内核映像。\nzImage/bzImage：它们不仅是一个压缩文件，而且在这两个文件的开头部分内嵌有解压缩代码。 两者的不同之处在于，老的 zImage 解压缩内核到低端内存(第一个 640K)， bzImage 解压缩内核到高端内存(1M 以上)。如果内核比较小，那么可以采用 zImage 或 bzImage 之一， 两种方式引导的系统运行时是相同的。大的内核采用 bzImage，不能采用 zImage。\nuImage uImage 是 uboot 专用的镜像文件，它是在 zImage 之前加上一个长度为 0x40 的头信息(tag)（也就是说 uImage 是一个二进制文件），在头信息内说明了该镜像文件的类型、加载 位置、生成时间、大小等信息.换句话说，若直接从 uImage 的 0x40 位置开始执行，则 zImage 和 uImage 没有任何区别.命令格式是#make uImage.这种格式的 Linux 镜像文件多存放在 NAND 上.\n .notice { --root-color: #444; --root-background: #eff; --title-color: #fff; --title-background: #7bd; --warning-title: #c33; --warning-content: #fee; --info-title: #fb7; --info-content: #fec; --note-title: #6be; --note-content: #e7f2fa; --tip-title: #5a5; --tip-content: #efe } @media (prefers-color-scheme:dark) { .notice { --root-color: #ddd; --root-background: #eff; --title-color: #fff; --title-background: #7bd; --warning-title: #800; --warning-content: #400; --info-title: #a50; --info-content: #420; --note-title: #069; --note-content: #023; --tip-title: #363; --tip-content: #121 } } body.dark .notice { --root-color: #ddd; --root-background: #eff; --title-color: #fff; --title-background: #7bd; --warning-title: #800; --warning-content: #400; --info-title: #a50; --info-content: #420; --note-title: #069; --note-content: #023; --tip-title: #363; --tip-content: #121 } .notice { padding: 18px; line-height: 24px; margin-bottom: 24px; border-radius: 4px; color: var(--root-color); background: var(--root-background) } .notice p:last-child { margin-bottom: 0 } .notice-title { margin: -18px -18px 12px; padding: 4px 18px; border-radius: 4px 4px 0 0; font-weight: 700; color: var(--title-color); background: var(--title-background) } .notice.warning .notice-title { background: var(--warning-title) } .notice.warning { background: var(--warning-content) } .notice.info .notice-title { background: var(--info-title) } .notice.info { background: var(--info-content) } .notice.note .notice-title { background: var(--note-title) } .notice.note { background: var(--note-content) } .notice.tip .notice-title { background: var(--tip-title) } .notice.tip { background: var(--tip-content) } .icon-notice { display: inline-flex; align-self: center; margin-right: 8px } .icon-notice img, .icon-notice svg { height: 1em; width: 1em; fill: currentColor } .icon-notice img, .icon-notice.baseline svg { top: .125em; position: relative }     如何生成 uImage？\n在 uboot 的/tools 目录下寻找 mkimage 文件，把其 copy 到系统/usr/local/bin 目录下， 这样就完成制作工具。然后在内核目录下运行 make uImage，如果成功， 便可以在 arch/arm/boot/目录下发现 uImage 文件，其大小比 zImage 多 64 个字节。\n由于 bootloader 一般要占用 0x0 地址，所以，uImage 相比 zImage 的好处就是可以和 bootloader 共存。 其实就是一个自动跟手动的区别,有了 uImage 头部的描述,u-boot 就知道对应 Image 的信息, 如果没有头部则需要自己手动去搞那些参数。\n 内核编译脚本 编译完成后，用\u0026ndash;kerenel 应该能够执行，因为目前没有 rootfs，所以会 panic 进不了 shell。\n# get linux source code wget http://ftp.sjtu.edu.cn/sites/ftp.kernel.org/pub/linux/kernel/ # extract tar xvf linux-4.12.1.tar.gz # enter dir cd linux-4.12.1/ # generate .config make ARCH=arm64 CROSS_COMPILE=aarch64-none-linux-gnu- defconfig make ARCH=arm64 CROSS_COMPILE=aarch64-none-linux-gnu- menuconfig # compile make ARCH=arm64 CROSS_COMPILE=aarch64-none-linux-gnu- Image -j16     亲测 Wsl2 编译 Linux 内核时不能用-j而不手动指定任务数，会使 Wsl 爆内存。\n 构建根文件系统 根文件系统有两种方式传递给 Qemu:\n 通过在-append 参数执行 root 的设备名称，hdx 指定的可以是任意格式，ext4、raw 通过使用—initrd 参数指定 inital ramdisk 进行加载，必须是 linux 能识别的 ramfs 格式(cpio+gzip 可以）      \u0026ndash;append 中的 root=/dev/vdb 和 -hda -hdb 有什么关系？\n如果说只有一个磁盘文件，那么传递-hda 还是 hdb 都会在启动时映射到/dev/vda, 只有当同时传入多个-hda 和 hdb 时，这是通过 root=来指定 rootfs 是哪个。\n 源码下载 我使用 Busybox 构建, 下载源码时可能比较慢, 暂时没有发现国内镜像站。\n# Download busybox source code wget https://busybox.net/downloads/busybox-1.35.0.tar.bz2 编译 Compile and install to _install/. Change to static build.\nmake ARCH=arm64 CROSS_COMPILE=aarch64-none-linux-gnu- menuconfig make ARCH=arm64 CROSS_COMPILE=aarch64-none-linux-gnu- -j make ARCH=arm64 CROSS_COMPILE=aarch64-none-linux-gnu- install 适配-initrd=方式 Create rootfs\ncd ../ # Create null rootfs, `also can be done by `dd` command # TODO: different from initrd and initramfs mkdir myinitramfs \u0026amp;\u0026amp; cd myinitramfs # Copy target files from busybox just compiled cp -r ../busybox-1.34.0/_install/* . # Create other necessary dirs mkdir proc sys dev etc lib # Copy lib/ from cross compiler # TODO: No need now! Continue configging rootfs: make init script rcS.\nfstab 是另一个需要创建的文件， fstab 在 Linux 开机以后自动配置哪些需要自动挂载的分区， 这样在 rcS 中调用mount -a将这些分区进行挂载。\n# Config /etc/ mkdir etc/init.d touch etc/init.d/rcS etc/fstab chmod +x etc/init.d/rcS 将以下内容赋值到 rcS:\n#!/bin/sh mount -a /sbin/mdev -s mount -a 将以下内容赋值到 fstab:\n#device mount-point type options dump fsck order proc /proc proc defaults 0 0 tmpfs /tmp tmpfs defaults 0 0 sysfs /sys sysfs defaults 0 0 tmpfs /dev tmpfs defaults 0 0 debugfs /sys/kernel/debug debugfs defaults 0 0 tracefs /sys/kernel/tracing tracefs defaults 0 0    测试fstab  fstab可以直接在guest中执行mount -a测试\n 创建 inittab 文件: TODO\n打包与拆包的命令 # 拆包到test/目录下 gunzip -c rootfs.cpio.gz \u0026gt; rootfs.cpio cpio -D test -idmv \u0026lt; ./rootfs.cpio # 将test/打包到为根文件系统格式 cd test/ find . | cpio -H newc -o \u0026gt; ../rootfs.cpio cd .. gzip -c rootfs.cpio \u0026gt; rootfs.cpio.gz # 打包也可以整合为 find . | cpio -o -H newc | gzip -c \u0026gt; ../myinitramfs.cpio.gz 启动脚本如下，这种方式的缺点是修改仅在内存中，重启后失效。\n#!/bin/bash qemu-system-aarch64 \\  -machine virt,gic-version=3,its=off,secure=on,virtualization=on \\  -cpu cortex-a53 -smp 4 -m 2G \\  -kernel ./linux-4.9.1/arch/arm64/boot/Image \\  -initrd ./myinitramfs.cpio.gz \\  -append \u0026#34;rw rdinit=/linuxrc\u0026#34; \\  -serial mon:stdio \\  -gdb tcp::1234 \\  -nographic \\  $1 适配-append=\u0026quot;root=/dev/vda方式 因为通过-inird=指定的方法不能将修改保存到本地， 所以还得是借助非 ramdisk 的方式来实现根文件系统。\ndd if=/dev/zero of=rootfs.ext4.img bs=1M count=512 mkfs.ext4 rootfs.ext4.img sudo mount rootfs.ext4.img ./mnt-tmp cd ./mnt-tmp # 根文件系统的内容都一样，这个可以直接拷贝 cp ../myinitramfs/* . cd .. sudo umount ./mnt-tmp 启动脚本为，在 Guest 中的修改能够写回根文件系统，但是注意等待写回之后再退出 Qemu， 否则可能造成在内存中缓存的情况。后续可以查资料关闭文件在内存中的缓存。\n#!/bin/bash qemu-system-aarch64 \\  -machine virt,gic-version=3,its=off,secure=on,virtualization=on \\  -cpu cortex-a53 -smp 4 -m 2G \\  -kernel ./linux-4.9.1/arch/arm64/boot/Image \\  -hda ./rootfs.ext4.img\\  -append \u0026#34;root=/dev/vda rw rdinit=/linuxrc\u0026#34; \\  -serial mon:stdio \\  -gdb tcp::1234 \\  -nographic \\  $1 准备 Uboot（未完成） Image 不是内核的二进制文件吗？怎么可以使用 Qemu --kernel引导呢？ 其实在 Qemu 内部有一个 Bios，我们当然想尽可能接近真实的工作环境， 所以还是能用 Uboot 最好。\n源码下载  https://ftp.denx.de/pub/u-boot/  编译 # 不能用 make ARCH= 来指定，编译会报错，详见 # https://forums.raspberrypi.com/viewtopic.php?t=345377 export ARCH=arm64 export CROSS_COMPILE=aarch64-none-linux-gnu- make qemu_arm64_defconfig make -j 失败的折腾 Uboot 编译后好，先尝试直接启动 Uboot，没问题\n#!/bin/bash qemu-system-aarch64 \\  -machine virt\\  -cpu cortex-a53 -smp 4 -m 2G \\  -bios ./u-boot-2023.10/u-boot.bin \\  -serial mon:stdio \\  -gdb tcp::1234 \\  -nographic \\  $1     启动参数不能带virt,secure=on，会导致同步异常 uboot 卡死。\n      接下来就是结合 Uboot 和 linux kernel，最终和真实开发一样的流程： 内核镜像、设备树、根文件系统放在 sd 卡中，当 Uboot 启动后将其加载到内存，并引导。\n制作 Sd 卡 在 uboot 的 menuconfig 中加入 mmc 的支持:\nSymbol: MMC [=y] │ │ Type : bool │ │ Prompt: MMC/SD/SDIO card support Symbol: CMD_MMC [=n] │ │ Type : bool │ │ Prompt: mmc 启动时会报错，该 model 不支持 if=sd,bus=0\u0026hellip;.,\n \u0026ldquo;-sd sd.img\u0026rdquo; is shorthand for \u0026ldquo;-drive if=sd,index=0,file=sd.img\u0026rdquo;. Like all -drive (except for if=none), it requests the board to create a suitable device. Boards act on some requests, and ignore others. mpc8544ds ignores if=sd.\n 后续： virt 开发板不支持-sd 选项，但是 raspi3b 支持，\n用-hda传入镜像可以，在 uboot 里用 virtio ls 命令可以看到，后面觉得算了 没必要去折腾这些，用--kernel 也还行。\n制作HOST共享目录 QEMU8.1默认支持9p virtio文件系统，实现HOST与GUEST共享目录， 在调试时比添加硬盘（-hda）更加方便：\n host中创建 share/ 目录 qemu启动参数指定  -fsdev local,security_model=passthrough,id=fsdev0,path=./share \\ -device virtio-9p-pci,id=fs0,fsdev=fsdev0,mount_tag=hostshare \\ 启动guest linux后，在命令行中挂载9p文件系统  mkdir /mnt/share mount -t 9p -o trans=virtio,version=9p2000.L hostshare /mnt/share     添加到启动脚本中，自动挂载。\n 增加 perf perf已经集成到了 Linux 主分支中，源码的位置在tools/perf\n使用 perf 的基础功能不需要修改内核配置文件，但是貌似有些功能比如说 function Trace 是需要的， 目前没有用到，所以之后再来补充吧。\ncd tools/perf make clean make ARCH=arm64 CROSS_COMPILE=aarch64-linux-gnu- LDFLAGS=-static WERROR=0     这里换了编译器，可能是之前用的编译器版本太新了，编译会出错。 目前编译成功的版本是： gcc-arm-8.3-2019.03-x86_64-aarch64-linux-gnu\n 编译成功后，在当前目录下会有静态编译的 perf 可执行程序，移动到 rootfs 中就能直接使用了。\n~/linux-qemu/linux-4.12.1/tools/perf $ file perf perf: ELF 64-bit LSB executable, ARM aarch64, version 1 (GNU/Linux), statically linked, for GNU/Linux 3.7.0, with debug_info, not stripped 试用 KGDB 调试内核 增加 strace 下载源码：Releases · strace/strace (github.com)\n编译\u0026amp;\u0026amp;安装:\nmkdir build \u0026amp;\u0026amp; cd build ../configure --host=aarch64-none-linux-gnu --prefix=$HOME/linux-qemu/strace-6.0/_install --enable-mpers=no # 编译为静态链接方式 make LDFLAGS+=\u0026#39;-static -pthread\u0026#39; -j16 # 拷贝到 _install 目录 make install 编译内核模块的脚本 将Makefile和nlk.c放在同一目录下。\n# 最终生成的ko名，可以同时指定多个 obj-m := nlk.o # 指定内核源码路径：这里有交叉编译和host两种路径，按需选择 KERNEL_PATH := $$HOME/qemu_atf/linux # KERNEL_PATH := /lib/modules/$(shell uname -r)/build PWD := $(shell pwd) # 当前目录 MAKE := make --no-print-directory all: @$(MAKE) -C $(KERNEL_PATH) M=$(PWD) modules install: cp ./nlu ./nlk.ko ../share clean-ko: @$(MAKE) -C $(KERNEL_PATH) M=$(PWD) clean ","date":"2024-01-04T19:28:12+08:00","permalink":"https://wangloo.github.io/posts/os/arm64-linux-qemu/","section":"posts","tags":["Qemu"],"title":"Qemu 启动 Linux Kernel(Arm64)"},{"categories":["Photography"],"contents":"人像摄影如何引导模特 学习链接： https://www.bilibili.com/video/BV1aU4y1t7P2/?spm_id_from=333.788\u0026amp;vd_source=e819378fded474f59b1110fad57bac1b\n个人形象  会让模特到你是有审美的  女生最看重 瘦、高、脸好看、皮肤白\n平常心态 没有经验的摄影师+没有经验的模特，大概率是翻车， 所以保持平常心，当出去玩一样，最重要的是开心\n态度  重视拍摄，提前去到场地选好机位，想好姿势，不要临场才想， 规划一下路线，不要走太多。 尊重模特，说话客气、不要比较  前期准备  和模特商量 服装、妆容、发型 自己准备 灯光、道具  热身阶段 刚开始拍摄的时期，叫热身，一般半个小时。\n 不要急，边聊边拍 不看照片  姿势  如果模特自己会摆动作，即使不怎么好看，也先不要纠正，先拍， 慢慢找到一个对的感觉的姿势，找到她一个好看的眼神和表情。 慢慢你找到感觉可以开始慢慢调整了，一次只指导一个点，拍几张 然后肯定一下，再调整一下。 对于新人，可以试试她直面镜头，如果她不是很放松，那就不要 先强迫让她看镜头。 针对不会摆姿势的模特，要提前准备好一些样片，给她看一下。 （针对这点我表示怀疑哈哈哈，觉得不太专业） 每一次调整都要按快门，高速连拍 情绪表情不对的时候，要明确告诉模特方向，描述情绪氛围， 可以选择用一个场景对描述这个表情和情绪  夸赞  夸一个具体的细节（耳环、眼线） 不要提当场改不了的意见。（拍着拍着突然说：这件衣服不行啊， 看破不说破，不要毁了心情）  小技巧  跟刚认识的模特，保持舒适距离，2-3米，所以最好买一个85哈哈 直出尽量就拍好看 尽量用屏幕，让人更放松 先拍最差，再拍最好，热身；回放先看最好的，再看最差的；  ","date":"2024-01-04T16:21:27+08:00","permalink":"https://wangloo.github.io/posts/thinking/photography/","section":"posts","tags":["Photography"],"title":"人像摄影如何引导模特"},{"categories":["Hugo"],"contents":"写博文时避免不了插入一些图片，总结了几种方式。\n图床 最早在其他平台写博客时，因为 Markdown 格式编辑，不方便内嵌图片（好像听说支持 Base64 编码， 没试过）， 此时想要维护单个 md 文件，最好的方式就是用网络图片， 本地引用必须同时维护图片和文件在同一个目录，而且一些博客平台上传图片太麻烦。\nMarkdown 插入图像的语法本就支持网络图片，这里防一张图片作为演示：\n以前用的 Gitee（码云）搭建图床，后面码云官方禁止这种行为，考虑过换成其他收费的平台， 例如各家云公司的对象存储 OSS。但是仔细想想如果要迁移平台意味着所有的博客都要改动， 未免太麻烦了。\nHugo 使用 Hugo 搭建静态博客页面之后，其实对于远程链接的引用方式的依赖性就消失了。 反正都是用一个 Hugo 工程管理所有笔记，那么也统一管理所有图片也没太大所谓。 以前觉得本地管理很麻烦，需要传图片之类的，但最近用 Latex 写论文发现也还好。 工程放在 Windows 上，传图片直接另存为改下目录就行了，用虚拟机上确实不太方面。 还好 Hugo 对 Windows 的支持还不错。综上，目前就在尝试使用本地的方法管理图片。\nHugo 引用图片有两种方式：\n 建立一个 Page bundle，图片作为 Page source。通过![](sunset.jpg) 即可访问，Hugo 官方描述。 属于各自 blog 的图片放到各自的目录下，这样的好处是看起啦比较清晰。 但是麻烦的地方就在于需要引用图片的博文都需要建立一个 Page bundle， 而且我不喜欢 index.md 这种文件名，难以搜索。 content/ └── posts/ └── post-1/ \u0026lt;-- page bundle ├── index.md └── sunset.jpg \u0026lt;-- page resource  所有博文的图片都放到的/static目录下，统一管理。 /static可能不是必须存在，可以手动创建。此时的图片通过 ![](/sunset) 的方式来访问，多了一条斜杠。 Latex论文里的图片就是这样管理的，以前担心混乱， 实际上因为图片不多，命名规范也还好。  Shortcode Md支持的原生图片引用方式调整大小、对齐等操作比较麻烦， Hugo在这方面引入了默认的Shortcode: figure 帮助实现引用本地图片。\n{{\u0026lt; figure src=\u0026#34;/test.jpg\u0026#34; width=\u0026#34;100%\u0026#34; \u0026gt;}} 另外，我自己根据网上的资料写了引用外部图片的shortcode: insertFigure。\n","date":"2024-01-03T13:39:42+08:00","permalink":"https://wangloo.github.io/posts/hugo/hugo_image/","section":"posts","tags":["Hugo"],"title":"Hugo 引用图片"},{"categories":["C"],"contents":"const 修饰成员函数 C++允许将成员函数添加const修饰符，代表此成员函数不会对成员变量进行修改， 否则会发生编译错误。在下面的示例中，set函数用const修饰就会出错， 而get函数用const修饰就能清楚的告诉别人这个函数不会修改类的成员。\n对于一个声明为const的类实例，C++规定它只能调用const修饰的成员函数， 也就是说明这个类的成员是不允许被修改的。\nclass A { int num; public: void set_num(int x) { num = x; } int get_num(void) const { return num; } }; const A a; a.set_num(10); // Compile error a.get_num(); // Success 说起a为什么不允许调用set函数，我这里尝试从C的角度去进行解释， 毕竟C和C++本是同根生。C++定义的成员函数会有一个隐形的参数叫this指针， this总是指向这个类的示例，所以实际上我理解调用成员函数的时候会将成员地址作为参数也传递给成员函数，毕竟这样才能用this指针嘛。然后就说为什么不能调用set函数呢？ 我猜测对于一般的成员函数，规定接受的隐形参数this的类型是 A*， 而const修饰的成员函数接受的this类型为 const A*， 这样做就能限制用const修饰的类实例在将其自身地址传递给普通成员函数的时候出错， 即const A * 不能传递给参数类型为 A* 的函数哦，导致编译错误。\n// 猜测C实现C++类 struct A { int num; void (*set_num)(struct A *a, int x){...} void (*get_num)(const struct A *a) {...} }; const struct A a; a.set_num(\u0026amp;a, 10); // Compile error a.get_num(\u0026amp;a); // Ok 查看编译后的结果能够证实上述的猜想，确实需要将类变量的地址传递给成员函数作为隐式参数。https://godbolt.org/z/dT9rnsvKz\n ","date":"2023-12-22T18:51:49+08:00","permalink":"https://wangloo.github.io/posts/c/cpp/","section":"posts","tags":["C"],"title":"C++ 特性的底层原理"},{"categories":["Thinking"],"contents":"一家人一起吃饭是最美好的事情 人生在世，最孤独的就是一个人吃一桌子饭，味同嚼蜡，苦涩难咽。你有过这样的体验吗？当你品尝到美食，第一时间就会相当最亲的人。即使是普通的一日三餐，有人陪着吃，才会有人间烟火的味道。简单的一日三餐有质朴之味，有温馨之味。\n人会死三次 我说过一种说法，说人一生要死三次。\n 第一次是你自然死亡。 第二次死是葬礼结束，就是你这辈子结交的人在丧礼仪式之后就把你放下了。 第三次死是在这个世界上最后一个还记得你的人也死了，你跟这个世界了无瓜葛。  像苏东坡这样的人呢，第三次他死不了，永远会有人记得他，这才是永生。\n我现在也慢慢理解了这句话，回想自己心里敬佩的、对你好的那些人：毛主席、长辈、好街坊，我们聚在一起还总是谈论他们的好，偶尔一个恍惚还会想念起他。我觉得这就是算做人没有失败。所以说，寥寥一生，尽力去做一些对他人、对社会有意义的事情，奉献真的是一个人的最高境界。\n入职汇报 20240822 公司里据说李想本人非常关注校招生培养，要抽几个人一对一交流，耿哥说我们部门选择我去。不知道这是件好事还是坏事，我觉得总体上来说还是一件好事吧，毕竟能跟跨越阶级层次的大人物交流，先不说能不能学到什么东西，起码锻炼了自己的一些汇报和沟通的能力。\n不过这个汇报还是需要格外的小心和谨慎的，一方面需要体现出部门的重要性，向领导汇报部门层面的一些业务。另外，不要发表对自己部门不好的言论，因为这样也间接是害自己！\n今天，借着这个缘由，琛哥也是让我在所有校招生和导师面前进行了一次述职和分享，结果还是不错的，但是自己还是有一些感悟和教训需要在这里写下。\n 说话不够清楚，应该顿挫有致，有一些节奏型，有机会再重听下自己的汇报讲话。有些词语的使用不够恰当。 不喜欢这种被人捧起来的感觉，自己在之后一段时间内还是保持低调。毕竟，现代职场上都有教会徒弟，饿死师傅之说。  读书有什么用？ 只有读书可以培养出一个人的人生观和价值观，没有自己人生观和价值观的人，人生是没有希望的。\n怎么判断别人是不是喜欢你？  快乐脚。假如你发现对方跟你交谈时，双脚的脚尖往上翘，往往说明对方很高兴。而且不光是脚尖往上翘，一旦你从对方身上看出有那种向上的趋势，那就是高兴的表现。 “嗜同神经行为”。简单来说就是对方不自觉的跟你做一样的动作。比如你说话的时候跷二郎腿，对方也不自觉地这么做了。或者步伐不自主的和你保持同步。  该直接给上司提反对意见吗？ 如果你不是公司的法人、CEO，不要直接给你的领导提反对意见。 加入你的老板说要给长城贴瓷砖，给珠穆朗玛峰装电梯这种项目，下面的中层领导做的一定不是反对老板，而是提供几个方案给老板做选择，因为这个项目做与不做，公司的盈利和亏损都不会直接的影响到自己的薪资和年终奖。即便是公司效益不好，也可以跳槽去另一个拿着同样的高薪，演着同样的戏。直接反对老板通常是一个费力不讨好的行为。\n当然，除非你能拿出充分的分析数据来证明一些事情，那么我觉得把这件事说明白还是有必要和有好处的。这也取决于你反对的形式和方法，在私下单独交流，而不是在大家面前公开发对。\nAd-hoc 工作 Ad-hoc 工作，这个术语在外企中经常被提及，指代那些灵活的、非结构化的工作内容。\nAd-hoc 工作通常出现在以下情境中：\n 紧急任务：当出现紧急任务，需要立即解决，而没有事先规划的时间。 特殊要求：满足特定客户或合作伙伴的个性化需求，可能需要不同于常规的工作流程。  看 LOL 比赛有感 2024 年 5 月 12 日 今天休息，随便打开看了眼 MSI 的比赛，是 T1 和 BLG 的，两边队伍里我唯一认识的就是 Faker 了，他也是从我玩 LOL 开始到现在都在 T1 未交易换队的选手。也是我能清晰记得他的原因。\n就这件事来说，我有一点感触就是现在的人都拿钱看的太重，因为隔壁队伍愿意花高的价钱挖你就轻易离开，一个可能今年在这个队，明年又去了另一个，后年再换一个。当然，这种情况也不是只有 LPL 有，在 NBA 队伍中也时常发生，最早 10 年左右看 NBA 也是几乎一个球员的生涯也就呆 2、3 支队伍，现在的交换频率绝对是大幅提升的。\n由此我也想到目前社会上跳槽的频率，一个人在公司待到两年已经算是时间长的？大家这么频繁跳槽的原因可能有以下几种：\n 觉得在公司干的活不是自己愿意的，或者觉得没有价值 觉得团队内部的人不好相处 觉得涨薪的速度太慢  我个人觉得你在一家公司待的不开心，也一定有自身的原因，我们不能保证在职场中遇到的每个同事都和你的性格相投，如何与不同性格的人交流是一种能力。 对于钱来说，我个人看的并不是特别重要，从 40w 到 50w（20%的涨幅）有很大的区别吗？给你的生活带来不了很大的改变。 我觉得，至少在一家公司 4 年才能完全的了解公司文化和你所做的任务。也会给到别人一种你很靠谱，而不是随随便便易主的人（参考吕布 hh）。\n理想校招入职培训感悟 本周作为一个实习生的身份参加了基本都是正式入职的校招生的培训课程， 这个时间段正式入职的都是留学生，经过和他们一周时间的相处，自己感悟也很深，某些方面来看也是认识到了自己的差距吧。另外最重要的是理想汽车的校招培训方案我觉得真的是非常好，PBC、TBP 问题解决法、高七都让我到能学到新的知识，不像是常规培训那种纯理论的洗脑。在此我就简单的回顾下本次培训中我的一些具体的感想。\n高七培训的内容中，我感受到老师真的用心思想把我们教会。我记得很清楚的一件事是在设定“个人使命宣言时”，老师通过层层递进的方式来帮助我们找到自己的使命宣言，最开始先让我们选择最想共进晚餐的 5 人，并写出他们的品质和个性，实际上是在挖掘我们内心中敬仰的品性。接着假设来 80 岁的生日宴，让我们选择邀请的人并写出他们的祝词，目的也是通过期待他人什么样的评判来找到自己的目标。这个过程我觉得层次递进的非常好，真的能更加流畅的确定出我们的使命宣言是什么。\n另外我还想说这次培训的分组，以前很多的课程中都会分组，便于讨论或者交流自己的感想。但其实就拿我自己在国内上课的这几年来说，我几乎没遇到过真正有效的小组交流，大家好像都比较抗拒这件事（包括我自己）。但是在这次的小组中，我感受到了不同。首先老师通过若干活动让我们对彼此都快速熟悉破冰，我也意识到我的组员朋友们都是属于积极、阳光的人，所以在后面这几天的培训中，我自认为我们的关系处的都非常好。甚至在今天分别时我产生了一种强烈的不舍，这种心情我说实话已经至少 5 年没有过了。这种感觉对我的冲击很大，我不禁开始联想原因是什么，完全只是巧合吗？\n思考过后，我觉得原因之一是外出留学经历，接受过国外的教育方式可能会对本性中那些可塑性的方面产生影响。俗话说“读万卷书不如行万里路”，见识过一些不同的生活方式、思维方式，你才有机会去主动积极的选择那些你认为好的，而不是被动的接受唯一的选项。第二就是家庭从小的培养方式上，我说农村出身，从小的条件和他们也是没办法比的，当然从小时候的教育上也没办法相提并论，所以这中习惯的养成，或许从出国前就已经慢慢养成。\n最后，拿我自己来说，在以后对下一代的培养上，或许传统教育方法中内向的方式也需要改变了，需要让孩子养成大方的性格，但是必须注意谦虚，不能太炫耀自己。\n研三寒假和范老师交流 初一给范老师拜年打电话，相约等年后有机会一起聊聊天。 我个人是觉得和范老师交流总是有比较大的收获， 一个是行业方面，因为同样都比较了解嵌入式方向， 在职业发展、个人技术成长方面总是能给到建设性的建议。 二是生活上，作为地地道道的青岛人、即墨人， 我们从个人情感方面或许可以感同身受，我在生活上的一些想法也能得到肯定或者意见。\n其实，一直不知道范老师到底希不希望我去拜访。因为说实话， 以我家庭的实力和个人的现状，和范老师的家庭显然是无法相比的。 因为暂时也没有参加工作，没有多少能拿得出手的礼物送给他。 我唯一能做的就是陪他说说话，缓解中老年人子女不在身边的孤独感吧， 暂时想到的也就是这一点。索性就按照这个想法来， 只带一些水果、点心，表达自己的心意即可。\n大年初九，怀着忐忑的心情在下午三点给范老师打去了电话， 询问是否有时间可以拜访。范老师的回复也是高兴和欢迎， 暂且不说是否真心，起码我的心情得到了一些缓解。 或许是客气，无法从电话中的语气上判断是否真心愿意， 但是起码回复积极，加上我表示不吃饭后还是留我在吃饭， 这些我觉得足以证明是希望我去的。就这样认为吧， 如果以后不是这样了，可能就说明我不必再去了。\n带的礼物是一箱苹果和崂山绿茶，原本是苹果+饼干， 后来由于临时去朋友家，不得已将饼干送了出去。 经过后面的观察，带礼物方面有以下几点需要注意的：\n 范老师有糖尿病，苹果含糖量不少，后期可以换成猕猴桃、橙子， 这是家里桌子上摆的。 范老师喝红茶会上火，碰巧这次是绿茶，还好一些， 但是据我观察范老师喝的茶叶比较高档（白茶+熟普洱）。 一般的茶叶还是不要再带了。 饼干其实挺好的，因为看到家里也准备了不少点心、甘果之类的， 说明平常也会吃。  因为已经约好了吃中饭，我就不必那么早去，在 10：30 前开车到达单元楼下。 下午 4:30 左右才离开，后面看来呆的时间有点长，早些离开比较好。 但是我观察范老师谈话的情绪还比较高，所以也没有主动提出。 想等到范老师什么时候说的不那么兴致勃勃了再离开， 可能这一点也印证了上面说的，总的来说老师还是希望我过去拜访的。\n这回交流主要总结了两点：\n 关于家族成长。自己出身寒门，上天眷顾+父母疼爱得以求学二十载， 有句话说的好族旺留原籍，家贫走他乡。自己手中的牌不能支持我在家里谋得一份顺心的差事， 也不想放弃自己学了六七年的技术。索性只能外走他乡， 向上保证自己以后的结婚生子无需父母操心物质上，向下为孩子提供良好的物质条件和精神教育。 此乃吾辈之大任，不求靠自己寒窗苦读十年超越别人三代努力。 步子是一步步走的，要有目标，但也不能好高骛远。 我们俩都是即墨农村人，对家族的感情很浓重。我每次回到家里看到一大家子人， 心里是格外的亲切和欣慰，打心里希望家族兴旺。之前不管， 从我这里开始就要做好规划，争取给小辈提供一些人生路上的建议。 老师后面又给我发了个视频讲解，关于家族成长的整体规划，我觉得非常有帮助： https://www.douyin.com/video/7334992899735637298。 关于事业规划。基础的技术是很多的，要多了解行业内的知识。 拿这段时间来说，我一开始想的是多补充基础知识，比如研究 QEMU 的源码等等。 老师给我的建议是先去公司实习，做一些边缘的项目。 为的是在不耽误毕业进度的前提下了解行业内的基础知识， 尽快的入门。不要去做核心业务，会挫败你的积极性，也可能耽误毕业的主任务。  最大的福报 人一生中最大的福报是什么？有人说他当上科长处长，他赚到钱了等等。 我不这么认为，一个人一辈子最大的福报是接受了一套积极向上正确的认知。 活得阳光、活得正派、活得上进、活得积极、活得快乐。\n要相信积极向上 徐涛抖音\n徐涛：多年轻朋友开始不相信了，不相信风雨之后能见彩虹， 不相信只要努力量变能够达到质变，不相信只要踏踏实实本本分分， 未来就能更好。\n一个朋友：那我们到底该不该相信？\n如果说该相信，那有很多反驳的例子在等着。祖祖辈辈要这样以后就应该这样吗？ 时代变了等等的话；如果说不该相信，那这个话题提起就没啥意义。 徐涛最终说了：这不是一个该不该相信的问题，是一个要不要相信的问题。 因为该不该相信谈的是真理问题，就讨论对错的问题。 而要不要相信是谈的是方法问题，我不管事实怎样，也不管时代变了， 如果我选择相信，会以一个更加昂扬、积极向上的面貌呈现在世界上。\n如今社会面对繁多的信息，要做大量的选择。当你面对一些选择犹豫不决， 不能足够理性的思考时，选择去相信积极正面的，可能最后会落空， 但是这会让你始终呈现一种积极向上的精神面貌。 人为了呈现在社会上、家庭中、个人心里的面貌而活着。\n阅读感悟 2024 年 1 月 17 日\n距离回青岛还有三天了，今天忙里偷闲去深圳演艺公园逛了逛， 随后经过南山图书馆，看到几篇杂志里的文章比较有趣，在这里写下一点感悟。\n 看说自助的这篇文章，我其实蛮认同的。初判断一个人三观和你是否相合， 其实吃饭能看出不少。\n 从点菜开始，选择菜品的价格是否合适？ 也就是判断这个人的家境和心态，是否考虑对方的喜好和忌口， 也是一个重要的考察点。 然后说到吃的过程中，也能透露家教品德， 对待服务员是否尊重？饭碗有没有端起来？（自己之前有忘记的时候） 是否尽量和对方同步进度？（避免出现一方等待另一方）。 当然在吃饭的途中你们会交谈，会说一些对菜品的评价等等， 这些都是衡量观念是否相同的好机会。如果是喝酒， 其实是考验人品性最重要的时刻。装好人谁都会，所以在最放松的时候， 才能看到褪去伪装下真实的性情。（所以说老丈人目标把女婿喝趴下是有道理的） 用餐结束后，逃避买单？（男方理应主动买单）是否在饭店里就当面嫌弃菜品等。    什么是教育？不仅仅是知识能力的灌输，更应该是人格品质的培养。 他们的诚实、正直、孝顺\u0026hellip;有比成绩更重要的衡量标准。\n 因为我是农村人，周围的邻居虽然普遍文化程度不高，但我从小受了很多关照。 以前邻里之间的和睦让我觉得比现在的生活幸福的多，我的确是不喜欢住楼房。\n还想起了一位发小，他学习不好，但每到农忙季节干的活绝对是比父母多， 从来不对外有任何怨言。他单纯、质朴的性格总让我担心找另一半时会不会被欺骗\u0026hellip; 虽然目前回家的时候不多，但请我一定记住回去多看看他。\n 感同身受，我一直不喜欢网上聊天，总有许多敷衍的词句在里面， 不如两个人见面聊的痛快。而且，见面的好处是你能切实的观察到对方听到你的话是什么反应， 如果他表现出了厌恶的微表情，我也能做到及时的转移话题。\n回顾实习结束前 2024 年 1 月 13 日\n在 HW 实习的最后一天有一件事没干妥当，就是走之前没有和性能仿真那边打个招呼。 虽然说现在功能和性能已经划分开，但毕竟已经在一起聚过，也一起讨论过工作。 应该正式的打一声招呼再走的。\n闻吴起事迹反思 2024 年 1 月 12 日\n吴起是战国初期的军事家，所著《吴起兵法》传播广泛。 但是听百家讲坛中介绍吴起的事迹确实是很难让人赞同。\n 吴起最早跟随曾子，其母去世后，曾子问为何不回家守孝， 吴起回答专注学习，母亲死了就死了。 在鲁国任命时，因为其妻子是齐国人，被拒绝任命大将军。 吴起知道后，将其妻子杀害，以表忠心。  吴起最终死的很惨，在我看来缘于心恶没有孝心。 只追逐于当下的功名利禄，抛弃了人与人的爱情与亲情， 实在是狼心狗肺之人。\n一瞬间我就想到了自己高中时候做的一件错事： 当时我座位的前边是一个非常调皮、爱说话的同学， 时常让我和同桌的好朋友都不得安心学习，在忍无可忍之后， 我居然自己去找班主任换了座位。\n这个事情做的也算是自私，没有真正的解决问题而是选择逃避。 把自己的好朋友抛弃，虽然自己得了一方清闲但实属不义之举。 故在此进行反思，以后请做一个重情重义之人，不要被天下人耻笑。\n初一、十五不能理发 2024 年 1 月 12 日\n今晚给父母致电告知回家的日期已定，提到今天理发时父亲反应很大， 说初一、十五不能理发，理发要选 3、6、9 日。这项习俗我确实不知， 长到这么大也没在意过这个，属是不应该。很多老习惯、 老习俗还是需要多了解，是否遵守且再谈，但不应该如此无知。\n算命科学吗 2024 年 1 月 6 日 观： 对话中原：张其成—传统文化的魅力（1）\n首先只看八字一定是不科学人的，跟你同一个时辰一起出生的人有很多， 全世界有几千万。所以要看一个人的命有三个方面：天、地、人， 八卦就是这三个方面形成的。\n 天：你出生的天时 地：你出生的地方，不同地方的人是有文化特征的，地域文化有所不同。 人：最重要的是人自身，人分先天和后天。先天包括相貌、体质、举止， 这些一般来说是难以更改的，大变化没有。重要的也包括后天，就是人的性格。  阿帅与冒老师 2024 年 1 月 6 日\n从去年 3、4 月份开始，阿帅和冒老师的飞花令游戏引了不少热度， 大部分人和我一样都是想来磕 Cp，但是冷静下来想想基本不可能。\n下面就把自己假设成阿帅，想想会是什么心理。 冒老师是什么人，上海某高等院校博士，阿帅是北京理工大学珠海学院本科， 这个学历似乎相差比较大，虽然我感觉阿帅绝对不输现在某些高等院校的硕博研究生， 但是不得不考虑冒老师自己和其家庭的考虑。\n阿帅在当时粉丝可能十万左右，也是靠着这一波热度涨了不少粉丝， 那么想想冒老师这么做的动机是什么呢？ 首先，她也非常喜欢诗词，与阿帅讨论诗词、玩飞花固然可以理解， 但为什么要搞得像暧昧不清的关系呢？在这里我感觉应该冒老师是想借助阿帅的热度来建立自己的粉丝。 后面也确实如此，现在也算是几万粉丝的 Up 主了，给她刷礼物的人也非常多，毕竟有学识、 声音又甜、情商还高的人谁不喜欢呢？\n感谢室友 2024 年 1 月 1 日\n最近这段时间（半年左右）对诗词有不小的兴趣，尤其经常通过看阿帅的直播来长知识， 在成都那阵就自己在房间里看，去上海也是在自己房间里。就这次实习结束之后在宿舍放了台电脑， 这下大部分时候是下班回去在宿舍里看，因为舍友也经常在桌子上用电脑， 所以很多时候我外放的直播或者视频他也会听着，时不时互动一下。\n为什么我会选择外放呢？其实我也想过也观察过，我舍友这个人呢比较直， 一般想什么就会说什么，说实话大部分时候和他聊天也会聊不到一块去， 经常就是话不投机半句多。这种性格呢其实适合讨论一些专门的问题， 不管是专业方面还是诗词方面，讨论问题就是讨论问题，他不会想其他的方面， 专注于这个问题本身了。而且感觉他对诗词也是有一些兴趣的， 可能也不算是兴趣吧，至少不讨厌它，所以遇到想不起来的诗词问他， 还是讨论一些历史背景都是挺有趣的，感觉找到了他的“正确使用方式”。\n还有我发现，有人愿意陪伴你一起看，比你自己看更加有趣， 而且也会帮助你坚持看下去。可惜，光阴似箭， 还有半年就要毕业了，我却刚刚发现这一点。\n感谢姐夫 在我刚上初中的时候，我姐毕业在青岛差不多稳定了下来，于是我放假便经常去青岛找她玩。 不久，我姐姐与我姐夫相识，姐夫对我不错，除了请我吃喝玩乐以外， 我现在想起仍然感慨万分的是：他帮助我建立厚脸皮、外向的性格。\n其实在此之前我是一个非常内向的人，也是大家口中的乖孩子， 跟圆滑、变通这些词毫无关系，而每当我在青岛的时候，我姐夫便以身作则， 给我展示一个小老板是如何圆滑处事，偶尔也让我开口去和外人交流。 我始终觉得就是这一段段时间，一件件事的影响和磨练，使我现在变得不那么自卑和内向。 面向陌生人也能大大方方的交流，起码不使人尴尬吧。\n这个点我的父母，甚至我的姐姐应该很难观察到，他们估计觉得姐夫就是带我玩而已， 而我自己将永远铭记在心。\n胶片风格摄影爆火 2023 年 08 月 20 日\n富士的价格为什么被炒的越来越高？如果单说是外观，那尼康的 zfc、索尼、佳能的一些微单并不输给他很多， 我觉得其中有一个很重要的原因就是富士的胶片模拟风格。\n作为一个程序员，我当然知道这些都是软件层面的东西， 其他厂家如果想做是完全可以做的，可能他们对这块也没什么兴趣。不得不承认富士可能在这方面做了一些 功夫，很可能并不单单只是颜色调整而已，它对于高光部分有更加细致的处理。\n今天主要想说的是为什么这种古老的风格会再次风靡？，如今数码时代的进步使得一张照片的清晰度、还原真实诚程度飙升， 为何还要去追求这种模糊与做旧呢？这是审美的倒退吗？\n我觉得，我们对美的认识或者说定义并不是随着科技的进步而进步的，有一些东西是不需要创新或者说无法进行创新的， 老的、旧的并不一定就差于现代的，衡量美的标准可能就是如此。\n那么我就想，其他东西是否也会这样呢？是否在过了几十年几百年的发展之后，我们回过头来再看，还不如原来固有的。 我想中华文化就在这之列，我们盲目的学习西方追求自由、绝对的平等，我相信时间会证明这不是适合中国人的社会风气。\n将欲取之，必先予之 这句话出自老子《道德经》，说是你想要从别人那里得到些什么，必须先给予别人些什么。 可能单看这句话不容易理解，结合最近看到的一些事情：\n 田间小路自己的儿子与一个卖货商人相逢，谁也不肯让谁，恰巧你儿子买菜回来急等着用， 此时你看到这一幕应该怎么做？你跟商人说：大哥我真的有急事，能不能麻烦你先下到田地里躲避一下， 让我儿子先过去。商人大哥果断拒绝并说凭什么。此时你的正确做法是：首先亲自下到田里， 跟商人说自己确实有事，让他先把货物放到自己肩膀上，让自己的儿子先过去，一定不会弄脏货物。 此时商人自己也感到羞愧，让你的儿子先过去了。 银行里，或者某个办事处，一份资料需要家人签字，恰好家人不在身旁。 如果你问工作人员：必须本人签字吗？他一定会告诉你是的。 正确的做法应该是拿着资料去一个看不见的地方，自己把名字签上， 不必多说多问。 疫情时，有个 120 急救车正在小区里救治某个病人，恰好另一个男士过来说： 你们有 AED 吗？我的母亲急需，能否借给我？医生指指后面说：有是有， 但是按照规定不能外接。对话就僵持在这，正确的做法应该是，既然医生已经指明了位置， 先夺到手再说，医生告诉你在哪里就等于是告诉了你应该 怎么办。  所以这句话的意思是：求人办事可以，但你不能让别人承担一些后果，这种情况需要你主动站出来承担。\n","date":"2023-12-17T17:19:44+08:00","permalink":"https://wangloo.github.io/posts/thinking/growth/","section":"posts","tags":["Thinking"],"title":"一些胡思乱想"},{"categories":["Thinking"],"contents":"零零碎碎的开发笔记，如果思考比较多应该写成单独的博文。\n6.828 还能这么拷贝代码 将一段汇编代码从一个地址拷贝到另一个地址，你会怎么做？\n我能想到的是利用链接脚本，将该段代码限定在某个段里，然后利用变量来定位代码所在的地址，执行拷贝。\ninit.c的boot_aps()提供了一种新的思路：在代码的前后定义一个全局变量，就能在外面访问到代码的地址和范围了。\n转换函数的一种写法 我们经常会用到两种指代之间的转换，比如用id找到结构体指针（JOS中的envid2env），你会怎么设置函数的参数和返回值？\n我以前只能想到：\nstruct Env *envid2env(envid_t envid) 正常情况下返回转换完成的结构体指针，否则返回NULL。\n然而，JOS提供了一种别样的实现方式：\nint envid2env(envid_t envid, struct Env **env_store, bool checkperm) { struct Env *e; // If envid is zero, return the current environment. \tif (envid == 0) { *env_store = curenv; return 0; } e = \u0026amp;envs[ENVX(envid)]; if (e-\u0026gt;env_status == ENV_FREE || e-\u0026gt;env_id != envid) { *env_store = 0; return -E_BAD_ENV; } if (checkperm \u0026amp;\u0026amp; e != curenv \u0026amp;\u0026amp; e-\u0026gt;env_parent_id != curenv-\u0026gt;env_id) { *env_store = 0; return -E_BAD_ENV; } *env_store = e; return 0; } 外面传入一个指针的地址（无需申请空间），是传出参数。这样的好处是空出一个返回地址，可以用来表示多种出错的类型。\nspring OS 2023-07-01 如果kernel也用低地址， 其实是不行的，因为这样在切换到用户 进程的时候，需要切页表对吧。 但是切换之后用户进程的ttbr是 没有内核的页面映射的。 它们又都用了用一个页表。\n所以说看来是还是需要用两个页表实现起来比较方便些， 让内核用ttbr1，即映射在高地址。 做法是：\n 首先boot阶段的代码是要在低地址的，因为此时没有开mmu（用uboot+PIC就没有这个顾虑）。 在boot代码中，mmu开启前需要建立映射，除了映射内核的代码段、数据段之外。 还有一个很重要的是恒等映射ttbr0，需要将boot代码建立恒等映射。 等到mmu启动后，访问的还是boot的代码，这时恒等映射生效。 但是当跳转到内核的代码时， 因为VMA是高地址， 所以用ttbr1，之前就映射好了。可以直接访问的。  2023-07-02 task_init():\ntask-\u0026gt;affinity = -1\n如果不是内核任务, 默认情况下task-\u0026gt;state = TASK_STATE_WAIT_EVENT, 在create hook中进行的 内核任务的话, task-\u0026gt;state = TASK_STATE_SUSPEND, 在task_init()中进行的\n除了idle外, 其他task的task-\u0026gt;cpu = -1, 在task_init()中进行的\nwakeup_common(): task-\u0026gt;task = TASK_STATE_WAKING task-\u0026gt;pend_stat = pend_state\ntask_ready():\n 更新task-\u0026gt;cpu, 如果初始值是-1, 更新为NR_CPUS-1, 这是TBD, 否则是affinity 然后根据当前cpu是否为task-\u0026gt;cpu, 做出判断:  如果是, 那么直接调用add_task_to_ready_list() 将任务加到readylist中 否则,将任务加到new_list, 而不是readylist, 然后发送核间中断通知task-\u0026gt;cpu    sched_tick_handler():\n 当前的task-\u0026gt;ti.flags | __TIF_TICK_EXHAUST 当前的task-\u0026gt;ti.flags | __TIF_NEED_RESCHED  irqwork_handler():\n 遍历当前pcpu-\u0026gt;next_list:  将task-\u0026gt;state = TASK_STATE_READY task加入pcpu的readylist    ","date":"2023-12-17T17:19:44+08:00","permalink":"https://wangloo.github.io/posts/thinking/dev_note/","section":"posts","tags":["Thinking"],"title":"杂乱的开发日记"},{"categories":["DevTools"],"contents":"Task.json Vscode中，可以为编译、打包等过程创建自动化任务，避免每次手动敲一些命令。 在我看来，Vscode Task就像是一个强大的、与Vscode联动的Shell脚本。\n创建一个Task 创建一个Task很简答，Terminal-Configure Tasks， 然后根据引导就可以创建一个默认的task，对他进行配置的文件是workspace/.vscode/task.json。\n展示一下我刚刚创建的一个编译并执行单元测试的任务，关键的参数是label也就是任务的名字， type除了shell不知道还有啥，command就是该任务会执行的shell命令。 更多的参数下面会介绍。\n{ // See https://go.microsoft.com/fwlink/?LinkId=733558  // for the documentation about the tasks.json format  \u0026#34;version\u0026#34;: \u0026#34;2.0.0\u0026#34;, \u0026#34;tasks\u0026#34;: [ { \u0026#34;label\u0026#34;: \u0026#34;build-ut\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;shell\u0026#34;, \u0026#34;command\u0026#34;: \u0026#34;bash tools/vscode_build_ut.sh\u0026#34;, \u0026#34;presentation\u0026#34;: { \u0026#34;echo\u0026#34;: true, \u0026#34;reveal\u0026#34;: \u0026#34;always\u0026#34;, \u0026#34;focus\u0026#34;: true, \u0026#34;panel\u0026#34;: \u0026#34;shared\u0026#34;, \u0026#34;showReuseMessage\u0026#34;: true, \u0026#34;clear\u0026#34;: false }, \u0026#34;problemMatcher\u0026#34;: [], } ] } 支持的参数 支持的参数很多，我主要介绍几个，Vscode的官方文档说的非常通俗易懂，修改参数时最好参考一下。\n label: 此任务的名字 type：类型  shell：作为shell命令执行 process：创建一个新进程执行   command：任务实际执行的命令 group：任务的分组 presentation：定义如何处理Task的输出  reveal：终端是否显示 echo：任务输出是否到终端中 focus：任务执行时是否聚焦到终端 showReuseMessage：是否显示最后的提示信息 clear：任务运行前是否清理终端输出   options：定义当前目录和一些环境变量 runOptions：定义任务何时运行以及如何运行 problemMatcher: 自定义错误匹配机制，这个应该很强大，我这里单纯是为了运行时不需要再选一次所以用了一个默认值。具体怎么用可以参考: https://code.visualstudio.com/docs/editor/tasks#_defining-a-problem-matcher  Launch.json 早就看Vscode左边的\u0026quot;Run and Debug\u0026quot;栏不爽了，呆在那也没啥用。 其实在实习的时候看过他用Vscode调试Qemu guest， 抽时间把这个给研究了一下，感觉比直接执行gdb方便一些。\nLaunch.json就是定义一些运行与Debug的动作，结合Vscode的界面， 比Gdb Tui还是好看了一些。这里列出我当前项目所使用的配置项。\n 注意：如果同时在项目根目录有.gitinit文件，可能会导致错误， 详细: QEMU: Terminated via GDBstub error\n { // Use IntelliSense to learn about possible attributes.  // Hover to view descriptions of existing attributes.  // For more information, visit: https://go.microsoft.com/fwlink/?linkid=830387  \u0026#34;version\u0026#34;: \u0026#34;0.2.0\u0026#34;, \u0026#34;configurations\u0026#34;: [ { \u0026#34;name\u0026#34;: \u0026#34;qemu-kernel\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;cppdbg\u0026#34;, \u0026#34;request\u0026#34;: \u0026#34;launch\u0026#34;, \u0026#34;miDebuggerPath\u0026#34;: \u0026#34;/usr/bin/gdb-multiarch\u0026#34;, \u0026#34;miDebuggerServerAddress\u0026#34;: \u0026#34;localhost:1234\u0026#34;, \u0026#34;program\u0026#34;: \u0026#34;${workspaceFolder}/your/exec/file\u0026#34;, \u0026#34;cwd\u0026#34;: \u0026#34;${workspaceFolder}\u0026#34;, \u0026#34;MIMode\u0026#34;: \u0026#34;gdb\u0026#34;, \u0026#34;stopAtConnect\u0026#34;: true, } ] } ","date":"2023-12-17T15:25:12+08:00","permalink":"https://wangloo.github.io/posts/tools/vscode/task_launch/","section":"posts","tags":["tools"],"title":"Vscode task.json \u0026 launch.json"},{"categories":["Dwarf"],"contents":"前言 栈回溯是调试代码常用的功能之一，Gdb 中对应的命令是bt,info frame等。 这篇文件将介绍利用 Dwarf 生成的调试信息实现栈回溯的方法。\n原理 Dwarf v2 开始提供一种叫做 Call Frame Information（简称 CFI）的信息， 它存储在.debug_frame中，调试器可以通过解析这个 Section 完成栈回溯。 .debug_frame里的内容可以看做是一张二维表格，一列是 pc， 另一列是对于此 Pc 如何查找上一个 Frame。\nDemo 例如，对于以下的 C 代码和对应的汇编（通过object -S生成)， 汇编代码有一点长，但没关系我们不需要关注每一条汇编指令。 这段代码共有两个函数，main()和fibonacci()， 由 main 函数调用 fibonacci 来计算第 10 个 bibonacci 数。 目前暂时不需要看汇编。\n选择 fibonacci()作为例子的原因是模拟一个非叶子函数， 因为 Arm64 下对叶子函数可能不会生成正确的 CFI 信息， 因为这种情况不常见，所以我们先讨论普通的情况。 另外，我知道这个计算 fibonacci 数的算法不是最优的， 但是我们毕竟不是算法优化的主题，所以能够说明问题即可。\nint fiboncci(int n) { if (n \u0026lt;= 2) return 1; else return fiboncci(n-1) + fiboncci(n-2); } int main(void) { int result; result = fiboncci(10); return 0; } int fiboncci(int n) { 400594: a9bd7bfd stp x29, x30, [sp, #-48]! 400598: 910003fd mov x29, sp 40059c: f9000bf3 str x19, [sp, #16] 4005a0: b9002fe0 str w0, [sp, #44] if (n \u0026lt;= 2) 4005a4: b9402fe0 ldr w0, [sp, #44] 4005a8: 7100081f cmp w0, #0x2 4005ac: 5400006c b.gt 4005b8 \u0026lt;fiboncci+0x24\u0026gt; return 1; 4005b0: 52800020 mov w0, #0x1 // #1 4005b4: 14000009 b 4005d8 \u0026lt;fiboncci+0x44\u0026gt; else return fiboncci(n-1) + fiboncci(n-2); 4005b8: b9402fe0 ldr w0, [sp, #44] 4005bc: 51000400 sub w0, w0, #0x1 4005c0: 97fffff5 bl 400594 \u0026lt;fiboncci\u0026gt; 4005c4: 2a0003f3 mov w19, w0 4005c8: b9402fe0 ldr w0, [sp, #44] 4005cc: 51000800 sub w0, w0, #0x2 4005d0: 97fffff1 bl 400594 \u0026lt;fiboncci\u0026gt; 4005d4: 0b000260 add w0, w19, w0 } 4005d8: f9400bf3 ldr x19, [sp, #16] 4005dc: a8c37bfd ldp x29, x30, [sp], #48 4005e0: d65f03c0 ret 00000000004005e4 \u0026lt;main\u0026gt;: int main(void) { 4005e4: a9be7bfd stp x29, x30, [sp, #-32]! 4005e8: 910003fd mov x29, sp int result; result = fiboncci(10); 4005ec: 52800140 mov w0, #0xa // #10 4005f0: 97ffffe9 bl 400594 \u0026lt;fiboncci\u0026gt; 4005f4: b9001fe0 str w0, [sp, #28] return 0; 4005f8: 52800000 mov w0, #0x0 // #0 } 4005fc: a8c27bfd ldp x29, x30, [sp], #32 400600: d65f03c0 ret 400604: d503201f nop 400608: d503201f nop 40060c: d503201f nop 因为在编译时添加了-g选项，所以 Gcc 默认会生成.debug_frame， 让我们来看看里面的内容是什么。\naarch64-none-linux-gnu-objdump --dwarf=frames-interp frame 00000088 0000000000000020 0000008c FDE cie=00000000 pc=0000000000400594..00000000004005e4 LOC CFA x19 x29 ra 0000000000400594 sp+0 u u u 0000000000400598 sp+48 u c-48 c-40 00000000004005a0 sp+48 c-32 c-48 c-40 00000000004005e0 sp+0 u u u 000000ac 0000000000000020 000000b0 FDE cie=00000000 pc=00000000004005e4..0000000000400604 LOC CFA x29 ra 00000000004005e4 sp+0 u u 00000000004005e8 sp+32 c-32 c-24 0000000000400600 sp+0 u u 这是经过解释之后的.debug_frame，在实际存储的时候可能通过压缩。 解释之后就明显展示出二维表格的样貌。上述代码里共有两段表， 第一段对应我们在fibonacci()中如何查找上一个 Frame， 第二段则是main()函数中的计算规则。\n暂时到这里其实就 Ok 了，你只需要知道它起码看起来像是一个二维表格的结构， 我们下面再说它到底是怎么帮助实现栈回溯的。\n解剖 .debug_frmae CIE \u0026amp; FDE 上面不是说表格中存的是栈回溯的规则吗，这张大表可以按照函数的界限来划分， FDE 就是对应某个函数的计算规则。一些函数共同的部分提取成一个 CIE。\n栈回溯的过程 还是以上面的代码为例，假设我们位于 Fibonacci()中的4005a4地址上， 此时我们要进行栈回溯，找到 main()中的调用点。\n首先，在第一个 FDE 里找到当前地址4005a4的计算规则， 因为连续的一段地址可能计算规则不变，可以将他们存成一条，节约空间。\n00000088 0000000000000020 0000008c FDE cie=00000000 pc=0000000000400594..00000000004005e4 LOC CFA x19 x29 ra 0000000000400594 sp+0 u u u 0000000000400598 sp+48 u c-48 c-40 00000000004005a0 sp+48 c-32 c-48 c-40 00000000004005e0 sp+0 u u u 第一列 LOC 是每个规则相同的连续地址块的起始地址，由此得到4005a4需要参考第三行规则。\n再看到第二列，CFA 的含义是 caller 的 sp， 第三列ra 的含义是返回地址(Returen address)， 表格中的值 u 代表不变，c 代表 CFA。\n所以说，由表格中的数据可知，caller'sp=sp+48，而返回地址就存储在cfa-40的地址上， 这是一个栈的地址，由于函数调用不会破坏之前栈的内容，所以可以放心取出 ra，也就是返回地址。 这就找到了 main 函数中的调用点，如果 main 之上还有 caller 的话，可以继续查 main 的 FDE 来寻找。\n原理 其实，这种方法就是利用了每次进入函数时时会在栈上保存返回地址 x30， 基于 Fp 的栈回溯方法也是这样做，Fp 是通过记录每个栈的栈底， 而每次保存 x30 的位置相对于栈底都是固定的，所以知道栈底也就能取出 x30。\n.debug_frame可以看作将每次函数调用的栈底存在本地成为一张表， 这就省了一个通用寄存器。\n关于 Caller-saved Regs 注意  上面说到，用.debug_frame实现栈回溯时，起点不能是叶子函数。 叶子函数不会调用任何函数，所以 Arm64 会优化而不保存 Lr 在栈上（反正你也不调用其他函数，x30 不会被破坏）。 我们的方法就不奏效，可以验证叶子函数的 FDE 是空的。  ","date":"2023-12-16T15:51:49+08:00","permalink":"https://wangloo.github.io/posts/binary/dwarf/frame/","section":"posts","tags":["Dwarf"],"title":"Dwarf: Stack Unwinding"},{"categories":["Binary"],"contents":"# 输出 section header table readelf -S xxx.elf # 输出 program header table readelf -l xxx.elf # 输出 ELF header readelf -h xxx.elf # 输出 elf header，section header table，program header table(常用） readelf -e xxx.elf # 输出Elf中的所有符号(基于符号表非调试信息) nm xxx.elf readelf -s xxx.elf # detailed # 打印某个section的内容 readelf -p .strtab xxx.elf # 判断编译时有没有使用-g readelf -n bin # 输出源码和汇编 objdump -DS your_binary # 仅输出汇编, 所有汇编, 不仅仅是代码相关 objdump -D your_binary ","date":"2023-12-14T13:21:27+08:00","permalink":"https://wangloo.github.io/posts/binary/gnu_binutils/","section":"posts","tags":["Binary"],"title":"GNU 二进制工具集"},{"categories":["C"],"contents":"背景 今天在写 C 代码时，遇到一个问题，我忘记 include 头文件而调用某个函数， 一般情况下在编译时会报警告 ⚠，然后也会链接成功，所以我这次就没管它因为只是暂时测试一下。 然而令我费解的是函数的执行结果异常，检查汇编后发现，我声明的函数返回 u64 类型， 而编译后的代码在返回前裁切成了 32 位，就是这里导致的错误！\n这与我之前的理解不同，我以为要么就链接找不到符号，要不就成功链接， 为什么会有这种返回类型识别错误呢？\n思考 我忽然想起，会不会是因为编译器将返回值识别为了默认的 int 类型， 进而，我的猜想是：\n 链接时能用符号名找到符号的地址，所以能成功调用 但因为没有参数和返回类型的说明（没有 include），所以导致类型出错  简单验证之后，确实我的猜想是正确的，我调用时多传入一个参数， 还是能够成功编译，汇编只是把参数寄存器赋值，内部用不用得到无法判定。 返回类型则统一认定为默认的int类型。\n由此，我又产生了一个想法，既然C语言只使用符号名作为匹配的标准， 那么必然不支持同名函数（参数、返回类型不同）。然而C++明确是支持的， 那么C与C++的符号管理有什么不同吗？\n进一步验证 我写了内容相同的C和C++两个文件来尝试解答问题：\n// Same code in demo.c/demo.cpp void func(int a, int b) { func(b, a); } 对他们进行编译，查看大小仅相差8字节，猜测是符号的管理有所不同。\n$ ls -al total 8 drwxr-xr-x 1 loo loo 512 Dec 14 14:09 . drwxr-xr-x 1 loo loo 512 Dec 14 12:03 .. -rw-r--r-- 1 loo loo 42 Dec 14 14:09 demo.c -rw-r--r-- 1 loo loo 1480 Dec 14 12:04 demo.c.o -rw-r--r-- 1 loo loo 42 Dec 14 12:04 demo.cpp -rw-r--r-- 1 loo loo 1488 Dec 14 12:04 demo.cpp.o 进一步查看section的差别，忽略地址的差异，其实差异就在.shstrtab的大小， C++编译处的目标文件多了几个字节，而.shstrtab我们给的样例中也就是存符号func。\n$ diff \u0026lt;(readelf -S demo.c.o) \u0026lt;(readelf -S demo.cpp.o) 1c1 \u0026lt; There are 13 section headers, starting at offset 0x288: --- \u0026gt; There are 13 section headers, starting at offset 0x290: 10c10 \u0026lt; [ 2] .rela.text RELA 0000000000000000 000001e8 --- \u0026gt; [ 2] .rela.text RELA 0000000000000000 000001f0 24c24 \u0026lt; [ 9] .rela.eh_frame RELA 0000000000000000 00000200 --- \u0026gt; [ 9] .rela.eh_frame RELA 0000000000000000 00000208 29,30c29,30 \u0026lt; 000000000000000d 0000000000000000 0 0 1 \u0026lt; [12] .shstrtab STRTAB 0000000000000000 00000218 --- \u0026gt; 0000000000000014 0000000000000000 0 0 1 \u0026gt; [12] .shstrtab STRTAB 0000000000000000 00000220 继续查看.shstrtab的内容，就能得到最终的结果，确实C语言只存储符号名， 而C++则既有符号名，也有参数和返回值类型。\n$ readelf -p .strtab demo.c.o String dump of section \u0026#39;.strtab\u0026#39;: [ 1] demo.c [ 8] func $ readelf -p .strtab demo.cpp.o String dump of section \u0026#39;.strtab\u0026#39;: [ 1] demo.cpp [ a] _Z4funcii  通过nm命令也一样能够查看\n$ nm demo.cpp.o 0000000000000000 T _Z4funcii  总结 确实C语言只存储符号名，而C++则既有符号名，也有参数和返回值类型。 这是C++能够支持重载的本质。 有时我们在写C++时，如果找不到函数会报一个乱码的函数名， 其实也就是这种经过压缩存储的符号。\n","date":"2023-12-14T12:21:27+08:00","permalink":"https://wangloo.github.io/posts/c/linker_symbol/","section":"posts","tags":["C"],"title":"C/C++ 符号管理的区别"},{"categories":["Thinking"],"contents":"起因：今天与一位同学一起尝试去配置Linux静态IP，这中间有不少坎坷，想简单把思考的过程写下来， 复盘一下是不是应该有可以更快的定位到问题并解决的方案。\n提出问题 Cl同学想要达到启动Linux后自动设置某个静态Ip的效果， 在我的理解里这并不是一件很复杂的事。\n他给我的想法是在Kernel Command Line参数中指定Ip， 我之前没有看到过这种方式配网，但是网上搜了一下确实有这样的例子。 所以他目前已经完成的是:\n Linux是通过Uboot起的，要增加Linux Command Line， 可能是在Uboot的bootargs中添加。 但是他在修改完bootargs并重启的时候，发现变量没有成功赋值， 即使已经成功saveenv。所以就邀请我和他一起讨论。\n 动手实践 了解到问题之后，我先说出了我的想法：\n 配置静态Ip这个事其实我第一时间想到的是以前修改/etc/network/interfaces文件的方式 但是我愿意陪他先看下为什么命令行参数没有配置上去  这是两条路，因为他的系统里没有真正的文件系统，而是initrd， 所以我提出的方案需要去解包inird的压缩文件，还是尽量先去研究为什么命令行参数没有配置上去。\n为什么CMDLINE没有配置上去呢? 首先它说bootargs没有保存成功，这个我也不知道为啥， 可以先不管，即便在每次启动之前在Uboot里设置了Bootargs， 他说在启动之后Kernel的打印也没有输出配置的项目。\nUboot中Bootargs设置的值是和Kernel Command Line配套吗？ 这个我反正是不太确定。\n好，那能不能通过别的方式来设置CmdLine呢？ 我们搜索找到了两种方式：\n Dts中 Menuconfig中修改  没有尝试Menuconfig是因为他说“目前Menuconfig配置的CmdLine为空， 但是实际Kernel启动后又是有值输出的，那么说明肯定是其他的地方有添加。” 对于这句话我也表示认同，Menuconfig里给的说明是：“默认配置”， 所以即便添加了也无法保证会不会被其他的给冲刷掉。所以，一个根本问题就是： CmdLine配置的顺序，或者说优先级是什么？\n先去Dts里改改试试吧，找到了一个chosen结点有关于bootargs的配置， 不管怎么样改了一下，发现并没有生效，和最终Kernel输出的对不上。\n所以，看起来修改CmdLine这条路要失败了，只能去修改initrd试试。\n修改Initrd达到目的 initrd是打包好的，用的是cpio+lz4的方式。要修改首先要把他解开， 解开到还好说，网上能搜得到命令。 但是重新压缩回去问题很多，前期我就想到了我在华为实习时期遇到的类似的问题， 压缩的算法不对、打包的版本差异都会导致Kernel无法解析重新打包的initrd而panic。\n实际也遇到了这个问题，但是这有个小插曲：即便是换回原来的initrd也还是panic。 最终破案是因为需要make clean之后重新make，猜测可能是用了什么中间文件。 不得不感慨Linux Kernel的构建还是相当复杂的。\n问题来了：修改/etc/network/interfaces并没有改变静态Ip， 这就使我产生了疑惑，想着可以先在系统启动之后修改试试嘛， 执行ip down和ipup发现确实没有成功修改，这不禁让我想问为什么？\n此时，我们突然想到一个问题，既然shell命令能成功修改Ip， 那么就在启动时增加一个脚本去执行设置Ip的行动，不就行了吗？\n确实是可以的，所以暂时先不管为什么interfaces不生效。 那就修改有关于/etc/init.d和/etc/inittab相关的知识了， 这一部分我就没参与了，网上的资料的非常全，最终是成功达到目的。\n感慨 虽然成功达到了目的，但是消耗了4个小时左右的时间，我觉得这件事并不应该这么复杂。 主要原因是Linux可以配置网络的方式太多了，以至于像我们这种不是非常熟悉的人一时间不知道如何下手。\n另外，其实这中间还有一些问题没有去解决，可能以后有时间再搞一个完整的qemu-liunx环境去测试一下吧💭。\n","date":"2023-12-08T17:19:44+08:00","permalink":"https://wangloo.github.io/posts/thinking/cfg_linux_ip/","section":"posts","tags":["Thinking"],"title":"Thinking: Config Linux Network"},{"categories":["C"],"contents":"在设计一个消息传递类似的子系统时，消息经常需要各种参数， 通常消息的个数和类型是根据消息自身的类型决定的。\nvoid handle_open(..., int flags, int mode); void handle_read(..., size_t len, int offset); // ... 有的消息/命令参数比较多，不想写这么长的参数那就把这些参数封装到struct里\nstruct arg_open { int flag; int mode; }; struct arg_read { size_t len; int offset; }; // 这里用结构体还是结构体指针都可以，不是重点! void handle_open(..., struct arg_open *arg); void handle_read(..., struct arg_read *arg); 这种方法有什么缺点呢?\n 不具有通用性；无法用函数指针来实现进一步抽象，即跳表。 \u0026hellip;（暂时没想到）  所以说，一个更好的抽象方式来了，将所有的参数利用union放到一个结构体中。\nstruct proto_open { int flag; int mode; }; struct proto_read { size_t len; int offset; }; // GOOD DESIGN struct proto { // ... 可能有公共的参数, 例如ID  union { struct proto_open open; struct proto_read read; // ...  }; }; // 因为每个类型的消息/命令都有自己的处理函数 // 所以各个函数知道自己应该从那个union成员里取 void handle_open(..., struct proto *proto) { int flag, mode; flag = proto-\u0026gt;open.flags; mode = proto-\u0026gt;open.mode; } void handle_read(..., struct proto *proto) {...} 这样做的最大好处就是可以用跳表来设计了，减少了代码量，增加了易读性！！\n","date":"2023-11-26T16:21:27+08:00","permalink":"https://wangloo.github.io/posts/c/good_design_proto/","section":"posts","tags":["C"],"title":"Good Design: 抽象消息参数"},{"categories":["C"],"contents":"字节序与比特序 字节序又称大小段，网络中传输的是大端，在CPU上处理的一般是小端。\n字节序与比特序转换 字节序转换 比特序转换 两种方法，一种直接法，另外有一种优化的技巧。\n（1）\n// Bit reverse unsigned char bit_reverse(unsigned char x) { unsigned char newx = 0; for (int i = 0; i \u0026lt; 8; i++) { newx |= (((x \u0026gt;\u0026gt; i) \u0026amp; 1) \u0026lt;\u0026lt; (7-i)); } return newx; } (2) https://mp.weixin.qq.com/s/KNUH_RmIhUHhuSZLSmN4LQ\n// Bit reverse(faster) // 碟式交换法 unsigned char bit_reverse_faster(unsigned char x) { x = (x\u0026lt;\u0026lt;4) | (x\u0026gt;\u0026gt;4); // [ 5678 1234 ]  x = ((x\u0026lt;\u0026lt;2)\u0026amp;0xcc) | ((x\u0026gt;\u0026gt;2)\u0026amp;0x33); // [ 78 56 34 12 ]  x = ((x\u0026lt;\u0026lt;1)\u0026amp;0xaa) | ((x\u0026gt;\u0026gt;1)\u0026amp;0x55); // [ 8 7 6 5 4 3 2 1 ]  return x; } 测试工具函数:\nint to_binary_str(unsigned long val, char *bin_str, int *len) { char *p, *q; int cnt = 0; while (val) { char tmp = val \u0026amp; 1; bin_str[cnt++] = tmp+\u0026#39;0\u0026#39;; val = val \u0026gt;\u0026gt; 1; } p = bin_str, q = bin_str+cnt-1; while (p \u0026lt; q) { char tmp = *p; *p = *q; *q = tmp; p++, q--; } bin_str[cnt] = 0; *len = cnt; return 0; } int main(void) { char bin[65]; int len; unsigned char x = 0b11110000; unsigned char y = 0b10101010; to_binary_str(bit_reverse(x), bin, \u0026amp;len); printf(\u0026#34;bin: %s\\n\u0026#34;, bin); to_binary_str(bit_reverse(y), bin, \u0026amp;len); printf(\u0026#34;bin: %s\\n\u0026#34;, bin); assert(bit_reverse(x) == bit_reverse_faster(x)); assert(bit_reverse(y) == bit_reverse_faster(y)); return 0; } ","date":"2023-11-25T16:21:27+08:00","permalink":"https://wangloo.github.io/posts/c/byte_bit_order/","section":"posts","tags":["C"],"title":"Byte/Bit Order"},{"categories":["Binary"],"contents":"分析Elf文件 映射 Segments 对栈进行预处理  int main(int argc, char **argv, char **envp) {...} 见到一个main函数的定义，你是否考虑过:\n main函数使用这些参数的作用分别是什么? Elf运行前，他们是如何被正确放置的? 我们又如何正确的访问?   内核中的Elf加载器还需要将辅助向量和其他信息(argc,argv,envp)一起放在栈上。 初始化后，进程的堆栈如下所示(64位架构下):\nposition content size (bytes) + comment ------------------------------------------------------------------------ [ free used for process ] stack pointer -\u0026gt; [ argc = number of args ] 8 [ argv[0] (pointer) ] 8 (program name) [ argv[1] (pointer) ] 8 [ argv[..] (pointer) ] 8 * x [ argv[n - 1] (pointer) ] 8 [ argv[n] (pointer) ] 8 (= NULL) [ envp[0] (pointer) ] 8 [ envp[1] (pointer) ] 8 [ envp[..] (pointer) ] 8 [ envp[term] (pointer) ] 8 (= NULL) [ auxv[0] (Elf64_auxv_t) ] 16 [ auxv[1] (Elf64_auxv_t) ] 16 [ auxv[..] (Elf64_auxv_t) ] 16 [ auxv[term] (Elf64_auxv_t) ] 16 (= AT_NULL vector) [ padding ] 0 - 16 [ argument ASCIIZ strings ] \u0026gt;= 0 [ environment ASCIIZ str. ] \u0026gt;= 0 (0xbffffffc) [ end marker ] 8 (= NULL) (0xc0000000) \u0026lt; bottom of stack \u0026gt; 0 (virtual) ------------------------------------------------------------------------ 在这之上，我们最常用的是argc和argv，所以还是需要介绍一下envp和auxv。\nEnvironment 环境变量的结构和argv相同，都是一些字符串指针的方式去访问。 只不过没有用于表示数量的\u0026quot;envc\u0026quot;，而是以NULL表示结尾。\nAuxiliary Vectors Auxiliary Vectors 简称Auxv, OS内核在加载Elf时, 可以将一些键值对类型的数值传递给用户态程序， 即进程启动时内核向用户态传递信息的一种方式。\nAuxv的存储结构不是argv和envp那样的间接形式，而是顺序存一些Elf64_auxv_t结构体，在Linux上，结构体的定义在/usr/include/elf.h中。\ntypedef struct { uint64_t a_type; /* Entry type */ uint64_t a_val; } Elf64_auxv_t; 可以看到就是一个类型和数值，直接就能存下，不支持字符串的形式。\n我们可以在Linux上测试Auxv，在启动一个用户程序之前加上LD_SHOW_AUXV=1, 可以打印出所有的Auxv。\n~ $ LD_SHOW_AUXV=1 /bin/ls AT_SYSINFO_EHDR: 0x7ffc3b3de000 AT_HWCAP: 1f8bfbff AT_PAGESZ: 4096 AT_CLKTCK: 100 AT_PHDR: 0x55a318711040 AT_PHENT: 56 AT_PHNUM: 13 AT_BASE: 0x7f0f5ac91000 AT_FLAGS: 0x0 AT_ENTRY: 0x55a3187177d0 AT_UID: 1000 AT_EUID: 1000 AT_GID: 1000 AT_EGID: 1000 AT_SECURE: 0 AT_RANDOM: 0x7ffc3b272ab9 AT_HWCAP2: 0x2 AT_EXECFN: /bin/ls AT_PLATFORM: x86_64 一般来说，普通的用户程序不需要获取内核的信息，但对于一些位于用户态和内核态之间的、 交互非常紧密的用户态程序而言则比较有用。比如说解释器、init进程、微内核OS中的root-service等等。\n测试你的Elf Loader 在Elf中输出这些辅助信息，看是否能顺利读到。这里分别给出（1）只打印Auxv（2）打印所有\n#include \u0026lt;stdio.h\u0026gt;#include \u0026lt;elf.h\u0026gt; main(int argc, char* argv[], char* envp[]) { Elf32_auxv_t *auxv; while (*envp++ != NULL); /* from stack diagram above: *envp = NULL marks end of envp */ /* auxv-\u0026gt;a_type = AT_NULL marks the end of auxv */ for (auxv = (Elf32_auxv_t *)envp; auxv-\u0026gt;a_type != AT_NULL; auxv++) { if (auxv-\u0026gt;a_type == AT_SYSINFO) printf(\u0026#34;AT_SYSINFO is: 0x%x\\n\u0026#34;, auxv-\u0026gt;a_un.a_val); } } int main(int argc, char *argv[], char *envp[]) { int i; // Print all arguements  printf(\u0026#34;argc: %d\\n\u0026#34;, argc); for (i = 0; i \u0026lt; argc; i++) { printf(\u0026#34;argv[%d]: %s\\n\u0026#34;, i, argv[i]); } // Print all enviroment variables  for (i = 0; envp[i]; i++) { printf(\u0026#34;env[%d]: %s\\n\u0026#34;, i, envp[i]); } // Print all auxv  Elf64_auxv_t *auxv = (Elf64_auxv_t *)(envp+i+1); for (; auxv-\u0026gt;a_type != AT_NULL; auxv++) { if (auxv-\u0026gt;a_type == AT_PAGESZ) { printf(\u0026#34;AT_PAGESZ: 0x%lx\\n\u0026#34;, auxv-\u0026gt;a_un.a_val); } } } 设置User Context Reference  About ELF Auxiliary Vectors  ","date":"2023-11-24T16:21:27+08:00","permalink":"https://wangloo.github.io/posts/binary/elf_load/","section":"posts","tags":["Binary"],"title":"Elf 加载器的工作流程"},{"categories":["DevTools"],"contents":"Vim插件YouCompleteMe国内安装  Update 2023/11/23: vim下现在我不用YCM了，换成Coc.nvim来进行代码补全。 不过在我看来其实没有特别明显的优势，所以YCM的配置注意事项还是留在这吧。\n YCM 插件对 python, vim 的版本均有要求。\n下载 可以使用 vim-plug 等工具下载, 也可以下载源码然后拷贝到.vim目录下\n编译 编译用到 python3, 这里是问题最多的一步\n# 编译并添加对C的提示支持 python3 install.py --clangd-completer --verbose Searching Python 3.8 libraries... ... Downloading Clangd from https://github.com/ycm-core/llvm/releases/download/13.0.0/clangd-13.0.0-x86_64-unknown-linux-gnu.tar.bz2... 使用--clangd-completer参数时, 脚本会去下载 clangd-14.0.0-x86_64-unknown-linux-gnu.tar.bz2 文件, 比较慢. 也可以提前根据提示的网站自己手动下载压缩包.\n下载完成后, 放到本地目录下:\n:~/.vim/plugged/YouCompleteMe/third_party/ycmd/third_party/clangd/cache$ ls clangd-14.0.0-x86_64-unknown-linux-gnu.tar.bz2 还需对脚本YouCompleteMe/third_party/ycmd/build.py进行修改, 防止重新下载.\ndef DownloadClangd( printer ): ... MakeCleanDirectory( CLANGD_OUTPUT_DIR ) if not p.exists( CLANGD_CACHE_DIR ): os.makedirs( CLANGD_CACHE_DIR ) # 注释下面的语句 # elif p.exists( file_name ) and not CheckFileIntegrity( file_name, check_sum ): # printer( \u0026#39;Cached Clangd archive does not match checksum. Removing...\u0026#39; ) # os.remove( file_name ) if p.exists( file_name ): printer( f\u0026#39;Using cached Clangd: { file_name }\u0026#39; ) 配置 YCM 配合一个配置文件.ycm_c_c++_conf.py, YCM 搜索的位置在 vimrc 中指定:\nPlug \u0026#39;rdnetto/YCM-Generator\u0026#39;, { \u0026#39;branch\u0026#39;: \u0026#39;stable\u0026#39; }let g:ycm_global_ycm_extra_conf = \u0026#34;~/.ycm_c_c++_conf.py\u0026#34;其内容的 example:\nimport os import ycm_core flags = [ \u0026#39;-Wall\u0026#39;, \u0026#39;-Wextra\u0026#39;, # \u0026#39;-Werror\u0026#39;, \u0026#39;-Wno-long-long\u0026#39;, # \u0026#39;-Wno-variadic-macros\u0026#39;, \u0026#39;-fexceptions\u0026#39;, \u0026#39;-ferror-limit=10000\u0026#39;, \u0026#39;-DNDEBUG\u0026#39;, \u0026#39;-std=c99\u0026#39;, \u0026#39;-xc\u0026#39;, \u0026#39;-isystem/usr/include/\u0026#39;, ] SOURCE_EXTENSIONS = [ \u0026#39;.cpp\u0026#39;, \u0026#39;.cxx\u0026#39;, \u0026#39;.cc\u0026#39;, \u0026#39;.c\u0026#39;, ] def FlagsForFile( filename, **kwargs ): return { \u0026#39;flags\u0026#39;: flags, \u0026#39;do_cache\u0026#39;: True } 使用方式 🔻 对于C/C++来说, YCM的使用最好配合compilation database 来使用, 例如compiledb. 否则, 可能头文件的path识别出问题(stackoverflow).\n2022年2月13日我使用的compilation database生成工具从compiledb换成了bear, 因为bear更好的支持递归, 即有make -C的情况.\n需要的compilation database生成工具介绍: Compilation database — Sarcasm notebook\n","date":"2023-11-17T19:28:12+08:00","permalink":"https://wangloo.github.io/posts/tools/vim/ycm/","section":"posts","tags":["tools"],"title":"Vim-YouCompleteMe插件国内安装"},{"categories":["Operating System"],"contents":" 在进程的地址空间中，栈和堆直接夹着的区域为文件映射区。 它的空间是动态的，和堆空间一起实现动态内存的分配与释放。\n文件映射区中包含了一段段的虚拟内存区域（也称线性区），代码里标识符是struct vm_area_struct。其中包含文件映射和匿名映射。\n 匿名映射是malloc()的底层实现之一，当请求大块内存时，移动brk可能带来大碎片， 不如用匿名mmap()来的灵活。\n 下图就展示了一个进程地址空间中即存在文件映射，又存在匿名映射的情况：\n Linux 地址空间线性区组织形式 不只是文件映射区包含线性区，所有其他的区域（代码段、数据段等）都可以用线性区来描述， 统一进行维护。代码里用struct vm_area_struct描述一个线性区，其中重要的成员有:\n vm_mm(struct mm_struct *): 指向所属的地址空间描述符 vm_start(unsigned long): 此线性区的开始 vm_end(unsigned long): 下一个线性区的开始(此线性区结束地址+1） vm_next(struct vm_area_struct *): 指向进程线性区的 next vm_rb(struct rb_node): 此线性区对应红黑树中的节点  此线性区的大小就可以表示为: vm_end - vm_start.\n 双向链表和红黑树 进程虚拟内存空间中的所有 VMA 在内核中有两种组织形式：一种是双向链表，用于高效的遍历进程 VMA，这个 VMA 双向链表是有顺序的，所有 VMA 节点在双向链表中的排列顺序是按照虚拟内存低地址到高地址进行的。 第一个区在mm_struct-\u0026gt;mmap, 下一次通过vm_area_struct-\u0026gt;vm_next找到，依次类推。并且，mmstruct-\u0026gt;map_count成员记录了进程所有线性区的数量。\n另一种则是用红黑树进行组织，用于在进程空间中高效的查找 VMA， 正常来说，想要查找某个地址是否存在于进程的地址空间，遍历上述链表的效率是 O(n)。\n通常一个进程地址空间的文件映射区会有非常多的线性区。因此，Linux2.6 引入红黑树来优化查找速度， 所有线性区同时组织成一个红黑树， 首部通过mm_struct.mm_rb指向。 然后每个线性区的vm_area_struct.vm_rb 存储节点的颜色和双亲信息。\n现在，当需要插入/删除一个线性区描述符时，用红黑树查找前后元素，再操作链表进行插入。\nmmap()的使用方式 mmap()用于在文件映射区创建一个真实的文件映射或者匿名映射。\nvoid* mmap(void* addr, size_t length, int prot, int flags, int fd, off_t offset); 参数prot 通过 mmap 系统调用中的参数 prot 来指定其在进程虚拟内存空间中映射出的这段虚拟内存区域 VMA 的访问权限，它的取值有如下四种, 组合使用：\n#define PROT_READ 0x1 /* page can be read */#define PROT_WRITE 0x2 /* page can be written */#define PROT_EXEC 0x4 /* page can be executed */#define PROT_NONE 0x0 /* page can not be accessed */ PROT_READ 表示该虚拟内存区域背后映射的物理内存是可读的。 PROT_WRITE 表示该虚拟内存区域背后映射的物理内存是可写的。 PROT_EXEC 表示该虚拟内存区域背后映射的物理内存所存储的内是可以被执行的，该内存区域内往往存储的是执行程序的机器码，比如进程虚拟内存空间中的代码段，以及动态链接库通过文件映射的方式加载进文件映射与匿名映射区里的代码段，这些 VMA 的权限就是 PROT_EXEC 。 PROT_NONE 表示这段虚拟内存区域是不能被访问的，既不可读写，也不可执行。用于实现防范攻击的 guard page。如果攻击者访问了某个 guard page，就会触发 SIGSEV 段错误。除此之外，指定 PROT_NONE 还可以为进程预先保留这部分虚拟内存区域，虽然不能被访问，但是当后面进程需要的时候，可以通过 mprotect 系统调用修改这部分虚拟内存区域的权限。   mprotect 系统调用可以动态修改进程虚拟内存空间中任意一段虚拟内存区域的权限。\n 参数flag flags决定了这段线性区的映射方式。\n#define MAP_FIXED 0x10 /* Interpret addr exactly */#define MAP_ANONYMOUS 0x20 /* don\u0026#39;t use a file */ #define MAP_SHARED 0x01 /* Share changes */#define MAP_PRIVATE 0x02 /* Changes are private */但如果我们指定的 addr 是一个非法地址，比如 [addr , addr + length] 这段虚拟内存地址已经存在映射关系了，那么内核就会自动帮我们选取一个合适的虚拟内存地址开始映射，但是当我们在 mmap 系统调用的参数 flags 中指定了 MAP_FIXED, 这时参数 addr 就变成强制要求了，如果 [addr , addr + length] 这段虚拟内存地址已经存在映射关系了，那么内核就会将这段映射关系 unmmap 解除掉映射，然后重新根据我们的要求进行映射，如果 addr 是一个非法地址，内核就会报错停止映射。\n当我们将 mmap 系统调用参数 flags 指定为 MAP_ANONYMOUS 时，表示我们需要进行匿名映射，既然是匿名映射，fd 和 offset 这两个参数也就没有了意义，fd 参数需要被设置为 -1 。当我们进行文件映射的时候，只需要指定 fd 和 offset 参数就可以了。\n而根据 mmap 创建出的这片虚拟内存区域背后所映射的物理内存能否在多进程之间共享，又分为了两种内存映射方式：\n MAP_SHARED 表示共享映射，通过 mmap 映射出的这片内存区域在多进程之间是共享的，一个进程修改了共享映射的内存区域，其他进程是可以看到的，用于多进程之间的通信。 MAP_PRIVATE 表示私有映射，通过 mmap 映射出的这片内存区域是进程私有的，其他进程是看不到的。如果是私有文件映射，那么多进程针对同一映射文件的修改将不会回写到磁盘文件上。   这里介绍的这些 flags 参数枚举值是可以相互组合的, MAP_PRIVATE | MAP_ANONYMOUS 表示私有匿名映射，我们常常利用这种映射方式来申请虚拟内存\n ","date":"2023-10-06T14:51:49+08:00","permalink":"https://wangloo.github.io/posts/os/linux/addrspace/mmap/","section":"posts","tags":["Operating System"],"title":"Linux mmap 函数"},{"categories":["Operating System"],"contents":"伙伴系统的优势 作为一个页分配器，伙伴系统主要解决外部碎片过多的问题， 保证系统中尽可能有大的连续空间可以使用。\n这也正是伙伴系统要设计成相邻内存块合并的原因。\n","date":"2023-09-18T17:51:49+08:00","permalink":"https://wangloo.github.io/posts/os/linux/mem/buddy/","section":"posts","tags":["linux","Operating System"],"title":"Linux Buddy 内存分配器"},{"categories":["Architecture"],"contents":"为什么要关心内存模型 内存模型是一个约定或者规则, 是体系结构决定的，定义了内存的某些属性和行为。 一般各个架构之间有所不同，比如 ARM 会做合并访存、乱序执行这类优化方法。\n所以，某些情况下，指令的执行顺序可能不与你程序设计的一模一样，只是为你呈现的结果相同罢了。 当然这里边还有编译器来优化（捣乱 hh）。\n一般程序无需关心内存模型带来的差异，除非你从事底层软件开发（嵌入式开发）这种需要和寄存器打交道， 涉及系统底层机制的实现时，你必须按照内存模型来合理的规划你的程序。\n各种内存模型 不同的处理器架构有不同的内存模型.\n 例如, ARM 架构可能优化内存读写指令的顺序, 但是 X86/64 架构通常不会这样做. X86 架构的每次内存加载指令都带有 acquire 语义, 每次写内存都带有 release 语义. ARM 架构就不一定, 拿 ARMv8 来说, 仅有LDRA/STRL指令带有此含义.   我们称类似 ARM 架构行为的内存模型为 Relaxed Memory Model\n  将 X86/64 上稳定运行的 Lock-free 的代码搬到 ARM 上, 就不一定是可行的.\n 顺序一致性模型 Sequential Consistency Model 指令的执行顺序总是和可执行文件一致.不论是否存在内存访问指令重排等优化操作.\n举个例子,\n 先写后读内存的模型中, 总是能实现读内存时值是新的(不会被优化成先读后写). 多条ldr指令的执行顺序也是严格按照程序所写   多处理器环境下, 每个核的执行顺序都是可执行文件中的指令顺序. 多核之间的同步需要程序员来保证.\n 宽松一致性模型 Relaxed Consistency Model 各种优化 buff 叠满，一般加载/存储指令的执行顺序不能保证，需要程序员自行维护。\n这种宽泛的规则，给了处理器很大自主决定空间，它可以根据当前的情况决定是不是如何处理你的访存指令。\n宽松内存模型下几种保证正确性措施 \u0026ldquo;volatile\u0026rdquo; 关键字  这里对volatile的描述都是基于 C 语言的.\nvolatile(JAVA) != volatile(C/C++)\nvolatile(JAVA) == atomic(C/C++)\n volatile解决的是编译器的过度优化问题， 添加了volatile关键字表示该变量可能随时被改变, 即便当前的程序中没有体现, 也可能被其他的线程修改，或者对于寄存器来说自身就会发生变化。\n对于添加volatile关键字的变量, 编译器会严格按照你所写的来编译:\n 不会删除内存分配 不会在寄存器中缓存变量, 每次访问都会重新读内存. 不会改变赋值的顺序  看一个未添加volatile关键字可能导致的问题: 下面是一个简单的函数, 作用是为在等到设备完成当前任务后关闭设备.\nvoid poweroff(dev_t ID, reg_addr_t *busy) { while(*busy) ; poweroff(); } 看上去似乎是正确的, 但\u0026quot;过于聪明\u0026quot;的编译器可能让这段程序失效. 编译器总认为我们的程序是单线程的, 即没有人会来修改busy. 这种过分的优化导致汇编的结果仅仅读busy一次, 然后陷入死循环. 显然不是我们想要的.\nvoid poweroff(dev_t ID, reg_addr_t *busy) { if (busy) do_endless_while(); poweroff(); } 对关键的busy变量添加volatile关键字将拯救我们!\nvoid poweroff(dev_t ID, reg_addr_t volatile *busy) { while(busy) ; poweroff(); }  延申阅读材料: 为什么大部分情况下使用volatile关键字都是错误的. 只要锁正确实现, 那么被锁锁住的变量就完全不需要volatile来声明, 因为获得锁时其他的 core 不能修改它. 这是锁来保证的, 不应该添加多次一举的 volatile!\nWhy the “volatile” type class should not be used — The Linux Kernel documentation\n  内敛汇编中的 volatile\n  asm volatile(\u0026#34;\u0026#34;:::\u0026#34;memory\u0026#34;);  volatile 向编译器说明禁止内敛的语句与其他语句 reorder。但不能保证内部 reorder， 那是下面内存屏障的任务 \u0026quot;memory\u0026quot; 向编译器说明对于所有内存访问操作，不能使用 asm 之前预加载到寄存器中的值 ，而必须在 asm 内部重新加载。保证其内部访问内存值具有可见性和正确性。   内存屏障 Memory Barrier 对于可执行文件中的指令顺序, CPU并不会严格的依次执行, 而是进行更底层的\u0026quot;优化\u0026quot;来保证高效率, 即CPU乱序执行(Out of order)。 内存屏障指令能够保证乱序执行不会跨过该指令。\n正如下面的例子, 两条指令之间没有数据相关, 所以指令执行的顺序是不确定的.\nldr [x1], x2 # load x2 -\u0026gt; *x1 str x3, [x4] # store *x4 -\u0026gt; x3 而在指令中间插入一条内存屏障指令, 就能强制保证内存屏障指令后面的指令不能先于其前面的指令执行.\nldr [x1], x2 # load x2 -\u0026gt; *x1 # An Memory Barrier Instruction str x3, [x4] # store *x4 -\u0026gt; x3 AArch64 内存屏障指令 AArch64 提供了三种类型的屏障指令, 其中DMB和DSB属于内存屏障指令:\n ISB(指令同步屏障) DMB(数据内存屏障) DSB(数据同步屏障)  ISB 字面翻译为指令同步, 执行后指令流水线被刷新, 后续的指令需要再次fetch. 实际上可以理解为上下文同步. ARMv8将上下文定义为系统寄存器的状态, 并将上下文更改操作定义为: Cache, TLB和分支预测器的维护操作, 或对系统寄存器的修改.\n这些上下文更改操作对其后的指令来说并不是立即可见的. 只有在发生上上下文同步事件之后才可见. 所有的上下文同步事件包括:\n 发生异常 异常返回 执行ISB指令  所以ISB的作用可以表示为: 同步ISB前面的上下文更改操作, 并刷新指令流水线, 确保后面的指令可见新的上下文.\n所有的上下文更改后都需要添加ISB指令来保证后续指令执行时, 更改操作已经完成. The following example shows how to enable the floating-point unit and SIMD, which you can do in AArch64 by writing to bit [20] of the CPACR_EL1 register. The ISB is a context synchronization event that guarantees that the enable is complete before any subsequent FPU or NEON instructions are executed.\nMRS X1, CPACR_EL1 // Copy contents of CPACR to X1 ORR X1, X1, #(0x3 \u0026lt;\u0026lt; 20) // Write to bit 20 of X1. (Enable FPU and SIMD) MSR CPACR_EL1, X1 // Write contents of X1 to CPACR ISB  This does not mean that an ISB is required after each instruction that modifies a processor register. For example, reads or writes to PSTATE fields, ELRs, SPs, and SPSRs always occur in program order relative to other instructions.\n DMB 内存屏障指令ARM的实现, 上面已经介绍过. 这里再给出一个例子:\nLDR X0, [X1] // Must be seen by the memory system before the // STR below. DMB ISHLD ADD X2, #1 // May be executed before or after the memory // system sees LDR. STR X3, [X4] // Must be seen by the memory system after the // LDR above. DSB 在DMB的基础上进一步阻止除了内存读/写外的其他指令. 如下示例保证DC的执行结果为ADD操作可见。\n其后可以跟SEV指令, 它将等待此处理器发出的所有Cache、TLB和分支预测器维护操作完成.\nDC ISW, X5 // operation must have completed before DSB can // complete STR STR X0, [X1] // Access must have completed before DSB can complete DSB ISH ADD X2, X2, #3 // Cannot be executed until DSB completes  从上面的例子中可以看到，DMB和DSB指令接受一个参数, 用来指定生效的地址区域.\nLearn the architecture - ARMv8-A memory systems\n 单向屏障指令 LDAR/STLR 上面介绍的屏障指令能够保证,: 程序中所有在屏障前面的内存访问在执行屏障指令之前那一刻对于所有的master都是可见的(visible). 说中国话就是指定内存域(通过屏障指令的参数指定)的访存指令不能够跨过屏障指令而乱序执行.\n+----------+ | LOAD +\u0026lt;--+ +----------+ | valid reorder | STORE +\u0026lt;--+ +----------+ | DMB | +----------+ | LOAD +\u0026lt;--+ +----------+ | valid reorder | LOAD +\u0026lt;--+ +----------+ +----------+ | LOAD +\u0026lt;--+ +----------+ | | STORE | | +----------+ | invalid reorder | DMB | | +----------+ | | LOAD | | +----------+ | | LOAD +\u0026lt;--+ +----------+ 然而, 这种双向的barrier太过于严格, 以致于导致不少性能的损失. 所以, ARMv8提供给我们单向的内存屏障指令, LDAR/STLR\nLoad-Acquire (LDAR)\n限制程序中所有在LDAR指令之后的内存访问必须在执行完该LDAR指令后才对其他master可见.\n用中国话说就是程序中所有在LDAR之后指令的内存访问都不能被execution-reorder到LDAR之前.\n再通俗点, 就是仅仅设定了一个reorder的上限.\nStore-Release(STLR)\n可以对比LDAR, 限制程序中所有在STLR之前的访存操作必须在执行STLR之前就对其他master可见, 不能再往后延迟了, 通俗点说就是设置了reorder的下限.\n用一张ARM用户编程手册中的图来解释, 黑色箭头代表每条指令最远能够reorder的路径.\n 独占访问指令?? ","date":"2023-09-10T18:02:04+08:00","permalink":"https://wangloo.github.io/posts/arch/armv8/memory_model_and_barrier/","section":"posts","tags":["armv8"],"title":"ARMv8 内存模型"},{"categories":["Operating System"],"contents":"SystemV IPC Linux 引入了 SystemV 中 IPC 的集中实现方式，包括：信号量、共享内存、消息队列。\n共享内存 共享内存基于文件实现，用操作文件的方式来操作共享内存区。\n原理是对一块物理内存做多个映射，用引用计数来维护，只有引用计数为0时，才能释放。\n共享内存的特点是：\n 速度快，但自身没有同步功能，需要配合外部的同步机制。  信号量  为什么说信号量也是一种通信机制?\n其实通信并不一定就是要发送数据，只要能够相互感知，通知到对方，就算是一种通信。 类比抛媚眼也算是通信的一种。\n 消息队列  并非基于文件，由自己的一套API，使用起来不方便。 消息队列是面向消息的（并非字节流），消息由类型。 消息队列有自己的同步机制，无需外部添加。  信号 常用于父子之间通信，只要你知道了对方的PID，就可以给对方发信号。\n用kill(pid, signal)来发送信号。\n","date":"2023-09-08T16:21:27+08:00","permalink":"https://wangloo.github.io/posts/os/linux/ipc/linux-ipc/","section":"posts","tags":["Operating System","linux"],"title":"Linux 进程间通信概述"},{"categories":["Qemu"],"contents":"Qemu 的工作方式 Qemu有两种工作方式：全系统模拟（Full-system emulation）和用户模拟（User-mode emulation）。\n用户模拟仅仅对目标格式的Elf文件进行指令翻译并执行， 在遇到需要使用系统资源的命令（通过系统调用）时， 就转换成实际host的系统调用来完成，将执行完的结果返回。 Elf就是一个用户态的应用，不能直接操作硬件。 总之，用户模式下Qemu仅仅实现了讲Guest指令翻译为Host指令并执行， 不模拟资源。\n全系统模拟的方式下，Qemu在用户态模拟了完整的一套Guest硬件资源， 包括Cpu、内存、外设等，此时Qemu更像是一个虚拟机管理器。 Guest Elf可以直接对硬件进行操作。\n指令翻译 在 host 上运行 guest 架构代码的能力由 QEMU TCG 模块提供。\nTCG 做指令翻译的思路是 “边翻译边执行”， 并且将翻译工作分为前后端，中间会有一层中间指令， 这样能够方便添加对新指令的支持。这个有点类似于现代编译器，也是由类似间结果的流程，称为 IR。\nTCG 执行一次翻译的单位是 Translation Block，以分支跳转、页边界为划分条件。\nQemu 全系统模拟启动内核 \u0026ndash;kernel选项后面接一个Elf格式的系统镜像，Qemu内部用seaBios来实现引导Elf， 所以我们可以不关心如何引导Elf的问题。\n","date":"2023-09-08T16:21:27+08:00","permalink":"https://wangloo.github.io/posts/qemu/1/","section":"posts","tags":["Qemu"],"title":"QEMU 工作原理"},{"categories":["Operating System"],"contents":"   名词 含义解释     Unix 起源于BELL实验室的一个操作系统家族, 指代一类OS。\n这些OS共同遵守Unix特性，但各个分支在实现上有所不同。\n包括SystemV、BSD等分支   SystemV 是Unix的特殊版本，由AT\u0026amp;T公司开发   GNU 目标是开发一个完全自由、开源的OS，借鉴Unix   Linux OS内核，借鉴了Linux。后与GNU工具集结合，称为GNU/Linux                        ","date":"2023-09-08T16:21:27+08:00","permalink":"https://wangloo.github.io/posts/os/abbreviation/","section":"posts","tags":["Operating System"],"title":"操作系统：相关名词汇总"},{"categories":["Hugo"],"contents":"footer属于 partial模板之一, 创建一个新文件footer.html, 然后在baseof模板中, 指定footer内容显示的位置.\n\u0026lt;body\u0026gt; \u0026lt;div id=\u0026#34;app\u0026#34;\u0026gt; {{- partial \u0026#34;sidebar.html\u0026#34; . -}} \u0026lt;main class=\u0026#34;container\u0026#34;\u0026gt; {{- block \u0026#34;main\u0026#34; . }} {{- end }} {{- partial \u0026#34;footer.html\u0026#34; . -}} \u0026lt;/main\u0026gt; {{- partial \u0026#34;script.html\u0026#34; . -}} \u0026lt;/div\u0026gt; \u0026lt;/body\u0026gt; 下面将按照功能划分, 添加各种内容到footer模板中.\n文件创建和lastmode时间  commit: https://github.com/wangloo/hugo-theme-puer/commit/d263d9af65808ff03b2307abfb4db397ae1bcc2a\n 文件创建时间是获取的footer中的变量, lastmod其实也可以通过这种方式获取, 但是这样每次修改都要手动更新太复杂, 我们可以借助git追踪的文件的修改时间来作为lastmod, 默认不是这样的, 需要在config.toml中指定.\n[frontmatter] lastmod = [\u0026#39;lastmod\u0026#39;, \u0026#39;:git\u0026#39;, \u0026#39;:fileModTime\u0026#39;, \u0026#39;date\u0026#39;, \u0026#39;publishDate\u0026#39;] 然后就是在footer.html中引用这两个变量即可:\n\u0026lt;HR width=\u0026#34;100%\u0026#34; id=\u0026#34;EOF\u0026#34;\u0026gt; {{- if not .Lastmod.IsZero -}} \u0026lt;p style=\u0026#34;color:#777;\u0026#34;\u0026gt;创建于: {{ .Date.Format \u0026#34;2006-01-02T15:04:05\u0026#34;}}, Lastmod: {{ .Lastmod.Format \u0026#34;2006-01-02T15:04:05\u0026#34;}}\u0026lt;/p\u0026gt; {{- end -}} ","date":"2023-09-02T18:39:42+08:00","permalink":"https://wangloo.github.io/posts/hugo/new_theme_7/","section":"posts","tags":["hugo"],"title":"Hugo 主题创建(7): footer"},{"categories":["Algorithm"],"contents":"实际上我做过的二分搜索的题目并不少，但是一直以来没有静下心去研究它的 【循环条件】【边界调整】【返回值】的细节，通过这个题目希望自己能完整、 清晰的了解二分搜索。\n题目 https://leetcode.cn/problems/find-first-and-last-position-of-element-in-sorted-array\n 给你一个按照非递减顺序排列的整数数组 nums，和一个目标值 target。请你找出给定目标值在数组中的开始位置和结束位置。\n如果数组中不存在目标值 target，返回 [-1, -1]。\n你必须设计并实现时间复杂度为 O(log n) 的算法解决此问题。\n 示例 1：\n输入：nums = [5,7,7,8,8,10], target = 8 输出：[3,4]\n  解答(python): def searchRange(self, nums: List[int], target: int) -\u0026gt; List[int]: if nums == []: return [-1, -1] # 第一次二分，确定右边界 left, right = 0, len(nums)-1 while left \u0026lt;= right: mid = (left + right) // 2 if nums[mid] \u0026lt;= target: left = mid+1 else: right = mid-1 end = right # 第二次二分，确定左边界 left, right = 0, len(nums)-1 while left \u0026lt;= right: mid = (left + right) // 2 if nums[mid] \u0026lt; target: left = mid+1 else: right = mid-1 sta = left print(sta, end) if end \u0026lt; 0 or sta \u0026gt; len(nums)-1 or nums[sta] != target or nums[end] != target: return [-1, -1] else: return [sta, end] 细节 写好一个二分搜索就是需要确定三件事:\n 循环边界条件 调整边界 返回值  这三件事是环环相扣的，先说确定的，调整边界的操作一定是left=mid+1 or right=mid-1, 整数的二分不存在left=mid这种操作，仅限于浮点数中。\n再说边界条件，我个人喜欢使用带等号的判断，即while left \u0026lt;= right, 这纯粹是个人习惯.\n问题转化 以求右侧下标为例, 可以等价为: 搜索\u0026lt;=target的最大值. 这其实是问题的关键, 只是另外加一个判断说如果求得数 不是target, 返回特殊值就行了. 如果你还是不理解这两个问题为什么是等价的, 那么看完下面的解释应该也能清楚.\n先说搜索\u0026lt;=target的最大值的计算方法, 一般的二分搜索, 搜索完成之后, 如果没有找到target, right=left-1, 且 right 指向比 target 首个小的元素,left 指向首个比 target 大的元素.\n那么代码是不是可以这么写:\nleft, right = 0, n-1 while left \u0026lt;= right: mid = (left + right) // 2 if nums[mid] == target: return mid elif nums[mid] \u0026lt; target: left += 1 else: right += 1 return right 更进一步的说, 如果\u0026quot;把target也看作是小于target\u0026quot;, 也就是让循环不停下, 最后平衡的条件也一定是满足 right 指向比 target 首个小的元素,left 指向首个比 target 大的元素., 只不过此时=target 也被算作是小于target, 走小于target的处理流程. 最终的结果就是right指向的就是target(如果存在), 要不就是比target小的那个数.\n于是代码就可以被优化为:\nleft, right = 0, n-1 while left \u0026lt;= right: mid = (left + right) // 2 if nums[mid] \u0026lt;= target: left += 1 else: right += 1 return right 再审原题 上述这种进一步思考的思想是不是与原题中的要求类似? 我可以有一连串的target, 我要求的是最右边的target在哪, 如果把=target也看作是小于target, 让循环继续跑, 最后right指向的就是最右边的那个target.\n","date":"2023-08-20T20:30:35+08:00","permalink":"https://wangloo.github.io/posts/algorithm/bsearch/","section":"posts","tags":["Algorithm"],"title":"一道题搞定二分法的细节"},{"categories":["Hugo"],"contents":"shortcode 可以当成是一些对 html 代码块封装的函数，在写 markdown 的时候就会方便一些， 举个例子来说，我有时需要往 post 中插入图片，并调整它的大小，这时候每次都手动写一些 html 简直是太麻烦了，使用 shortcode 就像是调用函数一样，告诉它函数名和必要的参数， 它会在生成网页时自动转换为对应的 html 语法。\nshortcode 分为两种：Hugo 默认和自定义的。Hugo 默认支持的 shortcode 有这些 https://gohugo.io/content-management/shortcodes/ ，这里面同时包含了告诉我们如果使用 shortcode 的基本语法。\n figure 插入图片 ref/relref 引用本地文档  当然hugo支持创建自定义 shortcode，详细的使用方法可以看这里， https://gohugo.io/templates/shortcode-templates/ ，我会大概说一下。\n 定义一个新的shortcode，即在layouts/shortcodes/下创建一个新的xxx.html文件，文件名就是你的函数名 这个shortcode会做什么事，就是在这个html中进行实现  插入链接图片 remoteFigure，参考的是diary主题的实现支持调整图片大小、填充样式、对齐、添加图片描述等。\n puer 主题的 Github commit\n Reference  中文介绍Shortcode  ","date":"2023-08-20T18:39:42+08:00","permalink":"https://wangloo.github.io/posts/hugo/new_theme_6/","section":"posts","tags":["hugo"],"title":"Hugo 主题创建(6): shortcode"},{"categories":["C Language"],"contents":"C 中的qsort, python 中的sorted()很多时间需要自己构造比较的规则，也就是告诉排序函数怎么衡量两个值的大小关系？\nTL;DR 升序的写法(C-qsort):\nint cmp(const void *a, const void *b) { return *(int *)a - *(int *)b; } int main(void) { int nums[] = {2, 1, 3, 5, 4}; qsort(nums, 5, sizeof(int), cmp); return 0; } 升序的写法(python-sorted()):\nfrom functools import cmp_to_key nums = [2, 3, 1, 4, 5] nums = sorted(nums, key=cmp_to_key(lambda x,y: x-y)) print(nums)  python3 丢弃了sorted()中的cmp选项， 全部用 key 选项进行指定， 所以需要cmp_to_key进行转换\n 升序的写法(C++-sort()):\n// sort()原型 void sort (RandomAccessIterator first, RandomAccessIterator last, Compare comp); bool cmp(int a, int b){ return a \u0026lt; b; } int main(){ int a[10]={8 ,3 ,10 ,9 ,5}; sort(a,a+10,cmp); return 0; } 详解 正如上面所说，cmp 函数的作用是给排序函数一个比较的依据。\n  c 和 python 的 cmp 函数属于同一种，返回的是 int 类型的值，代表的含义是：a 相对于 b 的位置。 返回正数代表 a 在 b 之后，负数则反之。所以用a-b算式就能表达升序排序\n  而 C++返回的则是布尔值，代表的含义是：a 排在 b 的前面吗?，所以用a\u0026lt;b， 也能表达升序排序\n  这样看起来，貌似 c++的写法更好理解一些。\n 有时我们会看到 python 中这样表示升序:\nlambda x,y: -(x \u0026lt; y) 这其实是和x-y的效果是相同的, 只是有的时候一些类型不能够相减，比如说字符串， 但是可以使用\u0026lt;\u0026gt;比较，所以执行这样一个转换的小 trick。\n ","date":"2023-08-20T17:59:22+08:00","permalink":"https://wangloo.github.io/posts/c/cmp-func/","section":"posts","tags":["c","python"],"title":"C/python: cmp函数应该怎么写"},{"categories":null,"contents":"排序 使用sorted()来做, 不修改原来的变量, 而是返回一个新的。 自定义cmp函数的例子\n 被排序的类型必须是iterable的。\n 字符串 无重复字符的最长子串 def lengthOfLongestSubstring(self, s: str) -\u0026gt; int: mp = {} left, right = 0, 0 max_len = 0 while right \u0026lt; len(s): if s[right] not in mp: mp[s[right]] = 1 else : mp[s[right]] += 1 while mp[s[right]] \u0026gt; 1: mp[s[left]] -= 1 left += 1 max_len = max(max_len, right-left+1) right += 1 return max_len 牛客网处理输入 https://blog.nowcoder.net/n/0632a788b94b4923976b7c82c45eca95\n写递归 遇到需要用递归的题目中, 常常需要传值出来. 比如写一个求 sum(1..n)的函数\n这样写是错误的, 因为每次对 Sum 的更新都是局部的, 并不会影响到 parent frame 的值. 所以最后传出的值一定是 0\ndef func(n, Sum): if n == 0: return else: Sum+= n func(n-1, Sum) result = 0 func(3, result) 有两个方案解决:\n 使用全局变量来保存结果, 见全局变量章节 将传出的参数用可修改的类型来保存, 比如说 List. 以上代码可以修改为:  def func(n, Sum): if n == 0: return else: Sum[0] += n func(n-1, Sum) result = [0] func(3, result) 全局变量的使用 在写机试题时, 一般不会出现函数嵌套, 所以用不到nonlocal关键字.\n反而需要使用global关键字, 使用的方法为:\nmax_len = 0 def dfs(..): global max_len # 在dfs()中修改或者访问的max_len就是全局的了 ... 进制以及 ascii 码转换 ascii 和字符相互转换, ord()和chr()互为逆函数:\nc = \u0026#39;a\u0026#39; ac = ord(c) # 65 c = chr(ac) # \u0026#39;a\u0026#39; 进制转换\n 如果要生成整型数据, 不管什么进制, 统一使用int()在最外层 如果要生成字符串, 统一使用format()在最外层, 当然它和bin(), hex()这类是等价的  下面给出几个常用的例子:\n# \u0026#39;1010\u0026#39; -\u0026gt; 10 int(\u0026#39;1010\u0026#39;, 2) # 10 # 10 -\u0026gt; \u0026#39;1010\u0026#39; 二进制字符串 format(10, \u0026#39;b\u0026#39;) # \u0026#39;1010\u0026#39; format(10, \u0026#39;#b\u0026#39;) # \u0026#39;0b1010\u0026#39; , 等价于bin(10)的结果 # 10 -\u0026gt; \u0026#39;12\u0026#39; 八进制的字符串 format(10, \u0026#39;o\u0026#39;) # \u0026#39;12\u0026#39; format(10, \u0026#39;#o\u0026#39;) # \u0026#39;0o12\u0026#39; , 等价于 oct(10)的结果 浮点数的处理 浮点数打印精度(四舍五入)\nx = 1.23 print(\u0026#34;{:.1f}\u0026#34;.format(x)) print(format(x, \u0026#39;.1f\u0026#39;)) # 我自己习惯统一使用此方法 字符串/字符的常用处理  字符串中含有非字母转小写/大写: 可直接调用.lower(), .upper() 非字符会默认保持不变  string 和 list 相互转换\n# list to str a = [\u0026#39;h\u0026#39;, \u0026#39;e\u0026#39;, \u0026#39;l\u0026#39;, \u0026#39;l\u0026#39;, \u0026#39;o\u0026#39;] s = \u0026#39;\u0026#39;.join(a) # str ot list s = \u0026#39;hello\u0026#39; a = list(s) 字符串是多个数字字段的组合, 如何分割每个字段转成int并存入 list:\ns = \u0026#34;10 20 30\u0026#34; s = s.split() l = [int(x) for x in s] 字符和整数之间的转换\n# c = \u0026#39;b\u0026#39; c = chr(ord(\u0026#39;a\u0026#39;)+1) # c = \u0026#39;2\u0026#39; c = chr(ord(\u0026#39;1\u0026#39;)+1) 字符串回文判断\ns == s[::-1] 统计字符出现的次数: 不一定要借用字典\nstring 和元组一样, 有.count(x)方法统计 x 的出现次数\ns = input() for i in s: if s.count(i) == 1: print(i) break else: print(\u0026#39;-1\u0026#39;) 搜索一个字符串中是否包含另一字符串, 不要再使用.find() != -1了 直接使用in关键字即可\nif s1 in s2: print(\u0026#34;s1 is included in s2\u0026#34;) 字符串删除指定字符:\ns = \u0026#34;hello\u0026#34; #删除所有 l s = s.replace(\u0026#39;l\u0026#39;, \u0026#39;\u0026#39;) #删除前一个 l s = s.replace(\u0026#39;l\u0026#39;, \u0026#39;\u0026#39;, 1) 字典的常用处理 字典按照 value 排序:\n# 返回降序的value list d = {} l = list(sorted(d.values(), reverse=True)) # 返回按value升序排序的的字典 d_sorted = dict(sorted(d.items(),key=lambda x: x[1])) # 返回value降序的字典 d_sorted = dict(sorted(d.items(), key=lambda x: -x[1])) # 返回按value降序,如果value相同时按key升序排序的字典 d_sorted = dict(sorted(d.items(), key=lambda x: (-x[1], x[0]))) 集合 # 创建一个空集合 s = set() # 集合中添加元素 s.add(123) 列表的常用处理 建立非重复的列表, C++中的集合(set)\ns = \u0026#34;abcdabcd\u0026#34; # 想要得到[\u0026#39;a\u0026#39;, \u0026#39;b\u0026#39;, \u0026#39;c\u0026#39;, \u0026#39;d\u0026#39;] set_list = [] for c in s: if c not in set_list: set_list.append(c) 列表删除元素\nl = [1, 2, 3, 3] l.remove(3) # 删除第一个3 # 删除所有3 for c in l: if c == 3: l.remove(c) 工具模块 lru_cache 装饰器优化递归\n注意, 用此装饰器的函数参数必须为hashable的, 例如 list 就是 unhashable 的, 需要转为元组: func(tuple(lst))\nimport functools @functools.lru_cache(2**20) def fibonacci(n): ... 典型问题整理 称砝码 以小见大, 假设我们有三个砝码, 要统计可能出现的所有重要, 我们的方法是:\n 先放 A, 统计所有可能 [0, A] 再放 B, 与之前统计的所有可能相加, 去重后加入所有可能 [0, A, B, A+B] 再放 C, 与之前统计的所有可能相加, 去重后加入所有可能 [0, A, B, A+B, C, A+C, B+C, A+B+C]  ","date":"2023-08-19T10:30:35+08:00","permalink":"https://wangloo.github.io/posts/python/algo/","section":"posts","tags":["Python"],"title":"Python 做机试题目技巧"},{"categories":["Hugo"],"contents":"通过 tag 可以实现对post进行分类，用到的支持是 HUGO Taxonomy Template（分类模板）\n原理 实现tag的功能需要完成两类页面的设计： /tags/ 和 /tags/\u0026lt;one-tag\u0026gt;\n前者属于 Taxonomy Terms（分类术语）页面，用分类术语模板实现， 后者属于 Taxonomy List （分类列表）页面，用分类列表模板实现，他们都属于 Taxonomy 模板。\n不难推测出，分类术语模板规定了如何展现某个分类方式，比如说用云图来展示tag分类方法。 而分类list模板的作用是展示选中某一类之后的页面，比如说在云图中选中了某个tag。\n更加详细的描述可以看官方文档: https://gohugobrasil.netlify.app/templates/taxonomy-templates/\n设计 正与文档中所说，分类terms模板可以有多个查找的优先级：\n/layouts/taxonomy/\u0026lt;SINGULAR\u0026gt;.terms.html /layouts/_default/terms.html /themes/\u0026lt;THEME\u0026gt;/layouts/taxonomy/\u0026lt;SINGULAR\u0026gt;.terms.html /themes/\u0026lt;THEME\u0026gt;/layouts/_default/terms.html 这样的好处是，比如说我有两种terms，tag和categories，我想在分类术语页面对这两种分类展示不用的页面， 就可以定义tag.terms.html和category.terms.html，注意是单数形式。参考Commit：拆分tag和category样式\n分类list模板也是，使用最通用的list.html, 和其他的list公用，并没有对分类list做单独的页面。\n 对应的 commit: https://github.com/wangloo/hugo-theme-puer/commit/63d8bb762b16a3d4657ba3523d6b6fb38cf5f9ca\n上面的commit不小心提交了menu.html, 实际不属于taxonomy的目的，所以在这纠正: https://github.com/wangloo/hugo-theme-puer/commit/0af07f66807b540fd9d3be84e8d7faca7f962c4b\n References  中文博客介绍Taxonomy(1): https://hugo-in-action.foofun.cn/zh/docs/part1/chapter4/4/ 中文博客介绍Taxonomy(2): https://note.qidong.name/2017/10/hugo-taxonomy/  ","date":"2023-08-15T18:39:42+08:00","permalink":"https://wangloo.github.io/posts/hugo/new_theme_5/","section":"posts","tags":["hugo"],"title":"Hugo 主题创建(5): Tag 分类支持"},{"categories":["Architecture"],"contents":"之前在特斯拉面试的时候被问到了 cache 的 maintain 操作有哪些, 一时间竟想不起一个准确的词来, 这里就再学习一下, 把这个坑填上吧。\n可能不会说的很细，目的只是把一些概念复习，做到心中大致有数。\ncache 是个硬件 cache 的本质是一种 SRAM, 容量很小, 速度很快(ns 级)。\n拿 Cortex-A53 来说，共有三级 Cache：\n L1 cache 是 Core 单独的，分为数据 cache 和指令 cache，容量是 KB 级 L2 cache 一般是 cluster 内共享，容量是 MB 级 L3 cache 是所有 core 共享，容量是 MB 级  cache 控制器 单独的 cache 就是一个存储设备，得有一个控制器告诉它存什么以及什么时候存。\ncache 控制器的任务举个例子说：比如 cache miss 的时候，需要从主存向 cache 回填数据，然而此时 CPU 那边记着要数据，我们都知道 cache 操作的单位 是 cache line 嘛，但这是 cache 控制器会有限填充一个 cache line 中 CPU 要的那一条（或几条），最后在后台默默填充完剩下的。\ncache 控制器的行为是不可配置的，软件不可见，不可编程。\ncache policy（策略） cache policy 就说了两件事：\n cache 分配：执行 load 操作时需要分配入 cache 吗？ cache 更新：执行 str 修改数据时需不需要与主存同步？  cache 的更新方式有两种：\n Write back，写回；即仅修改 cache 中数据，然后设置一个 dirty 标志位 ，当且仅当此 cache line 被 clean 时才对 dirty 数据回写主存 Write through，写直通；即每次修改 cache 都同步修改主存，也就不需要 dirty 标志了  cache 相关的内存属性 一段内存可被设置为 cacheable 或者 uncacheable，uncacheable 的内存直接访问主存。\ncacheable 又可划分为 inner 和 outer 两种：\n inner: 可入L1 cache，或者L2 cache，实现定义 outer: 可入外部板级的 cache(L3 cache)  cache maintain（维护） 为什么需要维护cache？\n 主存中的内容更新了 此部分内存的权限改了或者映射改了  cache的三种维护操作（软件可见）：\n [invalidation]: 设置cache line对应的invalid位。常见于reset时，cache里的内容不可信， 所以需要将所有的cache invalid [clean]: clean的含义是清理，将原有的标记为dirty的line都与主存进行同步。当然， 仅更新策略为 write back的时候才需要 [zero]: 什么也不管，直接将cache line置0，数据丢了我也不关心   以上的三种操作都是有粒度的，包括整个 cache、指定va范围、某一路等。\n  软件只能通过体系结构提供的维护指令来控制 cache。\n ARMv8获取Cache信息 想要管理好整个cache系统, 首先要了解的信息是:\n 系统实现了几级cache? Cache line 是多大? 对于每一级的Cache, 它的 set/way 分别是多少?  这些信息都可以通过ARMv8的系统控制寄存器来读取.\nCLIDR_EL1 标识每一级Cache的类型以及系统最多支持几级Cache.\nCtype\u0026lt;n\u0026gt;字段用来描述缓存的类型. 系统最多支持7级缓存, 软件需要遍历Ctype\u0026lt;n\u0026gt;字段, 当读到的值为000时, 说明该级及以上都没有实现.\n 具体每种类型对应的值, 和其他字段的含义, RTFM\n CTR_EL0 记录了Cache line的大小, 以及Cache的策略.\nIminLine: 表示所有指令cache中最小的cache line, 单位是 word.\nDminLine: 表示所有数据cache中最小的cache line, 单位是 word.\nL1IP: 表示 L1 指令cache的策略. RTFM\nCSSELR_EL1 与CSSIDR配合工作. CSSELR用于选定查看某级的Cache, 再去读CSSIDR就是该级Cache的信息.\nCSSIDR_EL1 LineSize: 该级cache的cache line.\nAssociativity: 该级Cache的way\nNumSets: 该级Cache的set\n 该寄存器的字段分布与是否实现FEAT_CCIDX有关, RTFM## 获取Cache信息\n ","date":"2023-08-14T22:02:04+08:00","permalink":"https://wangloo.github.io/posts/arch/armv8/cache/","section":"posts","tags":["armv8"],"title":"ARMv8: cache相关知识"},{"categories":["HTML/CSS"],"contents":"display 是规定元素排列方式的属性，总的来说，元素的排列方式可分两种：block 和 inline。\n block 的含义是，该元素默认情况下的 width 表现为充满整个父元素，height 表现为根据内容决定。 inline 的含义是，该元素的 width 和 height 都是必须根据内容决定，不能使用显示的width和height来改变。  即便 block 可以去设置 width, 比如为 50%, 但是它永远必须独占一行，下面的元素也不会排到它的空白处， 这就是 block 称之为 block 的原因。\n细分来说，其实 display 这个属性共有五种取值： block, inline, inline-block, flex, grid。 我们将依次介绍。\nblock 默认 display 方式为 block 的标签有: p, h1-h6, div, li 等\ninline 默认 display 方式为 inline 的标签有: span, a, strong\ninline-block inline-block 是结合了 block 和 inline 的优势：既不必独占一行，又可以调整 width 和 height。\n一些 button 经常使用的 display 就是 inline-block。\nflex grid 不同 display 文字居中的方法 文字居中是开发中常见的需求，然而根据 display 的不同，决定了实现居中的方式也不同。\n居中大概分为水平居中和垂直居中\n水平居中 对于 inline、inline-block 来说，直接设置text-align=center即可实现。\n对于 block，设置text-align=center的效果是将 block 内部的文字相对与 block 居中，并不是 相对于 block 的父元素。\n但是很多情况下，我们是想让整个 block 同时再相对于父元素居中（因为block的width不一定是100%） 此时需要对 block 元素额外添加margin-left=auto和margin-right=auto属性。\n垂直居中 用 flex 比较方便实现。\n","date":"2023-08-11T22:02:04+08:00","permalink":"https://wangloo.github.io/posts/html-css/display/","section":"posts","tags":["css"],"title":"前端学习: display"},{"categories":["HTML/CSS"],"contents":"position 属性决定了一个元素在页面中的排放方式, 通过与 top、bottom、left、right 结合可以决定任一元素在页面中应该在什么位置上。\nposition 的取值可以是: static/absolute/relative/fixed/sticky ，下面我将依次对他们的使用方法和场景进行介绍。\nstatic static 是元素默认的 position，它使得元素按照顺序排列（什么样的顺序取决于display)。\n它不能与 top、bottom 等属性结合，就是最简单的依次排布。\nrelative relative 与 static 相比，支持了 tom、bottom 这些属性，使得元素在依次排布的同时 能调整相对于上一个元素的位置变化。\n据我所知，relative 并不常见。\nabsolute absolute 也就是我们常称的\u0026quot;绝对定位\u0026quot;， 产生的效果相对于父元素做了一些偏移，而不是上面所说的上一个元素，只有父元素的位置改变，它才按照偏移数值进行改变。 偏移数值的指定通过 top、bottom 来实现。\nabsolute 可以与 fixed 进行对比，两者相差很小。\n absolute 无视 static。上面说 absolute 是基于父元素进行调整，仅当父元素是 static 时例外，absolute 会跳过这一层，找它的爷爷元素。\n fixed fixed的含义是使元素的排列始终固定在页面的某个位置，换句话也可以说它总是基于body做relative的 排列。当然，偏移是通过top、bottom给出的。\n一些页面的小广告用的排列就是fixed。\nsticky sticky像默认的static，但它也有top、bottom等属性值，这些值有特殊含义： 当元素随着页面滚动变化，而使元素的页面绝对位置（相对于body）达到top、bottom值时， 便固定在那不会再移动，使元素永远不会被移动出页面。\n看起来就好像是用页面的外框对sticky元素画了一个笼子，它永远跑不出页面之外。\nsticky目前被广泛应用与导航栏，只要设置top=0\n sticky是新增的属性，某些浏览器支持的可能不是很好\n ","date":"2023-08-11T21:02:04+08:00","permalink":"https://wangloo.github.io/posts/html-css/position/","section":"posts","tags":["css"],"title":"前端学习: position"},{"categories":["Hugo"],"contents":"字体替换  commit: https://github.com/wangloo/hugo-theme-puer/commit/861ca01617c06c83b701506c9a574cc2726d36d8\n 修改的参考：\n 一般文字用最近很火的【霞鹜文楷】 代码使用一些比较通用的代码字体，注意用!important提高优先级  ","date":"2023-08-11T18:39:42+08:00","permalink":"https://wangloo.github.io/posts/hugo/new_theme_4/","section":"posts","tags":["hugo"],"title":"Hugo 主题创建(4): 样式打磨"},{"categories":["Hugo"],"contents":" commit:\n 为什么选择fast search? hugo本身是不支持站内搜索功能的, 如果你写的文章较多就只能按照tag去检索分类. 这样至少也需要三次点击操作, 如果每个页面的边栏或者顶栏有一个搜索框, 能够 搜索文章的内容或者标题、Tag这些，对我来说效率就能得到显著提升。\nfast search 是我检索到的目前比较简单、成熟的方案，它的亮点：\n 最小外部依赖（无需jQuery） 支持实现键盘唤出 无需NPM, grunt等外部工具 无需额外的编译步骤，你只需要像往常一样执行hugo 可以方便地切换到任意可使用json索引的客户端搜索工具  集成 集成的步骤我是参照的这篇文章 , fast search官方也有说明类似的步骤，过程不难，大概可分为：\n  Add index.json file to layouts/_default Add JSON as additional output format in config.toml Add search.js and fuse.js (downloaded from fusejs.io) to static/js Add searchbox html 到你想布局的位置 对searchbox添加样式文件   具体的步骤看博文或者官方文档就行，这里不赘述。\n改动 做了一些让自己舒服的改动：\n 让搜索框常驻，只是搜索结果可以隐藏(ESC) /聚焦搜索框，和vim相同 简化样式，贴合我的主题 搜索结果只显示title就够  这样以后不论在哪，想要切换到一篇文章只需要两次鼠标（或者两次键盘）就能精准定位并打开，不必使用鼠标的方式可能更有作用哈哈。\nTODO  只能搜索标题，不能搜索内容、tag？  ","date":"2023-08-11T16:39:42+08:00","permalink":"https://wangloo.github.io/posts/hugo/new_theme_3/","section":"posts","tags":["hugo"],"title":"Hugo 主题创建(3): 站内搜索"},{"categories":["Hugo"],"contents":" commit: https://github.com/wangloo/hugo-theme-puer/commit/32abfccc6bafd3763e07b751f0315a5403c6eaff\n 与顶栏相比，我更喜欢侧边栏，现在的屏幕纵向空间很宝贵。\n本文创建了侧边栏模板的框架，预留了未来实现各种功能的布局，这个过程也是第一次接触partials/ 下的文件的作用——页面的某个组成部分。而_default/下的模板则是描述不同类型的页面。\n布局 基于hugo模板的分类思想，侧边栏属于页表的一个部分，所以侧边栏的模板需要放在partials/下， 同理的还有footer、toc、comment等。我们给侧边栏模板起一个名字sidebar.html。\n因为想在站点所有的页面（section、single、list）都显示侧边栏， 所以在baseof.html中需要引入sidebar模板：\n\u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; {{- partial \u0026#34;head.html\u0026#34; . -}} \u0026lt;title\u0026gt; {{ block \u0026#34;title\u0026#34; . }} {{ .Site.Title }} {{ end }} \u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;div id=\u0026#34;app\u0026#34;\u0026gt; {{- partial \u0026#34;sidebar.html\u0026#34; . -}} \u0026lt;main class=\u0026#34;container\u0026#34;\u0026gt; {{- block \u0026#34;main\u0026#34; . }} {{- end }} \u0026lt;/main\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; sidebar.html的内容就比较简单了，目前的计划是添加首页、TAG和一个搜索框， 不着急，先展位，以后再实现这些功能，本次先实现框架。\n\u0026lt;div id=\u0026#34;sideContainer\u0026#34; class=\u0026#34;side-container\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;nav-link-list\u0026#34;\u0026gt; {{/* TODO: 回到首页 */}} \u0026lt;div class=\u0026#34;a-block nav-link-item \u0026#34; href=\u0026#34;\u0026#34;\u0026gt; BACK \u0026lt;/div\u0026gt; {{/* TODO: articles... */}} \u0026lt;div class=\u0026#34;a-block nav-link-item \u0026#34; href=\u0026#34;\u0026#34;\u0026gt; POSTS \u0026lt;/div\u0026gt; {{/* TODO: tags */}} \u0026lt;div class=\u0026#34;a-block nav-link-item \u0026#34; href=\u0026#34;\u0026#34;\u0026gt; TAGS \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; 样式 这是首次接触样式的修改，也就是用到css语言。顺便说下，我非常敬佩视频网站上那些对CSS玩的很溜 的人，我觉得CSS中的细节远比我的工作中的多，可能你糊弄一下能得到一个相同的效果，但是一个优秀的 前端工程师是要清楚每个属性的作用，他们之间是如何搭配的，绝对不是凑出结果。\n主题中如何添加css文件呢？创建模板时会自动创建目录 static/css/，其中可以放置一些css文件， 比如我为sidebar.html创建的叫style.css, 在样式不多的情况下其他部分的样式也都可以放在这。\n不在一个目录下，如何联系html和css呢？这就不得不提到partials/下的另一个重要模板head.html, 通过baseof.html中它的位置就能大概知道它的作用：\u0026lt;head/\u0026gt;标签的模板，基本上就是描述样式的css语法嘛。 这就是html和css连接的桥梁。\n以下是style.css文件内容：\n.container { padding-left: 25%; width: 75%; min-height: 100vh; white-space: normal; } .side-container { position: fixed; top: 0; height: 100vh; width: 25%; text-align: left; padding: 20px 0 50px 0; display: flex; flex-direction: column; justify-content: space-between; } .nav-link-list { flex-grow: 1; .nav-link-item { margin-bottom: 10px; border-right: 2px solid transparent; /* padding: 8px 28px 8px 30px; */ cursor: hand; transition: all 0.2s linear; } } 有了侧边栏后，我们需要启用内容的wrap line，且目前暂时用padding-left+width=100%的方式 来避免当文字过长出现滚动条时滑动会破坏布局。 本质还是由于侧边栏的实现是通过padding方式，sidebar和内容互相不能感知对方。\n","date":"2023-08-11T15:39:42+08:00","permalink":"https://wangloo.github.io/posts/hugo/new_theme_2/","section":"posts","tags":["hugo"],"title":"Hugo 主题创建(2): 添加侧边栏"},{"categories":["Hugo"],"contents":" 本次对应的commit，应该属于站点的仓库，因为仅修改 config.toml\n 代码高亮 hugo 内置一套highlight引擎, 参见官网的描述 , 所以我们只需要对站点的配置文件(注意不是模板的配置文件)进行修改, 就能最简单的实现代码高亮.\n如果你需要对其进行自定义, 且将其固化到你的主题中, 那么就可能需要使用highlight.js来完成, 遵循\u0026quot;提前优化是万恶之源\u0026quot;的理论, 暂时使用hugo提供的高亮支持就能符合我们的目标.\n这是我的配置文件config.toml中关于代码高亮的启用:\n[markup] [markup.highlight] anchorLineNos = false # 行号格式化为\u0026lt;span\u0026gt; codeFences = true # 代码围栏, 不启用高亮无效 guessSyntax = true # 自动推断高亮语言 hl_Lines = \u0026#39;\u0026#39; # 突出显示某些特定的行 hl_inline = false # 高亮 inline code, ver\u0026gt;=0.101.0 lineAnchors = \u0026#39;\u0026#39; #　与 anchorLineNos 配合 lineNoStart = 1 # 行号开始 lineNos = true # 是否显示行号 lineNumbersInTable = true # 生成html中分开行号和代码 noClasses = true noHl = false style = \u0026#39;vs\u0026#39; tabWidth = 4 参考  hugo代码高亮引擎描述引导页: https://gohugo.io/content-management/syntax-highlighting/ 参数的详细描述: https://gohugo.io/functions/highlight/  ","date":"2023-08-11T07:39:42+08:00","permalink":"https://wangloo.github.io/posts/hugo/new_theme_1/","section":"posts","tags":["hugo"],"title":"Hugo 主题创建(1): 内置样式"},{"categories":["Hugo"],"contents":" commit: https://github.com/wangloo/hugo-theme-puer/commit/c014d1fae09eea1fcc44e03c69b6dd4d185f91fd\n 背景交代 到现在为止我使用hugo也一年多了, 记了几十条的博客，对于使用频率如此高的工具来说， 有一个顺眼的外观、方便的功能布局简直是梦寐以求。\n然而，试过了这么多的现有主题，始终没有一个让我觉得满意，可能我的要求过于苛刻：\n 搜索；我经常需要翻阅之前的博客/笔记，期望可以检索Tag，且不需要二次点击（ 上方直接是一个搜索框而不是一个按钮）。 TOC；要求可是展开显示三级的目录，且布局好看些。 外观；简洁，不花里胡哨，代码高亮看起来舒服。 xxx  所以，既然Hugo是一个开源的、社区环境较好的工具，那么为什么不尝试打造一款属于自己主题呢。\n我是一名嵌入式开发工程师，对于前端的知识生疏，希望在良好的社区环境下能帮助我早日完成满足我个人需求的主题。\n计划  搭建框架 制作模板，熟悉模板的概念，各个模板负责的区域 在上面的了解过程中逐渐加入对布局的调整，这一块可能需要学习css的知识 观摩学习前人的代码，结合百家之长，磨合出适合自己的布局和功能  开始动手：搭建脚手架 创建的过程可以参考这个博客 , 我主要想按照我的理解对整个框架进行详细的介绍。\n目录结构 . ├── layouts │ ├── 404.html │ ├── _default \u0026lt;--- 此次重点研究 │ │ ├── baseof.html │ │ ├── section.html │ │ ├── single.html │ │ └── list.html │ ├── index.html \u0026lt;--- 此次重点研究 │ └── partials │ ├── footer.html │ ├── header.html │ ├── head.html │ └── script.html ├── LICENSE ├── static \u0026lt;--- 目前是空的, 后续再研究 │ ├── css │ └── js └── theme.toml \u0026lt;--- 干什么用的不清楚,后续研究 此次重点探讨index.html和_default目录下的文件.\nindex.html 是整个网站的首页, 打开你的站点最先看到的就是它的内容.\n{{ define \u0026#34;title\u0026#34; }} 首页 {{ end }} {{ define \u0026#34;main\u0026#34; }} \u0026lt;p\u0026gt; 这里是个人站的首页, 仅展示用, 请DIY自己的首页覆盖它 :] \u0026lt;/p\u0026gt; {{ end }} 你可能看不懂这段代码, 这不是正常的html, 但马上你就能明白了.\n_dafult下的文件被hugo称之为模板, 顾名思义他们的存在是为了减少代码的重复度. 不同名称的模板代表了hugo将页面划分为不同的类, 这个在官方文档中应该有介绍, 后续可以插入个链接(TODO).\n single.html: 普通页面的模板, 我们写的博客中的内容页面就算是single page list.html: 列表页面的模板, 好几个博客分布在同一个子目录下, 访问这个目录的 地址就是 list page section.html: content/是hugo工程放置内容的目录, 其下需要建立子目录, 比如posts/代表这是一些博客  baseof.html需要着重介绍, 它相当于模板的模板, 目的是为了消除模板代码中的重复, 其中使用hugo提供的block语法, 建立基础模板, 目前我们baseof.html的内容如下:\n\u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; {{- partial \u0026#34;head.html\u0026#34; . -}} \u0026lt;title\u0026gt; {{ block \u0026#34;title\u0026#34; . }} {{ .Site.Title }} {{ end }} \u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; {{- partial \u0026#34;header.html\u0026#34; . -}} \u0026lt;main class=\u0026#34;container\u0026#34;\u0026gt; {{- block \u0026#34;main\u0026#34; . }} {{- end }} \u0026lt;/main\u0026gt; {{- partial \u0026#34;footer.html\u0026#34; . -}} {{- partial \u0026#34;script.html\u0026#34; . -}} \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 这还稍微像一点html, 能看出是一个html的框架, 其中用block声明了title和main变量.\n其他的模板文件中(包括index.html), 只要实现这两个变量, 就相当于把整段的代码都拷过来, 并且将{{ block \u0026quot;xx\u0026quot; }} 和 {{ end }} 之间的内容替换为你define的内容.\n在baseof.html中对{{ block \u0026quot;xx\u0026quot; }} 和 {{ end }} 之间提前填充就实现了, 对网页的title设置了一个默认值, 如果重定义了, 那么覆盖原先的默认值. 看index.html就能明白, 它将网站的title替换成了\u0026quot;首页\u0026quot;, 内容也改变了, 其他的都是相当于和 baseof.html相同.\n 这里不介绍hugo的更多详细语法使用, 官方文档中都有\n  这里先不介绍优先级的概念, 假设这些模板文件在全局中只有一个\n 参考  https://gohugo.io/templates/base/  ","date":"2023-08-10T17:39:42+08:00","permalink":"https://wangloo.github.io/posts/hugo/new_theme_0/","section":"posts","tags":["hugo"],"title":"Hugo 主题创建(0): 脚手架"},{"categories":["Openwrt"],"contents":"构建 openWRT  我在此步骤失败了，后面项目没有依赖完整的编译过程， 所以可能对你不构成参考\n 过程可参考官方教程, 编译过程非常长，使用到的工具非常多，这里提供两个优化的思路:\n提前安装本地依赖，忘了./scripts/feeds update -a还是./scripts/feeds install -a时需要检查系统的各种依赖, 可以提前统一安装一波.\nsudo apt install g++ sudo apt install libncurses5-dev sudo apt install zlib1g-dev sudo apt install bison sudo apt install flex sudo apt install unzip sudo apt install autoconf sudo apt install gawk sudo apt install make sudo apt install gettext sudo apt install gcc sudo apt install binutils sudo apt install patch sudo apt install bzip2 sudo apt install libz-dev sudo apt install asciidoc sudo apt install subversion sudo apt install python sudo apt install git 提前下载dl, dl是默认在编译时下载的一些工具源码, 你可以将他们提前下载好 放到dl/下, 即可省去下载的时间, 特别当你不能翻墙时.\n就像这个仓库这样, 但是它里面 的软件版本可能比较老了而且有的软件是缺失的, 以后如果真的要自己编译, 需要查makefile去替换真正依赖的软件和其对应的版本.\n最终还是因为编译某个模块失败, 且编译时间太长(连交叉编译工具链都需要现场编译) , 导致排查困难, 没有编译成功。好在后面也没有直接依赖编译的结果。\n编译的tips  make V=99 build with verbose  ptgen 正如上面所言, 我最终没有完整的编译成功。但其中的一个小工具ptgen是我 需要用的到，它在过程中被编译出来了，相对独立些。\nptgen是OpenWRT开发的一个用来生成gpt分区表的工具，创建的sdcard镜像， 只有配合分区表才能正确的被bootrom加载起来。\n使用方法及参数 ptgen使用的参数说明:\nptgen [-v] -h \u0026lt;heads\u0026gt; -s \u0026lt;sectors\u0026gt; -o \u0026lt;outputfile\u0026gt; [-a 0..4] [-l \u0026lt;align kB\u0026gt;] [[-t \u0026lt;type\u0026gt;] -p \u0026lt;size\u0026gt;...] -v: 指定是否打印调试信息,可选 -h: 指定起始磁头号 -s: 指定起始扇区号 -o: 指定输出文件名 -a: 指定激活分区为哪个, 可选 -l: 指定多少KiB对齐,可选，这个参数会决定每个分区的偏移扇区号，非常重要 -t: 指定文件系统分区标志类型值,是0x83指linux,0x0b指Win95 FAT32,可选 -p 指定分区大小,可选 ptgen使用案例 这里贴出我使用ptgen创建一个BananaPi M2 Ultra可以识别的sd卡镜像文件， 对bootfs进行挂载可放入一些文件，在uboot下能访问。\n#!/bin/bash  if [ -f \u0026#34;sd.img\u0026#34; ]; then echo \u0026#34;warning: sd.img already exist, do nothing\u0026#34; exit fi if [ -f \u0026#34;bootfs.ext4\u0026#34; ]; then echo \u0026#34;warning: bootfs.ext4 already exist, do nothing\u0026#34; exit fi BOOTFS_SIZE=16M # make ext4 fs which including kernel.bin dd bs=\u0026#34;$BOOTFS_SIZE\u0026#34; if=/dev/zero of=bootfs.ext4 count=1 sudo mkfs.ext4 bootfs.ext4 [ -d \u0026#34;./mnt\u0026#34; ] || mkdir ./mnt sudo mount -o loop bootfs.ext4 ./mnt sudo cp kernel.bin ./mnt sudo umount ./mnt # create empty image dd bs=32M if=/dev/zero of=sd.img count=1 # generate parition table # -t 0xc: FAT32 # -t 0x83: ext4 set $(./ptgen -o sd.img -h 4 -s 63 -l 1024 -t 0x83 -p \u0026#34;$BOOTFS_SIZE\u0026#34;) BOOTFS_OFFSET=\u0026#34;$(($1 / 512))\u0026#34; # write in uboot and bootfs dd bs=1024 if=u-boot-sunxi-with-spl.bin of=sd.img seek=8 conv=notrunc dd bs=512 if=bootfs.ext4 of=sd.img seek=\u0026#34;$BOOTFS_OFFSET\u0026#34; conv=notrunc echo -e \u0026#34;\\n\\nsd.img is ok\u0026#34; 我正是依赖这个工具生成了最终的镜像而已，其他的模块其实并不是特别需要。 本来u-boot也是必须的，但是后面发现我用的硬件(BananaPi M2 Ultra) 在uboot中有直接的defconfig，所以也就不依赖openWRT的编译结果了。\n","date":"2023-08-05T19:28:12+08:00","permalink":"https://wangloo.github.io/posts/embedded/openwrt/","section":"posts","tags":["tools"],"title":"openwrt 开发日记"},{"categories":["DevTools"],"contents":"博客站 向优秀的前辈们学习~\n  hitzhangjie\n 腾讯 一本有关Dwarf的gitbook: https://www.hitzhangjie.pro/debugger101.io/ Blog也是基于Hugo构建，风格很好，移动端体验不错。https://www.hitzhangjie.pro/blog/    stdcc\n 上海交大 IPADS Blog风格很好，https://stdrc.cc/ Slides一定得学习，https://stdrc.cc/slides/write-os-in-rust-2.0/slides.html 用notion整理表格 https://stdrc.notion.site/c93719166f094ac187dfba6fc199b566 \u0026hellip;    工具站  Armv8 寄存器、指令速查：http://hehezhou.cn/a64/ Emoji cheat sheet https://www.webfx.com/tools/emoji-cheat-sheet/ Windows10搭建局域网FTP服务器 跟我一起写Makefile https://seisman.github.io/how-to-write-makefile/Makefile.pdf 网络调试工具 http://free.cmsoft.cn/download/cmsoft/assistant/netassist5.0.3.zip Gnu gcc 内联汇编官方手册: https://gcc.gnu.org/onlinedocs/gcc/Using-Assembly-Language-with-C.html#Using-Assembly-Language-with-C  交叉编译工具   Linaro: 经常用来编译armv7架构的一些项目。 https://releases.linaro.org/components/toolchain/binaries/\n  Gnu: https://developer.arm.com/tools-and-software/open-source-software/developer-tools/gnu-toolchain/gnu-a/downloads\n   目前我组织的ARM64项目都使用 aarch64-none-linux-gnu- 作为交叉编译工具集, 直达链接: https://armkeil.blob.core.windows.net/developer/Files/downloads/gnu-a/10.3-2021.07/binrel/gcc-arm-10.3-2021.07-x86_64-aarch64-none-linux-gnu.tar.xz\n ","date":"2023-08-05T19:28:12+08:00","permalink":"https://wangloo.github.io/posts/tools/useful_sites/","section":"posts","tags":["tools"],"title":"工具\u0026\u0026博客站点集合"},{"categories":["DevTools"],"contents":"前言 写这篇博客的背景是我实在忍受不了每次换新的开发机器都得费好大的劲来完全恢复以前的环境， 而且，我平常喜欢搜集各种有用的工具、好看的主题，字体这些，如果零零散散的记录，大概率会忘记或者记不得某些细节。\n所以，最后期望达到的是能够使我每次在新机器上搭建环境只需要看这一篇文章就可以了。因此这里会记录：\n 帮助提升开发效率的小工具 好看的字体、主题 配置某些环境的要点及注意事项   🥀 到目前为止，我还未发现一种方式能够完全达到“一键式布置”，这也不是本文的目的。 付出至少半天的时间的一定的，希望未来能发现一种好的方法。\n 字体 Fira Code 这款字体适合做编程字体，蛮好看的。我在 vscode 和 terminal 下都使用了这款字体。\n详情及安装参考github\n霞鹜文楷 开源的中文字体，做博客、PPT 不错。\n详情及安装参考github\nvscode vscode的所有配置通过其内置的sync功能实现, 目前用的是Github账号同步。\n Command+Shift+o 或者搜索框中输入@ ==\u0026gt; 搜索outline 搜索框中输入% ==\u0026gt; 全局快速搜索quick search  vscode多个窗口群组（Group）可以有两种排列方式：自由排布和放大某一个。 使用Toggle Editor Group Sizes命令来切换。\nvscode常用快捷键  Remote SSH 连接失败 使用Remote SSH插件总是连接失败，但终端使用指令可以连接成功。这种情况下是插件挂了，解决方法参考链接：\n VS Code Remote SSH Connection not working - Stack Overflow 删除服务器上的~/.vscode-server目录，并重试连接  Release 1.88.0  内置终端中按Ctrl+Alt+R执行历史命令。选择时按住Alt可以不自动执行 // #MARK：在minimap中标记region Quick search中按Command+⬆️/⬇️来在一次跳转文件   Ubuntu2004源 新版本的Clangd  Clangd用15+才能用vscode的inlay hint功能。\n 获取签名\nwget -O - https://apt.llvm.org/llvm-snapshot.gpg.key | sudo apt-key add - 添加源地址到/etc/apt/sources.list, 修改完后别忘了sudo apt update\n# 15, 后缀可以改成你需要的版本号 deb http://apt.llvm.org/focal/ llvm-toolchain-focal-15 main deb-src http://apt.llvm.org/focal/ llvm-toolchain-focal-15 main 新版本的Vim  Vim 8+才有pack插件管理\n sudo add-apt-repository ppa:jonathonf/vim 安装和升级node sudo apt install npm npm install -g n sudo n stable 下载完成后 如果发现 node -v 仍然是之前的版本，根据不同的 shell 版本执行 hash -r 或者 rehash 即可。\n终端软件安装 源替换 https://mirrors.tuna.tsinghua.edu.cn/help/ubuntu/\nsudo apt install python3-pip sudo apt install tmux sudo apt install fzf sudo apt install zsh sudo apt install cmake # low version? sudo apt install tldr sudo apt install coreutils # tar包含在其中 # CLI 代码高亮 sudo pip3 install pygments # hstr 是一款可以轻松查看、导航和搜索历史命令的小工具，它支持 Bash 和 Zsh。 # hstr 配置：https://blog.csdn.net/easylife206/article/details/107925366 sudo add-apt-repository ppa:ultradvorka/ppa \u0026amp;\u0026amp; sudo apt-get update \u0026amp;\u0026amp; sudo apt-get install hstr # brew install hstr # MACOS shell zsh oh-my-zsh oh-my-zsh可以看作对zsh的配置文件做一层抽象，使配置更方便。 一键式安装：\nsh -c \u0026#34;$(curl -fsSL https://gitee.com/mirrors/oh-my-zsh/raw/master/tools/install.sh)\u0026#34; .notice { --root-color: #444; --root-background: #eff; --title-color: #fff; --title-background: #7bd; --warning-title: #c33; --warning-content: #fee; --info-title: #fb7; --info-content: #fec; --note-title: #6be; --note-content: #e7f2fa; --tip-title: #5a5; --tip-content: #efe } @media (prefers-color-scheme:dark) { .notice { --root-color: #ddd; --root-background: #eff; --title-color: #fff; --title-background: #7bd; --warning-title: #800; --warning-content: #400; --info-title: #a50; --info-content: #420; --note-title: #069; --note-content: #023; --tip-title: #363; --tip-content: #121 } } body.dark .notice { --root-color: #ddd; --root-background: #eff; --title-color: #fff; --title-background: #7bd; --warning-title: #800; --warning-content: #400; --info-title: #a50; --info-content: #420; --note-title: #069; --note-content: #023; --tip-title: #363; --tip-content: #121 } .notice { padding: 18px; line-height: 24px; margin-bottom: 24px; border-radius: 4px; color: var(--root-color); background: var(--root-background) } .notice p:last-child { margin-bottom: 0 } .notice-title { margin: -18px -18px 12px; padding: 4px 18px; border-radius: 4px 4px 0 0; font-weight: 700; color: var(--title-color); background: var(--title-background) } .notice.warning .notice-title { background: var(--warning-title) } .notice.warning { background: var(--warning-content) } .notice.info .notice-title { background: var(--info-title) } .notice.info { background: var(--info-content) } .notice.note .notice-title { background: var(--note-title) } .notice.note { background: var(--note-content) } .notice.tip .notice-title { background: var(--tip-title) } .notice.tip { background: var(--tip-content) } .icon-notice { display: inline-flex; align-self: center; margin-right: 8px } .icon-notice img, .icon-notice svg { height: 1em; width: 1em; fill: currentColor } .icon-notice img, .icon-notice.baseline svg { top: .125em; position: relative }     zsh默认的主题进入git目录下会比较卡，取消命令前缀显式git分支可以解决。 我的方案下默认就没有展示分支。\n OMZ 插件下载 # zsh-syntax-highlighting # 高亮语法，输入正确语法会显示绿色，错误的会显示红色，实时检查语法 git clone https://github.com/zsh-users/zsh-syntax-highlighting.git ${ZSH_CUSTOM:-~/.oh-my-zsh/custom}/plugins/zsh-syntax-highlighting # zsh-autosuggestions # 命令补全提示，我愿称之为OMZ插件之王 # 以下两个地址都可以 git clone https://github.com/zsh-users/zsh-autosuggestions ${ZSH_CUSTOM:-~/.oh-my-zsh/custom}/plugins/zsh-autosuggestions git clone https://gitee.com/phpxxo/zsh-autosuggestions.git ${ZSH_CUSTOM:-~/.oh-my-zsh/custom}/plugins/zsh-autosuggestions OMZ 插件安装 OMZ配置文件.zshrc中写入如下，重新source之后即可生效。\n# Which plugins would you like to load? # Standard plugins can be found in $ZSH/plugins/ # Custom plugins may be added to $ZSH_CUSTOM/plugins/ # Example format: plugins=(rails git textmate ruby lighthouse) # Add wisely, as too many plugins slow down shell startup. plugins=( git zsh-syntax-highlighting zsh-autosuggestions rand-quote ) OMZ 插件参考博客  oh my zsh插件安装详细教程及常用插件 宝可梦说话 mac上使用oh my zsh有哪些必备的插件推荐？ git缩写、🐄说话  ssh 密钥 ssh-keygen -t rsa -C \u0026#34;cnwanglu@icloud.com\u0026#34; tmux tmux 在远程开发时比较有用，解决了以下几个痛点：\n ssh连接主机不稳定，在休眠或者网络波动时经常断开，以前进入的目录或者vim打开的文件就需要重新做。而tmux是CS架构，只要远程主机上的server不死，永远可以重新连接并恢复到之前的窗口。甚至，tmux提供了将现场保存到本地文件中的功能。在远程主机重启后，也可以从文件中恢复现场。 ssh连接主机实现多窗口麻烦，一般需要在终端软件（如XShell，iterms）中开多个标签，多次连接ssh。tmux内置多窗口的实现方案，不依赖连接的终端，窗口创建、切换等方式可以做到统一。  问题：调整显示尺寸时，tmux未重新绘制窗口 有时候我们在调整终端软件的显示大小时，发现tmux的显示窗口并没有跟着变化，而是在多余的串口中显示一些点。就像下面图片展示的那样。\n 原因在于该会话有多个绑定的连接，而tmux将窗口绘制为所有连接中最的最小尺寸。最简单的方法是在连接的时候将其他客户端从会话中断开：\ntmux attach -d reference  Tmux使用手册 解决窗口尺寸问题  科学上网 Clash 最完整的教程，包括下载和安装使用：https://docs.gtk.pw/contents/macos/cfw.html#%E4%B8%8B%E8%BD%BD%E5%AE%89%E8%A3%85\nClash for Mac 直接下载桌面版，镜像下载地址：https://github.com/clashdownload/Clash_for_Windows/releases\nClash for Linux 目前clash的作者已经删除跑路，但是已经发布的版本还是可以正常使用的。这一章节介绍如何在Linux上用命令行配置Clash。\n首先需要准备好一些文件：\n clash在linux中的命令行可执行文件，目前这里还可以下载 https://github.com/Kuingsmile/clash-core/releases， 去下载clash-linux-amd64-v1.18.0.gz Country.mmdb为全球IP库，可以实现各个国家的IP信息解析和地理定位，没有这个文件clash是无法运行的。 但目前版本的clash有点问题，不会自动生成MMDB文件，所以需要使用命令行下载。去这个地方或者这个地方看看 config.yaml为clash的代理规则和clash的一些其他设置。代理规则不需要我们自己编写，通过订阅地址直接下载即可。 此处将订阅链接粘贴进双引号中间。注意不要删除双引号，不要删除空格。 wget -O ~/.config/clash/config.yaml \u0026quot;订阅链接\u0026quot;。或者，如果你有clash的其他客户端，可以由已有的配置导出。  下载上面的文件，就可以准备好安装了：\n 创建~/.config/clash/，并将config.yaml和Country.mmdb放进去，如果已经存在请忽略 mkdir ~/.config/clash/ mv Country.mmbd ~/.config/clash/ mv config.yaml ~/.config/clash/  解压clash-linux-amd64-v1.18.0.gz，并将可执行文件放到一个合适的位置 gunzip clash-linux-amd64-v1.18.0.gz chmod +x clash-linux-amd64-v1.18.0.gz mv clash-linux-amd64-v1.18.0 ~/tools/clash-v1.18.0 cd ~/tools/  运行clash可执行文件，如果成功运行应该可以看到以下LOG $ ./clash-linux-amd64-v1.18.0 INFO[0000] Start initial compatible provider 故障转移 INFO[0000] Start initial compatible provider 自动选择 INFO[0000] Start initial compatible provider 大机场 Big Airport INFO[0000] inbound mixed://:7890 create success. INFO[0000] RESTful API listening at: 127.0.0.1:9090   到此，clash就可以正常运行了，由于我的订阅地址有3条规则，所以会有3条Start initial compatible provider xxxx。\ninbound mixed://:7890 则代表已经开启了http(含https)和socks代理，只要服务器内有软件流量通过7890这个端口，流量都将进入clash从而被代理。（但有些不支持设置，后面会说如何使用全局代理）\nRESTful API listening at: [::]:9090代表clash已经开启了ui控制面板，是的，Linux的clash有可视化控制面板。\n验证科学上网 根据我们之前前台运行可得知，默认是监控了自己的7890端口，验证方式可以通过curl向google发送一个请求看是否能正常返回。\ncurl --proxy 127.0.0.1:7890 www.google.com 返回正常 Google成功返回数据，代表7890端口代理正常，clash运行正常。注意目前必须手动指定代理的地址和端口，后面会介绍启用全局代理。\nClash全局代理 可以添加这个配置到你的.bashrc/.zshrc中，使得终端的所有请求都走代理。\nexport http_proxy=127.0.0.1:7890 export https_proxy=127.0.0.1:7890 这里只设置了http和https，初次之外，还可代理其他协议。\n可以做成一个sh命令，当想临时关闭科学上网的时候执行unproxy。\nfunction proxy() { export http_proxy=http://127.0.0.1:7890 export https_proxy=$http_proxy echo -e \u0026#34;proxy on!\u0026#34; } function unproxy(){ unset http_proxy https_proxy echo -e \u0026#34;proxy off\u0026#34; } 验证全局代理配置成功只需要再执行一次curl即可，这次无需手动指定代理。\ncurl www.google.com 将Clash作为一个服务 使clash一直运行在前台会占用一个终端，而且总感觉不是很优雅，更好的方法是将clash作为一个服务来操作。\n 在/etc/systemd/system/目录新建一个clash.service文件 [Unit] Description=Clash service After=network.target [Service] Type=simple User=root ExecStart=这里写你的clash运行的绝对路径（本文中的路径是`~/tools/clash-v1.18.0`） Restart=on-failure RestartPreventExitStatus=23 [Install] WantedBy=multi-user.target  之后就可以用systemctl系列命令来确认是否启用成功： systemctl status clash 查看clash服务 systemctl start clash 启动clash服务 systemctl stop clash 停止clash服务 systemctl restart clash 重启clash服务 systemctl enable clash 设置开机自启clash服务 systemctl daemon-reload 如果修改了clash.service文件，需要此命令来重载被修改的服务文件   Reference  Linux中安装Clash并且实现全局代理（纯命令行） https://github.com/Kuingsmile/clash-core/releases clash-for-linux Ubuntu配置 命令行Clash 教程 Clash can\u0026rsquo;t initial MMDB of Country.mmdb  MacOS 环境配置 XCode XCode下载官方网站很慢，跑不满带宽，通过这个下载工具可以跑满带宽XCodeApp，使用文档可以参考这个：一分钟下载最新 XCode - 知乎\n如果使用如下命令检测安装是否成功：\n$ xcodebuild -version Xcode 12.5.1 Build version 12E507 brew 替换清华源 参考：homebrew | 镜像站使用帮助 | 清华大学开源软件镜像站 | Tsinghua Open Source Mirror\n 加入zshrc  export HOMEBREW_API_DOMAIN=\u0026#34;https://mirrors.tuna.tsinghua.edu.cn/homebrew-bottles/api\u0026#34; export HOMEBREW_BOTTLE_DOMAIN=\u0026#34;https://mirrors.tuna.tsinghua.edu.cn/homebrew-bottles\u0026#34; export HOMEBREW_BREW_GIT_REMOTE=\u0026#34;https://mirrors.tuna.tsinghua.edu.cn/git/homebrew/brew.git\u0026#34; export HOMEBREW_CORE_GIT_REMOTE=\u0026#34;https://mirrors.tuna.tsinghua.edu.cn/git/homebrew/homebrew-core.git\u0026#34; export HOMEBREW_PIP_INDEX_URL=\u0026#34;https://pypi.tuna.tsinghua.edu.cn/simple\u0026#34; 执行  for tap in core cask{,-fonts,-versions} command-not-found services; do brew tap --custom-remote --force-auto-update \u0026#34;homebrew/${tap}\u0026#34; \u0026#34;https://mirrors.tuna.tsinghua.edu.cn/git/homebrew/homebrew-${tap}.git\u0026#34; done brew update 其他指令 # 检查包的依赖是否安装好 brew info \u0026lt;package\u0026gt; # 检查包的依赖都有哪些 brew deps \u0026lt;package\u0026gt; Homebrew 的设计哲学 | 楚权的世界\n(42 封私信 / 58 条消息) brew的各种疑问？ - 知乎\nWindows下迁移WSL WSL2目前已经相当好用了，在对性能要求不极致的场景下用WSL开发非常舒服。\n迁移WSL到别的位置/别的机器还是比较方便的，也有人写了脚本来做这些，它是针对迁移到其他硬盘位置的，所以我这次还是自己手动做一遍，原理都是相同的。\n步骤 1. 关闭WSL # 检查WSL是否在运行 wsl -l -v NAME STATE VERSION * Ubuntu2004 Running 1 # 关闭 wsl --shutdown 2. 导出WSL镜像 wsl --export Ubuntu2004 D:\\Ubuntu2004_202311.tar 3. 注销原系统(可选) wsl --unregister Ubuntu2004 4. 将镜像压缩文件复制到新机器/新位置 如果是新机器，还需要重新配置好WSL，开启一些选项:\n控制面板-\u0026gt;程序-\u0026gt;启用或关闭 windows 功能，开启 Windows 虚拟化和 Linux 子系统（WSL2)以及Hyper-V。 勾选完成后，Windows11 会自己下载些东西，并提示你重启。等电脑彻底重启完以后，进行后续操作。 5. 在新机器上导入镜像文件 wsl --import Ubuntu2004 D:\\wsl\\Ubuntu2004\\ D:\\Ubuntu2004_202311.tar 执行的时间比较长, 执行完后至此WSL就迁移完毕了，剩下的是一下配置的修正。\n6. 配置 设置默认用户 这样移过来现在登陆就是root，我们需要进行一些配置:\nSet your default user inside your distro by adding the following configuration to your /etc/wsl.conf.\n[user] default=loo If the file doesn\u0026rsquo;t exist create it manually. Then exit your distro, terminate it (wsl -t Ubuntu2004) and start it again.\n设置默认distro wsl -s Ubuntu2004 这样完成后，所有的一切就OK了。\nReference  https://zhuanlan.zhihu.com/p/622706723  Linux组织Dotfiles Linux开发环境中的许多软件都由配置文件，重新捣鼓一台新环境时去重新设置这些配置文件是非常复杂的一件事情，所以我想着用一种统一的方式进行管理。\n vimrcs 用单独的子仓库管理 vim 插件使用单独的子仓库管理 其他的配置文件暂时都使用mackup管理   不将vim插件也归于mackup管理的原因是: 我的.vim/pack/xx/下的所有插件都是通过submodule的方式管理,这样有利于维护和更新。但是在mackup的管理方式中是将整个pack/的内容拷贝过来，这就与submodule的理念冲突了。此时去改mackup的实现不如将vim的插件系统单独进行维护更容易。\n 新环境恢复Dotfile  vimrcs的恢复方法: wangloo/myvimrcs vim插件的恢复方法: wangloo/myvimpack 其他配置文件，教程参考：wangloo/dotfiles  Reference  Installing Vim(8) plugins with the native pack system  ","date":"2023-07-17T19:28:12+08:00","permalink":"https://wangloo.github.io/posts/tools/dev_env/","section":"posts","tags":["tools"],"title":"开发环境构建指南"},{"categories":["Course"],"contents":"学习日历 - 激励自己学习 因为最近在写论文，所以每两天能学习一次，并记录每次学习的事件\n2024年1月4日22点09分 配置环境\nlab00目录的组成：\n lab00.py: The template file you\u0026rsquo;ll be adding your code to ok: A program used to test and submit assignments lab00.ok: A configuration file for ok  What Would Python Do? (WWPD)\npython3 ok -q python-basics -u --local 结尾的--local避免输入伯克利邮箱。\n解释一个函数的组成：\n  The lines in the triple-quotes \u0026quot;\u0026quot;\u0026quot; are called a docstring, which is a description of what the function is supposed to do. When writing code in 61A, you should always read the docstring!\n  The lines that begin with \u0026raquo;\u0026gt; are called doctests. Recall that when using the Python interpreter, you write Python expressions next to \u0026raquo;\u0026gt; and the output is printed below that line. Doctests explain what the function does by showing actual Python code. It answers the question: \u0026ldquo;If we input this Python code, what should the expected output be?\u0026rdquo;\n   结束时间:23点22分，完成了Lab00和Lab01\n 2024年1月7日16点41分  结束时间:19点07分， 完成了Lab02和一半Hog\n 2024年1月9日19点33分  结束时间:21点17分，完成了hog剩下的，和lab04的Q1\n 2024年1月11日11点24分  结束时间:14点01分，完成了lab04\n 2024年1月12日22点00分  结束时间:22点34分，完成了Cat的前几个问题\n 2024年1月13日17点31分  结束时间:18点55分，完成了Cat。\n 2024年1月14日21点58分4 抽象数据类型（ADT）的含义是什么？ Tree的ADT在Python中就是根节点和分支的List。\ntuple 是不可变的列表，意味着可以作为字典的key。\npython中使用默认的可变函数参数是非常危险的，并不会在每次调用之后被释放， 相当于函数内部的静态变量。\ndef f(s=[]): s.append(5) return len(s)  结束时间:22点58分，完成了Lab05\n 2024年1月18日10点58分 一个可迭代的Container支持对外提供一个迭代器，以按某种顺序访问容器里的元素。\n字典的keys、values、items都是可迭代的集合\n items集合的顺序在3.6+中是加入的顺序，而在之前是以字符大小排序的。\n map(),filter() 返回的都是迭代器，而不是元素集合。 可以通过显式的转换将其转到list或者tuple等。\n使用迭代器的好处：\n 遍历的代码无需关心原本的数据结构是什么 迭代器可以传递给其他函数进行操作，并且可以保证每个元素只遍历一次， 子函数在迭代后无需返回新的值，父函数能看到。（这有利有弊吧，根据场景需求）  生成器是一种特殊的迭代器，如同map()返回也是一种特殊的迭代器。\n生成器函数是返回生成器的函数，其中有yield关键字。\n类属性与实例属性 class A: attr1 = 0 # Class attr def __init__(self): self.attr2 = 0 # instrace attr  结束时间:22点08分，完成了lab06和Ants\n 2024年2月3日13点05分  结束时间:22点12分，完成了lab07和lab08\n 参考链接  CS 61A Fall 2023 Lab CS61A 学习经验\u0026amp;感想 - 知乎 FyisFe/UCB-CS61A-20Fall个人Solution  ","date":"2023-07-17T19:28:12+08:00","permalink":"https://wangloo.github.io/posts/course/cs61a/","section":"posts","tags":["Course"],"title":"课程学习：cs61a"},{"categories":["Operating System"],"contents":"slub 和 slob 是基于 slab 思想针对某些场景下的优化实现。\nSLUB  当 slab 分配器面对过多的申请需求时，cache 中就会有多个 slab (struct slab), 在以前的 slab 分配器设计中， slab 描述符是放在物理页中的，即物理页的结构为： （slab 描述符+freelist+对象 s）,管理数据结构的开销就比较大。后期 SLUB 首先将 slab 描述符与struct page共用（通过 union 实现）。后面该思想被 SLAB 采纳。 SLAB 中每个 cache node 有三个 list: free, partial, full， 管理起来很麻烦， SLUB 中只有一个 partial 链表。 放弃着色，效果不明显  SLOB SLOB 的设计更加简洁，只有 600 行左右代码（SLAB，SLUB 都是 4000+），适合小内存的嵌入式设备。\nSLOB 中没有对象的概念，每个 slab 中分配的小块内存大小可以是不同的， 通过长度+偏移来记录下一个小块内存的位置。\n另外，SLOB 基本上放弃了 cache 的思想，系统中通过创建三个全局的链表: small, medium, large, 分别应对\u0026lt;256b, \u0026lt;1k, \u0026lt;PAGESIZE 的请求， slab 直接挂在这三个链表上，因为 slab 中的内存分配大小可以不同， 用三个链表可以加速查找。\n 从思想上，SLOB 仅仅保留 slab 中分配小块内存的思想，舍弃了 cache 的设计方案，所以实现上非常简单。\n ","date":"2023-05-26T18:51:49+08:00","permalink":"https://wangloo.github.io/posts/os/linux/mem/slab3/","section":"posts","tags":["linux","Operating System"],"title":"Linux SLAB 内存分配器(3): SLUB/SLOB"},{"categories":["Operating System"],"contents":"上一篇介绍了数据结构，这一篇主要介绍 slab 分配器的分配和释放算法。\n最外层接口: kmalloc()/kfree() 最上层的接口是kmalloc(size, flag)。\nslab 分配器维护了多个不同大小的 kmem_cache，放在数组kmem_caches[]中, 其对应的 object 大小和该 kmem_cache 的 name 在另一个数组kmalloc_info[] 中，它们的下标是对应的。使得我们能根据请求分配的大小来找到对应的struct kmem_cache结构。 【代码】\n专用的\u0026quot;cache\u0026quot; 上面的结构，会遍历系统初始化创建的一些内存池，来寻找一个大小满足要求的 object， 但是通常不能找到大小相等的，如果系统中存在的固定 cache 中 object 的大小太稀疏， 就容易发生空间浪费的问题。\n因此，我们可以为某个特定大小的内存请求再创建一个单独的 cache，仅仅用于满足这一类 结构体的申请，也是符合 slab 分配器关于面向对象的设计思想。\nslab 分配器提供的相关接口是:\n kmem_cache_create(): 创建一个专用 cache kmem_cache_alloc()： 从指定的 cache 里分配 object kmem_cache_free(): 释放对象到指定的 cache kmem_cache_destory(): 销毁某个 cache  Reference https://blog.csdn.net/u010923083/article/details/116518646?spm=1001.2014.3001.5502\n","date":"2023-05-20T18:51:49+08:00","permalink":"https://wangloo.github.io/posts/os/linux/mem/slab2/","section":"posts","tags":["linux","Operating System"],"title":"Linux SLAB 内存分配器(2): 算法"},{"categories":["Operating System"],"contents":" 参考的 linux kernel 代码版本 4.12\n slab 是什么 slab 属于 linux 内核内存分配器的一种，满足细粒度的小块内存的请求。 内核中还有其他的内存分配器例如伙伴系统，它是满足页为单位的分配请求。 因为内核中大部分的分配请求都用不到一个页那么大，所以 slab 的出现能够减小 内存碎片的出现。\n另外，非常重要的是，除了基本的小块内存分配， slab 的最初设计开始就基于 对象缓存的思想，加速分配和初始化的过程，下面将详细介绍缓存的设计思想。\n slab 分配器的实现在 linux 中是基于伙伴系统的，slab 管理的内存来源 就是伙伴系统，只是进行“二次管理”， 。\n slab 的设计思想 对象缓存特性 经常会在 slab 接口中看到kmem_cache这个前缀，我最初也有疑问说 slab 不就是一个内存分配算法，和 cache 扯上什么关系呢？\nslab 一般用于分配一些结构的内存，拿struct task来举例，我们通常会为 struct task创建一个内存池，里面包含了若干大小为sizeof(struct task) 的内存块，用的时候从里面取，释放之后回归池子里即可。这是 slab 分配小块内存的 基本思想。\n内核中的很多数据结构，我们在申请完空间之后立马做的一件事，就是初始化对象的成员 为某些特定的值，可以称这个过程为结构体(类)的构造函数，意为所有对象都会 做的那些相同的事。比如说，多核环境下很多结构中会有锁，或者链表，那么申请完空间 之后都会做锁或链表做初始化，这是固定的。实际上这些操作消耗的时间甚至大于申请 一块内存。\n基于以上事实，slab 分配器做的缓存优化是：为每个类别的内存池都绑定一个构造函数 和析构函数，当用完的对象空间被释放时，调用析构函数将某些成员的值恢复为默认状态 ，这样下次申请的时候，直接拿就行了，省略了重复的初始化流程。而构造函数被调用的 情况仅仅是当该小块内存第一次被申请时。\n由于这个思想，整个内存池也就被声明结构 struct kmem_cache, 它是整个 slab 算法的顶层数据结构，其中包含了许多相同大小的小内存块，slab 通过一些算法对其进行 管理。\n整体数据结构的规划 上面说了整个系统的顶层结构是struct kmem_cache, 其中可以再划分为多个\u0026quot;slab\u0026quot;, 这个 slab 就能代表一个或多个连续的物理页嘛，从 buddy 申请来的。\n表示一个 slab 的描述符可以与struct page，即物理页描述符共用，只是有一些 特定的成员不同，但毕竟 slab 描述符含义上来说也是表示一个或多个联系的物理页。 只是这些物理页中可以再此进行划分为小的内存块。\nslab 算法称这些小的内存块为object, 对象, 每个kmem_cache中的所有 slab 中的所有 object 的大小都是一致的。\nslab所指向的连续物理页中的内容=（一大堆 object +辅助快速定位 object 的结构）。 [图]\n这个结构就差不多了，另外，如果让kmem_cache下的所有 slab 都放在一起，不好判断那些 slab 中的 object 已经全部分配了，哪些 slab 是空的？为了方便管理和查找，slab 算法还 封装了一个struct kmem_cache_node结构，组织了三条链表: free, partial, full。 特定状态的 slab 挂在特定的链表上，方便查找。【图】\nReference https://blog.csdn.net/u010923083/article/details/116518248\n","date":"2023-05-20T17:51:49+08:00","permalink":"https://wangloo.github.io/posts/os/linux/mem/slab1/","section":"posts","tags":["linux","Operating System"],"title":"Linux SLAB 内存分配器(1): 概述"},{"categories":["Operating System"],"contents":"软中断、tasklet、工作队列都是中断上下部分离的具体实现方案。\n软中断 我们可以将某些中断配置为软中断，相当于建立一张 INTID 到软中断的映射表，这样在 中断到来时就能判断是否为软中断。\n这张“表”的建立是静态的，即编译时确定的。key 为 INTID，value 为描述一个软中断 的数据结构，在下面会介绍。\n 软中断的服务函数必须是可重入的，即多个 CPU 可以同时执行同一个 softirq 的处理函数，涉及到的全局结构可以用 spinlock 钳制。\n 表示 softirq 的数据结构 struct softirq_action代表一个软中断，系统中所有支持的软中断组成一个数据 softirq_vec[], 所有的软中断按照优先级来分配下标。\nstruct softirq_action { // 指向softirq的处理函数  void (*action)(struct softirq_action *); }; softirq 的中断流程 在中断的上部，如果识别到当前中断是一个 softirq， 那么系统会标记一个软中断发生， 即raise_softirq()函数。其做的事情包括:\n 标记某个软中断发生，记录的结构是irq_cpustate_t.__softirq_pending (这个字段使loca_softirq_pending()访问) 唤醒ksoftirqd内核线程，之后介绍  光标记不行，那么什么时候执行它们的服务函数呢？\n几个可能的检查点:(1) 中断退出前 (2)ksoftirq被唤醒时\n如果在检查点发现有标记挂起的 softirq(local_softirq_pending() != 0), 内核调用do_softirq()处理它们：\n 如何in_interrupt()返回非 0， 直接返回。此时代表要么禁用了 softirq，要么当前是 在中断嵌套的环境下，也可能正在执行do_softirq()时中断嵌套的，而do_softirq() 函数是不能嵌套执行的。 调用__dosoft_irq(), 对于local_softirq_pending()的每一位都调用其 softirq_vec[nr]-\u0026gt;action()  这里有个重要的问题，此时处于中断下部，即开中断的情况，所以在处理 softirq 时会有新的 softirq 到来，这里就有两种策略：\n 不断的获取最新的local_softirq_pending(), 直到不再有新的 softirq 产生才返回 忽略新来的 softirq，使其在下次检查点再被处理  这两种方案其实各有利弊，首先第一种方案，提高了 softirq 的响应速度，但如何 softirq 过多或者处理时间太长就会导致用户态线程已知得不到运行；而第二种方案则会增加 softirq 的响应延迟。\n实际上，softirq 的处理函数do_softirq()是采用折中的方案，它会在内部循环检查 10 次 （是可配置的），检查有无新的 softirq 到来。对于那些在循环之后到来的 softirq，那么 唤醒 ksoftirqd 线程来处理剩下的，不延迟用户态的运行。\nksoftirqd 内核线程 ksoftirqd 是一个内核线程，每个 CPU 都有，它的任务是不断检查是否存在挂起的 softirq， 并 执行其处理函数。\nfor (;;) { set_current_state(TASK_INTERRUPTABLE); schedule(); while (local_softirq_pending()) { preempt_disable(); do_softirq(); preempt_enable(); } } ksoftirqd 的优先级较低，这样当do_softirq()循环 10 次还有新的 softirq 时， 唤醒 ksoftirqd 线程不会耽误用户态的执行，但当系统空闲时间，挂起的 softirq 又 会很快得到处理。\ntasklet tasklet 是基于其中一个软中断(TASKLET_SOFTIRQ)构建，其关系有点像线程与用户态 线程之间那种嵌套关系。\ntasklet 的分配可以是运行时确定的(例如使用 insmod)增加新的 tasklet。\n 内核对 tasklet 的服务函数进行了更加严格的控制：不能在多个 CPU 上同时运行同一个类型的 tasklet 函数(不同类型的 tasklet 可以)。，这样就使得 tasklet 服务函数不必非得 实现为可重入的， 简化驱动开发者的工作。\n 表示 tasklet 的数据结构 描述一个 tasklet 的数据结构为tasklet_struct, 成员包括:\nstruct tasklet_struct { // 指向下一个tasklet，所有tasklet链表串联  struct tasklet_struct *next; unsigned long state; // tasklet 对应的处理函数  void (*func)(unsigned long); // func 中可以使用的数据  unsigned long data; }; tasklet 的中断流程 TASKLET_SOFTIRQ的 action 指向遍历所有tasklet_struct的方法，该方法中 执行每个 tasklet 的func()。\n工作队列 工作队列创建了一个内核线程kworker, 原理与ksoftirqd差不多。\n主要的区别是ksoftirqd运行在中断的上下文，因为其调用了do_softirq(), 而中断上下文中是禁用用户抢占的，也就是说不能发生调度(不影响嵌套中断)。\n 中断上下文中禁止抢占的原因是开启了中断嵌套，代价是必须禁止抢占。 如果同时允许中断嵌套和抢占，那么“嵌套的”中断返回时如果发生了调度， 返回别的高优先级的进程去了，此时初级的中断还未结束。如此时在新进程里 又发生了初级类型同样的中断，就很有可能发生数据不一定或者死锁。\n 工作队列是运行在进程的上下文中的，也就是一般情况下。此时当然可以发生 抢占，所以工作队列适用于那种需要中断服务函数需要发生调度的情况， 比如说调用了sleep().\n工作队列 ","date":"2023-05-13T20:51:49+08:00","permalink":"https://wangloo.github.io/posts/os/linux/interrupt/softirq/","section":"posts","tags":["Operating System"],"title":"Linux 中断管理: 软中断/tasklet/工作队列"},{"categories":["Operating System","C Language"],"contents":"linux 内核为创建【用单链表解决冲突的哈希表】设计了专门的数据结构 hlist。\nhlist 整体来说是带头结点的双向链表，头结点的类型为hlist_head, 普通节点 的类型为hlist_node. 为什么要区别两种类型？节约空间， 因为哈希表的 表项类型可以是hlist_head, 它其实不需要prev指针, 比起一般的结点，一个 哈希表能节约一半的空间。\n所以一个哈希表和头结点的结构可表示为:\nstruct hlist_head { struct hlist_node *first; }; struct hlist_head table[TALBE_SZ]; 二象性 任何事物都具有二象性，区分两种类型节约空间的空间，也带了一个问题： 首个hlist_node结点的prev指向哪呢？\n正常情况下肯定毫不犹豫的指向头结点，即hlist_head，但注意此时类型是 不同的，prev不能同时是struct hlist_head*和struct hlist_node *。\n解决方案有两个，首先可以使首个结点的prev=NULL, 这样虽然避免了类型引发的 问题，也能保证功能正确，但是却破坏了一致性，使得操作的复杂度上升，增加了许多 判断分支。\n// delelt a node void del_node(struct hlist_head *head, struct hlist_node *node) { // 这个if 本来是不需要的，甚至参数的head 也不需要传，  // 更好的处理方式见解决方案2  if (node == head-\u0026gt;first) { head-\u0026gt;first = node-\u0026gt;next; } else { node-\u0026gt;prev-\u0026gt;next = node-\u0026gt;next; } if (node-\u0026gt;next) { node-\u0026gt;next-\u0026gt;prev = node-\u0026gt;prev; } } // insert a node void add_node_before(struct hlist_head *head, struct hlist_node *new struct hlist_node *next) { // 这个if 本来是不需要的，参数head也是不需要传递的  if (next == head-\u0026gt;first) { new-\u0026gt;prev = NULL; head-\u0026gt;first = new; } else { new-\u0026gt;prev = next-\u0026gt;prev; new-\u0026gt;prev-\u0026gt;next = new; } new-\u0026gt;next = next; next-\u0026gt;prev = new; 更好的解决方案: **prev 改变struct hlist_node的构成，使用二级指针:\nstruct hlist_node { struct hlist_node *next; struct hlist_node **pprev; }; 使得每个结点的pprev = \u0026amp;(prev_node-\u0026gt;next), 首先类型是统一的，其次删除和添加 都无需额外的分支了。\nvoid del_node(struct hlist_node *node) { *(node-\u0026gt;pprev) = node-\u0026gt;next; if (node-\u0026gt;next) node-\u0026gt;next-\u0026gt;pprev = node-\u0026gt;pprev; } void add_node(struct hlist_node *new, struct hlist_node *next) { new-\u0026gt;pprev = next-\u0026gt;pprev; *(new-\u0026gt;pprev) = new; new-\u0026gt;next = next; next-\u0026gt;pprev = \u0026amp;(new-\u0026gt;next); } Ref:\n **prev 可以提高删除的效率 stackoverflow  ","date":"2023-05-11T20:51:49+08:00","permalink":"https://wangloo.github.io/posts/os/linux/data_struct/hlist/","section":"posts","tags":["c","linux"],"title":"Linux 内核数据结构 hlist"},{"categories":["Operating System"],"contents":"管道属于实现进程间通信的一种方式，正如其名，一个进程在一头读，另一个进程在一头写。\n管道被看做是打开的文件，但在已安装的文件系统中没有相应的实体，即并不是一个 真正的文件。\n管道的创建和使用 可以使用pipe()系统调用来创建一个管道(后面会介绍另一个方式)，其返回一对文件 描述符，一个用来写一个用来读。必须返回两个描述符的原因是： POSIX 只定义了半双工 的管道，所以读写需要两个端口。\n POSIX 另外要求使用一个描述符前需要关闭另一个描述符。 但 Linux 中则可以不关闭， 可以实现全双工，但为了可移植性， 一般还是将另一个先关闭。\n 用ls | more组合命令来解释如何使用pipe()实现通信:\n shell 调用pipe(), 返回 fd3(对应读通道),fd4(对应写通道) 两次调用 fork() 创建两个子进程，由于属于不同的地址空间， 所以操作自己的文件描述符不会影响其他进程，但都指向同一个管道 父进程调用close()关闭这两个文件描述符  第一个子进程执行ls程序，其操作如下，\n 调用dup2(fd4, stdout), 执行文件描述符的拷贝，从此stdout 就代表管道的写通道 由于stdout代表写通道，所以可将 fd3 和 fd4 均关闭 exec()执行ls程序，默认情况下，其输出结果到 stdout， 当下即管道的写通道，即向管道中写了数据  第二个子进程执行more程序，其操作如下：\n 调用dup2(fd3, stdin), 从此stdin代表管道的读通道 同样可以将 fd3 和 fd4 关闭 exec()执行more程序，由于现在stdin就是管道的读通道, 上面的子进程向管道中写了数据，所以stdin现在有数据，more 可以正常输出  popen(): 更简单的 API 当管道的使用是单向的，即某个进程仅仅想知道另一个进程的执行输出，或者 某个进程想把数据灌入到另一个进程的输入。\n此时 Linux C 库中的popen()和pclose()简化使用pipe()中 调用dup2(), close()这些繁琐的步骤。\npopen()接受两个参数: 可执行文件的路径和使用方式 type, 返回 一个指向 FILE 的指针。\npopen()做的事包含:\n pipe()创建一个管道 创建一个新进程，执行:  如果使用方式是 r, 绑定管道的写通道到stdout, 否则绑定读通道 到stdin. 关闭pipe()返回的两个描述符 exec()执行指定的可执行文件   回到父进程，如果使用方式是 r, ·关闭管道的写通道。否则关闭读通道 返回管道剩下的文件描述符地址  这样父子进程就能单向通信了，如何使用方式是 r, 父进程可用popen() 返回的 FILE 来读取可执行文件的输出；相反，父进程可向 FILE 中写数据 到可执行文件的输入。\n因为返回的是 FILE 指针，所以通常配合fprintf(), fscanf(), fgets() 这类函数使用。\npclose()等待popen()创建的子进程结束。\npopen()样例 父进程读\n#include \u0026lt;stdio.h\u0026gt;#include \u0026lt;unistd.h\u0026gt; int main(void) { FILE *fp = NULL; char s1[32], s2[32]; fp = popen(\u0026#34;ls\u0026#34;, \u0026#34;r\u0026#34;); // read the first two files and print their name  fscanf(fp, \u0026#34;%s %s \u0026#34;, s1, s2); printf(\u0026#34;s1 = %s, s2 = %s\\n\u0026#34;, s1, s2); // close the read side of pipe  pclose(fp); return 0; } 父进程写\n#include \u0026lt;stdio.h\u0026gt;#include \u0026lt;unistd.h\u0026gt; int main(void) { FILE *fp = NULL; char s1[32], s2[32]; fp = popen(\u0026#34;wc -l\u0026#34;, \u0026#34;w\u0026#34;); fprintf(fp, \u0026#34;one\\ntwo\\nthree\\n\u0026#34;); pclose(fp); return 0; } ","date":"2023-05-11T20:51:49+08:00","permalink":"https://wangloo.github.io/posts/os/linux/ipc/pipe/","section":"posts","tags":["Operating System"],"title":"Linux 进程间通信(1): 管道"},{"categories":["Operating System"],"contents":"Linux 中其实并不区别进程和线程，都用task_struct来描述，可以说 它们之间的联系大于区别。\n创建进程的接口是fork()， 创建线程的接口是pthread_create()， 但是它们最终都是调用的clone()系统调用， 只是参数不同而已。\n当一个进程/线程发起创建线程的请求时，不像创建进程那样重新申请mm_struct 和打开的文件等结构， 而是直接将指针赋值为父进程的值，所以它和父进程共享同一个 地址空间这些。\n 上面说的父进程，因为没有父线程的概念，如果创建线程的task_struct也是一个 线程，那么它的地址空间也是最终指向某个进程的，所以父亲和新的线程就是同等 地位了。\n 再说说 PID，PID 能够唯一的标识一个进程，一个进程下所有的线程的 PID 都与父进程 相同，那么问题来了，如何标识线程的从属关系呢？\ntask_struct.tgid标识自己所归属的进程 ID，或者叫主线程 ID，反正就是地址空间 的真正来源。 而进程如何知道自己创建了哪些线程呢？， 通过task_struct.children 链表来查找，但这里面即有子进程又有线程，需要过滤。\n 有的地方会使用一个名词 管理线程， 其实就是线程共享的地址空间这些的原主。\n 内核线程 内核线程是一种特殊的进程，当然也是用task_struct来描述，内核线程的特殊点：\n mm成员=NULL，没有用户空间的数据，不能访问用户空间 每个内核线程有私有数据，用set_child_tid成员指向， 是一个struct kthread结构，用to_kthread()来访问私有数据  内核线程也像普通线程一样参与调度，其创建的地方在内核，使用kthread_create() 创建，不能由用户态创建。\n内核线程一般负责执行一些内核任务，比如软中断 就有一个内核线程，来专门执行到来中断的服务函数中不着急的部分。\n","date":"2023-05-10T20:51:49+08:00","permalink":"https://wangloo.github.io/posts/os/linux/process/thread/","section":"posts","tags":["Operating System"],"title":"Linux 进程与线程的关系"},{"categories":["Architecture"],"contents":"ARMv8 与 ARMv7 相比的改动  指令集： 新增 A64 指令集， 但也兼容原来的 A32 指令集 权限等级： AArch64 下新增 EL0-EL3 异常等级，对应 V7 的特权等级 通用寄存器：31 个通用寄存器，V7 15 个 虚拟地址长度：64 位的地址长度，理论支持 256TB 的寻址范围  关于 Spsel 寄存器的使用 linux 内核里，内核（EL1）和用户态（EL0）都使用各自的栈空间，即 spsel 始终为 1。 这种情况下，当内核里时，sp_el0 是可以复用的寄存器。进入内核前保存原值，然后将其保存当前进程 task_strcut 结构体的地址。因为内核中经常会调用 current 宏，这时可以快很多。\natf 中，在 EL3 用 sp_el0 作为运行时栈空间，而 sp_el3 保存一个重要结构上下文的地址。在进入 EL3 时，系统会自动切换到 spsel=1，即 sp_el3，此时 （1）保存当前的上下文到 sp_el3 （2）切换到 sp_el0 当作 c 调用栈 看起来好像是反过来，我能想到的原因是：\n ATF 在 ELF 如果用 sp_el0 指向结构体，在外面有可能被破坏？而用 sp_el3 在外面不会被动  https://developer.arm.com/documentation/ka005621/latest/\n关于 PMU PMU 是一个独立的单元，不和体系结构绑定。而是每个 SOC 都可以不同。比如说 Cortex-A53 实现了 PMUv3 架构，但别的基于 ARMv8 架构的 Soc 可能实现 PMUv4 或者其他版本。\nPMU 内部有六个计数器，所以可以记录六个事件的发生次数。计数器的数值不一定绝对的正确，因为管道的存在，所以一般来说还是通过长时间计数来减弱影响。\nPMU 和 ETM 的区别 记录的事件不同\n PMU：Cache Miss、分支预测失败、TLB Miss 等 ETM：记录分支指令、内存屏障指令等所有指令的执行，包括地址、结果等。 另外还可以记录数据读写的地址、结果（可选）。  记录的粒度不同\n PMU：仅用计数器来记录事件发生的次数 ETM：指令的类型、地址、执行结果等。数据访问也类似。  所以说，ETM 的信息量大，需要专门的缓存机制。而 PMU 只需在定时器结束时记录发生的次数就行， 不需要什么缓存，没有实际的数据流。\n通用寄存器  x0-x7 参数寄存器: Restore function parameters and return vaule. x9-x15 caller-saved 临时寄存器: callee 默认可以直接使用来保存临时变量, 不需要保存和恢复. 如果 caller 在里面存储了非临时信息, 那么在函数调用之前应当由 caller 负责保存. x19-x28 callee-saved 寄存器: callee 应该避免使用. 如果必须要使用，那么在返回前必须恢复. 特殊寄存器:  x8 restore indirect result. Commonly used when returning a struct. x18 platform reserved register. x29 frame pointer register(FP). x30 link register(LR).     All general-purpose register xN is 64-bit width. They all have corresponding wN register using the lower 32-bit of xN. And write to wN will clear the upper 32bit of xN.\n .notice { --root-color: #444; --root-background: #eff; --title-color: #fff; --title-background: #7bd; --warning-title: #c33; --warning-content: #fee; --info-title: #fb7; --info-content: #fec; --note-title: #6be; --note-content: #e7f2fa; --tip-title: #5a5; --tip-content: #efe } @media (prefers-color-scheme:dark) { .notice { --root-color: #ddd; --root-background: #eff; --title-color: #fff; --title-background: #7bd; --warning-title: #800; --warning-content: #400; --info-title: #a50; --info-content: #420; --note-title: #069; --note-content: #023; --tip-title: #363; --tip-content: #121 } } body.dark .notice { --root-color: #ddd; --root-background: #eff; --title-color: #fff; --title-background: #7bd; --warning-title: #800; --warning-content: #400; --info-title: #a50; --info-content: #420; --note-title: #069; --note-content: #023; --tip-title: #363; --tip-content: #121 } .notice { padding: 18px; line-height: 24px; margin-bottom: 24px; border-radius: 4px; color: var(--root-color); background: var(--root-background) } .notice p:last-child { margin-bottom: 0 } .notice-title { margin: -18px -18px 12px; padding: 4px 18px; border-radius: 4px 4px 0 0; font-weight: 700; color: var(--title-color); background: var(--title-background) } .notice.warning .notice-title { background: var(--warning-title) } .notice.warning { background: var(--warning-content) } .notice.info .notice-title { background: var(--info-title) } .notice.info { background: var(--info-content) } .notice.note .notice-title { background: var(--note-title) } .notice.note { background: var(--note-content) } .notice.tip .notice-title { background: var(--tip-title) } .notice.tip { background: var(--tip-content) } .icon-notice { display: inline-flex; align-self: center; margin-right: 8px } .icon-notice img, .icon-notice svg { height: 1em; width: 1em; fill: currentColor } .icon-notice img, .icon-notice.baseline svg { top: .125em; position: relative }    Caller-saved\u0026amp;callee-saved   Caller-saved 寄存器又称为临时寄存器, 常用来存放临时变量. 例如 A() 调用 B(), 那么 B() 可以直接使用 caller-saved 寄存器, 也就是说 A() 在调用 B() 之前不会在这些寄存器里保存重要信息(编译器实现), 不能保证调用 B() 前后其值不变. 如果必须要保证, 那么保存和恢复(利用栈)这件事是 A() 来做. Callee-saved 寄存器则相反, 通常持续使用的值会保存到这些寄存器中. 还是拿 A() call B() 来举例. 如果 A() 中的一个变量需要在调用 B() 前后持续有效, 那么它应当保存到 callee-saved 寄存器中. 而且 B() 正常来说不应该动这些寄存器, 如果非得动(例如寄存器不够用), 那么 B() 需要在使用他们的前后进行保存和恢复(利用栈).  异常返回指令（ARM32/64） 当异常处理程序结束后，需要执行异常返回指令恢复进入异常之前的状态。具体来说:\n 恢复发生异常前的 PC 从 SPSR 中恢复 PSTATE 寄存器(现场)  异常返回的指令根据当前执行状态为 AArch32 还是 AArch64 有所不同.\nAArch32 AArch32 的异常返回指令在不同的模式下也有所不同:\n  若异常是在 Hyp 模式下处理: 仅可执行ERET指令从异常返回.\n  若异常是在其他模式下处理, AArch32 提供了以下的异常返回指令:\n ERET 指令 使用带 S 后缀的数据处理指令直接操作 PC(例如, MOVS, PC, LR), 恢复 PSTATE RFE 指令: RFE \u0026lt;Rn\u0026gt;. 从基址寄存器指向的地址依次加载 PC 和 PSTATE LDM 指令: LDM \u0026lt;Rn\u0026gt; {pc..}. 若目标寄存器中包含 PC, 则会同时恢复 PSTATE    AArch64 AArch64 下统一使用 ERET 指令进行异常返回.\n指令格式及用法 ERET ERET 指令自动完成:\n 从 ELR_ELx 中恢复 PC 指针 从 SPSR_ELx 中恢复 PSTATE 寄存器的状态.  LDM(Load Multiple)  格式: LDM \u0026lt;Rn\u0026gt; {registers} 含义: 从基址寄存器\u0026lt;Rn\u0026gt;指向的地址开始依次加载多个寄存器值. 若目标寄存器中包含 PC, 则同时恢复 PSTATE.  例如: LDM \u0026lt;r0\u0026gt; {pc, r1} 等价于:\npc = [r0] r1 = [r0+4] PSTATE = SPSR ;仅当目标寄存器包含PC时自动完成 RFE(Return From Exception)  格式: LDM \u0026lt;Rn\u0026gt;  含义: 从基址寄存器\u0026lt;Rn\u0026gt;指向的地址依次加载 PC 和 PSTATE.  例如: RFE \u0026lt;r0\u0026gt; 等价于:\npc = [r0] PSTATE = [r0+4] Armv8.2 SPE SPE 的全称为 Statistical Profiling Extension, 统计分析扩展， 是 Armv8.2 引入的一个特性。\nPMU 能统计事件发生的次数，但是无法直到是哪一条指令导致的。 采样因为要通过中断的方式，所以准确性不高，太高的准确率会造成系统很大的负担。 因此开发者一般只能确定是哪一个函数，但是确定哪一行就比较困难。\nSPE 就是通过硬件的方式解决这个问题，直接在流水线上对指令进行采样。 用硬件对性能的损耗就会很低。\n有个计数器，没取指一次，计数器-1，减到 0 之后的指令就是要采样的指令。\n采集的指令非常全面：时间戳、PC、指令的分类、运行的时间等。\n采集之后，可以做一次过滤，只保存关心的事件（执行时间大于几个 Cycle？指令类型 lr/str？）\n保存的 buffer 满了之后，触发中断，软件读取。\n借助 perf 使用 SPE  FEAT_SPE Armv8.2 Support from 4.14 and 5.3 FEAT_SPEv1p1 Armv8.5 Only support from 5.11  perf list | grep arm_spe_0 perf record -e arm_spe_0/branch_filter=1,ts_enable=1,pct_enable=1,pa_enable=1,\\ load_filter=1,jitter=1,store_filter=1,min_latency=0/ -- ./user.app perf report -D -i perf.data  Arm 架构下性能分析与优化介绍-云视频-阿里云开发者社区  ","date":"2023-05-09T21:19:01+08:00","permalink":"https://wangloo.github.io/posts/arch/armv8/introduce/","section":"posts","tags":["arch","armv8"],"title":"ARMv8 基础"},{"categories":["C Language"],"contents":"C++几乎是 C 的超集，只有很少的 C 的特性在 C++中不支持\nC++增加了需要方便实现面向对象特性的语法和封装，当然这些用 C 应该也能实现， 只不过 C++使其实现起来更简单。\n C++ 改进了一些 C 中的缺点，比如 new 自动计算大小避免出错 C++ 增加一些语法糖，比如迭代器等 C++ 原生支持一些方便的库文件，比如 STL 库  ","date":"2023-05-09T20:51:49+08:00","permalink":"https://wangloo.github.io/posts/c/c_and_cpp/","section":"posts","tags":["c"],"title":"C 和 C++ 的区别与联系"},{"categories":["Dwarf"],"contents":"想要描述一个变量，必须知道它类型信息，才能知道变量的大小、输出的格式等。\nDwarf 为 C 语言定义了一些描述数据类型的 DIE，包括 basetype, array,pointer, structure\u0026hellip;\nbasetype 今天我们先介绍最简单的 basetype。\nbasetype 是指那些 C 语言自身定义的基础类型，像int, double这些。\nbasetype 类型的 DIE 通常有属性:\n DW_AT_name: basetype 的名称 DW_AT_byte_size: 该 basetype 占空间大小  下面给出描述int和double的 DIE 展示(还是通过objdump工具输出）：\n\u0026lt;1\u0026gt;\u0026lt;43\u0026gt;: Abbrev Number: 3 (DW_TAG_base_type) \u0026lt;44\u0026gt; DW_AT_byte_size : 4 \u0026lt;45\u0026gt; DW_AT_encoding : 5\t(signed) \u0026lt;46\u0026gt; DW_AT_name : int \u0026lt;1\u0026gt;\u0026lt;60\u0026gt;: Abbrev Number: 4 (DW_TAG_base_type) \u0026lt;61\u0026gt; DW_AT_byte_size : 8 \u0026lt;62\u0026gt; DW_AT_encoding : 4\t(float) \u0026lt;63\u0026gt; DW_AT_name : (indirect string, offset: 0x9): double Array 数组表示为 DW_TAG_array 的 DIE，通常含有属性:\n DW_AT_type： 指向数组元素的 DIE  数组的长度信息如何表示呢？每个 array DIE 的每个 child 都代表一个维度信息，最左边的 child 描述第一个维度信息。\n描述维度信息的 DIE 为 DW_TAG_subrange_type, 其包含两个属性:\n DW_AT_type: 指向所属 array 的 DIE DW_AT_upper_bound: 表示数据在该维度下的长度, 数值是-1 的  所以要得到一个数组的总长度，需要遍历其 DIE 的所有 child。\n下面给出一个二维数组int var_array[3][5]的相关 DIE 信息:\n\u0026lt;1\u0026gt;\u0026lt;43\u0026gt;: Abbrev Number: 3 (DW_TAG_base_type) \u0026lt;44\u0026gt; DW_AT_byte_size : 4 \u0026lt;45\u0026gt; DW_AT_encoding : 5\t(signed) \u0026lt;46\u0026gt; DW_AT_name : int \u0026lt;1\u0026gt;\u0026lt;4a\u0026gt;: Abbrev Number: 4 (DW_TAG_array_type) \u0026lt;4b\u0026gt; DW_AT_type : \u0026lt;0x43\u0026gt; \u0026lt;4f\u0026gt; DW_AT_sibling : \u0026lt;0x60\u0026gt; \u0026lt;2\u0026gt;\u0026lt;53\u0026gt;: Abbrev Number: 5 (DW_TAG_subrange_type) \u0026lt;54\u0026gt; DW_AT_type : \u0026lt;0x60\u0026gt; \u0026lt;58\u0026gt; DW_AT_upper_bound : 2 \u0026lt;2\u0026gt;\u0026lt;59\u0026gt;: Abbrev Number: 5 (DW_TAG_subrange_type) \u0026lt;5a\u0026gt; DW_AT_type : \u0026lt;0x60\u0026gt; \u0026lt;5e\u0026gt; DW_AT_upper_bound : 4 \u0026lt;2\u0026gt;\u0026lt;5f\u0026gt;: Abbrev Number: 0 ","date":"2023-05-09T16:51:49+08:00","permalink":"https://wangloo.github.io/posts/binary/dwarf/1_basetype/","section":"posts","tags":["Dwarf"],"title":"Dwarf(2): basetype类型"},{"categories":["Dwarf"],"contents":"Dwarf 把源文件中每个可描述的模块（例如函数，变量，结构体的声明等）描述为一个 DIE (Debugging Information Entry)，所以每个源文件可以描述为若干 DIE 的组合。\n每个 DIE 由一个 tag 和若干 attribute-val 键值对构成:\n tag: 描述此 DIE 的类型 attribute-val: 描述此 DIE 的一些细节属性，项目根据 DIE 的类型不同而有差别  各个 DIE 之间会相互联系，一个 DIE 可能含有 parent，若干的 child 和 sibling， 它们之间组成树的结构。\n查看一个 ELF 的所有 DIE ELF 文件中的所有 DIE 存储在.debug_info section 中，通过 GNU utils 中的objdump工具 可以解析为可阅读的结构:\nobjdump --dwarf=info \u0026lt;file\u0026gt; 若我们有一个 demo.c 如下:\nvoid func(void) { int var_local; } 编译为可执行文件后， 执行上述的objdump命令， 可以得到如下的输出（节选）：\n\u0026lt;1\u0026gt;\u0026lt;68\u0026gt;: Abbrev Number: 5 (DW_TAG_subprogram) \u0026lt;69\u0026gt; DW_AT_external : 1 \u0026lt;69\u0026gt; DW_AT_name : (indirect string, offset: 0x32): func \u0026lt;6d\u0026gt; DW_AT_decl_file : 1 \u0026lt;6e\u0026gt; DW_AT_decl_line : 3 \u0026lt;6f\u0026gt; DW_AT_decl_column : 6 \u0026lt;70\u0026gt; DW_AT_prototyped : 1 \u0026lt;70\u0026gt; DW_AT_low_pc : 0x1129 \u0026lt;78\u0026gt; DW_AT_high_pc : 0xb \u0026lt;80\u0026gt; DW_AT_frame_base : 1 byte block: 9c (DW_OP_call_frame_cfa) \u0026lt;82\u0026gt; DW_AT_GNU_all_call_sites: 1 \u0026lt;2\u0026gt;\u0026lt;82\u0026gt;: Abbrev Number: 6 (DW_TAG_variable) \u0026lt;83\u0026gt; DW_AT_name : (indirect string, offset: 0x28): var_local \u0026lt;87\u0026gt; DW_AT_decl_file : 1 \u0026lt;88\u0026gt; DW_AT_decl_line : 4 \u0026lt;89\u0026gt; DW_AT_decl_column : 9 \u0026lt;8a\u0026gt; DW_AT_type : \u0026lt;0x43\u0026gt; 上述例子中节选了两个 DIE，分别是函数func()和局部变量var_local, 可以看到它们的 tag 是不同的，且都具有一系列属性。\n并且，值得注意的是，这两个 DIE 的关系可以从首列\u0026lt;\u0026gt;中的数字得知，数字代表 DIE 构成树的 深度，此例子中\u0026lt;1\u0026gt;下面紧靠的\u0026lt;2\u0026gt;就表示\u0026lt;2\u0026gt;是\u0026lt;1\u0026gt;的 child。理论上也是如此，因为局部变量 是属于对应的函数体的。\n小结 之后的章节打算介绍 Dwarf 是如何描述源文件中的不同对象的(函数,变量,数据类型等)\n","date":"2023-05-09T15:51:49+08:00","permalink":"https://wangloo.github.io/posts/binary/dwarf/0_basic/","section":"posts","tags":["Dwarf"],"title":"Dwarf(1): 基础"},{"categories":["C Language"],"contents":"内存对齐为何被需要 架构规定了数据类型大小的同时，也规定了对这些类型的变量合法访问的对齐要求。 也就是说，变量不能随便的放在内存的任意位置，起始地址必须满足特定的对齐要求， 对不满足要求的变量强行访问就叫做非对齐访问， 非对齐访问通常会触发异常。\n一般数据类型的对齐要求 对于一般的数据类型，比如 int, long, char 这些，要求其变量地址对齐到自身大小， 比如 ARM64 中，int 变量的地址必须对齐到 4 字节，long 变量地址必须对齐到 8 字节等等。\n那么对于*(int *)0x1001 = 1234;, 这类的内存访问就叫非对齐的内存访问。\n 即 （变量 addr % 变量 size) ！= 0, 就称为非对齐内存访问。\n 结构体的对齐要求 上面说的还都是一般的数据类型，对于结构体这种复杂的类型，对齐的要求也复杂些。\n 首先是结构体成员，每个成员都必须满足其自身的对齐要求 然后是结构体变量自身的起始地址的对齐要求是其所有成员的最大对齐要求。  然而两个要求均满足有时候根本不可能，比如一个结构体声明为:\nstruct foo { char mem1; int mem2; short mem3; }; 不可能同时做到 foo 变量和其成员 mem2 同时满足对齐到 4 字节，所以编译器会依据 上面的两条要求在成员之间添加 padding。\n除了变量中间添加 padding 外，在末尾也会添加，使得结构体数组容易满足对齐需求。\n最后 foo 变量在内存中的样子可能是:\nstruct foo { char mem1; char _pad1[3]; // 保证结构体和成员均对齐正确  int mem2; short mem3; char _pad2[2]; // 保证【结构体数组】对齐正确 };  若结构体的成员还是一个结构体，嵌套操作就可以了，编译器可以 handle。\n  对于结构体的定义来说，若不想添加 padding，可以使用__attribute((packed)) 来声明。 常用于一些数据包的声明，除非你清楚自己为什么要这么做，要不别用。\n 如何做到内存对齐 上面一节说明了各个类型的变量对于内存对齐的需求，只要是各个类型变量的地址满足要求了， 对所有变量的访问也就 OK 了。那么如何保证每个变量地址都满足需求呢？\n对于静态分配的变量，即在编译链接时期就能确定地址，由编译器完成这项工作。编译器保证 分配给这些变量的地址是满足对齐要求的，这个完全不用担心。\n对于运行时动态分配的变量，例如malloc()接口返回的，其实 malloc 本身不知道要申请 空间的对齐规则，因为它只接受一个 size 作为参数。 所以一般来说，为了保证满足所有的 对齐要求，malloc() 返回的地址总是满足最大的对齐请求，即指针的大小 8 字节。\n malloc() 的实际效果与运行库的实现有关，并不是规定死的。不过我还没有见过不是 按照最大对齐要求分配的实现方法:)\n AArch64 对非对齐访问的支持 非对齐访问的结果是架构定义的， 不同的架构可能造成的结果不同：\n 架构可能支持非对齐访问，成功读取数据 架构不支持非对齐访问，产生异常  AArch64 架构支持 16、32、64 和 128 位的非对齐访问，但是有几个前提条件:\n 关闭系统的对齐检查: SCTLR_ELx.A bit 来控制 exclusive load/store 和 load-acuqire/store-release 两类指令必须是对齐访问的 。这就表示构建信号量和其他锁机制时必须是对齐访问的 非对齐访问仅“普通内存”可用，\u0026quot;Device memory\u0026ldquo;必须是对齐访问的   AArch64 非对齐访问的原理是分解为多次的访存，所以不能保证原子性，且性能是较差的。\n  虽然 AArch64 支持非对齐访问， 但编译器默认还是会生成满足对齐要求的代码。\n ","date":"2023-05-08T17:19:44+08:00","permalink":"https://wangloo.github.io/posts/c/alignment/","section":"posts","tags":["arm64","c","Operating System"],"title":"C 语言的内存对齐要求"},{"categories":["TODO"],"contents":"当进程被创建时，就预留了一块特殊的线性区，其开始地址和结束地址单独保存在 mm_struct.start_brk和mm_strcut.brk成员中，并不由vm_area_struct 链接，这块特殊的线性区就叫堆。\n进程使用的malloc()和free()等相关 API 都是操纵的堆空间。\n修改堆空间的接口 对用户态进程来说，提供brk()系统调用来修改自身的堆空间。\nbrk(): 参数addr, 效果是修改mm_struct.brk到 addr，即修改一个堆的结束地址。\nbrk() 系统调用的实现，在内核态是调用do_mmap()扩充堆，或者do_unmap()缩小堆。 并且移动mm_struct.brk的值而已，这是 brk()的实现。\n 用户态进程还有一个接口: sbrk(), 参数是字节，代表扩充的字节数。 其下层还是调用的 brk()。\n malloc()的实现 进程刚创建时，堆空间的大小为 0， 即bkr==start_brk。\n调用malloc()，即对堆空间扩充，上面介绍了修改堆空间的接口， 所以我们可以使用brk()来实现malloc().\n对于进程本身来说，只能通过brk()简单的增加/减少堆的总大小，这样做的效率是比较低的。 比如连续执行了三次malloc(), 如果要将中间的地址 free 掉，其实是无法实现的。\n而且这种最简单的情况下，每次malloc()都要使用brk()系统调用，效率也是很低的。\n所以，通常在 C 库则一层，即malloc()和brk()之间，会有一层对堆内存的管理， 包含碎片回收，内存池等算法来避免频繁的使用系统调用。\n","date":"2023-05-08T10:51:49+08:00","permalink":"https://wangloo.github.io/posts/os/linux/addrspace/heap/","section":"posts","tags":["Operating System"],"title":"Linux 进程地址空间 堆的管理"},{"categories":["Operating System"],"contents":"当前存在的问题 未启用写时复制时，fork()创建子进程地址空间的流程如下:\n 动态申请子进程的页表 动态申请子进程的物理页面，大小和父进程的相同 创建父进程虚拟地址-新物理页的映射到子进程页表 memcpy()将父进程所有页面拷贝到子进程地址空间下  这样做有什么问题呢？ 在fork()的常规调用环境下，fork()之后 接的一般是exec()类函数，即载入一个新的可执行文件，继续用父进程 的情况不多。\n这样的话，上述过程中memcpy()父进程的页面就是多余的，而且如果 父进程比较大，会非常耗时。\n写时复制的优化 执行 fork() 时，不给子进程分配新的物理页，而是将父进程的页表项 完全的拷贝到子进程中，结果就是父子进程的虚拟地址指向同一个物理地址。\n换句话说，这样做就不需要memcpy()父进程所有的页面，仅仅是memcpy()一份 父进程的页表，给子进程用。\n 那么是否连新页表都不申请，直接用父进程的页表？\n显然是不行的，因为本质上父子进程拥有不同的地址空间， 最后都要分隔开（无论是否执行exec()），所以没必要 推迟页表的申请，本身不怎么耗时。\n但是创建线程时，确实使用同一张页表。\n 当然，仅设计到这步是不行的，因为按理来说父子进程是独立的，对子进程的 修改不应该影响父进程的地址空间。\n所有，在 copy 完页表后，会将父子进程的所有地址空间（实际是页表项）设置 为只读属性，当父/子进程尝试修改地址空间时，触发异常，配合特定的 异常处理机制，为其创建一个新的屋里也，拷贝原来的+执行修改。\n下图是对上述情况的描述，仅给出一个页面的示例，可以推广到整个地址空间：\nVMA VMA ┌───────┐ │ ┌───────┐ Parent │ │ │ Parent │ │ │ │ │ │ │ ├───────┤ │ ├───────┤ │ ├────┐ │ │ ├────┐ ├───────┤ │ PMA Write │ ├───────┤ │ PMA │ │ │ ┌───────┐ ────┼───► │ │ │ ┌───────┐ │ │ │ │ │ │ │ │ │ │ │ │ │ │ │ │ │ │ │ │ │ │ └───────┘ │ ├───────┤ │ └───────┘ │ ├───────┤ ├────►│ │ Read │ └────►│ │ RW ┌───────┐ │ ├───────┤ only │ ┌───────┐ ├───────┤ Child │ │ │ │ │ │ Child │ │ │ │ │ │ │ │ │ │ │ │ ├───────┤ ├───────┤ │ │ │ │ ├───────┤ ┌─►│ │ RW │ ├────┘ └───────┘ │ │ ├───────┘ ├───────┤ ├───────┤ │ ├───────┤ │ │ │ │ │ │ │ └───────┘ │ │ │ │ │ │ │ │ │ │ └───────┘ │ └───────┘ │ 这样就完美了吗 实际上不是的，拷贝父进程的页表和vm_area_struct就不占内存了吗？\n当页表是稀疏的，vm_area_struct的数量过多时，其本身的数据结构 就会占用很大的空间。\n就 AArch64 来说，针对页表过大的问题，提供了 2M 和 1G 的巨型页(Huge Page) 可供选择，能在申请大而稀疏的页面时显著的减少页表的大小，同时也增加了 TLB 的 命中率，因为同样大小的内存大页只需要一个 TLB 表项即可。\n然而，还有一种情况更加严重，若fork()后父进程写了地址空间的内容， 如上所说就要拷贝这些物理页面，此时如果写的页面过多可能发生fork()到exec() 那一段间隔时间里的物理内存占用极高。虽然这种情况极少发生，前提必须是内存 分配稀疏+父进程修改的内存也是稀疏的，但是并不能完全忽略这种情况。\n当然，这个问题不能归根于 COW，而是fork()带来的，fork()应该提供参数 给那些子进程立马调用exec()的场景，就不用拷贝父进程的这些数据结构了。\n","date":"2023-05-08T09:51:49+08:00","permalink":"https://wangloo.github.io/posts/os/linux/addrspace/cow/","section":"posts","tags":["Operating System"],"title":"Linux 进程地址空间 写时复制"},{"categories":["Dwarf"],"contents":"Function dwarf_alloc.c _dwarf_get_alloc() char * _dwarf_get_alloc(Dwarf_Debug dbg, Dwarf_Small alloc_type, Dwarf_Unsigned count) 函数功能: 根据类型申请一块空间\n注意, 申请时大小会多DW_RESERVE, 此函数返回的地址是 mem_alloc()返回的地址+DW_RESERVE\n_dwarf_error() void _dwarf_error(Dwarf_Debug dbg, Dwarf_Error * error, Dwarf_Sword errval) 函数功能 错误处理的函数\n函数流程  判断传入参数error是否为空, 如果为空则跳转到 step 4. 分配一个新的Dwarf_Error空间 将传入的错误信息存入Dwarf_Error, 并将其作为指针返回 error为空时, 一般要在出错时执行一些方法,即 dbg-\u0026gt;de_errhand() 所以, 此时dbg 和 dbg-\u0026gt;de_errhand 必须非空.  dwarf_elf_access.c dwarf_elf_object_access_init() int dwarf_elf_object_access_init(u64 elf_base_addr, int libdwarf_owns_elf, Dwarf_Obj_Access_Interface** ret_obj, int *err) 函数功能 初始化 Dwarf_Obj_Access_Interface 结构\n函数流程  初始化其成员object, 使用的是dwarf_elf_object_access_internals_init方法 申请空间 为成员赋值 为全局变量_dwarf_get_elf_flags_func_ptr赋值, 为获取elf section flags的方法  _dwarf_get_elf_flags_func() static int _dwarf_get_elf_flags_func( void* obj_in, Dwarf_Half section_index, Dwarf_Unsigned *flags_out, Dwarf_Unsigned *addralign_out, int *error) 函数功能 获取elf指定section的flags\ndwarf_original_elf_init.c dwarf_elf_object_access_init() static int dwarf_elf_init_file_ownership(u64 elf_base_addr, int libdwarf_owns_elf, Dwarf_Unsigned access, Dwarf_Handler errhand, Dwarf_Ptr errarg, Dwarf_Debug * ret_dbg, Dwarf_Error * error) dwarf_init_finish.c this_section_dwarf_relevant() static int this_section_dwarf_relevant(const char *scn_name,int type) 函数功能: 通过section name判断该section是否与dwarf相关\nget_basic_section_data() static int get_basic_section_data(Dwarf_Debug dbg, struct Dwarf_Section_s *secdata, struct Dwarf_Obj_Access_Section_s *doas, Dwarf_Half section_index, Dwarf_Error* error, int duperr, int emptyerr ) 函数功能: 填充 Dwarf_Section_s 中一些基本信息, 不包含dss_data, 即section load不在这个函数完成\n_dwarf_load_section() int _dwarf_load_section(Dwarf_Debug dbg, struct Dwarf_Section_s *section, Dwarf_Error * error) 函数功能: 加载一个ELF section, 填充对应的struct Dwarf_Section_s. 其caller一般为_dwarf_load_debug_xxx(), 例如_dwarf_load_debug_info().\n函数流程:\n 检查这个段是否已经被加载了 调用methods-\u0026gt;load_section() 加载section的dss_data 只需要赋值dss_data就行, 因为其他的成员在get_basic_section_data()时候已经完成了  add_debug_section_info() static int add_debug_section_info(Dwarf_Debug dbg, /* Name as seen in object file. */ const char *name, unsigned obj_sec_num, struct Dwarf_Section_s *secdata, /* The have_dwarf flag is a somewhat imprecise way to determine if there is at least one \u0026#39;meaningful\u0026#39; DWARF information section present in the object file. If not set on some section we claim (later) that there is no DWARF info present. see \u0026#39;foundDwarf\u0026#39; in this file */ int duperr,int emptyerr,int have_dwarf, int havezdebug, int *err) 函数功能: 已经确定好某个section是debug相关section的前提下, 填充dbg-\u0026gt;de_debug_sections[]\n★_dwarf_setup() static int _dwarf_setup(Dwarf_Debug dbg, Dwarf_Error * error) 函数功能: 填充dbg中与debug section相关的所有信息\n函数流程:\n 填充dbg中一些字段, 无关紧要 申请所有section的 struct Dwarf_Section_s 循环elf中所有的section, 每次index+1 调用get_section_info(), 获取该段的信息, 存入struct Dwarf_Obj_Access_Section_s 通过名称对比此段是否与dwarf相关, 若非dwarf相关段, 则返回step3 继续解析下一个段头 若属于dwarf相关段, 则将其相关信息添加到dbg-\u0026gt;debug_sections[]数组中 返回step3进行下一段的初始化  dwarf_die_deliv.c dwarf_next_cu_header_d() int dwarf_next_cu_header_d(Dwarf_Debug dbg, Dwarf_Bool is_info, Dwarf_Unsigned * cu_header_length, // Returns the length of the just-read CU header.  Dwarf_Half * version_stamp, // Returns the version number (2 to 5) of the CU header Dwarf_Unsigned * abbrev_offset, // Returns the .debug_abbrev offset from the the CU header  Dwarf_Half * address_size, // Returns the address size specified for this CU, usually either 4 or 8.  Dwarf_Half * offset_size, // Returns the offset size (the length of the size field from the header) specified for this CU  Dwarf_Half * extension_size, // If the section is standard 64bit DWARF then this value is 4. Else the value is zero.  Dwarf_Sig8 * signature, Dwarf_Unsigned * typeoffset, Dwarf_Unsigned * next_cu_offset, Dwarf_Half * header_cu_type, // Returns DW_UT_compile, or other DW_UT value  Dwarf_Error * error); 函数功能: return information on next CU header\n函数流程:\n 计算下一个CU在.debug_info section的offset 检查下一个CU是否之前被解析过 如果是第一次解析这个cu, 构造一个Dwarf_CU_Context, 链接到Dwarf_Debug_InfoTypes中 填充返回参数  _dwarf_next_die_info_ptr() static int _dwarf_next_die_info_ptr(Dwarf_Byte_Ptr die_info_ptr, // start of the DIE  Dwarf_CU_Context cu_context, Dwarf_Byte_Ptr die_info_end, // end of CU the die belong to  Dwarf_Byte_Ptr cu_info_start, // start of CU  Dwarf_Bool want_AT_sibling, Dwarf_Bool * has_die_child, Dwarf_Byte_Ptr *next_die_ptr_out, Dwarf_Error *error) 函数功能: 这个函数功能分为两部分, 取决于传入参数want_AT_sibling\n if true, 且DIE有AT_sibling属性, 则其返回指向sibling DIE开始位置的指针. 如果没有属性, 则表现的行为像false if false, 返回指向下一个紧邻的DIE的指针?  true时的函数流程:\n 解析出传入DIE的attr和attrform, while解析到attr=AT_sibling停止 再根据attrform解析出attr的value, 即 sibling 的 offset cu_info_start + offset 即为 sibling 的开始  dwarf_siblingof_b() int dwarf_siblingof_b(Dwarf_Debug dbg, Dwarf_Die die, Dwarf_Bool is_info, Dwarf_Die * caller_ret_die, Dwarf_Error * error) { 函数功能:\n 首先这个函数的功能分为两部分, 如果传入参数die=NULL, 那么函数的功能是返回当前读取cu的DIE_cu; 如果die!=NULL, 那么函数的功能是返回指定die的sibling DIE  在die!=NULL时, 函数流程为:\n 调用 _dwarf_next_die_info_ptr 得到 sibling的 global offset 申请一个新的 Dwarf_Die, 填充相应字段  dwarf_offdie() int dwarf_offdie(Dwarf_Debug dbg, Dwarf_Off offset, Dwarf_Die * new_die, Dwarf_Error * error) 函数功能: 给定一个global offset(不是相对于cu的), 返回其对应的Dwarf_Die描述体.由caller 负责调用dwarf_dealloc()释放空间\nStructure Dwarf_Error typedef struct Dwarf_Error_s* Dwarf_Error; struct Dwarf_Error_s { /* 等效于error */ Dwarf_Sword er_errval; /* If non-zero the Dwarf_Error_s struct is not malloc\u0026#39;d. To aid when malloc returns NULL. If zero a normal dwarf_dealloc will work. er_static_alloc only accessed by dwarf_alloc.c. If er_static_alloc is 1 in a Dwarf_Error_s struct (set by libdwarf) and client code accidentally turns that 0 to zero through a wild pointer reference (the field is hidden from clients...) then chaos will eventually follow. */ int er_static_alloc; }; struct Dwarf_Obj_Access_Section_s Used in the get_section interface function\nstruct Dwarf_Obj_Access_Section_s { /* addr is the virtual address of the first byte of the section data. Usually zero when the address makes no sense for a given section. */ Dwarf_Addr addr; /* Section type. */ Dwarf_Unsigned type; /* Size in bytes of the section. */ Dwarf_Unsigned size; /* Having an accurate section name makes debugging of libdwarf easier. and is essential to find the .debug_ sections. */ const char* name; /* Set link to zero if it is meaningless. If non-zero it should be a link to a rela section or from symtab to strtab. In Elf it is sh_link. */ Dwarf_Unsigned link; /* The section header index of the section to which the relocation applies. In Elf it is sh_info. */ Dwarf_Unsigned info; /* Elf sections that are tables have a non-zero entrysize so the count of entries can be calculated even without the right structure definition. If your object format does not have this data leave this zero. */ Dwarf_Unsigned entrysize; }; struct Dwarf_Section_s 将很多对section相关的描述信息结合到一起\n dss_data 指向这个section的起始地址  struct Dwarf_Section_s { Dwarf_Small * dss_data; Dwarf_Unsigned dss_size; /* dss_index is the section index as things are numbered in an object file being read. An Elf section number. */ Dwarf_Word dss_index; /* dss_addr is the \u0026#39;section address\u0026#39; which is only non-zero for a GNU eh section. Purpose: to handle DW_EH_PE_pcrel encoding. Leaving it zero is fine for non-elf. */ Dwarf_Addr dss_addr; Dwarf_Small dss_data_was_malloc; /* is_in_use set during initial object reading to detect duplicates. Ignored after setup done. */ Dwarf_Small dss_is_in_use; /* If this is zdebug, to start data/size are the raw section bytes. Initially for all sections dss_data_was_malloc set FALSE and dss_requires_decompress set FALSE. For zdebug dss_requires_decompress then set TRUE On translation (ie zlib use and malloc) Set dss_data dss_size to point to malloc space and malloc size. Set dss_requires_decompress FALSE Set dss_was_malloc TRUE */ Dwarf_Small dss_requires_decompress; /* For non-elf, leaving the following fields zero will mean they are ignored. */ /* dss_link should be zero unless a section has a link to another (sh_link). Used to access relocation data for a section (and for symtab section, access its strtab). */ Dwarf_Word dss_link; /* The following is used when reading .rela sections (such sections appear in some .o files). */ Dwarf_Half dss_reloc_index; /* Zero means ignore the reloc fields. */ Dwarf_Small * dss_reloc_data; Dwarf_Unsigned dss_reloc_size; Dwarf_Unsigned dss_reloc_entrysize; Dwarf_Addr dss_reloc_addr; /* dss_reloc_symtab is the sh_link of a .rela to its .symtab, leave it 0 if non-meaningful. */ Dwarf_Addr dss_reloc_symtab; /* dss_reloc_link should be zero unless a reloc section has a link to another (sh_link). Used to access the symtab for relocations a section. */ Dwarf_Word dss_reloc_link; /* Pointer to the elf symtab, used for elf .rela. Leave it 0 if not relevant. */ struct Dwarf_Section_s *dss_symtab; /* dss_name must never be freed, it is a quoted string in libdwarf. */ const char * dss_name; /* Object section number in object file. */ unsigned dss_number; /* These are elf flags and non-elf object should just leave these fields zero. Which is essentially automatic as they are not in Dwarf_Obj_Access_Section_s. */ Dwarf_Word dss_flags; Dwarf_Word dss_addralign; }; struct Dwarf_dbg_sect_s 描述一个debug相关的section\nstruct Dwarf_dbg_sect_s { /* Debug section name must not be freed, is quoted string. This is the name from the object file itself. */ const char *ds_name; /* The section number in object section numbering. */ unsigned ds_number; /* Debug section information, points to de_debug_*member (or the like) of the dbg struct. */ struct Dwarf_Section_s *ds_secdata; int ds_duperr; /* Error code for duplicated section */ int ds_emptyerr; /* Error code for empty section */ int ds_have_dwarf; /* Section contains DWARF */ int ds_have_zdebug; /* Section compressed. */ }; Dwarf_CU_Context typedef struct Dwarf_CU_Context_s *Dwarf_CU_Context; 描述一个CU的内容.\n包含描述 CU header的成员:\n cc_length cc_version_stamp cc_abbrev_offset cc_address_size  cc_debug_offset 是该CU header在section中的offset\ncc_dbg 是该CU所属的dbg\nDwarf_Debug_InfoTypes typedef struct Dwarf_Debug_InfoTypes_s *Dwarf_Debug_InfoTypes; 是一个将.debug_info中所有CU组织起来的数据结构\n de_cu_context 指向刚刚读取到的CU de_cu_context_list .debug_info的所有CU链表 de_cu_context_list_end CU链表的结尾 \u0026hellip;  Dwarf_Die typedef struct Dwarf_Die_s* Dwarf_Die; 描述一个DIE\n di_debug_ptr DIE在section中的offset di_cu_context DIE所在的cu  Dwarf_Abbrev_List typedef struct Dwarf_Abbrev_List_s *Dwarf_Abbrev_List; 描述每个缩写\n abl_code abbreviation code, unsigned LEB128编码 abl_tag unsigned LEB128编码, 对应DIE的tag abl_has_child 指代此DIE是否有子项 abl_abbrev_ptr Points to start of attribute and form pairs in the .debug_abbrev  其他联动方式 struct Dwarf_dbg_sect_s 和 struct Dwarf_Section_s 之间的关系 Dwarf_dbg_sect_s 是外层, 其成员 ds_secdata指向一个Dwarf_Section_s.\n除此之外, 它还包含, 描述section number, 是否包含dwarf信息等成员.\nDwarf_Debug 和 其拥有的 struct Dwarf_dbg_sect_s之间的关系 Dwarf_Debug 中的成员de_debug_sections记录了加载的所有debug相关section, 成员de_debug_sections_total_entries 代表加载的section数量.\n同时, Dwarf_Debug 的成员 de_debug_xxx 是 struct Dwarf_Section_s 类型的, 按照名称记录各个section, 方便直接访问, 不需要遍历 de_debug_sections 来查询\n动态申请的空间何时释放? 我们经常会用到例如 dwarf_offdie(), dwarf_attr() 等接口来返回一个特定的dwarf相关结构. 在其中都调用了 _dwarf_get_alloc() 使用操作系统提供的动态内存分配算法申请一块空间, 那么是否需要我们来控制释放这些空间呢?\n某些API的描述中说, 只要是使用_dwarf_get_alloc使用的空间, 必须由用户显式调用dwarf_dealloc() 释放. 在这个版本的libdwarf中, 这个过程其实是不必要的.\n因为在_dwarf_get_alloc()中其实会将申请的空间记录在 Dwarf_Debug的成员de_alloc_tree中. 所以在dwarf_finish()中会遍历树, 将这些空间依次释放, 所以其实不显式的调用dwarf_dealloc()也不会造成内存泄漏.\n","date":"2023-05-07T14:51:49+08:00","permalink":"https://wangloo.github.io/posts/binary/dwarf/libdwarf_func/","section":"posts","tags":["Dwarf"],"title":"Libdwarf 函数介绍及其实现方法"},{"categories":["Operating System"],"contents":"何为进程地址空间?  进程地址空间的含义是进程能访问的所有虚拟地址, 一般来说可以划分为若干线性地址区域(也称\u0026quot;虚拟内存区域\u0026quot;)。\n每个线性区域由起始地址、长度和属性来描述。\n在进程刚创建时，其地址空间仅包含 4 个线性区，分别是：代码段、数据段、栈区和堆区， 其中堆区的初始大小为 0，栈有一个默认大小。\n 栈区对用户是透明的，所以我们一般将其归于内核管理，并非进程本身。\n 线性区增加的典型情况:\n 使用mmap()为一个文件映射内存空间 创建一个 IPC 共享线性区与其他进程协作 调用malloc()扩张自己的堆区  Linux 描述地址空间的数据结构 在进程的 tcb 中，描述地址空间相关的结构都保存在成员mm中，其类型为struct mm_struct, 其中重要的成员有：\n mmap(struct vm_area_struct*): 指向所有线性区的链表头 mm_rb(struct rb_root): 指向所有线性区对象红黑树的根 pgd(pgd_t *): 指向进程的页表 mmlist(struct list_head): 指向下一个地址空间描述符(所有进程的地址空间描述符 被链接起来)  Linux 描述线性区的数据结构 进程地址空间所有线性区的组织 进程拥有的所有线性区通过单链表串联（按地址排序），\n红黑树优化查找 正常来说，想要查找某个地址是否存在于进程的地址空间，遍历上述链表的效率是 O(n).\n因此，Linux2.6 引入红黑树来优化查找速度， 所有线性区同时组织成一个红黑树， 首部通过mm_struct.mm_rb指向。 然后每个线性区的vm_area_struct.vm_rb 存储节点的颜色和双亲信息。\n现在，当需要插入/删除一个线性区描述符时，用红黑树查找前后元素，再操作链表进行插入。\n分配一个线性区 接口是do_mmap(), 参数为:\n file, offset; 如果有文件映射 addr, len prot; 该线性区的权限  步骤大致包含:\n 用红黑树确定新线性区的前后， 对应find_vma_prepare() slab 分配一个struct vma_area_struct，并初始化 操作链表插入，对应vma_link()  释放一个线性区 接口是do_munmap()\n步骤大致包含:\n 红黑树确定要删除线性区的位置，以及做分割（必要时） 调用detach_vmas_to_unmapped()将其从链表中删除 unmap_region()删除页表项 释放 vma_area_struct 的空间  ","date":"2023-05-07T14:51:49+08:00","permalink":"https://wangloo.github.io/posts/os/linux/addrspace/addrspace/","section":"posts","tags":["Operating System"],"title":"Linux 进程地址空间 概述"},{"categories":["Operating System"],"contents":"Linux 为什么要引入信号? 信号是用户进程感知外部事件的一种方式。内核可以发送信号给用户程序，当然用户程序之间也可以互相发送信号，进程通过对某个信号绑定Handler实现对信号的响应。\n所以说信号也属于进程通信的一种方式，但是这种通信比较简单直接，目标进程只能知道信号来源的PID，无法直接附带其他数据。\n信号传递的原理 每个进程的TCB里都有一条链表存该进程等待的所有信号，给某个进程发送信号就表示为挂一个节点到目标进程的此链表上，内核发送信号当然可以直接操作，进程之间的话会转换成系统调用间接完成。当目标进程被调度时会检查并处理等待的所有信号。\n 目标进程只能同时有一个同种类型的信号处于挂起状态，也就是说，如果上一个同种信号没有被处理，那么之后到来的同类信号会被忽略。\n 更详细的说，这个信号的队列（链表）不止一条，分为进程组共享和进程私有的挂起队列。 才能实现某些信号是发送给整个进程组的，比如kill()，而一些是指定某个进程的， 比如tkill().\n信号被处理 对目标进程来说，它可以提前设置自定义的handler，所以在其TCB中还需要记录对于每个信号的处理方式。可能有三种：ignore, default handler, user-defined handler。\n当进程被调度获得CPU时，在返回用户态执行代码之前会检查是否有挂起的信号。如果有则执行对应的handler。\n 这个过程对应内核函数do_signal()。\n 有一个问题是，自定义的信号处理函数是在用户态的, 而do_signal()是发生在 内核态，所以内核要做一些特殊的操作：\n 创建一个临时的用户栈，不能破坏保存的原来用户态环境 ELR(返回地址) = 自定义处理程序，和其他的用户态环境构建 返回用户态，CPU 会执行处理函数 执行完毕后，通过之前对用户栈的特殊构建，使得程序接下来会运行一个 syscall (sys_sigreturn), 返回内核态 如上述操作检查完所有挂起的信号 当所有信号都被处理完成后，则恢复用户进程的原有环境，继续执行  ","date":"2023-05-05T20:51:49+08:00","permalink":"https://wangloo.github.io/posts/os/linux/signal/","section":"posts","tags":["Operating System"],"title":"操作系统：信号的由来和实现原理"},{"categories":["Operating System"],"contents":"为何需要同步互斥机制 同步互斥存在的意义只针对多个任务都会修改同一块内存的场景。这块内存也叫临界区， 要求是必须各个任务独占访问的。比如说许多线程都会往 ringbuffer 中填数据， 必须使用同步互斥机制才能保证数据的正确性。\n所以说，在以下的场景中，无需考虑同步互斥：\n 如果你只有1个CPU，该CPU上只运行1一个线程 如果会存在多个线程（可能是多个core或者一个core上的多线程环境），但是他们不会涉及同一块内存 即便是多个线程访问了同一块内存，但是都是读操作   需要同步互斥的场景在OS内核和用户态程序中都很常见：\n 内核中常见的临界资源包括：对内存区域的引用计数操作，或者对调度队列的修改操作等。 用户态那就更不用说了，同步互斥的场景很多，比如典型的读者写者问题(Buffer)  因为OS内核和用户态程序的权限不同，所以实现同步互斥的方案也不太相同。\n 同步互斥的常见方案 per-cpu 变量 OS 内核里有些数据结构如果不需要CPU之间共享，可以定义成per-cpu形式。\n 比如说调度队列，每个CPU只关心自己核上队列的情况，如果想要访问其他CPU的， 比如进程迁移请通过核间通信IPI来做，并不能直接访问。\n  per-cpu 变量通常被安排在不同的 cache line，避免 cache 的频繁刷新\n  优点：多 CPU 之间互不干扰 缺点：  要求逻辑独立， 极少数临界资源可以实现为 per-CPU 形式 需要考虑内核抢占的影响，如果OS内核修改percpu变量时被调度，新的进程也可能修改这个变量。 如果在中断服务函数中可能修改，还需要另外关闭内核中断。    原子操作 如果临界资源只是一个基础类型变量，比如说一个Flag或者引用计数。那么实现同步互斥的逻辑就比较简单。\n我们知道，如果多个CPU同时对一个变量做修改(flag++)，结果是不可知的。这是因为一次修改其实在处理器来看分为三步:\n load mem =\u0026gt; register update register store register =\u0026gt; mem  ISA 会提供一些原子操作的指令，将这三步绑定在一起，一旦有一个core执行了写动作，会对该内存总线独占， 只有此次写入完成后，其他core才能发起写入请求。\n 这就行了？并不是\n原子操作只能排除上面描述的问题出现，但是多CPU情况下的同步互斥还很复杂。比如说，一个Core修改了 这个变量，至于其他core能不能看到这次写操作，就和 memory consistency 和 cache coherence 相关， 实际应用中还需要考虑这些来保证逻辑的正确性。\n 原子操作指令的特权级别是用户级的，也就是说OS内核和用户态程序都可以用，比如说C++就提供了相应的原子操作库函数。\n 缺点：仅适用于临界资源是简单的基础数据类型的情况。当然，复杂操作的同步互斥实现底层也是在原子操作上做封装  锁和信号量 锁的实现底层就是利用了原子操作，锁应用的场景包含OS内核和用户态:\n OS内核:  自旋锁 Spinlock 互斥锁 Mutex 读写锁以及其改进版 RCU   用户态:  Futex（Fast Userspace mutex)     关于信号量\n信号量和锁的本质是相同的，书籍会写信号量是解决同步问题，锁是解决互斥问题。二值信号量就是互斥锁。\n 选择合适的同步互斥机制 (1) 内核中避免使用自旋锁: 获取不到锁的 CPU 会一直死等，浪费 CPU 资源\n(2) 若临界区仅仅是一个共享的整数变量操作，那么用原子操作即可完成，不需要复杂的锁。 例如各类数据结构的引用计数通常声明为 atomic_t。\nReferences  Let\u0026rsquo;s Talk Locks!  ","date":"2023-05-04T20:51:49+08:00","permalink":"https://wangloo.github.io/posts/os/linux/sync/","section":"posts","tags":["Operating System"],"title":"操作系统：同步互斥机制"},{"categories":["Operating System"],"contents":"tracepoint 是 Linux trace system 中 data source 之一， 其 trace 的对象是 kernel，属于一种静态的插桩方法。\n 添加和删除需要手动修改内核源码 可以向上提供接口，可以通过 frontend 来开启或者关闭，也可以自定义数据处理方式 在 disable 时， 仅有一次 if 判断的损耗，所以效率还算高。但缺点是不够灵活。  tracepoint 的组成 看其源码struct tracepoint就能知道它的组成结构：\nstruct tracepoint { const char *name; #define TP_STATE_DISABLE 0 #define TP_STATE_ENABLE 1  int state; // 并非用于注册hook的函数，而是注册hook时的hook  int (*reghook)(void); void (*unreghook)(void); // 在tracepoint触发时将调用的hook  struct tracepoint_hook *hooks; };  name: 是该 tracepoint 的名称 state: 用于控制其开关状态 hooks: 是一系列的函数指针，当 tracepoint hit 时，这些函数会被依次调用 reghook/unreghook: 在注册/注销 hook 时将被调用，可以用来输出一些提示信息  为了提供对 tracepoint 操作的接口，定义一个 tracepoint 时，会同时定义一系列功能函数, 包括：\n 放在内核代码之中的插桩函数；其被调用说明 tracepoint hit， 如果 enable 状态， 则依次执行其 hook 用于注册 hook 的接口；为该 tracepoint 添加新的 hook 注销某个 hook 的接口；  tracepoint 工作原理 类似于一般的日志记录函数， 在合适的位置放置trace_##event()作为“插桩”，运行到 此处代表该做一些事了，至于做什么事不是 tracepoint 该管的。它只能负责提供给你一些接口 ，让你能把“做事”的函数与 tracepoint 联系起来，到时候触发时调用它们。\n这就是上面说的，tracepoint 仅负责 data source 这一部分。\n小结 下一节将介绍如何 Linux trace system 中的数据记录组件，毕竟每次触发都输出到控制台还是 太乱了，而且不是 trace 这个系统的工作内容（log 系统应该是干这个的）。\n","date":"2023-04-23T23:51:49+08:00","permalink":"https://wangloo.github.io/posts/os/linux/trace/tracepoint/","section":"posts","tags":["linux","Operating System","trace"],"title":"Linux Trace(1): Tracepoint"},{"categories":["Architecture"],"contents":"从进入 IRQ/FIQ 中断向量开始，中断处理的完整流程:\n 保存上下文 切换中断栈，为进入“真正的”中断服务程序做准备 执行真正的中断服务程序 恢复之前的上下文  “真正的”中断服务程序 “真正的”意为不算那些对于所有异常、中断来说都相同的“套话” ，只讨论对于中断特有的行为。\n承认一个中断 真正的中断服务程序从接受 CPU Interface 传来的中断 开始算起，这一步的实现通过读取ICC_IAR1_EL1, 返回当前 中断的 INTID。\n拿到 INTID 后，就根据不同的 ID 调用各自对应场景下的服务函数， 比如若 INTID 是对应与时钟中断，那么此步需要清楚状态寄存器、 重新开启时钟定时器。\n标记中断处理完毕 做完相干的事情后，需要将该中断标记为已完成，方便后面的中断进来， 也就是上一节说的优先级下降和中断失效过程。\nGICv3 支持将这两步合为一次操作，实际我们也是这样做的，通过写入 ICC_EOI1_EL1寄存器来完成标记处理完成。此中断的状态也就从 active-\u0026gt;inactive.\n 中断服务程序中，承认中断和标记完成两步操作应该是用 while 循环 包裹起来的。\n反复的读取 IAR、标记中断已完成\u0026hellip; 如果此时该 CPU 上已经没有 中断待处理了，读取 IAR 会返回特殊 INTID: 1023\n 中断的上下部机制 中断服务函数的停留时间应该越短越好，否则影响其他任务占用 CPU，这是老生常谈的。\n以上观点存在的原因是：中断服务函数中是关闭中断的，CPU 只有串行的处理完当前 中断后， 才能继续做下一件事情，即便是高优先级任务也得等待，因为时钟中断被关闭！\n所以 Linux 在 2.6 引入了中断的上下部机制，将整个中断服务函数拆分为上部和下部:\n 上部：那些不能被打断的步骤，比如保存上下文，承认和标记中断完成等 下部：宽松的管理方式，执行过程就算被打断也没关系，指的就是上面说的对应各自中断 应用场景下的服务函数，比如一个按键触发代表的实际行为  ARMv8 如何支持中断上下部 ARMv8 中，进入异常向量是自动关中断的，可执行msr DAIFClr, #imm来手动开启。\n所以说，直到手动开中断之前的所有操作都属于中断的上部。\n那么，应该在何时开启中断呢？我认为分割后的正确中断处理流程应该是：\n 承认一个中断 根据 INTID 标记其应该做的行为，注意只是标记 标记该中断完成 待该 CPU 上的所有中断都完成后，开中断 遍历检查所有标记，如果有待完成的任务在此时执行  上面说的标记和执行过程可以用许多方式实现，包括 softirq, tasklet, workqueue 等， 都属于实现中断上下部机制的实现。\nsoftIRQ softirq 定义了一些中断事件和处理函数，在中断的上半部中，如果 INTID 属于定义的软中断 之一， 则添加标志其处理函数需要被执行，只是标志，并不实际执行。\n当中断服务程序退出之前，会遍历软中断列表中的状态，如果有需要处理的，则调用注册的处理函数。\n注意，软中断处理函数的执行是在中断上下文中，用户进程只能等待中断完成才能有机会被调用， 所以软中断的一个问题是， 如果需要执行的处理函数过多，会导致一般线程长时间不能被调度。\n同样地，因为处理函数的执行在中断上下文，所以也不能执行可能导致进程睡眠的操作， 例如申请锁，可能导致优先级反转。\ntasklet workqueue ","date":"2023-04-13T23:51:49+08:00","permalink":"https://wangloo.github.io/posts/arch/armv8/gicv3/3/","section":"posts","tags":["armv8"],"title":"ARMv8 中断管理(3): 中断服务程序"},{"categories":["Operating System"],"contents":"抢占的含义 抢占指的是强制使一个任务让出 CPU 给其他任务。\n抢占是调度器做的，每次执行schedule()就可能发生一次抢占，所以 抢占发生的地点是内核，也就是schedule()的执行环境。\n用户抢占 与内核抢占相对应的是用户抢占，用户抢占不是指抢占发生的地点，因为 上面说了抢占发生的地点一定是内核。\n所以用户抢占的含义是：抢占的时机是用户态，换句话说就是抢占发生之前， 系统正处于用户态。\n用户抢占的经典场景是时钟中断，用户进程 1 执行的好好地，被时钟中断打断 然后中断返回时执行重调度，选择了新的用户进程 2。其他的可能用户抢占的场景 还有系统调用返回时， 总之是内核返回用户态时都会发生用户抢占。\n内核抢占 启用内核抢占增加了系统中发生抢占的点，即抢占前系统正处于内核。\n当一个进程正处于内核态执行任务时，比如执行mmap()系统调用的任务，在 未开启内核抢占的情况下，中断返回时只可能继续执行当前进程的任务，不会 发生调度。\n当启用内核抢占时，上述情况下若发生中断，系统在退出中断后，即使此时不是 返回用户态，也可以执行schedule()，即可以发生抢占。此之谓内核抢占。\n抢占发生的条件 启用内核抢占之后，其实抢占的过程也不区分用户态和内核态，只要满足条件都会 执行schedule()。\n执行重调度的条件有两个:\n 是否需要重调度? 是否可以重调度?  是否需要重调度也就是何时执行schedule()的问题，大概包含以下的场景:\n 时钟中断 新进程创建 修改进程的 nice 值 中断返回内核态 内核恢复为可抢占(下面会介绍)  然而有一些情况不可以重新调度，比如内核中一些关键的步骤，那些不能被打断的 原子操作。\n在关键步骤之前，需要调用preempt_disable()，此时 linux 会在 tcb 中会改变 preempt_count的值，这个操作不是关闭中断，而是在中断返回时即使有更高优先级的其他进程， 只要该值不符合要求，重调度也不会发生。\n关键步骤执行完，调用preempt_enable()，此时为了去满足关键区域内可能 有新加入的高优先级进程，会调用一次重调度，这也正是上面所说需要重调度的场景之一。\n","date":"2023-04-13T23:51:49+08:00","permalink":"https://wangloo.github.io/posts/os/linux/schedule/kernel_preempt/","section":"posts","tags":["linux","Operating System"],"title":"Linux 内核抢占"},{"categories":["Architecture"],"contents":"一个中断完整的生命周期大概包括:\n 产生中断 中断分发: by Distributor or Redistributor 中断传递: deliver to CPU Interface 中断激活: pending-\u0026gt;active 优先级下降: priority drop 中断失效: active-\u0026gt;inactive  中断的产生 外设传来中断信号，或者处理器触发 SGI， GIC 此时将该中断标记为pending状态。\n中断的分发 中断生命周期中的重要部分，根据中断的类型不同可能由 Distributor 和 Redistributor 负责分发工作。\n分发器查配置得到此中断的优先级，目的 CPU 等信息。此时可能有多个中断想要发往同一 CPU， 优先级决定先分发哪个中断。将其顺利分发目的 CPU 的 CPU Interface\n中断传递 CPU Interface 做最后一步检查，是否满足优先级屏蔽? 是否符合抢占条件?\n如果条件都满足，给 CPU 一个信号，CPU 准备激活中断\nTODO: 关于running priority 和 highest pending priority的解释\n中断激活 CPU 此时将触发 IRQ/FIQ，执行对应的中断服务程序。\n中断服务程序中需要显式的执行一些操作将中断状态由 pending 置为 active。\n 异常向量（中断处理函数）的详细步骤见下一节\n 优先级下降和中断失效  优先级下降和中断的失效可以配置为同时发生，实际中我们也是这么使用的。\nTODO: 何种情况下需要将其分开？\n 中断服务函数结束后，需要执行一些额外的步骤来使中断失效，便于在该 CPU 上 pending 的其他中断能够进来。\n优先级下降意味着降低抢占的优先级限制，允许 CPU 上等待的其他中断进来。\n然后执行中断失效过程，将其状态由 active-\u0026gt;inactive， 至此中断的整个生命周期结束。\n小结 中断激活到中断失效的整个过程都属于中断服务程序的部分，由开发者显式控制， 将在下一节进行介绍。\n","date":"2023-04-12T23:51:49+08:00","permalink":"https://wangloo.github.io/posts/arch/armv8/gicv3/2/","section":"posts","tags":["armv8"],"title":"ARMv8 中断管理(2): 中断的生命周期"},{"categories":["Architecture"],"contents":"ARMv8 中断系统的架构 GIC 的输入为许多的中断线，但输出到 CPU 的只有 IRQ 和 FIQ 两种， 所以就要由 GIC 做中断的分发和过滤工作。\n总体来说，整个中断系统架构从底向上可分为三部分:\n 硬件接口；外设的引脚 中断控制器；桥梁，向下提供引脚连接外设，向上连接 CPU 在合适的时间 触发中断信号，充当中断系统的主管 中断处理函数；GIC 将中断信号传递到 CPU 后，CPU 执行中断处理函数  +-----------+ +-----------+ | Process | | Process | +---------+-+ ++----------+ | | +-+--------+----+ | | | GIC | | | +-------+-------+ | +-------------+----------+ | Peripheral Device | +------------------------+ 中断控制器 GICv3  GIC 的有许多版本，本文皆以 GIC version3 为例介绍, 简称为 GICv3\n 如上所述，GIC 在中断系统中充当“管家”的作用。如果将 CPU 比作老板， 到来的中断比作约见老板的员工，那么 GIC 就是秘书，统筹安排何人何时 与老板谈话。\nGICv3 的组成大概可分为 3 部分:\n Distributor Redistributor CPU Interface  如果将上面架构图中的 GIC 拆开，大概的结构如下图所示。能够注意到除了 GIC 被细分外，外设中断源也划分为两部分，在下面中断分类中会详细 介绍。\n+----------------+ +----------------+ | Process | | Process | +--+----------+--+ +--+----------+--+ | CPU | | CPU | | Interface| | Interface| +----+-----+ +----+-----+ | | +------+-------+ +------+-------+ | Reditributor | | Reditributor +-----+ +----------+---+ +--+-----------+ | | | | +---+-------------+-----+ | | | | | Distributor | | | | | +-----------+-----------+ | | | +---------+--------+ +-------+---------+ |Peripheral Device | |Peripheral Device| | (SPI) | | (PPI) | +------------------+ +-----------------+ Distributor 负责全局中断的分发\nRedistributor Redistributor 是 GICv3 相较于 v2 新引入的部件，在我看来，引入 Redistributor 的 主要原因是: 提高中断相应的效率。 在以前，无论是全局中断还是私有中断都是通过一个 Distributor 分发，如果中断到来的比较频繁，则可能产生延迟。\nRedistributor 就主要负责私有中断的分发，减轻了 Distributor 的负担。\nCPU Interface 物理结构上依附与 CPU，而不是 GIC。主要负责控制中断被 CPU 接收的过程， 即中断状态 pengding , active, inactive 的切换。\n同时， CPU Interface 还负责优先级的过滤，只有符合优先级条件的中断才会被 CPU 响应。 相关的寄存器有ICC_PMR_EL1，ICC_RPR_EL1等\n中断抢占的配置也是由其完成，详见ICC_BPRx_EL1寄存器。\nGICv3 Affinity Rounting GICv3 以前都是用 target-list, 来设置中断到达的目的 CPU，这种方式类似于位图， 以前只有 8bit 来做这个，所以采用 GICv2 的系统最多支持 8 个 CPU。\n而 GICv3 引入了 Affinity value 来支持更多的 CPU，类似于 IP 地址的方法，用 4 个 8bit 来标识。可以写作a.b.c.d\n c: 一般是指某个 cluster d: 转发时会填入 target-list，指定多个 CPU，最多 8 个(下图的形式还没有将d转为targetlist)    所以用 Affinity value 虽然能指定大于 8 个 CPU，但是一次只能发往一个 cluster 内的最多 8CPU。\n GICv3 中断的分类与标识 在使用 GICv3 的系统上，中断被划分为 4 种类型:\n spi: 全局的中断，可以被路由到任意的一个或多个 CPU。一般对应所有 CPU 共用 的外设，例如串口中断。 ppi: 每个 CPU 私有的中断，只能被路由到该 CPU。对应与 CPU 私有的外设中断， 例如 CPU 内部定时器中断。 sgi: CPU 触发的中断，可以被路由到任意 CPU。一般用于核间通信使用。 lpi: message-based interrupts 这里不做介绍.  中断标识: INTID CPU 如何区分当前来的中断是来自哪个外设的中断信号? 答案是通过 INTID，它是 GIC 定义的中断标识符，CPU 通过读取寄存器ICC_IAR1_EL1就能得知当前处理中断的 INTID。\nINTID 按照中断类型分类的, 对照表如下:\n   INTID 中断类型 Note     0-15 SGI 本地的, 不同 CPU 可使用同一中断号代表不同中断   16-31 PPI 本地的   32-1019 SPI 全局的   1020-1023 特殊中断    1056-1119 扩展的 PPI 本地的   4096 – 5119 扩展的 SPI 全局的     扩展中断号的最大值是实现定义的, 可以在GICD_TYPER.IDbits中读取。\n 特殊中断号  特殊中断不需要 end of interrupt or deactivation 过程.\n   1020:\n  1021:\n  1022:\n  1023: 读ICC_IAR1_EL1 返回该值表明当前的 CPU 上没有待处理的中断， 编程时可当做while退出的标志\n  小结 这节主要总结 ARMv8 中断系统的总体架构和 GICv3 的组成结构，下一节将介绍 一个中断的生命周期，即中断的状态转换，以及在此过程中各个组件的作用。\n","date":"2023-04-12T21:51:49+08:00","permalink":"https://wangloo.github.io/posts/arch/armv8/gicv3/1/","section":"posts","tags":["armv8"],"title":"ARMv8 中断管理(1): 架构与GICv3"},{"categories":["Architecture"],"contents":"有了虚拟内存系统之后，MMU 可以抽象出一些可配置的内存属性。\n例如，配置某个虚拟内存区域为不可执行、不被 cache 等，不可执行的属性 有助于防范攻击，不进入 cache 经常划分给外设 Memory-mapped 区域。\n内存属性和内存类型 首先，我们没法直接设置内存类型，我们能设置的是一些细粒度的内存属性字段， 比如说权限(WRX)、cacheable、shareable 等。\n我们说的内存类型也就是某些有意义的属性字段相互组合，ARM 给出了两种内存类型: 普通内存和设备内存。\n  普通内存会启用架构提供的所有优化技术，例如合并访存、乱序执行等。所以 普通内存有最高的性能，但同时不是那么的“安全”，需要底层人员手动使用 内存屏障等手段保证某些情况下的顺序性要求。\n  设备内存，顾名思义，常映射到外设的 Memory-mapped 区域。对于设备来说， 那些提高性能的技术会造成一些问题，例如某些寄存器的配置必须按照顺序， 这时就不能使用乱序执行。设备内存就牺牲了性能，优先保证正确性。\n  配置内存类型也是通过页表项中的其中一个属性字段: AttrIndx[2:0], 它与系统寄存器MAIR_EL1配合实现。\n具体表现为: mair_el1寄存器被划分为 8 个字段，我们为每个字段写入 不同的值可代表不同的内存类型和一些配套属性，具体的真值表可以参见 mair_el1寄存器的描述。\n mair_el1中内存类型配套属性只是属性的一部分，是和设备类型绑定的那部分。\n cacheable\u0026amp;shareable 傻傻分不清 先说 cacheable，一段内存被设置为 non-cacheable 属性说明不会进入 cache， inner-cacheable 是实现定义的，可能指进 L1 cache/L2 cache， outer-cacheable 说明会进入 L3 cache。\n要注意，只有普通内存才支持配置是否进入 cache，所有的设备内存需要 non-cacheable。\n 内存支持配置为是否被 cacheable，这在mair_el1的字段中配置。\n shareable 说的是一块内存的外部可见性，外部不可见并不是真的看不到，只是说不保证值的正确性。\nshareable 属性和 cacheable 其实是有关联的，他们俩比如配合使用，不能随便设置:\n 如果一块内存是 cacheable 的，则需要硬件提供 cache 的一致性维护机制。 如果不能保证 cache 的一致性，想要启用 shareable 就必须是 non-cacheable 对于 non-cacheable 的内存，一定是 shareable 的， 不需要配置。因为此时对数据的修改直接操作内存，读取操作亦是如此，一定 是外部可见的  如何设置内存属性  相关内容可以在 ARMv8 arm 手册 D5.3.3 Attuibute fields in stage 1 VMSAv8-64 Block and Page descriptors 中找到参考\n 对于每一个表示内存块(block)的页表项，都有两个属性字段: lower attr 和 upper attr.\n以下任何类型或者属性的设置都是通过这两个字段完成的。\n","date":"2023-04-12T08:01:33+08:00","permalink":"https://wangloo.github.io/posts/arch/armv8/memory_attr/","section":"posts","tags":["armv8"],"title":"AArch64 内存属性与内存类型"},{"categories":null,"contents":"为什么写 因为平常的工作中很少用到python, 但是不得不承认 python是一门优秀的语言, 对于我目前要准备秋招的情况来看, 有的公司做题如果支持python那会简单很多, 同样的代码,用C写要100行, 换到python最多30搞定.\n有人说C++也可以啊,而且对于常用C的人来说学习门槛更低, 但是我实在是受不了 C++的语法, 包括但不限于模板、迭代器，STL操作，感觉有点四不像的味道。 当然，这只是我的个人习惯，使用C++的人也是很多的，还是根据自己的习惯 选择一套趁手的工具比较好。\n因为我其他时间基本都在用C，所以在本篇文章中我会更多拿C来进行比较，这样更好记忆。\n我学习 Python 的知识点来源:\n 《Python 学习手册 第 4 版》李军等 UCB CS61A  列表 list 列表支持下标索引，所以它就像C语言中的“数组”，列表支持大小动态增长，所以更像“数组plus”，类似C++中的vector吧（不太确定）。\n列表支持定长声明或变长声明，像创建一些flag列表，用下标进行查找时，定长创建就是必要的。\n相关操作 创建一个列表 以下的创建操作都是支持的:\n# 创建一个空列表 lst = [] # 创建一个带有初值的列表 lst = [1, 2] # 创建二维空列表 # 应用的场景是: 按照索引来修改list, 此时如果单纯的初始化list=[], # 那么对list[1].append()会提示超出范围. 所以我们要提前规定list的长度, # 即将list声明为目标长度的二维list. lst = [[] for _ in range(5)] # 创建定长列表并附初值 lst = [0 for _ in range(5)] # 创建二维定长列表并附处置0 lst = [[0 for _ in range(5)] for _ in range(5)] 以下的方式是错误的! 因为每个子列表都指向同一个对象, 修改一个会同步其他的\nlst = [[]] * 5 List 的高级构建方法，充分利用python的灵活性:\n\u0026gt;\u0026gt;\u0026gt; odds = [1, 3, 5, 7, 9] \u0026gt;\u0026gt;\u0026gt; [x+1 for x in odds] [2, 4, 6, 8, 10] \u0026gt;\u0026gt;\u0026gt; [x for x in odds if 25 % x == 0] [1, 5] 其他操作  直接使用 +, *运算符实现多个列表的组合, 与字符串类似 append: 为列表增加一个对象(末尾) pop(pos): 删除列表中的某个元素(按位置)，并返回其值 insert(pos, val): 在列表的任意位置插入对象 remove: 删除列表中的某个元素(按内容) 多级列表是被支持的，像二维数组一样，但是操作比较复杂，一般不使用内置的列表来实现。 \u0026hellip;  Python 内置类型 实例的类型可以通过内置函数type()来查看。\n字符串 定义一个 python 字符串\nS = \u0026#39;Spam\u0026#39; 支持索引其中元素，也支持反向索引（即从右边开始计算），一般来说负的索引号会简单地与字符串的长度相加。\n\u0026gt;\u0026gt;\u0026gt; S[0] \u0026#39;S\u0026#39; \u0026gt;\u0026gt;\u0026gt; S[-1] \u0026#39;m\u0026#39; \u0026gt;\u0026gt;\u0026gt; S[len(S)-1] \u0026#39;m\u0026#39; python 也支持字符串分片操作，左边界的默认值为 0，右边界的默认值为字符串的长度。\n\u0026gt;\u0026gt;\u0026gt; S[1:] \u0026#39;pam\u0026#39; \u0026gt;\u0026gt;\u0026gt; S[0:3] \u0026#39;Spa\u0026#39; \u0026gt;\u0026gt;\u0026gt; S[:-1] \u0026#39;Spa\u0026#39; 字符串对于+操作符的表现是字符串的连接，这体现了 python 的多态性。 字符串创建后无法直接通过索引改变其元素，可以转而通过同名对象覆盖来实现：\n\u0026gt;\u0026gt;\u0026gt; S[0] = \u0026#39;z\u0026#39; Traceback (most recent call last): File \u0026#34;\u0026lt;stdin\u0026gt;\u0026#34;, line 1, in \u0026lt;module\u0026gt; TypeError: \u0026#39;str\u0026#39; object does not support item assignment \u0026gt;\u0026gt;\u0026gt; S = \u0026#39;z\u0026#39; + S[1:] \u0026gt;\u0026gt;\u0026gt; S \u0026#39;zpam\u0026#39; 字符串支持的属性，例如.find()可以通过内置命令 dir(S)来查看。\n dir 函数仅仅给出了方法的名称，如果想查询其具体使用方法，可以利用内置函数help(S.find)。\n string 的三种形式 Python 允许字符串被包括在单引号或者双引号中(它们的含义相同），它也允许在三个引号（单或双均可）中包含多行字符串常量，当 Python 脚本中嵌入像 HTML 这样的内容时，这是很方便的。\n\u0026gt;\u0026gt;\u0026gt; msg = \u0026#34;\u0026#34;\u0026#34; ... aaaaa ... bbbbb ... ccccc ... \u0026#34;\u0026#34;\u0026#34; \u0026gt;\u0026gt;\u0026gt; msg \u0026#39;\\naaaaa\\nbbbbb\\nccccc\\n\u0026#39; 字典 键值对\n支持通过 key 索引来修改， 所以与字符串和列表不同。\n\u0026gt;\u0026gt;\u0026gt; D = {} \u0026gt;\u0026gt;\u0026gt; D[\u0026#39;name\u0026#39;] = \u0026#39;Bob\u0026#39; \u0026gt;\u0026gt;\u0026gt; D[\u0026#39;age\u0026#39;] = 40 \u0026gt;\u0026gt;\u0026gt; D {\u0026#39;name\u0026#39;: \u0026#39;Bob\u0026#39;, \u0026#39;age\u0026#39;: 40} 字典也支持嵌套操作，在 json 中常用\n字典的操作  keys() 返回 key 的列表 value() 返回 value 的列表 item(): 返回(key,value)构成的元组列表  字典的限制  在python3.6之前字典是 unordered, 即存储的顺序不按照加入时间; 而在python3.6+, 字典改为 ordered. key 是唯一的, 如果你想让一个 key 对应多个值, 将其 value 设置为 list 是一种方案! list 只能是 value, 不能是 key  元组 元祖像一个不可改变的列表\n\u0026gt;\u0026gt;\u0026gt; T = (1, 2, 3, 4) \u0026gt;\u0026gt;\u0026gt; T (1, 2, 3, 4) 其专有的方法：\n index(x) 返回 x 所在元组中的下标 count(x) 计算 x 在元组中出现的次数   为什么要使用元组？ 一般来说，元组不如列表那样常用，因为它的不可被改变的特性。但是，这也赋予了元组天然的完整性约束，可应用在期望不会被改变的场景中\n 基础语法 iterator l = [1, 2, 3] k = iter(l) # 得到一个可以遍历的iterator next(k) # get 1 next(k) # get 2 iterator 任何情况下都可以等价于一个 for 循环!\nlist 的 iterator 像是一个 list, 不同的是它存在一个\u0026quot;监视者\u0026quot;会记录你当前所在的位置, 使得你可以调用一些方法(next()) 来得到当前位置的元素, 并监视下一个位置的元素.\n当然, 不仅仅 list 有对应的 iterator, 对于其他数据结构来说亦是如此.\n 如果在遍历k的途中改变了遍历对象的结构(例如lst.append(4)), 该 iterator 将不可再用!\n所以以下代码的行为是错误的:\nlst = [1, 2, 3] for item in lst: if item == 1: lst.remove(1) 可以专门创建一个 lst 的副本用于循环:\nfor item in list(lst): ... 但修改其中的值不影响(例如lst[0] = 0)\n 另一个有趣的事情是: 如果使用list()方法创建一个 iterator 的 list, python 实际的行为是 调用next()直到结尾来得到元素并插入新的 list. 所以下面的代码行为就容易理解了:\nt = iter([1, 2, 3]) list(t) # [1, 2, 3] list(t) # [] Python 内置功能函数 聚合可索引的类型 一些内置的功能函数可以将可索引的参数转换为有意义的数值. 例如 range, list 等.\nsum(iterable[, start]) 返回可索引的参数元素之和(不能是字符串), 加上 start(默认是 0). 当 iterable 为空时, 返回 start\n 为什么要有一个start? 使得如果输入字符串组成的列表(可以是其他可索引的数据结构), 会抛出异常. 详见下面实例\n \u0026gt;\u0026gt;\u0026gt; sum([2, 3, 4]) 9 \u0026gt;\u0026gt;\u0026gt; sum([\u0026#39;2\u0026#39;, \u0026#39;3\u0026#39;, \u0026#39;4\u0026#39;]) Traceback (most recent call last): File \u0026#34;\u0026lt;stdin\u0026gt;\u0026#34;, line 1, in \u0026lt;module\u0026gt; TypeError: unsupported operand type(s) for +: \u0026#39;int\u0026#39; and \u0026#39;str\u0026#39; 其实现的原理是: 保证前面iterable中元素求和的结果与start的类型相同. 例如:\n\u0026gt;\u0026gt;\u0026gt; sum([2, 3, 4], 5) 14 \u0026gt;\u0026gt;\u0026gt; sum([[2, 3], [4]], []) [2, 3, 4] \u0026gt;\u0026gt;\u0026gt; sum([[2, 3], [4]]) Traceback (most recent call last): File \u0026#34;\u0026lt;stdin\u0026gt;\u0026#34;, line 1, in \u0026lt;module\u0026gt; TypeError: unsupported operand type(s) for +: \u0026#39;int\u0026#39; and \u0026#39;list\u0026#39; max max(iterable[, key=func]) -\u0026gt; value max(a, b, c, ...[,key=func]) -\u0026gt; value key是用来预处理数据的, 默认为 lambda x: x\n其他特性 nonlocal声明 使用方法:\nnonlocal \u0026lt;name\u0026gt; 效果: 在声明某个变量为nonlocal之后, 对其所有赋值语句, 都不会建立一个局部的绑定, 而是将该变量重新绑定到当前 frame 向上能找到的第一个非局部 frame中对该变量的绑定.\n简单来说, 就是对该变量的所有赋值操作都改为操作能找到的第一个全局(这个全局是相对的)同名变量. 当然, 如果找不到一个同名全局变量, 就抛出异常.\n下面的例子中, 如果在withdrew()中不将balance声明为 nonlocal:\n if 语句是可以通过的, 因为访问balance会找到当前 frame 的 parent, 即make_withdraw()中声明的balance. 而 python 处理赋值操作就不一样了. 他会默认将balance绑定到局部, 而 这就与 if 语句产生了冲突, 会抛出异常.  所以就需要nonlocal的声明, 告诉 python: 赋值语句也得去上面 frame 中找一个全局的.\n# make_withdraw 建立一个银行账户, 并给出初始金额, # 其返回一个函数withdrew(), 调用该函数的行为是从 # 银行账户里扣款 def make_withdraw(balance): def withdraw(amount): nonlocal balance if amount \u0026gt; balance: return \u0026#39;Insufficient funds\u0026#39; balance = balance - amount return balance return withdraw wd = make_withdraw(20) wd(8) Python 动态类型 对象的垃圾回收 在 Python 中，每当一个变量被赋予了一个新的对象，之前对象占用的空间就会被回收。\n\u0026gt;\u0026gt;\u0026gt; x = 42 \u0026gt;\u0026gt;\u0026gt; x = 3.14 \u0026gt;\u0026gt;\u0026gt; x = \u0026#34;hello\u0026#34; 对象的引用值在此过程中被逐个回收，每次 x 指向一个新的对象，Python 将自动回收原来对象的内存空间。\nPython 使用引用计数来实现该功能。为每个对象维护了一个引用计数器，记录了当前引用该对象的变量数目，一旦计数值变成 0，则其空间被回收。\n深拷贝和浅拷贝 L1 = [2, 3, 4] L2 = L1 产生的结果是， L1 是一个包含了对象 2、3、4 的列表，当然列表自身也是个对象。L1 是一个变量，引用了该列表的对象。运行 L2 的赋值操作后，L1 和 L2 引用了相同的对象。\n此时如果使用索引对 L1 列表的某个元素进行修改，由于 L1 和 L2 引用的是同一个对象，相当于 L2 也做了修改。这就是浅拷贝\n浅拷贝是默认的，如果你希望使用深拷贝，即拷贝对象，而不是创建索引。对于列表来说，可以使用分片来实现\nL1 = [2, 3, 4] L2 = L1[:] 对于其他的内置类型，有的也可以用 X.copy()方法；而且标准库的copy模块有一个通用的赋值任意对象类型的方法，也有一个用于嵌套深拷贝的特殊方法。\nimport copy X = copy.copy(Y) # 只深拷贝top-level X = copy.deepcopy(Y) # 嵌套进行深拷贝 判断相等 基于上述深拷贝和浅拷贝的理论，就有关于 Python 中变量判断相等的方法。 Python 中有两种不同的方法检查变量是否相等：\n == 操作符：测试两个变量引用的对象是否具有相同的值 is操作符：检查对象的同一性，即是否指向同一个对象，是一种更加严格的相等性判断  字符串 特殊字符的转义 字符串中的\\n会被识别为换行符，与 C 语言类似，但 Python 不识别结束符(\\0)\n在字符串第一个引号之前输入r，会关闭转义机制，将反斜杠当做普通字符来保持。常用与 Windows 环境中打开文件\nfile = open(r\u0026#39;C:\\my\\path\\file.txt\u0026#39;, \u0026#39;w\u0026#39;) 索引和分片 分片的常见作用\n处理参数 在系统命令行中启动 python 程序时，获取附加的参数，需要使用内置的 sys 模块中的 argv 属性：\n# file echo.py import sys print(sys.argv) % python echo.py -a -b -c [\u0026#39;echo.py\u0026#39;, \u0026#39;-a\u0026#39;, \u0026#39;-b\u0026#39;, \u0026#39;-c\u0026#39;] 通常你只对跟随在程序名后边的参数感兴趣，这就是分片的典型应用，sys.argv[1:]就能满足你\n处理文件 分片也常常用作清理输入文件的内容。如果知道一行会以换行符结尾，就可以使用line[:-1]，把这行去除最后一个字符之外的内容提取出来。\n 值得注意的是，去除换行符常常推荐采用line.rstrip方法，因为这个方法将会正确的处理最后一行的情况。\n 字符串和其他类型转换 字符串和整数\n\u0026gt;\u0026gt;\u0026gt; int(\u0026#34;42\u0026#34;), str(42) (42, \u0026#39;42\u0026#39;) 字符和 ASCII 码\n\u0026gt;\u0026gt;\u0026gt; ord(\u0026#39;s\u0026#39;) 115 \u0026gt;\u0026gt;\u0026gt; chr(115) \u0026#39;s\u0026#39; 修改字符串 字符串是不可变序列，即不能通过索引来修改。\n若想改变一个字符串，需要利用合并、分片这样的工具来建立一个新的字符串，并将结果赋值给原始字符串变量\nS = S[:4] + \u0026#39;Bureger\u0026#39; 如果不得不对一个超长字符串进行多处的修改，为了优化脚本的性能和代码，可能需要将字符串转换为一个支持原处修改的对象，如 List\n\u0026gt;\u0026gt;\u0026gt; S = \u0026#39;spammy\u0026#39; \u0026gt;\u0026gt;\u0026gt; L = list(S) \u0026gt;\u0026gt;\u0026gt; L [\u0026#39;s\u0026#39;, \u0026#39;p\u0026#39;, \u0026#39;a\u0026#39;, \u0026#39;m\u0026#39;, \u0026#39;m\u0026#39;, \u0026#39;y\u0026#39;] 对于 L 可以使用索引来修改，完成后需要将其转换回字符串，可以使用字符串的join方法来实现:\n\u0026gt;\u0026gt;\u0026gt; S = \u0026#39;\u0026#39;.join(L) Python 中的 sprintf \u0026gt;\u0026gt;\u0026gt; \u0026#39;That is %d%sbird!\u0026#39; % (1, \u0026#39;dead\u0026#39;) That is 1 dead bird 字符串的方法 see Python standard manual\n列表 列表与字典都是其他对象的集合。\n列表能够完成 C 中结构体的工作，不需要手动实现。\nPython 中的列表是：\n 任意对象的有序集合 通过偏移读取 可变长度、异构以及任意嵌套 对象引用的数组。类似与 C 语言中的指针数组  列表实现 LIFO 在某些应用中，会使用列表的pop和append方法，实现快速的 LIFO 对战结构。\n字典 字典可以称作 Python 中最灵活的内置数据结构。字典当中的元素是通过 key 来存取，而不是通过偏移，类似 C++的 map。\n作为内置类型，字典可以取代许多搜索算法和数据结构。有时也能执行其他语言中的记录、符号表的功能，可以表示稀疏（多数为空）的数据结构等。\n字典的主要属性如下：\n 任意对象的无序集合 可变长、异构、任意嵌套 对象引用的散列表。字典的底层实现是散列表，一开始很小，根据要求增长。   列表和字典，不会经常用常量来创建，常使用动态方法\n 用字典模拟灵活的列表 列表对在其末尾外的元素赋值是非法的：\n\u0026gt;\u0026gt;\u0026gt; L = [] \u0026gt;\u0026gt;\u0026gt; L[99] = 1 Traceback (most recent call last): File \u0026#34;\u0026lt;stdin\u0026gt;\u0026#34;, line 1, in \u0026lt;module\u0026gt; IndexError: list assignment index out of range 虽然你可以预先分配足够的大空间，但这种情况用字典更为方便。字典的 key 为整数时，可以效仿列表在偏移赋值时增长：\n\u0026gt;\u0026gt;\u0026gt; D = {} \u0026gt;\u0026gt;\u0026gt; D[99] = \u0026#39;spam\u0026#39; \u0026gt;\u0026gt;\u0026gt; D[99] \u0026#39;spam\u0026#39; \u0026gt;\u0026gt;\u0026gt; D {99: \u0026#39;spam\u0026#39;} 好处是， 此时的 D 仅有一个元素，看上去好像是有 100 个元素。\n字典描述稀疏数据结构 字典创建的方法 共有四种不同的方案：\n{\u0026#39;name\u0026#39;: \u0026#39;mel\u0026#39;, \u0026#39;age\u0026#39;: 45} D = {} D[\u0026#39;name\u0026#39;] = \u0026#39;mel\u0026#39; D[\u0026#39;age\u0026#39;] = 45 dict(name=\u0026#39;mel\u0026#39;, age=45) dict([(\u0026#39;name\u0026#39;, \u0026#39;mel\u0026#39;), (\u0026#39;age\u0026#39;, 45)]) 上面四种方案建立的字典是相同的，它们分别应用与不同的条件：\n 如果你可以事先拼出整个字典，那么第一种是很方便的 如果你需要一次动态地建立字典的一个字段，第二种比较合适 第三种关键字形式所需代码量比较少，但是 key 必须都是字符串才行 如果你需要在程序运行时把 key 和 value 逐步构建成序列，那么用第四种  如今的 Python 代码中，第三种方式比较流行。\n","date":"2023-04-01T10:30:35+08:00","permalink":"https://wangloo.github.io/posts/python/basic/","section":"posts","tags":["Python"],"title":"Python 基础知识"},{"categories":["Operating System"],"contents":"Kconfig 介绍 Kconfig 是一个通用的配置系统，最初由 Linux 开发，提供了一种简单的可扩展的配置语言， 实现工程的模块化和可定制需求。\n在简单的工程中，或许我们使用简单的 C 语言宏就能解决问题，不必用到 Kconfig。 但对于大型项目，并不只是一个选项的开启和关闭，并不只是影响到源代码，还有基于 Makefile 的编译工作。并且，当可配置的选项增加时，开发者手动管理这些配置选项就显得不那么智能了。\nKconfig 的出现使得上述工作变得轻松：\n 在 build 前，我们可以使用图形化界面来选择此次构建启用了哪些编译选项, (menuconfig) 对于不同的厂商驱动，可以有不同的配置文件，厂商可以为我们提供一个默认的 config 文件，我们可以方便的应用这些默认选项进行编译, 或者基于这些默认选项进行改动，保存为自己的配置项文件(defconfig) 选项之间可以建立依赖关系，例如，只有 A 启用时，BCD 选项才有意义。对此 Kconfig 提供了一套简单上手的编辑语言  Kconfig 的使用必须配合 Makefile 进行，应该说，Kconfig 与 Makefile 结合是简化了 Kconfig 的使用步骤。\nKconfig 的使用方法 我们常用的功能大概包括：\n 使用一些默认配置文件来构建项目 自定义配置构建项目 将某套配置选项保存下来，方便下次使用  在分别介绍这些功能的使用方法之前，先得说明这些 Kconfig 中各种配置文件的用途了，还是比较容易混淆的。\n Kconfig: Kconfig 不仅在根目录，还可能存在于各级子目录下。里面的内容是整个 Kconfig 系统的所有配置项，以及每个配置项的默认值、描述等。如果想要添加、删除配置项，需要改动这个文件 xxxdefconfig: xxx 可以替换为任意字符，这些都是默认的配置项，通常由开发人员提供给使用者 .config: 这个文件存在于根目录下，我们可以叫他当前配置。可以把他当为服务与一次构建的“临时文件”，每次构建都是基于当前配置进行的 autoconfig.h: 由 Kconfig 系统根据当前构建使用的配置自动生成的头文件，C 源代码可以通过它来知道当前的配置情况  其实它们之间的关系不是那么复杂，到底是谁根据谁生成的谁，下面将要说明。\n使用默认配置(xxxdefconfig) 一般我们拿到一个 SDK，厂商会提供一些默认的配置项供我们使用。我们的使用方法一般是执行make xxxdefconfig，make 会调用 Kconfig 程序来读取这个 defcofig 文件，然后生成当前配置（即.config）\nxxxdefconfig中的配置项是需要和Kconfig文件配合的，其中的属性和值都是 Kconfig 中支持的配置项。并且，xxxdefconfig 不会记录 Kconfig 每个项目的值，只是记录那些非默认值的变化，这样大大减少了文件大小。\n 以上行为可以通过执行make xxxdefconfig后，查看.config和xxxdefconfig的文件差异来验证\n 改变当前配置 总是使用默认配置可不行，那么怎么修改当前配置呢? 一种显而易见的方法是修改defconfig或者.config，取决于你想你这次更改永远有效，还是只是这次编译有效，其实，最好不要改动厂商给的默认配置，你可以复制一份，然后进行修改。\n这里要介绍与 Kconfig 配合使用的工具——menuconfig，它为我们提供交互式的配置菜单，比面对 Kconfig 的语言来修改配置更加方便。可以把 menuconfig 理解为 Kconfig 的一个前端。\nmenuconfig 的使用方式是执行make menuconfig, 它会加载当前配置的内容（或者是 Kconfig 中定义的默认值），生成一个图形化的菜单，修改后还是保存为.config。每次构建都是使用最新的当前配置，就达到了临时修改配置的效果了。这不比直接修改.config方便多了？\n保存当前配置 有时，我们发现当前这个配置很好，想要将其保存为新的defconfig文件，这样不用每次都修改当前配置了。Kconfig 当然也支持这个功能，叫做savedefconfig。\n使用的方法是:make savedefconfig， 会将当前配置(.config)中的内容提取为一个 defconfig 的文件，保存的位置取决于 Kconfig 的配置（一般是conf.c的源码中），我们对他改个名字就成为自己的配置了。下次执行make xxxdefconfig 即可套用这一套配置\n其他的功能\u0026hellip; Kconfig 提供的功能很多，包括：一键启用所有的配置选项、最小的构建选项等等，但是不常用就不介绍了。\nKconfig 系统的工作原理 上面说道，Kconfig 的使用是需要配合修改 Makefile 的，在 Makefile 会增加几个目标: %defconfig, savedefconfig, menuconfig。 它们向上给用户提供选项，向下调用 Kconfig 系统的功能接口。\nKconfig 系统主要任务是由conf程序完成，它是一个 host 程序，负责解析 Kconfig，defconfig 等文件的内容，完成功能的实现。还有一个重要的程序是mconf，它负责实现 menuconfig 的功能。\n","date":"2023-03-28T16:15:03+08:00","permalink":"https://wangloo.github.io/posts/os/linux/kconfig/","section":"posts","tags":null,"title":"Linux Kconfig 概述"},{"categories":["C Language"],"contents":"枚举类型的优势 枚举类型完全可被宏定义替代，类如\nenum Furniture { DOOR = 1, DESK, LOCK, } 与下面的代码等效\n#define DOOR 1 #define DESK 2 #define LOCK 3 那么我们如何在两种设计方法中选择呢？在我看来某些情况下使用 enum 会有以下优势：\n 提高代码键入效率；仅适用于所需变量的值是连续的整数，就像上面的情况，可以只给第一个 DOOR 赋值，其余的值累加。如果首个变量的值要求是 0，甚至每一个都无需显式赋值 提高代码的可维护性；可以划定范围，编译器也会检查类型是否正确，偶尔会有用 提高代码的可读性；例如 DOOR, DESK, LOCK\u0026hellip; 都属于家具，均定义在 Furniture 中  枚举类型所占的大小 枚举类型所占内存的大小，即枚举变量的大小。\n由于枚举变量的赋值，一次只能存放枚举结构中的某个常数。所以 枚举变量的大小，实质是常数所占内存空间的大小（常数为 int 类型，当前主流的编译器中一般是 32 位机器和 64 位机器中 int 型都是 4 个字节），枚举类型所占内存大小也是这样。\n所以默认情况下，无论枚举变量的值是多少，都是占用 4 个字节。即执行：\nprintf(\u0026#34;sizeof(enum Furniture) = %d\\n\u0026#34;, sizeof(enum Furniture)); 输入的结果是 4。\n编译选项：-fshort-enums GCC 下关于这个编译选项的介绍：\n -fshort-enums Allocate to an enum type only as many bytes as it needs for the declared range of possible values. Specifically, the enum type is equivalent to the smallest integer type that has enough room. Warning: the -fshort-enums switch causes GCC to generate code that is not binary compatible with code generated without that switch. Use it to conform to a non-default application binary interface.\n 意思是说使用-fshort-enums 后，对改枚举类型所占空间的分配就会按照实际变量的占用空间，而非总是 4 字节。\n启用该选项之后，再打印它的 size 就会是 1，因为用 1 个字节就能表示所有枚举变量的值（DOOR=1，DESK=2，LOCK=3）.\n这个“1”不再是固定的，根据其中枚举变量值的不同，动态调整enum Furniture的大小。\nenum Furniture { DOOR = 256, DESK, LOCK, } 再打印它的 size，结果为 2。因为值 256 无法用 1 个字节存下。\nenum 潜在的可移植性问题 看似好像启用该选项会节约一定的内存空间，是的。但它也有一定的缺点，其一就是可移植性问题。\n例如你编写的应用在编译时没有启用了该“优化”选项，默认采用 4 字节存储枚举变量。而链接的库文件在编译时却使用了“优化”选项，则库内部此枚举类型的大小可能为 1 字节。若此时恰好你有调用某个库 API，将 enum 变量作为参数进行传递，那么就会发生错误。\n为避免不同库和应用程序使用“优化”选项的差异造成潜在的危险，常用的解决方案是强制使 enum 变量占用 4 个字节，无论其是否开启“优化”。实现方式是在 enum 变量末尾添加一个成员 XXXX_END = 0xFFFFF，例如：\nenum Furniture { DOOR = 1, DESK, LOCK, END = 0xFFFFF, } ","date":"2023-03-09T17:18:57+08:00","permalink":"https://wangloo.github.io/posts/c/enum/","section":"posts","tags":["c"],"title":"C 语言enum的使用"},{"categories":["C Language"],"contents":"函数指针 指针的数组 or 指向数组的指针? \u0026gt;\u0026gt; int (*p)[10] p是指针, 指向长度为10的数组. 加括号是为了强调p是一个指针, 区别包含10个指针的array. \u0026gt;\u0026gt; int *(p[10]) p是数组, 它的元素类型是int *, 加括号是为了强调p是数组. \u0026gt;\u0026gt; int *p[10] 等效于int *(p[10]) 程序的内存分布 我们写的高级语言代码最终会被编译成可执行文件被操作系统加载、执行。 ELF文件是由一个个section组成的，那么程序里的变量、指令都是如何排布的呢？\n   地址空间各部分 内容 是否与可执行文件相对应     代码段 所有的可执行代码, 属性一般为只读 是, 加载时直接映射   数据段 初始化非0的全局变量和局部static变量 是, 加载时直接映射   bss段 未初始化或初始化0的全局变量和局部static变量 是, 加载时需要清空   栈 局部变量, 参数传递等 无, OS分配空间, 编译器维护   堆 动态申请的空间 无, OS分配空间   常量区 定义的常量字符串等 是, 有时和代码段合并到一起     有的人喜欢说“静态区”这个概念，我也一直被忽悠不理解什么叫静态区。实际上就是表示 存储函数内部static变量的区域，本质上属于数据段的一部分。\n  static声明的全局变量，对于编译器来说有什么区别对待?\n除了预编译时不会建立符号外没有区别。\n  全局变量和局部变量可以重名吗？\n可以重名。因为局部变量用栈来相对索引就可以，不需要符号，也就不会产生冲突。 而全局变量都是用符号来索引的。默认访问的是局部变量，如果希望访问全局变量， 需要使用::val += 1;的语法。\n 灵活数组成员 Flexiable Array Member  C99支持的特性，目的是为了节约空间（灵活数组成员本身不占空间，见下输出） 使用灵活成员可以用于实现string结构，长度动态分配 灵活成员必须是结构的最后一个成员，且此结构体不能只包含一个灵活成员（最少俩） 使用了灵活成员后，就不能用结构体之间直接\u0026quot;=\u0026ldquo;赋值了，改用memcpy() 含有灵活成员的结构体不能嵌入其他结构体中  #include \u0026lt;stdio.h\u0026gt;#include \u0026lt;stdlib.h\u0026gt; struct st { int memb1; int memb2; int memb3[]; // flexiable array member }; int main(void) { printf(\u0026#34;sizeof struct st: %ld\\n\u0026#34;, sizeof(struct st)); /* instantiate */ struct st *st1; // 只能动态分配  int memb3_len = 10; st1 = malloc(sizeof(struct st) + memb3_len*sizeof(int)); /* use */ for (int i = 0; i \u0026lt; memb3_len; i++) st1-\u0026gt;memb3[i] = i; for (int i = 0; i \u0026lt; memb3_len; i++) printf(\u0026#34;st1-\u0026gt;mem3[%d] = %d\\n\u0026#34;, i, st1-\u0026gt;memb3[i]); free(st1); return 0; } 输出结果:\nsizeof struct st: 8 st1-\u0026gt;mem3[0] = 0 st1-\u0026gt;mem3[1] = 1 st1-\u0026gt;mem3[2] = 2 st1-\u0026gt;mem3[3] = 3 st1-\u0026gt;mem3[4] = 4 st1-\u0026gt;mem3[5] = 5 st1-\u0026gt;mem3[6] = 6 st1-\u0026gt;mem3[7] = 7 st1-\u0026gt;mem3[8] = 8 st1-\u0026gt;mem3[9] = 9 基础架构 // 函数指针 \u0026gt;\u0026gt; int (*f)(int) 说明f是一个指向函数的指针, 加括号为了区别返回值为int*的函数 \u0026gt;\u0026gt; f = function; 函数指针的赋值 \u0026gt;\u0026gt; (*f)(x) 函数指针指向函数的调用, 可简化为f(x). 但是容易将f误认为是函数. // 函数指针的数组 \u0026gt;\u0026gt; int (*(f[10])) (int) f是数组,元素为10个函数指针. 内层括号说明f是数组,外层括号说明元素类型是函数指针 \u0026gt;\u0026gt; int (*f[10]) (int) 与上面等效. 但外层括号不能省略 \u0026gt;\u0026gt; f[0] = function() 赋值 \u0026gt;\u0026gt; (*f[0])() 指向函数的调用, 可简化为f[0]() // 返回函数指针的函数 \u0026gt;\u0026gt; void (*signal(int sig, ...))(int); signal是一个函数, 参数有sig.... 它的返回值是一个函数指针, 指向任意返回值为void, 参数为int的函数. typedef帮助理解函数指针 signal()是一个系统调用, 用于告诉系统, 当某种特定\u0026quot;软件中断\u0026quot;发生时调用特定的程序. 它的真正名称应当是: Call that routine when the interrupt comes in.\n看signal()的原型, 非常复杂. 根据上面基础架构的铺垫, 可以看出signal()的返回值是函数指针, 同时它的参数也是一个函数指针. 且这两个函数指针所指向函数的返回值和参数相同.\nvoid (*signal(int sig, void(*func)(int)))(int); 可以借用typedef表示通用部分.\ntypedef void (*sighandler_t)(int); 而后signal的声明就是人能看懂的了:\nsighandler_t signal(int signum, sighandler_t handler); C语言标准 我们在使用C语言编程时很少有人告诉我们C语言各个标准的情况，于是我们在看见一些函数标定支持的C标准（例如仅支持C99及以后），内心不会有什么波澜。\n我们常见这些C标准：K\u0026amp;R C、ANSI C、ISO C、C89、C99、C11、C18。让我们补充点可能很少使用的知识吧。\n什么是K\u0026amp;R C？ 1978年，丹尼斯•里奇（Dennis Ritchie）和布莱恩•柯林汉（Brian ernighan）合作出版了《C程序设计语言》的第一版。书中介绍的C语言标准也被称作“K\u0026amp;R C”。\n最初的C标准与我们现在用的有较大差别，例如它竟然还不支持void类型！\n什么是ANSI C、ISO C、C89、C90标准？ 随着C语言使用得越来越广泛，出现了许多新问题，人们日益强烈地要求对C语言进行标准化。1983年，美国国家标准协会（ANSI）组成了一个委员会，X3J11，为了创立 C 的一套标准。经过漫长而艰苦的过程，该标准于1989年完成，这个版本的语言经常被称作ANSI C，或有时称为C89（为了区别C99）。在1990年，ANSI C标准（带有一些小改动）被美国国家标准协会（ANSI）采纳为ISO/IEC 9899:1990。这个版本有时候称为C90或者ISO C。综上，ANSI C、ISO C、C89、C90其实是同一种标准。\n这一版本的C就更接近我们平常使用的C了，大部分特性都引入了。\n什么是C99标准？ 2000年3月，ANSI 采纳了 ISO/IEC 9899:1999 标准。这个标准通常指C99。\nC99我们最常使用的新特性是：在源代码的中间位置声明变量。\n什么是C11标准？ C11标准是C语言标准的第三版（2011年由ISO/IEC发布），前一个标准版本是C99标准。与C99相比，C11有哪些变化呢？\n1、 对齐处理：alignof(T)返回T的对齐方式，aligned_alloc()以指定字节和对齐方式分配内存，头文件\u0026lt;stdalign.h\u0026gt;定义了这些内容。 2、 _Noreturn：_Noreturn 是个函数修饰符，位置在函数返回类型的前面，声明函数无返回值，有点类似于gcc的__attribute__((noreturn))，后者在声明语句尾部。 3、 _Generic：_Generic支持轻量级范型编程，可以把一组具有不同类型而却有相同功能的函数抽象为一个接口。 4、 _Static_assert()：_Static_assert()，静态断言，在编译时刻进行，断言表达式必须是在编译时期可以计算的表达式，而普通的assert()在运行时刻断言。 5、安全版本的几个函数：gets_s()取代了gets()，原因是后者这个I/O函数的实际缓冲区大小不确定，以至于发生常见的缓冲区溢出攻击，类似的函数还有其它的。 6、 fopen()新模式：fopen()增加了新的创建、打开模式“x”，在文件锁中比较常用。 7、 匿名结构体、联合体。 8、 多线程：头文件\u0026lt;threads.h\u0026gt;定义了创建和管理线程的函数，新的存储类修饰符_Thread_local限定了变量不能在多线程之间共享。 9、 _Atomic类型修饰符和头文件\u0026lt;stdatomic.h\u0026gt;。 10、改进的Unicode支持和头文件\u0026lt;uchar.h\u0026gt;。 11、quick_exit()：又一种终止程序的方式，当exit()失败时用以终止程序。 12、复数宏，浮点数宏。 13、time.h新增timespec结构体，时间单位为纳秒，原来的timeval结构体时间单位为毫秒。 什么是C18标准？ C18也称C17是于2018年6月发布的 ISO/IEC 9899:2018 的非正式名称，也是目前（截止到2020年6月）为止最新的 C语言编程标准，被用来替代 C11 标准。\nC17 没有引入新的语言特性，只对 C11 进行了补充和修正。\n​\n如何查看自己程序的C标准版本？ 使用宏__STDC_VERSION__可以输出当前使用的C标准版本，是一个长整型：\nprintf(\u0026#34;C std version:%ld\\n\u0026#34;, __STDC_VERSION__); 值与标准的对应关系：\n   标准 宏     C94 _STDC_VERSION_= 199409L   C99 _STDC_VERSION_= 199901L   C11 _STDC_VERSION_= 201112L   C18 _STDC_VERSION_= 201710L    ​\n如何指定按照某个标准执行编译？ 以下的介绍只针对GCC，我没有用过别的编译器。\nGCC中可以添加--std=xxx来指定C标准版本，常用的情况如下：\n-std=c11 Conform to the ISO 2011 C standard -std=c89 Conform to the ISO 1990 C standard -std=c90 Conform to the ISO 1990 C standard -std=c99 Conform to the ISO 1999 C stand -std=gnu11 Conform to the ISO 2011 C standard with GNU extensions -std=gnu89 Conform to the ISO 1990 C standard with GNU extensions -std=gnu90 Conform to the ISO 1990 C standard with GNU extensions -std=gnu99 Conform to the ISO 1999 C standard with GNU extensions  默认情况下，我电脑上的gcc 5.4.0使用-std-gnu11\n 参考目录 https://blog.csdn.net/zhengnianli/article/details/87387268\nC Dialect Options (Using the GNU Compiler Collection (GCC))\n含糊不清的符号扩展 问题出在哪？ 下面一段代码会输出什么呢？\nchar c = 0xff; if (c == 0xff) printf(\u0026#34;successful\\n\u0026#34;); else printf(\u0026#34;failed\\n\u0026#34;); 答案是取决于不同的编译器设定：\n 当编译器将char识别为signed char时，该判断会失败。因为常数0xff被识别为int类型，所以编译器首先要对c进行符号扩展，判断语句c == 0xff此时等价于(int)c == 0xff。而对于signed char类型是扩展其最高位，即(int)c=0xffffffff，if判断失败。 当编译器将char识别为unsigned char时，判断成功。对于unsigned char类型总是扩展0。   注：gcc可通过添加编译参数 -fsigned-char/ -funsigned-char来指定编译器如何识别char\n 同样的问题也存在与位域(bitfiled)中，详见-fsigned-bitfields/-funsigned-bitfields参数。\n如何避免？ 在使用char类型时，根据情况写清楚unsigned/signed char就ok\nunsigned char c = 0xff if (c == 0xff) printf(\u0026#34;successful\\n\u0026#34;); else printf(\u0026#34;failed\\n\u0026#34;); 右移和除法 你是否有听说过有符号数不能使用右移操作(\u0026gt;\u0026gt;)来代替除法？ 这篇短文会向你证明它，并尝试向你解释为什么。\nLogical Shift .vs. Arithmetic Shift 若你现在有二进制数x=1110B，对其施加右移操作，请问高位填0还是填1？\n逻辑移位不管造成的影响，总是用0来填充移位操作产生的空缺。但是这样简单的想法在一些情况总会出错。例如若上述x是有符号数，那么简单的填0就会造成错误，起码正负号出错了。\n算数移位支持有符号数的移位操作，在移位后使用符号位进行填充，结合补码的表示方法，就能实现正确的负数移位操作。\n总结来说：在有符号的场景下，使用算数位移；如果你能保证移位操作是无符号的，那么用逻辑位移也无妨.\nx86汇编代码中，shr代表逻辑右移指令，sar代表算数右移指令，我们可以通过以下C代码及其反汇编的结果来更好的理解逻辑移位和算数移位：\n#include \u0026lt;stdlib.h\u0026gt;#include \u0026lt;stdio.h\u0026gt; signed int x = -3; unsigned int y = 3; int main() { x \u0026gt;\u0026gt;= 1; y \u0026gt;\u0026gt;= 1; return 0; } x: .long -3 y: .long 3 main: push rbp mov rbp, rsp mov eax, DWORD PTR x[rip] sar eax mov DWORD PTR x[rip], eax mov eax, DWORD PTR y[rip] shr eax mov DWORD PTR y[rip], eax mov eax, 0 pop rbp ret https://godbolt.org/z/K4M4Ko4c7\n实践出真知 在我作为一个初级程序员的认知中，/2和\u0026gt;\u0026gt;1是等价的，甚至一起还听说过后者能够优化代码的效率。但是今天我要告诉你， Definitely wrong!\n或许在遥远的古代，我们使用位移操作真的能够对代码进行加速，但是当下编译器已经足够聪明，如果你真的动手反汇编\u0026rdquo;/2\u0026ldquo;的代码，那么你就会知道编译器已经替你优化为了位移操作。\n更糟糕的是，我们要避免使用移位操作来实现除法或者乘法，不仅仅是因为这两者等价，实际上，他们并不是等价的！并且会造成错误！\n考虑如下的C语言代码：\n#include \u0026lt;stdlib.h\u0026gt;#include \u0026lt;stdio.h\u0026gt; signed int x = -3; signed int y = -3; int main() { x \u0026gt;\u0026gt;= 1; y /= 2; return 0; } 他们的汇编代码是相同的吗？这里还是拿X86汇编举例：\n; Following is ‘x \u0026gt;\u0026gt;= 1’ mov eax, #-3 ;x sar eax mov x, eax ; Following is ‘y/= 2’ mov eax, #-3 ;y mov edx, eax shr edx, 31 add eax, edx sar eax mov y, eax 注意：以上的汇编代码省去了一些我认为无关紧要的操作，并不是完全正确的，但是足够表达他们的差别了。\n可以看出，除法比移位多了一步shr edx, 31过程，下面会探讨这个。\n还有一件使你震惊的事件，x, y的值最终是不同的！是的，正是因为那条看似“多余”的shr指令。\n为什么结果不同 首先，我们可以确定的一件事是：编译器真的帮我们将除法操作优化为移位。所以，再也不要说你的代码中使用\u0026gt;\u0026gt;来替代除法是为了增加执行效率了。\n让我们来解释下为什么两者的结果是不同的。\n首先，sar指令在x86指令集中表示算数右移，这个是我们熟悉的，那么-3进行算数右移后的结果就是-2. 意味着\u0026gt;\u0026gt;是向负无穷舍入的.\n那么除法操作又是在干什么呢? 它是将原值加上其符号位.Demo中使用的数据类型是32位int.\nshr edx, 31 add eax, edx 这样做必然改变了原值啊，动手算一下就会知道，-3/2的结果为-1. 并且只有负奇数会受影响，对于正数，其符号为0；对于负偶数，其补码的最低位必为0，刚加上的1会被下一步的算数右移丢弃，不对高位产生影响。\nAha, 差别就是向负无穷舍弃还是向0舍弃，一时间竟然不知道哪个是正确的了。\n我们应该如何做 根据最新的[C语言标准草案](ISO/IEC 9899:201x (open-std.org)) 6.5.7章节，负数的右移操作是implementation-defined，即取决于具体的实现：\n The result of E1 \u0026raquo; E2 is E1 right-shifted E2 bit positions. If E1 has an unsigned type or if E1 has a signed type and a nonnegative value, the value of the result is the integral part of the quotient of E1 / 2E2. If E1 has a signed type and a negative value, the resulting value is implementation-defined.\n 因此，理论上它依赖于实现。所以我们在实际应用中为了程序的可移植性，应当避免对有符号数使用移位操作。除非你能确定它的值一定是非负数，在此情况下，请将它用无符号类型来声明。\n对于除法操作，标准中的6.5.5章节规定了，除法操作总是向0舍入. 非常好！\n When integers are divided, the result of the / operator is the algebraic quotient with any fractional part discarded.\n 检查你的代码，恢复所有的“优化”乘除法的行为吧！\n","date":"2023-03-09T17:18:57+08:00","permalink":"https://wangloo.github.io/posts/c/feature/","section":"posts","tags":["c"],"title":"C 语言的特点与难点"},{"categories":["C Language"],"contents":"头文件的引用形式 C 中引用一个头文件有两种形式 #include \u0026lt;\u0026gt;和#include \u0026quot;\u0026quot;，在应用开发中，需要引用一些系统库文件，我们通常使用\u0026lt;\u0026gt;，对于自己定义的头文件，我们会使用\u0026quot;\u0026quot;。\n然而对于底层软件的开发，比如说操作系统，用到的库都是自己工程中的文件，那么此时用\u0026quot;\u0026quot;和\u0026lt;\u0026gt;有时都能 work，那么它们的区别是什么呢？\n搜索相关关键词得到的结论是: 两种方式的区别是搜索文件的优先级， \u0026quot;\u0026quot;优先搜索的当前目录，而\u0026lt;\u0026gt;优先搜索系统库文件目录。对于这个系统库，即那些使用gcc -I\u0026lt;dir\u0026gt;参数指定的路径。 当然，如果第一优先级位置没有被找到，也会到另一个目录中搜索。这么两种方式均可，实际工程中也有部分人混合使用，毫不在意规则。但是有时会导致一些细节问题，比如说我们经常会用到-MMD或者类似选项生成目标文件的依赖，方便实现增量编译。此时就可能会产生一些问题。\n假设你有一个头文件inc/father.h, 它里面会引用inc/child.h, 对于根目录下的源文件main.c，其引用语句该如何写呢？以下列出的几种形式都可以，任意的排列组合\n// 编译参数: -I. -MMD // main.c #include \u0026#34;inc/father.h\u0026#34;#include \u0026lt;inc/father.h\u0026gt; // father.h #include \u0026#34;inc/child.h\u0026#34;#include \u0026lt;inc/child.h\u0026gt;#include \u0026#34;child.h\u0026#34;#include \u0026lt;child.h\u0026gt; 如果 main.c 是使用系统库路径(-I.)来找到的 father.h, 即上面 main.c 的第 2 种情况，那么其生成依赖文件的形式内容都是绝对路径，包括 father.h 中的引用（因为即便 child.h 是相对路径找到的，相对的也是 father.h，其基准就是绝对路径）。例如:main.o: main.c /home/xx/father.h /home/xx/child.h 否则即以相对路径找到 father.h,即上说 main.c 的第 1 种，那么生成 father.h 依赖的方式一定是相对路径，但 child.h 的形式却取决于其本身.  也就是说，如果 child.h 的寻找方式是绝对的（上面的第 1,2,4 种），那么依赖文件的形式就是main.o: main.c inc/father.h /home/xx/child.h. 如果 child.h 的寻找方式是相对的(上面的第 3 种)，那么依赖文件的形式是main.o: main.c inc/father.h inc/child.h    依赖文件的形式很重要，最简单的方式是均使用绝对路径，此时不需要考虑依赖文件在 makefile 中 include 的位置，也就是不需要考虑 make 的“当前路径”。如果非得使用相对路径，那么已经要确定能够 makefile 中 include 时的 make 当前路径就是生成依赖文件的路径，否则不能建立正确的依赖关系。\n实际上，在“基础架构”优秀的项目中，不可能出现或者尽量避免出来两种形式都能找到头文件的情况。比如说，我们会将源文件统一放在子目录src/下与头文件隔离，这样就从根本上避免了相对依赖的生成，只能通过系统库的形式来找头文件。拿上面的例子来说，正确的方式是：main.c 放入 src/中，然后不管是源文件还是头文件，都统一使用#include \u0026quot;inc/xxx\u0026quot;。这样做即统一，也能保证所有的依赖都是绝对路径形式\n 另外说一点，其实依赖文件(.d)中源文件的依赖项形式也是需要考虑的，这不能通过系统架构来解决，只能用 Makefile 的技巧来实现。比如说，我们的 make 当前目录总是根目录，而在建立 OBJS 变量时为其加上绝对路径的前缀， 从而 make 不需要进入各级子目录，生成的依赖文件也都是相对于根目录的，include 依赖文件的行为也是在根目录进行的，保证统一。\n 外部库的使用方式 最近我在开发项目是, 需要使用到 libelf 库, 我在 Github 上找到了其源代码.\n我之前使用一个 lib 都是以链接的形式使用动态库/静态库, 但是既然它提供了源码, 那么我可以直接将源码拷贝到我的项目中吗? 答案肯定是可以, 那么这两种方案该如何抉择呢?\n在查阅了一些资料后, 我总结了以下几个判断依据:\n 库的大小/对编译时间的敏感度; 如果使用源代码, 每次编译项目时需要额外对库文件进行编译(起码是第一次), 而库文件的定义是不常修改的, 如果库文件比较大, 则会延长整个项目的编译时间. 是否需要版本控制; 要使用的库如果需要区分版本, 或者分配给其他的团队成员使用, 那么用库的形式似乎更为方便 发挥 git submodule 的优势;   Ref: c++ - Should I add the source of libraries instead of linking to them? - Software Engineering Stack Exchange\n const 修饰符的妙用 有些时候, 我们设计的结构体中会有name字段, 类型是char *. 在使用时为它分配空间, 不使用时需要回收.\n其实还有另一种情况, 就是name要指向预先定义好的\u0026quot;static name list\u0026quot;, 适用于 name 的取值是确定的范围. 例如, libdwarf 库中的描述 section name 的dss_name 成员.\n这时, 为了防止使用者调用free()来释放它, 我们可以将其声明为const char *, 此时如果调用free(.dss_name), 编译器会给出警告:\nconst.c:16:10: warning: passing argument 1 of ‘free’ discards ‘const’ qualifier from pointer target type [-Wdiscarded-qualifiers] 16 | free(dss_name); | ^~~~~~~~  实际上，不管是用const修饰什么变量或者形参， 都不会改变它的存储原理，该存在哪还是存在哪， const提供的仅仅是在编译时提供警示。\n ","date":"2023-02-27T19:20:20+08:00","permalink":"https://wangloo.github.io/posts/c/experience/","section":"posts","tags":["c"],"title":"C 语言程序设计的一些经验"},{"categories":["DevTools"],"contents":"Sed Sed stands for Stream Editor.\nBasic sed syntax:\nsed [options] {sed-commands} {input-file} Sed reads one line at a time from the {input-file} and executes the {sed-commands} on that particular line\n The input 并非必须是文件\necho \u0026quot;Some string\u0026quot; | sed '' 当然也是支持的.\n Option: -n  通常sed是按照行来处理文本的, 然后打印处理后的结果. 然而并不是符合匹配的行被打印, 所有的行都会被打印. 例如sed 's/t/T/'会输出所有的行, 并且替换其中某些行的t.\n这样的结果不是我们想见的(大多数情况下), 所以, 我们可以添加-n option 来 禁止自动打印所有内容, 例如sed -n 's/t/T/' 不会输出任何结果.\n如果想要将匹配的结果单独打印, 则sed为我们提供了p命令. 例如, sed -n 's/t/T/p' 只会打印替换后的行.\nOption: -i As we know, sed doesn\u0026rsquo;t modify the input files by default. Sed writes the output to standard output. When you want to store that in a file, you redirect it to a file (or use the w command.\n如果要修改到源文件, 我们以前只能这样做:\nsed \u0026#39;s/John/Johnny/\u0026#39; employee.txt \u0026gt; new-employee.txt mv new-employee.txt employee.txt  Don\u0026rsquo;t do sed 's/John/Johnny/' employee.txt \u0026gt; employee.txt\nBecause whell shell see \u0026gt; employee.txt in the command line, it opens the file employee.txt for writing, wiping off all its previous contents.\n 但现在, 有了-i, 我们可以选择直接修改input file.\nsed -i \u0026#39;s/John/Johnny/\u0026#39; employee.txt ‼️ 直接修改源文件是很危险的, 你也可以使用-ibak来做备份.\nsed -ibak \u0026#39;s/John/Johnny/\u0026#39; employee.txt Option: -z 原本sed是按行处理的, 也就是\\n结尾. 使用-z 选项后, 转换为以\\0 即0x00来结尾. 借用-z 一次跨行对整个文本进行处理.\nCommands g\np\nw\ni (ignore case)\nCommand: s (substitute) The most powerful command in the stream editor is substitute.\nsed \u0026#39;[address-range|pattern-range] s/old/new/[substitute-flags]\u0026#39; inputfile  匹配范围字段是可选的. 未指定情况下默认是all lines. 指定范围Example: sed '/Sales/s/Manager/Director/' employee.txt 仅替换包含Sales字段的行.  Sed 替换分隔符 When there is a slash/ in the original-string or the replacement-string, we need to escape it using \\. For this example create a path.txt file which contains a directory path as shown below.\nsed \u0026#39;s/\\/usr\\/local\\/bin/\\/usr\\/bin/\u0026#39; path.txt Substitution Grouping Sed中可以使用正则表达式中匹配分组. A group is opened with \\( and closed with \\).\nExample: 输出每个行第一个,前的所有内容.\nsed \u0026#39;s/\\([^,]*\\).*/\\1/g\u0026#39; employee.txt  [^,]* means zero or more non-comma.\nIn [], a , means just a comma. And the leading ^ means \u0026ldquo;anything but..\u0026rdquo;.\n Power of \u0026amp; - Get Matched Pattern \u0026amp; replaces it with whatever text matched the original-string or the regular-expression.\n$ echo 1234 | sed \u0026#39;s/123/\u0026lt;\u0026amp;\u0026gt;/\u0026#39; \u0026lt;123\u0026gt;4 Sed 处理Bash变量  一旦你的pattern中包含变量, 整个pattern必须由双引号包围.\n 对于某些变量里含有forward slash(/), 需要换一个pattern delimiter. Sed 允许替换为任意的字符, 需要做的工作针对不同的使用情况有些许区别.\nScenario #1: s command, 直接替换即可,\nsed -i \u0026#34;s:$pushed_dir:REPLACE:g\u0026#34; input_file Scenario #2: For patterns used in addresses, 需要首先对新的delimiter使用\\:进行escaped(转义)\nsed -i \u0026#34;\\:$pushed_dir:d\u0026#34; input_file  See: Using different delimiters in sed « \\1 (backreference.org)\n ","date":"2023-01-03T19:28:12+08:00","permalink":"https://wangloo.github.io/posts/tools/sed_awk_grep/","section":"posts","tags":["tools"],"title":"Sed/Awk/Grep 三剑客"},{"categories":["Operating System"],"contents":"使用VIM 打开一个文件时, 有时会看到例如 ^M 这类字符出现. 下面我会挖一下其出现的原因.\nEOL 字符 EOL 或者说 end-of-line 表示一个新行的开始.\nEOL 字符在不同的操作系统中是不同的. 本文中仅以 Linux 和 Windows 为例说明.\n Windows中是以读到回车\u0026lt;CR\u0026gt;和换行\u0026lt;LF\u0026gt; 表示 EOL. Linux 中仅以换行作为EOL    回车\u0026lt;CR\u0026gt; : Carriage return. 将光标回到行首, 对应C语言中的 \\r 换行\u0026lt;LF\u0026gt; : Line feed. 将光标下移一行, 对应C语言中的 \\n   在 Linux 中打开 Windows 下的文件将多余的回车通常显示成 ^M 或者 Control-M\nRef End Of Line Characters\n","date":"2022-12-24T01:35:24+08:00","permalink":"https://wangloo.github.io/posts/os/linux/end-of-line/","section":"posts","tags":["other"],"title":"行结束符在windows和linux的区别"},{"categories":["Operating System"],"contents":"我始终以为，C库中常用的 errno 仅是一个全局变量，使用了全局变量就无法保证线程安全了，因为全局变量在所有线程中都是共享的。\n要实现线程安全的errno 就必须将其设置为线程私有的变量，下面就来看看GCC是如何巧妙的实现的。\n正文 现在的errno定义并非一个全局变量, 而是一个宏定义, 以下是在usr/include/errno中的声明:\nextern int *__errno_location (void); # define errno (*__errno_location ()) 这种方式下其实现原理大概是: __errno_location 函数返回一个int指针, 而这个函数的实现中, 返回的就恰好是实际的errno 变量(与宏同名)的地址, 所以对其解引用就相当于对其值进行操作. 所以, 这种定义规则下, 左值和右值表达式均成立.\nerrno = 10; // *__errno_location () = 10 int x = errno; // x = *__errno_location (); __errno_location 的实现就至关重要, 因为如果其返回的变量地址不包含任何技巧的话, 就和原先直接定义全局变量的方式没差了, 说到底能否实现线程安全, 还得看实际保存errno的变量是否为线程独有的. 目前还没有发掘到其精髓, 只是套壳而已.\n以下给出/csu/errno-loc.c中__errno_location 的实现, 与我们预期一致, 返回变量的地址. 而同名变量errno则定义在/csu/errno.c中, 决定了能够实现errno的线程安全.\nint * __errno_location (void) { return \u0026amp;errno; } __thread int errno; \u0026ldquo;__thread\u0026rdquo; 是GCC提供的扩展前缀, 表示该变量将被库处理为线程私有的, 注意这一步是C库完成的, 对程序员透明. 相关的理论叫 Thread-local Storage, AArch64 架构实现的原理是利用TPIDR_EL0 寄存器, 其他架构可以参考此PDF\n ❓ 以上源文件中有注释为 non-threaded版本的实现, 是代表什么含义呢?\n ​\n虽然我暂时没有查阅到errno的其他线程安全的实现原理, 但起码GCC下该方式这是可行的. 依靠的是\u0026quot;__thread\u0026ldquo;的支持, 与换成宏定义的方式无关, 不排除可能为了考虑兼容其他实现方式的可能性.\n参考 c - How is thread-safe errno initialized if #define substitutes errno symbol? - Stack Overflow\n","date":"2022-12-21T19:08:22+08:00","permalink":"https://wangloo.github.io/posts/os/errno_thread_safe/","section":"posts","tags":["Operating System"],"title":"操作系统：浅谈 errno 的线程安全问题"},{"categories":["Git"],"contents":"合并操作: git merge merge行为的语义是将其他分支的修改合并到当前分支。由此就产生了两种内部的实现原理， 以下均假设当前分支为main，其他分支为dev：\n fast-forward： three-way merger：  Fast-forward Merge main是dev的某个直接祖先，或者说他们之间是一条线的关系。此时将dev的修改合并进来相当于移动main指针指向dev的最新commit(F1)。此时merge称为 fast-forward.\n例如, 当前在 main, 执行git merge dev的过程如下:\nmain main | | M1 --- M2 ===\u0026gt; M1 --- M2 -- F1 \\ | \\--- F1 dev | dev three-way Merge 合并的两者不构成直接的祖先-孩子关系，也就意味着main和dev分别位于两个分叉上（见下图左）。此时merge的步骤就相对复杂：\n 找到main和dev的公共祖先M2 列出main和dev分别基于公共祖先来说做了哪些修改  如果两条分叉的修改不冲突，完美合并 经常出现的是，两个分叉难免对同一片段做了不同修改，此时标记为冲突，等待用户解决   因为main和dev位于两个分叉，合并会新建一个节点（M4），commit的信息是“Merge dev into main”。如果步骤2中产生冲突了，那么解决冲突的行为就被记录到M4的diff。没有冲突时diff是空的。  main main | | M1 --- M2 --- M3 ===\u0026gt; M1 --- M2 --- M3 --- M4 \\ \\ / \\--- F1 \\--- F1 --- | | dev dev 因为此时merge需要借助三个 commit(main, dev, 公共祖先)，这种操作就叫做 three-way merge。\n检出: Checkout  ps: 就不能想出更易懂的名词吗？非得用一个“检出”？\n checkout是一个非常综合的命令，其后面既可以接 分支名、commitid、文件。其实也很难用一个词概括它的行为吧。\n初版: checkout \u0026lt;file\u0026gt; 我感觉checkout最初的功能是+文件名，使工作区恢复为HEAD的状态，但不影响暂存区（这是和reset命令不同的地方）。==\u0026gt; 通俗来说，该文件先回到HEAD，再应用暂存区的修改 ==\u0026gt; 再通俗点，放弃工作区中没有被暂存的改动。\n这种case下的checkout命令等价于 git restore。\n扩展1: checkout \u0026lt;commit\u0026gt; 扩展基础功能，git checkout \u0026lt;commit\u0026gt; 将仓库管理的所有文件都恢复到commit的状态。也是只影响在工作区中的改动，这个和初版相同。如果commit是HEAD以前的，那么此时如何标记分支状态？ ==\u0026gt; 用一个特殊的detached状态来标定。\n特殊case1: checkout \u0026lt;branch\u0026gt; 分支切换，跟扩展1不同，不会影响工作区的改动，仅仅是切换分支，如果有文件冲突，执行就会失败。\n这种case下的checkout命令等价于 git switch\n特殊case2: checkout \u0026lt;commit\u0026gt; \u0026lt;file\u0026gt; 特殊的case，git checkout \u0026lt;commmit\u0026gt; \u0026lt;file\u0026gt;，如果指定了commit，就不再只影响工作区了，也会影响暂存区。\n效果等同于git reset --hard \u0026lt;file\u0026gt;。 这个貌似也太难理解了，只能记住了。\n使用技巧 太麻烦了，还是少用git checkout。git也是感觉到了，所以才新建了restore和switch命令来代替。只是为了兼容不得不继续支持以前的功能。总结来说：\n 首先暂时切换到某个commit，用checkout detached state还是比较方便的。 分支切换和新建，也习惯了，继续用也行。 至于放弃某个文件工作区的状态，还是用新的restore命令吧。checkout万一用错了（初版和特殊case2），会造成暂存区内容的丢失。  变基: rebase rebase 命令需要指定一个基准分支，git rebase \u0026lt;base-branch\u0026gt;， rebase 会将当前所处分支整体移动到base-branch之后，即改变了当前分支的历史。\n// before rebase [A]---[B]---[C]---[D]\u0026lt;-dev \\ \\--[E]\u0026lt;-master // after rebase [A]---[E]---[B]---[C]---[D]\u0026lt;-dev | master 交互式 rebase 交互式 rebase 是一种更高级的用法。基础的 rebase 上面说了是将当前分支的所有提交移动到 base-branch 之后。而交互式 rebase 提供一个方法，在移动之前\u0026quot;挑选\u0026quot;当前分支的 commit。\n实际工程中，通常来说，我们将开发分支移动到 master 之前，可以经过交互 rebase 来整理开发分支中混乱的 commit 记录。\n具体的使用方法是，为git rebase指令提供-i参数:\ngit checkout dev git rebase -i master 这个命令会打开一个文本编辑器，列出当前 feature 分支的所有提交:\npick 33d5b7a Message for commit #1 pick 9480b3d Message for commit #2 pick 5c67e61 Message for commit #3 列出的内容就能完整的表示 dev 分支的所有提交，按照顺序。而我们不仅可以任意的重排这些 commit，而且修改pick关键字就能对这些 commit 做改动。举个例子，我们可能发现 commit2 只是对于 commit1 做了一个很小的改动，它们完全可以合并为一个 commit，那么直接 commit2 的pick修改为fixup，整个内容变为:\npick 33d5b7a Message for commit #1 fixup 9480b3d Message for commit #2 pick 5c67e61 Message for commit #3 当你保存并退出这个文件时，改动就会生效，不仅将 dev 整体移动到了 master 后，并且合并了前两个 commit。\n// after rebase interactive [A]---[E]---[B]---[D]\u0026lt;-dev | master rebase 整理多个 commit 如上面交互式 rebase 所述，当你开发完 dev 分支，需要merge到 main 分支时，可以先利用交互式 rebase\u0026quot;整理\u0026quot;一下 dev 分支的 commit。\n这里其实要用到一个小 trick，上面说过 rebase 命令需要指定一个 base-branch，实际上是一个 base-commit，这种场景下我们不是要合并其他分支，所以base-branch可以选择当前 dev 分支的前面某一次 commit。\ngit checkout dev git rebase -i HEAD~3 以上指令实现的功能就是给你整理最后 3 次提交的机会，但不会合并其他分支的东西。\n那如果我想整理整个 dev 分支呢？是向上找到 dev 的第一次 commit 吗？ Git 提供了一个方便找到 dev 分叉出来的那次 commit，将其输出传递给git rebase -i即可实现整理整个 dev 的所有 commit。\ngit merger-base dev main git merege vs git rebase 准则   如果分支已经被提交到远程仓库，就不能再改变他的历史了，即不能使用 rebase。 git 也会阻止你这么做，因为分支的历史已经被修改，除非 force-push。\n  你能进行 rebase 的分支是本地的”私人分支”，私人表示为: 只有你自己在使用，别人不会基于你的分支做东西。\n  dev 同步主分支的改动: rebase 假设我们正在本地的 dev 分支开发一个特性，此时你的同事在 main(也可以是其他的远程分支)上提交了一个重要的 commit，以至于你需要它来继续你的开发任务。\n这种情况我们使用 rebase 和 merge 都能完成目标，但是 rebase 是更好的选择。\n 首先满足 rebase 的使用条件，我们仅仅是破坏了本地 dev 分支的历史，并没有动到其他的远程分支，所以就不存在干涉别人 其次，在 dev 上 merge 其他分支会产生一次不必要的merge commit，其不代表任何实际意义，没必要存在的  合并 dev 到主分支: merge 很简单的逻辑，主分支或者其他合作开发的分支并不是你一个人在用，并且需要最后同步到远程仓库，不符合使用 rebase 的准则\ngit log 参数:    Parameter Description     non-param 列出所有历史提交的 SHA、作者、提交日期和 commit   -p 按补丁显示每次更新，比\u0026ndash;stat 更全   \u0026ndash;stat 显示每次更新修改文件的名称及添加（删除）的行数。比\u0026ndash;name-only 更全   \u0026ndash;name-only 显示文件清单   \u0026ndash;name-status 显示文件清单及改动方式(新增、删除、修改)   \u0026ndash;oneline 只显示前 6 位 SHA 值和 commit   -n 显示前 n 条 log   \u0026lt;branch\u0026gt; 查看某个分支的历史提交。该参数只能 log 命令之后   \u0026lt;branch1\u0026gt;..\u0026lt;branch2\u0026gt;             参考网站：https://www.cnblogs.com/bellkosmos/p/5923439.html\nExample 1: 彩色显示重要信息 git log --graph --pretty=format:\u0026#39;%Cred%h%Creset -%C(yellow)%d%Creset %s %Cgreen(%cr) %C(bold blue)\u0026lt;%an\u0026gt;%Creset\u0026#39; --abbrev-commit Example 2: 查看本地分支和对应远程分支的 commit 差异 git log --oneline main..origin/main 远程仓库 克隆远程仓库 默认克隆master分支\ngit clone \u0026lt;shortname\u0026gt; \u0026lt;url\u0026gt; 需要克隆指定的分支\ngit clone -b \u0026lt;branch\u0026gt; \u0026lt;shortname\u0026gt; \u0026lt;url\u0026gt; 克隆并指定文件名\ngit clone \u0026lt;shortname\u0026gt; \u0026lt;url\u0026gt; \u0026lt;dirname\u0026gt; .notice { --root-color: #444; --root-background: #eff; --title-color: #fff; --title-background: #7bd; --warning-title: #c33; --warning-content: #fee; --info-title: #fb7; --info-content: #fec; --note-title: #6be; --note-content: #e7f2fa; --tip-title: #5a5; --tip-content: #efe } @media (prefers-color-scheme:dark) { .notice { --root-color: #ddd; --root-background: #eff; --title-color: #fff; --title-background: #7bd; --warning-title: #800; --warning-content: #400; --info-title: #a50; --info-content: #420; --note-title: #069; --note-content: #023; --tip-title: #363; --tip-content: #121 } } body.dark .notice { --root-color: #ddd; --root-background: #eff; --title-color: #fff; --title-background: #7bd; --warning-title: #800; --warning-content: #400; --info-title: #a50; --info-content: #420; --note-title: #069; --note-content: #023; --tip-title: #363; --tip-content: #121 } .notice { padding: 18px; line-height: 24px; margin-bottom: 24px; border-radius: 4px; color: var(--root-color); background: var(--root-background) } .notice p:last-child { margin-bottom: 0 } .notice-title { margin: -18px -18px 12px; padding: 4px 18px; border-radius: 4px 4px 0 0; font-weight: 700; color: var(--title-color); background: var(--title-background) } .notice.warning .notice-title { background: var(--warning-title) } .notice.warning { background: var(--warning-content) } .notice.info .notice-title { background: var(--info-title) } .notice.info { background: var(--info-content) } .notice.note .notice-title { background: var(--note-title) } .notice.note { background: var(--note-content) } .notice.tip .notice-title { background: var(--tip-title) } .notice.tip { background: var(--tip-content) } .icon-notice { display: inline-flex; align-self: center; margin-right: 8px } .icon-notice img, .icon-notice svg { height: 1em; width: 1em; fill: currentColor } .icon-notice img, .icon-notice.baseline svg { top: .125em; position: relative }     `` clone或者fetch会将历史都下载到本地，内容可能很大。 使用--depth参数只克隆最近几次commit的内容，减少下载的时间。\ngit clone \u0026lt;url\u0026gt; --depth=1 # Clone最近一次提交only 以后如果需要下载历史，执行git fetch --unshallow即可下载完整内容。\n 分支操作 # 创建远程分支关联的本地分支，假设已经存在origin/v5.10 git checkout v5.10 子模块: submodule 新增一个子模块 (1) 将子模块上传到远端仓库上，或者使用已有的第三方项目\n(2) 执行\ngit submodule add [url] [path] (3) 此时看git status 会有两个changes，分别是：\n .gitmodules中会增加一条项目, 记录子模块的名称和地址 [submodule \u0026#34;SubmoduleTestRepo\u0026#34;] path = SubmoduleTestRepo url = https://github.com/jzaccone/SubmoduleTestRepo.git  [子模块同名的文件]: 记录主项目追踪的是子模块的哪个commit   .gitmodule和子模块同名文件的作用\n  先说比较简单的.gitmodule，记录主项目中用到的所有子模块。 一般来说仅仅记录子模块的路径和url，但有时还会有指定的分支名。 这个我们在下面会介绍。\n  然后是和子模块同名的文件，我们想一下，上面的.gitmodules仅仅告诉了从哪来， 但是一个仓库是有多个分支，对应多个commit的，那么需要有一种方式去指定使用绑定哪个commit， 这就是同名文件的作用。在同名文件中会记录一下commitid，表明主项目依赖这个commitid下的子模块， 他们之间具有绑定关系。\n   (4) git add这两处改动，git commit -m \u0026quot;add submodule xxx\u0026quot;\nSubmodule Command Execute git submodule --help to get more info.\ngit submodule init 此命令clone新项目的时候会用到, 完整的命令是\ngit submodule init [path]  在详细介绍前需要说明两个文件的差别: .gitmodule和.git/config:\n .gitmoudles在上面已经介绍过一些，这里主要想说它是跟随主项目一起提交的， 而.git/config是后面生成的本地文件。 .gitmodules会给出列出所有子模块，但是不一定每次都全部使用。 **具体会启用哪些由.git/config文件规定。   git submodule init指令会指定生成.git/config文件的内容。 选择某几个子模块启用即写入.git/config。\n 在缺省参数下的含义是添加所有在.gitmodules中的子模块。 未来update指令只会更新.git/config中的项目。  git submodule update 刚才说了，因为.gitmodules中的所有子模块并不一定都使用， 所以新clone下来的项目并不会同时下载所有的子模块。 在上面的init阶段生成了.git/config来指定需要哪些之后， update命令就是用于下载指定的子模块。\n\u0026ndash;init 由于此命令配合init命令使用，两者通常连续操作，所以可以合并为:\ngit submodule update --init \u0026ndash;remote 一般情况下，下载子模块都是checkout到.git/config指定的commit。 --remote则会checkout到追踪分支的最新commit，下面会说到如何设置追踪分支， 默认是master。\n如果最新的commit不等于.git/config指定的，那么执行完该指令后会产生一次同名文件的改动。\ngit submoudle set-x 修改的是哪个文件？\n\u0026ldquo;x\u0026quot;可以是url，修改子模块的地址。\n这里我主要想着重介绍set-branch命令，将原来追踪自模块的方式由commit更改为(branch+commit)。 想要修改追踪子模块的commit到某个分支的最新，有两种方法:\n 传统方案 cd lib1/ git checkout \u0026lt;branch\u0026gt; cd .. git add lib1 git commit -m \u0026#34;change lib1\u0026#39;s tracked commit\u0026#34;  使用set-branch参数 git submodule set-branch -b \u0026lt;branch\u0026gt; lib1/ # 改变设置之后，子模块不会立即变化 # 必须指定带remote参数的update命令，才会用更新到显式指定的分支最新， # 而不是同名文件中规定的commitid git submodule update --remote git add lib1 .gitmodules git commit -m \u0026#34;change lib1\u0026#39;s tracked commit\u0026#34;    set-branch修改了.gitmodules, 也同步到了.git/config中。如果你想手动修改.gitmodules来设置分支，不要忘了submodule init来同步到.git/config\n 修改URL  修改.gitmodules中对应子模块的URL git submodule sync 同步到.git/config文件中 git submodule update 更新子模块内容  使用Submodule注意事项 1.Submodule到底是追踪分支还是commit 事实证明子模块默认追踪的不是分支，容易验证。 我们将子模块基于当前分支（假设master）新建一个子分支，并做一些修改， 可以看到主项目中的子模块同名文件也发生了改动。 所以说，它默认并不是跟踪分支。\n我感觉可以证明它默认跟踪的是HEAD。还是用上面的例子， 此时主项目中同名文件发生了改动。但是如果将子模块的分支切换回原来的master， 子模块同名文件的改动就消失了。以我目前的见解我暂且这么认为。\n2. 同名文件发生了修改，应不应该stage？ 分两种场景: (1)如果子项目的这些更新有意义同步到主项目中，那么就add并commit这个同名文件的改动， message为\u0026quot;更新submodule\u0026rdquo;。 (2)如若只是更新子项目而已，或许是为了其他依赖的项目所改的，并不 想涉及到本主项目，那么就restore此次更新，或者重新执行submodule update即可(前提是对子模块 的修改已经push)。\n所以说，同意主项目中的这次change的人必须是更新这次子模块的人，由他决定是否同步到主项目。 其他人甚至在使用期间都不需要cd进入子模块做git pull的，这样也就不会有决策产生，即便 子项目在远端更新了，你要做的就是关注那个同名文件就行，当同名文件更新了，在主项目中 submodule update即可，\n子模块的优缺点 TODO\n补丁 关于Git生成补丁/打补丁的方法有两套命令：diff\u0026amp;apply 和 format-patch\u0026amp;am，这两套方案分别适用于不同的场景。\n git apply命令主要用于应用补丁文件。补丁文件通常是由git diff命令生成的， git apply不会自动创建提交记录，并且需要手动执行提交操作。 git am命令也是用于应用补丁文件，但主要用于处理Git发送的邮件补丁(Mbox格式)。 git am会自动创建提交记录，并且可以处理多个补丁文件。 git am会自动忽略已经应用过的补丁文件，这在处理多个补丁文件时非常方便。 git am还可以处理附件，通过提取附件内容并保存到工作目录中。这在处理有附件的邮件补丁时非常有用。  # (1) diff \u0026amp; apply # 生成补丁文件 git diff \u0026gt; patchfile.patch # 补丁文件应用到当前工作目录 git apply patchfile.patch # (2) format-patch \u0026amp; am # TODO am 和 apply命令的区别 ","date":"2022-12-13T17:39:42+08:00","permalink":"https://wangloo.github.io/posts/tools/git/git/","section":"posts","tags":["git","tools"],"title":"git 宝典"},{"categories":["电子电路"],"contents":"铜厚常规的1盎司，盎司是重量单位，1盎司的铜平铺到1平方米的面积上， 其厚度就是35μm。\n整流电路  整流：交流转直流，最简单的整流电路就是串联一个二极管。 逆变：直流转交流。  倍压整流 没有变压器的情况下，220V经过阻容降压+倍压整流给芯片供电。\n桥式整流电路   220V交流电先经过变压器变为12V左右交流电 整流器将其转为直流电 16V左右 滤波电容滤波 7812稳压12V 再滤波（大电解+小无极）   先整流再变压 现代开关电源的工作大致是：整流\u0026mdash;经过开关电路\u0026mdash;变成高频交流\u0026mdash;经高频变压器变压\u0026mdash;整流、滤波\u0026mdash;直流。 因为市电是50Hz低频，220V直接变压的话，频率低导致变压器绕线要长，从而使得变压器体积会很大。 所以都是要两次整流操作。\nPWM 占空比 占空比: 高电平持续的时间占整个周期的百分比\n输出的平均电压 = 高电压 x 占空比\n所以通过调整占空比就能调整输出的平均电压.\n频率  仅通过调整占空比, 只能完成高电平时电机全速转动, 低电平时停止转动的效果. 不能达到我们的预期, 所以还需要PWM的另一个参数: 频率\n 通过提高频率使得电机还未停下来时就又到达下一个高电平.\n稳压二极管 特性 稳压二极管反向接入电路是能够实现两端电压恒定, 工作时的状态是反向击穿, 能一直稳定在这个状态不会坏.\n稳压二极管的参数有两个: 稳压值和功率. 如果输入的电压小于其稳压值, 那么稳压作用消失, 如果大于稳压值, 那么稳压二极管两端的电压总是等于稳压值. 由于稳压二极管两端的电压是恒定的, 其功率的含义就是最大通过的电流.\n由于有功率的限制, 所以必须要串联限流电阻使用, 避免电流太大烧坏稳压管,\n限流电阻的计算 首先, 稳压二极管有最小工作电流, 通常为3-5mA, 规定了限流电阻的最大值.\n其次, 限流电阻需要确保二极管工作在规定的功率内, 因为当负载过大(极限状态下是空接)时, 所有的电流都通过稳压二极管. 按照其功率的1/2, 除以其稳压值就是工作电流.\n 我们通常说, 稳压二极管的带负载能力差. 这是因为保证稳压二极管的功率一般比较小, 最大通过的电流也就几十mA. 计算出的限流电阻的R和V(电源-稳压值)都是固定的, 则其通过的电流也是固定是, 是通过稳压二极管和通过负载的电流之和.\n 提高稳压二极管带负载能力的方法 TODO\n自恢复保险丝 是一种热敏电阻(PTC), 原理是当电流超过一定值是, 材料发热, 阻值迅速增加, 相当于断路.\n参数  熔断电流 耐压值  防反接电路 二极管防反接（1）  利用二极管的单向导电性, 将其串联到负载中.\n 使用的二极管为肖特基二极管, 相比普通二极管压降更低(一般为0.2V),\n 电路缺点：\n 工作电流较大时, 二极管有较大功耗. 一般来说, 适用于电流\u0026lt;2A的电流中 肖特基二极管能够承受的电流不能过大, 拿1N5819来说, 正向导通电流最好不超过1A.  二极管防反接（2）  针对以上的缺点, 可以设计使用二极管的第二种防反接方案。 图中的二极管可以不用肖特基。\n当接法正确是, 二极管不导通；当反接时, 二极管将负载短接 产生的电流足以熔断保险丝, 保护电路。\n 这里的保险丝可选择自恢复保险丝.\n Mos管防反接  改善二极管防反接电路的缺点, MOS管的压降比较小(mV级), 因此电路功耗比较小。\n使用的MOS管为P沟道MOS, DS是反接的。正接的时候, 体二极管导通, G级电压小于S级电压, MOS管导通；反接的时候， G级电压大于S级电压, MOS管关断, 整个电路不工作。\n 稳压二极管的目的是: 保护MOS管, 防止S和G之间的电压过高. 电阻R1,R2的目的是: R2的作用是防止通过稳压二极管的电流过大. 因为通过其电流可以表示为(Vcc-稳压值)/R2, 所以R2大一些可以降低额外的功耗.  ","date":"2022-12-07T10:30:35+08:00","permalink":"https://wangloo.github.io/posts/ee/","section":"posts","tags":["电子电路"],"title":"电子电路基础笔记"},{"categories":["Makefile"],"contents":"make命令参数 # 仅输出所有命令，不实际执行，调试用 make -nB 伪目标的依赖关系 Makefile 中的依赖关系指的是目标和依赖之间建立的关系，目标对应规则中的语句是否执行取决于依赖的状态。\n最简单的依赖关系可以拿两个文件来举例:\n# gcc语句执行当前仅当 main.c 新于 main.elf main.elf: main.c gcc main.c -o main.elf make 在执行main.elf的规则时，会先判断依赖关系。拿上面的例子来说， gcc 语句是否执行取决于main.c 和 main.elf的修改时间，只有当 依赖新与目标时，规则语句才会执行。\n然而许多情况下，目标或者依赖并不是一个文件，而是虚拟目标。虚拟目标 并不是一个文件，即它没有修改时间这个属性，此时 make 就不能作比较，结果就是 如果目标是伪目标，那么不管依赖如何都执行规则语句；如果依赖是伪目标， 那么目标的规则语句也永远被执行。下面是两个例子：\n# 伪目标作为目标文件出现 # build finish总是输出， 而gcc语句仅当main.c比main.elf新时才执行 .PHONY : all all: main.elf @echo \u0026#39;build finish\u0026#39; main.elf: main.c gcc $\u0026lt; -o $@ # 伪目标作为依赖文件中出现 # 不管main.c是否比main.elf更新，因为pre-work是伪目标 # 所以gcc语句总是执行 .PHONY : pre-work main.elf: main.c pre-work gcc $\u0026lt; -o $@ 上面的代码的效果是：两条规则中的语句都会执行，即使你并没有对 main.c 做任何修改！\n恐怖的空格 Makefile 中的变量结合很常见，例如$(FIXDEP)=$(FIXDEP_PATH)/build/fixdep.\n特别是当我们这些语句是从某些地方粘贴过来，要特别注意变量中是否有空格，Makefile 非常重视这个。假如$(FIXDEP_PATH)中有一个空格，那么$(FIXDEP)就变成两个宏了（不知道叫宏合不合适）。而且 Make 的执行过程很难检查出来。\n规则的执行顺序 如果不从命令行传入目标, Makefile 中定义的规则其实是以从上而下的顺序执行的, 但是我习惯把 all 这种默认规则放在最下面, 所以一般我们可以看到很多 Makefile 会在开头写一句规则all:, 作用就是告诉 make 默认(不显式指定)的目标是all.\n Busybox 根目录 Makefile 中的做法示例\n# That\u0026#39;s our default target when \u0026gt;none is given on the command line .PHONY: _all _all:  函数的魔法 patsubst $(patsubst \u0026lt;pattern\u0026gt;,\u0026lt;replacement\u0026gt;,\u0026lt;text\u0026gt;) 功能：查找\u0026lt;text\u0026gt;中的单词（以空格，tab，回车，换行分割），看其是否符合\u0026lt;pattern\u0026gt;, 如果符合，将其使用\u0026lt;replacement\u0026gt;替换。可以使用通配符%。\n以下两对是等效的, 明显还是直接使用变量的替换语法操作简单:\n$(patsubst \u0026lt;pattern\u0026gt;,\u0026lt;replacement\u0026gt;,$(var)) $(var:\u0026lt;pattern\u0026gt;=\u0026lt;replacement\u0026gt;;) $(patsubst %\u0026lt;suffix\u0026gt;,%\u0026lt;replacement\u0026gt;,$(var)) $(var:\u0026lt;suffix\u0026gt;=\u0026lt;replacement\u0026gt;) 使用 shell 变量 Make 将 $$var 转义为$var, 供 shell 处理.\ndemo(源自 6.828 根目录GNUmakefile):\nhandin-check: @if test -n \u0026#34;`git status -s`\u0026#34;; then \\  git status -s; \\  read -p \u0026#34;Untracked files will not be handed in. Continue? [y/N] \u0026#34; r; \\  test \u0026#34;$$r\u0026#34; = y; \\  fi  以上 demo 还使用了 test 命令来终止 make 的执行, 如果用户没有输入y, make 将会终止执行\n 使用另一个 Makefile 常见的有三种方式， make -C, make -f 和 include\nmake -C \u0026lt;dir\u0026gt; 的作用等价与 cd \u0026lt;dir\u0026gt;+make, 常见于在一个工程 的主目录下，依次编译生成其他子目录的目标文件。有cd命令的效果，会切换 当前目录。\nmake -f \u0026lt;file\u0026gt; 更像临时使用某个 Makefile 来执行一些操作，在指定的 Makefile 中如果想使用之前的变量，需要export. 目前还没有发现有必要的 应用场景，大部分用include方式替代。\ninclude \u0026lt;file\u0026gt; 一般用于引入一些通用规则，就像 C 语言的 include 头文件 一样，变量无需export.\n","date":"2022-12-03T19:08:22+08:00","permalink":"https://wangloo.github.io/posts/c/make/makefile_tricks/","section":"posts","tags":["makefile"],"title":"Makefile 一些技巧"},{"categories":null,"contents":" ..\n环境变量相关 内存操作 网络操作 EMMC和SD卡 BOOT操作指令 bootm go 其他命令 启动相关\nmd\nmmcinfo\ncp\n","date":"2022-11-27T22:03:48+08:00","permalink":"https://wangloo.github.io/posts/os/uboot/commands/","section":"posts","tags":null,"title":"Uboot: 常用命令"},{"categories":["C Language"],"contents":"计算数组元素的个数 #define nelem(array) sizeof(array)/sizeof(array[0]) ","date":"2022-11-24T01:35:24+08:00","permalink":"https://wangloo.github.io/posts/c/c-macros/","section":"posts","tags":["c"],"title":"C 语言工具宏"},{"categories":["C Language"],"contents":"TODO: inline 的发展历程: Myth and reality about inline in C99 – Jens Gustedt\u0026rsquo;s Blog (wordpress.com)\nGNU89: 函数的实现之前添加不同的关键字:\n  inline: 表明这个函数可能被优化. 如果没有被优化, 编译器就会视为一个常规函数的定义.\n  extern inline: 表明这个函数可能被优化. 如果没有被优化, 编译器就将这个函数的定义转换为该函数的声明, 即 extern inline func(); 因此当此函数被调用时, 可以调用一个外部的函数来替代. 如果没有函数调用它, 那么也可以没有外部的替代函数实现.\n  static inline: 表明这个函数可能被优化. 如果没有被优化, 编译器就会视为一个常规静态函数.\n  C99: 函数的实现之前添加不同的关键字:\n inline: 等效于gnu89中的extern inline extern inline: 等效于gnu89中的inline static inline: 与gnu89相同含义.  C++: 只有inline一个关键字, 如果不能优化就定义为普通函数\n Ref:\nc++ - What does extern inline do? - Stack Overflow\nMyth and reality about inline in C99 – Jens Gustedt\u0026rsquo;s Blog (wordpress.com)\n  C demo 关于以上的各种情况\n ","date":"2022-11-24T01:35:24+08:00","permalink":"https://wangloo.github.io/posts/c/inline/","section":"posts","tags":["c"],"title":"C语言 \"inline\" 关键字"},{"categories":["Architecture"],"contents":"符合调用约定使得调用函数能够正常获取参数, callee结束之后能够回到原来位置继续执行.\nX86 调用约定 函数调用 x86架构中, 函数调用以一条call指令为分界.\n在call指令执行之前, 所有的参数必须都躺在栈中, 参数入栈的规则是: 第一个参数最后入栈.\n另外, 执行call指令之前, 必须确保栈指针esp是16-byte对齐. 这项工作是编译器完成的, 如果它判断参数入栈之后的esp 不满足对齐条件, 则会手动调整esp使之对齐. 实现方式见下面例子.\ncall 指令的语义是:\npush pc+1 ;push next insttuction mov pc, func ;set pc = new function call 指令之后的下一条指令就是callee的内容了, 至此就算是进入新函数的地盘.\n但是在执行新的任务之前, callee还需要完成栈的转换, 因为此时使用的栈还是caller的.\npush ebp ;preserve location of caller\u0026#39;s stack mov ebp, esp ;new ebp is old esp 此时esp也就是栈指针等于ebp, 这是callee栈的初始条件. 万事俱备, 可以开始执行callee的实际任务了.\n ebp在整个函数执行过程中是固定的, 好处是: 能够快速的或者函数参数, 返回地址.\n 函数返回 callee执行完毕后, 需要返回到caller继续执行. 刚才说过, callee的返回地址在栈中, 所以我们要做的是找到返回地址所在的位置, 然后使pc = 返回地址. 当然, 还有另一个重要的任务就是恢复caller的栈.\n上述任务的实现使用两条汇编语句就可完成: leave 和 ret.\nleave 负责搞定栈, 其语义为:\nmov esp, ebp ;回滚栈空间 pop ebp ;恢复caller的ebp ret 负责搞定pc, 其语义为:\npop ebx ;取出返回地址 mov pc, ebx ;jmp to 返回地址 ret 之后, 就算是返回caller的地盘了. 还有一件小事别忘了做: 用于保存参数的栈空间还没有回收, 回到caller之后需要先将esp的位置进行调整.\nExample: 函数的调用和返回 一个关于函数调用和返回实现的完整例子.\nvoid caller() { Func(1, 2, 3); } void Func(int a, int b, int c) { /* Do something */ } (以下汇编是AT\u0026amp;T格式的, 请见谅).\n; Caller sub $0x4,%esp ;make 16-bytes align before call. 0x4 是由编译器计算的 push $0x3 ;push 参数, 顺序是从右到左 push $0x2 push $0x1 call f01000ad \u0026lt;Func\u0026gt; ;Func()\u0026#39;addr is f01000ad ;===========\u0026gt;\u0026gt; Turn to callee  ;Func()  push %ebp ;preserve old ebp  mov %esp,%ebp ;set new ebp, ebp=esp now  /* Do something */ leave ;restore stack  ret ;restore instruction point  ;\u0026lt;\u0026lt;=========== Back to caller add $0x10,%esp ;recycle stack(12 bytes parameters plus 4 bytes alignment) AArch64 调用约定 大体的思想与x86相似, 只是细节有些许不同\nCall A Function ARMv8的函数调用以bl指令为分界，在bl执行之前，caller需要将参数准备好。少于8个参数的函数在传参时, 参数是放在x0-x7中, 最左边的参数先使用x0, 以此类推. 参数超过8个的情况下才使用栈, 这与x86的方式不同.\nbl指令保存返回地址, 并跳转到callee执行, 其语义是:\nmov lr, pc+1 ;preserve return address  ;lr specially used for preservering return addr mov pc, new_func ;set pc = new function 至此到了callee的职责范围。进入函数时, 需要完成三个前置动作:\n; 为callee()的执行留出足够的栈空间 ; 0x10不是固定的, 编译器计算得到 sub sp, sp, #0x10  ; 保存lr和fp, 因为callee可能调用 ; 其他的函数, 会破坏当前的 stp x29, x30, [sp] ; 保存sp的值, 所以x29也称为帧指针 ; 原因是sp在callee的执行过程中可能 ; 会变化. 与退出时配合理解较好 mov x29, sp 上述动作完成后, sp是自由的了, callee()的函数体开始执行.\nFunction Return callee()执行完后, 也需要执行一些后置动作, 以便恢复调用前caller()的环境.\n; 经过callee的指令执行过后, sp ; 可能早就不是以前的sp了, 但是帧指针 ; fp总是保存着callee初始的sp mov sp, x29 ; callee如果调用了其他函数, lr和fp ; 也会被破坏, 所以从栈中恢复callee ; 正确的lr和fp, 才能正确回到caller ldp x29, x30, [sp] ; 收回为callee分配的栈空间, 此时sp ; 是调用callee之前的值. add sp, sp, #0x10 后置动作完成后, 环境已经大致恢复到调用callee()之前的状态了, 通用寄存器中的值, 其实不必担心, 因为ARMv8规定了哪些寄存器是caller-saved或者callee-saved, 再说到lr和sp, caller也会保存到栈中, 就像callee调用其他的函数时的情况相同.\n所以, 完成后置动作后, 执行ret来返回到lr的位置即可.\n为什么编译出的汇编文件没有mov sp, x29? 如果查看实际C函数编译后的汇编结果, 大部分情况下会发现前置和后置行为不是严格的按照A64PCS中规定的样子, 常见的是后置动作缺少恢复sp的执行, 即mov sp, x29.\n原因其实不难发现, callee中使用的寻址方式都是相对于sp寻址, 即不修改sp. 既然sp从始至终都没被改过, 自然也不需要恢复了. 这样不需要每次都需要sp, 更加高效.\n但是, 前置动作中的保存sp到fp的行为通常是不会被省略的, 我猜是因为调试行为(例如backtrace)的实现需要用到fp.\n不是每次都这样, 也有时会修改sp, 此时就必须恢复.\n帧指针(fp)存在的意义 上面说了, 如果一直使用sp相对寻址来操作栈, 那么fp的存在似乎是非必要的.\n我了解到的事实也是如此, fp存在的必要性似乎就是使得一些调试功能更加方便. 堆栈回溯是一个典型的利用fp的场景, 从callee的fp可以找到其caller的fp, 也就是caller的堆栈空间, 以此类推可以找到caller-caller的fp\u0026hellip;\n如何关闭帧指针 仅针对AArch64来说, GCC提供了一些相关的编译选项来给程序员选择是否启用fp的权利.\n -fomit-frame-pointer 强制省略fp -fno-omit-frame-pointer 强制不省略fp  参考  x86 call 指令执行前需要esp对齐到 16-byte: x86 - What are the following instructions after this call (assembly) - Stack Overflow x86栈帧原理 - 知乎 (zhihu.com) 破获ARM64位CPU下linux crash要案之神技能：手动恢复函数调用栈  结语 能够正确达到函数调用和返回的实现方式有很多, 不是仅有这一种方式, 约定仅仅是一个约定, 大家都这样去做降低了开发的难度.\n","date":"2022-11-21T10:30:35+08:00","permalink":"https://wangloo.github.io/posts/arch/armv8/function-call-conventions/","section":"posts","tags":["armv8","x86","Operating System"],"title":"AArch64/X86 函数调用约定"},{"categories":["C Language"],"contents":"问题源于我在知乎刷到的一个回答: 能分享你C指针用得最灵活（飘）的一次吗?\n文中提到了Linus关于无头节点单项链表的删除操作给出的一种新的思路, 我觉得对理解指针非常有帮助, 所以在这里详细描述一下这件事.\n从我学习数据结构起, 对不含头节点的单向链表的删除操作, 做法常是: 借用pre指针搜索. 这种情况下避免不了对于链表中第一个节点的特判(第一个节点没有pre).\nLinus提到了一种借助二级指针避免该分支的方法.\nvoid remove_if(node ** head, remove_fn rm) { for (node** curr = head; *curr; ) { node * entry = *curr; if (rm(entry)) { *curr = entry-\u0026gt;next; free(entry); } else curr = \u0026amp;entry-\u0026gt;next; } } 指针的内容就是地址, int *p = a 也就意味着变量p 中保存着变量a的地址. 所以参数head在内存中的含义为:\n假如要删除node2, 那么改变*curr实际上就是改了node1的next成员.\n","date":"2022-11-20T23:40:30+08:00","permalink":"https://wangloo.github.io/posts/c/pointers-pointers-list/","section":"posts","tags":["c"],"title":"二级指针操作链表技巧"},{"categories":["Operating System"],"contents":"大小端问题的由来 为什么计算机世界需要区分大小端? 内存里存取的单位是字节, 如果所有的数据类型长度都是一个字节, 那就完全不需要大小端了, 每个变量都仅占据单独一个字节.\n例如, 三个变量 a=10, b=20, c=30, 在内存中的布局可能就是:\n┌────────────┐ │ │ │ 10 │ a ├────────────┤ │ │ │ 20 │ b ├────────────┤ │ │ │ 30 │ c ├────────────┤ │ │ │ │ │ │ │ │ │ │ └────────────┘ 但是我们最常使用的数据类型肯定有超过一个字节的, int类型在64位的系统中就占4个字节. 例如变量a=0xaabbccdd\n一个变量的大小一旦超过4个字节, 内存的存取又是以字节位单位的, 那么要把它塞到内存里就必然会产生两种不同存放方式: 先放0xaa还是先放0xdd\n首先, 0xdd是变量a的低8位, 0xaa是最高8位, 这是确定的.\n  如果先放0xaa, 即低地址放高位, 就叫做大端, 如左图;\n  如果先放0xdd, 即低地址放低位, 就叫小端, 如右图.\n  startaddrof`a`startaddrof`a`┌────────────┐┌────────────┐│││││aa││dd│├────────────┤├────────────┤│││││bb││cc│├────────────┤├────────────┤│││││cc││bb│├────────────┤├────────────┤│││││dd││aa│├────────────┤├────────────┤││││││││└────────────┘└────────────┘什么情况? 看下面的代码, 猜测输出的结果\nunsigned int i = 0x00646c72; printf(\u0026#34;Hello Wo%s\u0026#34;, \u0026amp;i); %s 会按字节一直打印内存中的字符, 直到遇到\\0. 首先打印的字符便是变量i的地址处的内容.\n如果是小端存储方式, 变量i的地址处的一个字节值是0x72, 即字符r. 以此类推, 所以如果CPU的字节序是小端形式, 那么printf的结果是: Hello world\n大小端形式的优缺点 小端的优势:\n  以不同的长度读取变量非常方便, 不用计算地址. 例如u64 a=0x1234, 当(u16)a时, CPU不需要重新计算读取的起始位置, 永远都是变量a的起始地址.\n  Easily to do mathematical computations “because of the 1:1 relationship between address offset and byte number (offset 0 is byte 0), multiple precision math routines are correspondingly easy to write.”\n  ","date":"2022-11-17T10:30:35+08:00","permalink":"https://wangloo.github.io/posts/os/big-little-endian/","section":"posts","tags":["Operating System"],"title":"操作系统：大小端问题"},{"categories":["Operating System"],"contents":"本文基于AArch64执行环境, 介绍现代操作系统中上下文切换的相关内容.\n何为上下文 我们正在看一本书的时候如果被其他的事情打断, 返回时为了能够从上次被打断的位置继续读, 就要在被打断的时候记下来当前是读到了哪个第几页的第几行.\n操作系统对待线程也是如此, 需要保存的用于恢复线程执行的信息就称为线程的上下文.\n那么对于线程来说需要记下的内容有什么呢? 寄存器和栈即可. 拿 AArch64 架构来距离, 线程的上下文就是:\n 通用寄存器x0-x29: 函数调用的参数, 某些计算过程的中间值, 都要用到这些寄存器. 线程的执行流可能在任何时候被打断, 当然这些内容也不能丢. 通用寄存器lr(x30): lr 保存着返回地址, 即当前函数结束之后该返回到哪执行. 栈顶指针 sp: 栈的重要性无需多言. 程序计数器 pc: 被打断的线程如果再次执行, 从哪里执行呢? 显然是被打断指令的下一条(或者重新执行当前). 这个指令的地址当然也需要被保存好. PSTATE: 想一下, 有了以上的内容就能够保证线程完整的恢复之前的环境吗? 其他的例如中断是开还是关, 有哪些标志位(NZCV)被设置了. 这些信息在 AArch64 中是保存在 PSTATE 的各个字段中. ttbr0：保存着进程的页表  上下文保存和恢复 TODO\n协程的上下文 协程是用户级别的线程,\n 协程之间的切换不进入内核 切换协程只能是某个协程主动放弃控制权  我们在这里讨论一下协程切换时需要保存的上下文是否与线程有所不同.\n首先, PC 一定属于, 这个毋庸置疑. 其次是栈顶指针 sp, 每个协程都有单独的栈, 如果不保存栈的位置, 那么协程内部定义局部变量就没法访问了(局部变量的访问指令都是以 sp 为 base 的偏移来做的).\n另外, 关于通用寄存器, 由于协程的切换需要主动调用某个函数(通常叫做yield()), 在函数的最后将 PC 设置为新协程的上下文 PC. 保存当前协程上下文的操作也在这个函数中, 而其参数我们并不关心, 即x0-x7没必要保存. 同样的, caller-saved 寄存器也是没必要保存的, 因为这些寄存器作为函数调用使用的临时变量, 当再次返回该协程时, PC=yield()返回地址, caller 如果关心这些寄存器应当自己执行保存和恢复. 但是callee-saved 寄存器必须要保存到上下文中, 因为在 yield()中, 我们如果修改了 callee-saved 寄存器, 就需要在返回时(也就是再次调度到该协程时) 恢复, 这是 callee 该做的, 也就是上下文中应该有的唯一通用寄存器组.\n","date":"2022-11-14T22:13:06+08:00","permalink":"https://wangloo.github.io/posts/os/context/","section":"posts","tags":["Operating System"],"title":"操作系统：上下文切换"},{"categories":["C Language"],"contents":"介绍 setjmp() and longjmp() 是一对组合使用的函数, 可以实现全局的goto.\nsetjmp() 构造一个运行环境, 调用longjmp() 则将执行流切换到该环境.\n/* setjmp() 保存当前的运行环境(上下文)到 env 参数中 */ int setjmp(jmp_buf env); /* longjmp() 将控制流切换到 env 指定的运行环境 */ void longjmp(jmp_buf env, int val); 使用方法 #include \u0026lt;setjmp.h\u0026gt;#include \u0026lt;stdio.h\u0026gt; jmp_buf e; void foo() { longjmp(e, 1); } int main(void) { int ret; /* After calling longjmp(), the execution flow back to setjmp(), and setjmp() will return not 0. */ ret = setjmp(e); if (ret == 0) { printf(\u0026#34;Return from setjmp\\n\u0026#34;); foo(); } else { printf(\u0026#34;Return from longjmp\\n\u0026#34;); } return 0; } 基于 AArch64 的实现 .macro func _name .global \\_name .type \\_name, %function \\_name: .endm .macro endfunc _name .size \\_name, .-\\_name .endm /** * setjmp (jmp_buf env) * * See also: * longjmp * * @return 0 - if returns from direct call, * nonzero - if returns after longjmp. */ func setjmp stp x19, x20, [x0], #16  stp x21, x22, [x0], #16  stp x23, x24, [x0], #16  stp x25, x26, [x0], #16  stp x27, x28, [x0], #16  stp x29, x18, [x0], #16  mov x9, sp stp lr, x9, [x0], #16  mov x0, #0  ret endfunc setjmp /** * longjmp (jmp_buf env, int val) * * Note: * if val is not 0, then it would be returned from setjmp, * otherwise - 1 would be returned. * * See also: * setjmp */ func longjmp ldp x19, x20, [x0], #16  ldp x21, x22, [x0], #16  ldp x23, x24, [x0], #16  ldp x25, x26, [x0], #16  ldp x27, x28, [x0], #16  ldp x29, x18, [x0], #16  ldp lr, x9, [x0], #16  mov sp, x9 mov x0, x1 cbnz x0, 1f add x0, x0, #1 1: ret endfunc longjmp 需要保存的上下文包括\n callee-saved 通用寄存器, 因为可能第一次调用 setjmp() 之后的执行流修改了这些寄存器, 从第二次回到 setjmp() 的角度来看, 就是执行setjmp() 中破坏的. caller-saved 寄存器则不必, 因为本来即便看作是 setjmp() 破坏的, 也是正常的.  解释一下：在如下的调用场景中, 可以看到在setjmp()之前分别赋值了x2和x19， 这其中x2是caller-saved，x19属于callee-saved。 callee-saved寄存器在子函数调用之前和之后应该是不变的，所以说如果子函数需要修改他们应该在函数进入前进行备份。 所以说显然在(1)的步骤中应该有x19的备份过程，(6)中也应该有对应的恢复。\n那么对于setjmp()呢？它自身也是一个函数，也需要满足规定。所以必须保证(5)访问到数据一定是(3)中保存的。 问题是对于setjmp()的使用方法来说，不是都遵循(1)(2)(3)(4)(5)的调用，下次会从别的位置直接跳到(4)。 此时仍然需要确保x19寄存器的正确性，只能在首次调用setjmp()时将x19保存下来，以后每次不管从哪里调过来先去恢复保存的x19。这样就能够实现callee-saved寄存器的正确性。\n再说说caller-saved寄存器，也就是demo中的x2为例，在中间跨越一个setjmp()的条件下， arch不能保证(4)中得到的值一定是(2)保存的，因为setjmp()可以随意的修改caller-saved寄存器。所以说，如果func()不得不要求(4)访问值的正确性， 一个解决方法就是在调用setjmp()之前保存x2到栈中，在setjmp()之后立马恢复。 这是caller的责任，所以这个过程会在func()完成，而不是setjmp()内部。\n以上就是为什么setjmp()只需要保存callee-saved寄存器的解释。\nfunc() { // (1)  Set x2 // (2)  Set x19 // (3)  setjmp() Access x2 // (4)  Access x19 // (5)  // (6) } setjmp() 实现 try-catch ","date":"2022-11-01T23:38:54+08:00","permalink":"https://wangloo.github.io/posts/c/setjmp_and_longjmp/","section":"posts","tags":["armv8","c"],"title":"ARM64 上实现 setjmp/longjmp"},{"categories":null,"contents":" Kernel Monitor 是什么 Kernel Monitor 是一个适配我们微内核操作系统的 Kernel 调试和监控系统. 它能实现内核的动态调试和监控. 同时, 它还接管内核的同步异常和系统错误, 使开发者能够了解发生异常时系统的状态.\nKernel Monitor 具有一定的可扩展性, 例如通过统计内核中存储的 TCB 来实时监控系统中所有线程的状态. 可根据开发者的需求添加统计的对象, 如 Endpoint, Capability等.\n Kernel Monitor 总体设计 Kernel Monitor 系统包含 Clinet 和 Server 两个部分. 简单来说, Client 负责处理用户输入, 并将输入进行解析, 封装为 一系列基础命令. 发送给 Server. Server 负责执行这些 基础的命令, 如设置断点, 查看某个地址的值等.\n整个系统有两种架构: 本地 Monitor 和远程 Monitor.\n本地monitor 和远程 monitor 的区别是: Monitor Client 的位置在哪, 是否与 Server 在同一个机器上.\n 先说 Monitor Server, 它必须嵌入要调试的 Kernel 中, 位于一个地址空间, 方便操作 Kernel 的内存.\n 本地 Monitor 在本地 Monitor 中, client 和 sever 都位于目标机(Target)上, 目标机通常是开发板.\n对于 AArch64 体系结构来说, 最多有四个异常等级(EL0-EL3). Client 可以运行在EL2.\n远程 Monitor 远程 Monitor 架构则不同, Clinet 运行在宿主机(Host)上, 通常是Linux. 它与 Server 的通信是通过网络/UART实现的.\n Monitor Client 运行在本地和远程对于实现的难度和用户体验有影响.\n  如果 Client 实现在本地, 则 Client 无需实现网口和串口的驱动, 但Monitor 输入输出的串口与操作系统本身的串口相同, 信息冗杂在一起不易查看; 同时, 如果 Client 实现在本地, 那么对于ELF的解析需要在无操作系统提供的库支持下完成, 可能比较复杂.\n  如果 Client 实现在远程, 即为 Linux 上的一个APP. 那么它和 Server 的通信就需要通过外部的网口或者串口(对于我们使用的64位开发板只引出了一个串口, 所以只能使用网口). 需要在 Server 上实现网口的驱动, 这部分比较复杂. 但是好处是 Client 的实现简单很多, 因为有 Linux APP 运行环境的支持. 同时, 远程 Monitor 架构下, Monitor 和 操作系统自身的输入输出分开, 用户可读性更好.\n   Server 是嵌入到Kernel的代码中, 与Client进行交互. 它是整个 Monitor 系统的后端, 负责实现基础的调试操作. 例如, 设置断点, 内存的读写, 寄存器的读写等.\n 由于Server与 Kernel 位于同一个地址空间, 所以查看/修改内存的值是非常方便的. 对于寄存器也是同理. 断点(Breakpoint), 监视点(Watchpoint), 单步执行(Soft step)的实现依赖与 ARMv8 提供的的 self-hosted debug 支持.  同时, Server 还负责监视系统中所有的 同步异常和系统错误. 一旦发生, 可在 Monitor 中查看某些内存, 寄存器的值定位问题发生的原因.\nMonitor Client 设计 Client 的构成可分为三个模块 :\n 用户交互模块 符号处理模块 消息收发模块  用户交互模块负责处理用户的输入输出, 调用其他两个模块完成调试命令.\n符号处理模块负责解析可执行文件(ELF), 并建立静态符号表, 存储符号和地址的对应关系. 将用户输入的符号解析为虚拟地址, 或者反向解析.\n消息收发模块负责处理用户的输入, 将其转化为基础, 标准的命令, 发送给Server执行. Client 和 Server之间通信的数据包协议可以使用 GDB Remote Serial Protocol (以下简称RSP协议), 或者自己规定一个协议也是可行的.\n RSP协议支持三种基础命令:\n 寄存器相关 内存相关 程序控制命令   启用 Monitor 时 Kernel 启动流程  Kernel 首先做必要的初始化, GIC, 异常向量表, MMU等. 将控制权交给 Monitor, 等待用户输入.   Kernel debug 过程示例 示例一: 查看变量 var 的值  用户输入 print var 指令. 由符号处理模块, 将var符号转为var 虚拟地址. 由消息收发指令将请求封装为RSP协议包格式, 并发送到 Monitor Server. 执行流程交给 Monitor Server, 它访问该地址, 将内容封装发回 Monitor Client. Client 输出var的值, 继续等待用户输入  示例二: 添加断点到 main 函数  用户输入 break main 指令 由符号处理模块, 解析得到 main 函数的地址. 消息收发模块将请求封装为RSP包格式, 发送到Monitor Server. 执行流程交给 Server. 它执行 breakpoint exception 指令, 并设置相关软件断点相关寄存器 执行流交给 Kernel, 直到达到断点处(可使用地址+ContextID双重验证), 触发Debug异常 Debug异常属于同步异常, 由 Monitor 系统接管, 回到 Client 继续等待用户输入  示例三: 单步执行  用户输入 step 指令 消息收发模块将请求封装为RSP包格式, 发送到 Monitor Server. 执行流程交给 Server, 启用 software step. 然执行一次异常返回, 回到Kernel 继续执行. 因为启用了 Software step, 回到 Kernel 执行完一条指令后, 就会触发 Debug异常 Debug 异常属于同步异常, 由 Monitor 系统接管, 回到 Client 继续等待用户输入   其他拓展功能 back trace\n性能分析\n","date":"2022-10-28T22:56:19+08:00","permalink":"https://wangloo.github.io/posts/os/monitor/","section":"posts","tags":null,"title":"Armv8 Kernel Monitor"},{"categories":["Architecture"],"contents":"Introduction MMU: 专用于将虚拟地址转换为物理地址. 通常配合分页机制来工作.\n页表: 页表中的表项包含提供虚拟地址和物理地址之间的映射.\nMMU就是直接访问页表, 并且通过将频繁使用的映射缓存到TLB中.\nMMU 的结构 MMU是一种硬件, 可以通过在适当的安全状态下对其进行配置. 每个Core都有自己的MMU, 每个MMU包括:\n 一个TLB, 缓存最近访问的映射. 一个Table Walk Unit, 从内存中查询页表, 得到最终的虚拟地址-物理地址的映射.  MMU 控制着整个系统的缓存策略, 内存属性和访问权限. MMU开启后, 软件发出的所有内存访问都使用虚拟地址, 要求MMU为每次访问进行地址转换.\nMMU 的配置 在启用MMU前, 必须告知其页表存放的位置.\nMMU 地址转换的过程 对于每个转换请求, MMU首先检查TLB是否已经对该地址缓存, 如果该地址未缓存, 则需要遍历页表.\n页表遍历单元在页表中搜索相关的映射表项.\n 一旦找到映射, MMU就会检查权限和属性. 决定允许本次访问, 或者发出故障信号. 若未找到映射, 则触发缺页异常.  页表的工作原理 页表的工作方式是将虚拟地址空间和物理地址空间划分为大小相等的块, 称为页面.\n页表中的每个表项对应着一块虚拟地址空间中的块, 表项的值就是这块虚拟地址空间对应的物理地址块, 以及访问物理地址时要使用的属性.\n在查表过程中, 将虚拟地址分为两部分:\n 高阶位用作页表的索引. 用来找到对应的物理块 低地址是块内的偏移量, 不会因为映射而改变. 页表项中的物理地址与该偏移组合形成用于访问内存的物理地址.  多级页表 实际实现中, 多采用多级页表的方案, 各级页表自定向下组成树的形式, 协作实现虚拟到物理地址的转换.\n树中的分支成为页目录, 页目录中的表项不是直接存储目标物理地址, 而是下一级页表的地址; 最后一级页表的表项中保存着目标物理地址.\n 多级页表是减小页表占用存储空间过大的有效方案.\n 顶级页表将地址空间划分为大块, 每个表项可以指向大小相等的内存块. 也可以指向将块进行再次细分的下一级页表. 支持大块的优点:\n 大的内存块需要查表的次数更少 提升TLB的效率, 因为一个TLB表项覆盖更大的内存区域.  凡事都是有利有弊, 使用大块也增加了内存浪费, 实际使用时需要根据需要来权衡.\n内存类型 普通类型内存 普通类型的内存是弱一致性的(weakly ordered)内存模型, 没有额外的约束, 可以提供最高的内存访问性能.\n通常代码段, 数据段以及其他数据都放在普通内存中.\n普通内存允许处理器做很多优化, 如分支预测, 数据预取, Cache line预取, 乱序执行等.\n设备类型内存 CPU访问设备内存会有很多限制, 如不能进行数据预取等. 设备类型的内存严格按照指令的顺序来执行的.\n设备类型内容通常留给设备来访问, 例如中断控制器(GIC), 串口, 定时器等.\n两套页表  当CPU访问的地址属于用户空间时, MMU会自动选择TTBR0指向的页表. 当CPU访问的地址属于内核空间时. MMU会自动选择TTBR1指向的页表  EL2和EL3没有TTBR1, 只有TTBR0. 也就意味着:\n• If EL2 is using AArch64, it can only use Virtual Addresses in the range 0x0 to 0x0000FFFF_FFFFFFFF. • If EL3 is using AArch64, it can only use Virtual Addresses in the range 0x0 to 0x0000FFFF_FFFFFFFF.\n越权, 越界 在未使用虚拟地址空间之前, 所有的用户程序都可以访问全部的物理内存, 所以恶意程序可以修改其他程序的内存数据, 这使得整个系统处于危险的状态. 每个进程的地址空间都要受到保护, 以免被其他进程有意/无意的破坏.\n现代操作系统中, 每个进程都有独立的虚拟地址空间. 在进程的角度上, 它拥有整个虚拟地址空间. 不同的进程可以同时使用一个虚拟地址, MMU通过页表将其映射到合适的物理地址.\n两个物理地址空间 ARMv8 体系结构定义两个物理地址空间: secure address space 和 non-secure address space.\n理论上, 安全和非安全的地址空间是相互独立的, 然而现实中大多数系统都将安全和非安全视为访问控制的属性. 正常(非安全)世界只能访问非安全的物理内存; 而安全世界可以访问这两个地址空间.\nARMv8 MMU权限控制 程序请求某个地址时, MMU需要进行权限检查. 如果请求的地址是数据, 则检查读写权限; 如果请求的是地址, 则检查其可执行权限.\nARMv8 页表项的AP字段控制该不同异常等级下, 页面的读写权限.\n[表格]\nARMv8 页表项的PNX字段和XN/UXN字段来设置CPU是否对这个页面有执行权限.\n  当系统有两套页表时, UXN是用来设置用户空间页面是否有可执行权限; PXN 用来设置特权空间的页面是否有可执行权限.\n  若系统只有一套页表, 则通过XN字段控制\n  页表的结构 地址宽度 48bit\n页面粒度 页面粒度表示一次最小分配内存块的大小. AArch64支持三种页的大小, 4KB, 16KB, 64KB. 支持哪一种是由实现定义的。创建页表的代码能够读取系统寄存器ID_AA64MMFR0_EL1，以找出哪些是受支持的大小。Cortex-A53处理器支持所有三种尺寸，但有些处理器的早期版本并非如此，例如Cortex-A57，它不支持16K粒度。\nAArch64 页表项结构 无效页表项 table block 页表结构(4KB页面为例) 以4KB页面粒度, 虚拟地址宽度为 48位. 使用4级页表.\n48位地址每层转换有9个地址位，即每层512个条目，最后12位选择4kB内的一个字节，直接来自原始地址\n虚拟地址到物理地址的转换过程 当处理器为获取指令或数据访问发出一个64位的虚拟地址时，MMU硬件将虚拟地址转换为相应的物理地址。对于虚拟地址，前16位[63:47]必须全部为0或1，否则地址将触发故障。\nNon-secure and secure access ARMv8-A架构定义了两种安全状态:安全的和非安全的。它还定义了两个物理地址空间:安全的和非安全的. 正常(非安全)世界只能访问非安全物理地址空间。安全世界可以访问两个物理地址空间。这也是通过转换表来控制的。\n在非安全状态下，转换表中的NS位和NSTable位将被忽略。只能访问非安全内存。在安全状态下，NS位和NSTable位控制虚拟地址转换为安全物理地址还是非安全物理地址。\nYou can use SCR_EL3.SIF 来禁用安全世界访问非安全地址.\n相关的寄存器 与地址转换相关的寄存器主要有以下几个:\n 转换控制寄存器(TCR) 系统控制寄存器(SCTLR) 页表基地址寄存器(TTBR)  TCR IPS: 配置地址转换后输出物理地址的最大值\nTxSz: 配置输入地址的最大值, 即虚拟地址的宽度\nTG1: 配置TTBR1页表的页面粒度大小\nSHx: 配置TTBRx相关内存的Cache共享属性\nORGNx:\nIRGNx:\nSCTLR M: Disable/Enable MMU地址转换\nC: Disable/Enable Data Cache\nI: Disable/Enable Instruction Cache\nTTBR 存储页表的基地址\nAArch32 虚拟内存系统 ARMv8 AArch32 的虚拟内存系统向后兼容ARMv7, 与ARMv7的基本一致.\n","date":"2022-09-29T08:01:33+08:00","permalink":"https://wangloo.github.io/posts/arch/armv8/mmu/","section":"posts","tags":["armv8"],"title":"AArch64 MMU介绍"},{"categories":["C Language"],"contents":"语句结构 asm asm-qualifiers ( AssemblerTemplate : OutputOperands : InputOperands : Clobbers : GotoLabels) The asm keyword is a GNU extension. 当使用编译选项 -ansi 或 -std 时, 使用 __asm__代替 asm.\nQualifiers  volatile: 向编译器说明禁止内敛的语句与其他语句 reorder。但不能保证内部 reorder，那是内存屏障的任务 goto inline  Parameters AssemblerTemplate: 字符串, 汇编代码的模板\nOutputOperands: 输出操作数; 指令将会修改的变量集合\nInputOperands: 输入操作数; 指令将读取的变量集合\nClobbers: ???TODO\nGotoLabels: 仅当 qualifiers 使用goto时, 声明label集合.\n The total number of input + output + goto operands is limited to 30.\n  Param #1: AssemblerTemplate 多条语句可以放在一个asm字符串中, 但是更常见的是每条汇编语句使用一个字符串, 并在结束时使用换行符和制表符(\\n, \\t)来表示换行.\n 貌似对于 arm 汇编, 只用 \\n 也OK?\n  Param #2: OutputOperands 多个 OutputOperands 之间使用,隔开, 每个 OutputOperands 的格式如下:\n[ [asmSymbolicName] ] constraint (cvariablename) asmSymbolicName: 指定该操作数的名称\nconstraint: 对该操作数的一些限制\n//描述操作数的权限,输出操作数的约束必须以此开头=忽略现有值+读写,当原先值有意义时用它\u0026amp;禁止编译器将该操作数与不相关的输入操作数分配同一个寄存器//描述输出操作数所在位置,如果你不知道,可以同时设置,编译器会帮你决定r寄存器m内存//架构相关的zAArch64中存在.表达可以使用零寄存器(XZRorWZR).Usefulwhencombinedwith`r`torepresentanoperandthatcanbeeitherageneral-purposeregisterorthezeroregister.cvariablename: 输出到的 C 语言变量名\n Param #3: Input Operands 输入操作数的格式与输出操作数基本一致:\n[ [asmSymbolicName] ] constraint (cexpression)  对于输入操作数, 一般没有别的限制, 仅使用\u0026quot;r\u0026quot;(val)\n  Param #4: Clobbers 每个 clobber 都是用双引号括起来, 并用逗号分隔的字符串常量.\n常用的 clobber 参数:\n  \u0026ldquo;memory\u0026rdquo;\n向编译器说明对于所有内存访问操作，不能使用 asm 之前预加载到寄存器中的值， 而必须在 asm 内部重新加载。保证其内部访问内存值具有可见性和正确性。\n  \u0026ldquo;cc\u0026rdquo;\nThis stands for \u0026ldquo;condition codes\u0026rdquo;. Since the add instruction will affect the carry flag amongst other things, we need to tell gcc about it. Otherwise it might want to split a test-and-branch around our code. If it did so, the branch might go the wrong way due to the condition codes being corrupted. Basically, any inline asm that does arithmetic should explicitly clobber the flags like this.\n   Param #5: GotoLabels 尽量不使用, 可以在ASM的内部直接定义 label\nTODO\n 样例 最简单的模板 int src = 1; int dst; asm (\u0026#34;mov %1, %0\\n\\t\u0026#34; \u0026#34;add $1, %0\u0026#34; : \u0026#34;=r\u0026#34; (dst) : \u0026#34;r\u0026#34; (src)); printf(\u0026#34;%d\\n\u0026#34;, dst); 操作数使用 asmSymbolicName uint32_t c = 1; uint32_t d; uint32_t *e = \u0026amp;c; asm (\u0026#34;mov %[e], %[d]\u0026#34; : [d] \u0026#34;=rm\u0026#34; (d) : [e] \u0026#34;rm\u0026#34; (*e)); 内部定义 label long temp; long ret; asm volatile( \u0026#34;1: \\n\u0026#34; \u0026#34;ldxr %0, [%2]\\n\u0026#34; \u0026#34;sub %0, %0, %3\\n\u0026#34; \u0026#34;stxr %w1, %0, [%2]\\n\u0026#34; \u0026#34;cbnz %w1, 1b\\n\\t\u0026#34; : \u0026#34;=\u0026amp;r\u0026#34;(ret), \u0026#34;=\u0026amp;r\u0026#34;(temp) : \u0026#34;r\u0026#34;(p), \u0026#34;r\u0026#34;(val) : \u0026#34;memory\u0026#34; ); Reference Extended Asm (Using the GNU Compiler Collection (GCC))\nAArch64 Constraint codes\n","date":"2022-09-24T16:48:58+08:00","permalink":"https://wangloo.github.io/posts/c/inline-asm/","section":"posts","tags":["c"],"title":"GNU C 内联汇编学习"},{"categories":["Shellscript"],"contents":"sh 是个啥 busybox 的 shell 是 ash，ash 不同于主机上的 sh bash tcsh，它是个精简版，很多标准shell 支持的特性它都不支持。\nsh 的含义是默认的 shell，可能是bash、可能是dash，一般来说只是一个软链接。\n.notice { --root-color: #444; --root-background: #eff; --title-color: #fff; --title-background: #7bd; --warning-title: #c33; --warning-content: #fee; --info-title: #fb7; --info-content: #fec; --note-title: #6be; --note-content: #e7f2fa; --tip-title: #5a5; --tip-content: #efe } @media (prefers-color-scheme:dark) { .notice { --root-color: #ddd; --root-background: #eff; --title-color: #fff; --title-background: #7bd; --warning-title: #800; --warning-content: #400; --info-title: #a50; --info-content: #420; --note-title: #069; --note-content: #023; --tip-title: #363; --tip-content: #121 } } body.dark .notice { --root-color: #ddd; --root-background: #eff; --title-color: #fff; --title-background: #7bd; --warning-title: #800; --warning-content: #400; --info-title: #a50; --info-content: #420; --note-title: #069; --note-content: #023; --tip-title: #363; --tip-content: #121 } .notice { padding: 18px; line-height: 24px; margin-bottom: 24px; border-radius: 4px; color: var(--root-color); background: var(--root-background) } .notice p:last-child { margin-bottom: 0 } .notice-title { margin: -18px -18px 12px; padding: 4px 18px; border-radius: 4px 4px 0 0; font-weight: 700; color: var(--title-color); background: var(--title-background) } .notice.warning .notice-title { background: var(--warning-title) } .notice.warning { background: var(--warning-content) } .notice.info .notice-title { background: var(--info-title) } .notice.info { background: var(--info-content) } .notice.note .notice-title { background: var(--note-title) } .notice.note { background: var(--note-content) } .notice.tip .notice-title { background: var(--tip-title) } .notice.tip { background: var(--tip-content) } .icon-notice { display: inline-flex; align-self: center; margin-right: 8px } .icon-notice img, .icon-notice svg { height: 1em; width: 1em; fill: currentColor } .icon-notice img, .icon-notice.baseline svg { top: .125em; position: relative }    sh与$0之间的关系？  $0 具体代表什么含义是每个shell程序实现的，如果sh是指向dash，那么此时 $0 就会输出dash。\n  bash和dash的语法区别 - 博客园\n 常用Shell命令  ℹ️ 如未特殊说明，以下的命令在bash和zsh中都能正确生效。\n Grep - 内容匹配 Grep stands for Global Regular Expression Print.\n# 语法结构，PATTERN是正则表达式，所以不需要像find命令用*号 # 参数 # -n ==\u0026gt; print line number # -r ==\u0026gt; recursive search # -E ==\u0026gt; 扩展正则表达式 # -I ==\u0026gt; 跳过二进制文件 # --exclude/--exlude-dir ==\u0026gt; 排除路径和文件 grep -Inr page_fault mkfs.ext4 - 格式化文件 # 格式化文件为ext4分区 mkfs.ext4 \u0026lt;file\u0026gt; dd - 生成和转换文件 https://www.runoob.com/linux/linux-comm-dd.html\nmount - 挂载硬盘分区 sudo mount [file] [dir] # 挂载file到dir sudo umount [dir] sudo mount # 输出当前已经挂载的分区 find - 查找文件 # 查找24小时内修改过的文件 find . -mtime 0 # 查找2小时内修改过的文件 find . -mmin -$((2*60)) # 查找24小时内访问过的文件 find . -atime 0s 十六进制查看 xxd: 按字节解释。因为它来自于文本编辑器 Vim 嘛。\nhexdump: 默认类似于 -x 格式，两字节数值解释。小端序下和xxd是双字节内是反的。\ntee - 标准输入到文件 常用的情景是，执行一些命令的输出不仅想要打印要屏幕，同时想输出到文件中保存。\n# 与tee结合，同时输出到屏幕和文件 make 2\u0026gt;\u0026amp;1 | tee log.txt # 使用tee命令可以将一条命令的输出同时传递给多个命令进行处理。 ls | tee \u0026gt; (grep keyword) \u0026gt; (wc -l) echo - 输出字符串 # echo不自动换行 echo -n \u0026#34;some-string\u0026#34; # echo转义特殊字符 echo \u0026#34;some-string\\n\u0026#34; # 不转义\\ echo -e \u0026#34;some-string\\n\u0026#34; # 正确转义换行  Zsh中，echo默认带-e，bash中则不是。 所以说，如果输出的字符串有转义字符，不管要不要转义，都显式指定一下。\n -e 强制转义 -E 强制不转义   which/whereis - 定位文件路径 which 查看可执行文件的位置，whereis 除了可执行文件还能搜索其他类型的文件, 不常用, 详见 man whereis\n$ which python3 /usr/bin/python3 小技巧 如何理解2\u0026amp;\u0026gt;1? make # stdout和stderr，会输出到屏幕上 make 1\u0026gt; stdout.log # 仅将标准输出重定向到stdout.log文件 make \u0026gt; stdout.log # 同上，简略写法 make 2\u0026gt; stderr.log # 将stderr输出重定向到文件，有错误语句 make 2\u0026gt;1 # 将stderr输出重定向到文件名1的文件 make 2\u0026gt;\u0026amp;1 # 将stderr输出重定向stdout 将stdout和stderr结合，有啥用呢？\nmake 2\u0026gt;\u0026amp;1 \u0026gt;all.log # stdout和stderr都会被存到all.log中 make 2\u0026gt;\u0026amp;1 | tee log.txt # 与tee结合，同时输出到屏幕和文件 - 的妙用 一些命令支持使用 - 代替文件名, 输入输出都可以:\n 代替标准输出; 一些命令会将-o/-O 后面的-判定为输出到STDOUT, 详见下面示例. 代替标准输入;  下面给出两个同时代替输入输出的例子:\n# 将标准输入(STDIN)的内容作为gcc的输入, 编译后的结果输出到标准输出(STDOUT) echo \u0026#39;void foo() {}\u0026#39; | gcc -x c -o - - # 将下载的文件输出到标准输出, 同时作为tar命令的输入文件, 进行解压 wget -O - \u0026#34;https://www.dropbox.com/download?plat=lnx.x86_64\u0026#34; | tar xzf -     - 如何被解析是取决于命令的实现, 非标准. 比如 cd - 就有特殊的含义\n sort 应付多种场景 # 对版本号进行排序(x.y.z) echo -ne \u0026#34;1.2.3\\n4.5.6\\n3.4.5\u0026#34; | sort -V cp正确链接文件 执行cp命令时，如果目录下有链接文件，拷贝源文件而不是链接文件，这在链接文件指向相对地址时非常有用。\ncp -rL /path/to/ /path/from 查看当前shell echo $0 find 删除文件 rm和find结合，find过滤要删除的文件，传递给rm。建议删除前先输出到屏幕检查。\nfind . -maxdepth 1 -executable -type f | xargs rm 统计代码量 # 列出*所有的文件及其代码行数*, 只统计.c 和.h, 过滤`./scripts`目录. find -name \u0026#39;*.[c|h]\u0026#39; ! -path \u0026#39;./scripts/*\u0026#39; | xargs wc -l # +将内容按照代码行数降序排列 find -name \u0026#39;*.[c|h]\u0026#39; ! -path \u0026#39;./scripts/*\u0026#39; | xargs wc -l | sort -rn # 若仅列出*总的代码行数*, 去除**空行** (find ./ -name \u0026#39;*.[c|h]\u0026#39; -print0 | xargs -0 cat) | sed \u0026#39;/^\\s*$/d\u0026#39; | wc -l 其他  Bash脚本正式语句开始前加 set -e, 使得任何命令返回非0时立即退出整个Shell脚本。 规定分隔符。默认Shell会采用空格、tab、换行都作为分隔符， 有时需要屏蔽某些，仅使用空格 export IFS=\u0026#39; \u0026#39; # 启用空格分隔only flag=\u0026#34;false\u0026#34; for str in $qemu_ver; do # do something done unset IFS # 恢复默认   Shell脚本分析 shift 用于处理参数 shift命令将参数左移，应用场景:\n# 场景1：提取第二个参数及后面的所有 # ./shell qemu-system-aarch64 -machine raspi3b -smp qemu=$1 shift # 默认左移1 qemu_opt=$@ ## 场景2: 处理多参数且位置不定的情况 while [ \u0026#34;$#\u0026#34; -gt 0 ]; do case \u0026#34;$1\u0026#34; in -f|--file) file=\u0026#34;$2\u0026#34; shift 2 ;; -d|--directory) directory=\u0026#34;$2\u0026#34; shift 2 ;; -m|--mode) mode=\u0026#34;$2\u0026#34; shift 2 ;; *) echo \u0026#34;Unknown option: $1\u0026#34; exit 1 ;; esac done 实战学习：自动更新Git仓库 来源：南京大学ICS PA ics-pa-gitbook/update.sh\n#!/bin/sh  git fetch origin master # Trick 1: 1:-\u0026#39;@{u}\u0026#39; ==\u0026gt; 1代表参数传入，如果为空就 当前分支所跟踪的远程分支(\u0026#39;@{u}\u0026#39;) UPSTREAM=${1:-\u0026#39;@{u}\u0026#39;} . # Trick 2: @ ==\u0026gt; 当前分支 # Trick 3: git rev-pase ==\u0026gt; 列出某个分支最新的commit ID LOCAL=$(git rev-parse @) REMOTE=$(git rev-parse \u0026#34;$UPSTREAM\u0026#34;) if [ $LOCAL = $REMOTE ]; then echo \u0026#34;Already up to date.\u0026#34; exit fi git reset --hard origin/master git gc 变量的定义和引用 # 何时变量赋值要加\u0026#34;\u0026#34;? # =\u0026gt; 包含分隔符，空格或tab时 qemu_opt=\u0026#34;-machine raspi3b\u0026#34; # 引用变量时为什么加{}? ${var} # 引用变量时为什么加\u0026#34;\u0026#34;? \u0026#34;$var\u0026#34; # 变量赋值为什么$()? # =\u0026gt; ()里面是shell命令时用 qemu_ver=$($qemu --version | head -n 1) 判断执行脚本时带的参数 if [ $# -ne 1 ]; then echo \u0026#34;ONE parameter is needed\u0026#34; exit -1 fi if [ $1 == \u0026#39;build\u0026#39; ]; then # do something elif [ $1 == \u0026#39;run\u0026#39; ]; then # do something elif [ $1 == \u0026#39;gdb\u0026#39; ]; then # do something else echo \u0026#34;Not supported command\u0026#34; fi 自动拷贝文件到 SD Card  TODO\n 添加进度条   #!/bin/bash sd_path=$(find /media/$USER -maxdepth 1 -type d -name \u0026#34;*-*\u0026#34;) while [ ! -d \u0026#34;${sd_path}\u0026#34; ] do sleep 1 echo \u0026#34;waiting for inserting SD-Card\u0026#34; done echo \u0026#34;SD-Card is inserted\u0026#34; cp ./output/kernel/kernel.bin ${sd_path} echo \u0026#34;Copy completely\u0026#34; 获取所有文件信息(可递归进入子目录) 获取dir路径下的所有文件的信息, 这里获取的是文件的完整路径.\n TODO\n 操作数组下标的方式可能有待改进? filenum感觉没必要, 暂时还不会改 通过拼接获得文件信息(路径)的方式也有点怪异   dir=./ files=() filenum=0 function getfiles() { for file in `ls $dir`; do if [ -d $file ]; then cd $file getfiles cd .. else files[$filenum]=$(pwd $file)/$(basename $file) # echo file=$(pwd $file)/$(basename $file) let filenum++ fi done } 带颜色的输出 使用ANSI escape code\nBlack 0;30 Dark Gray 1;30 Red 0;31 Light Red 1;31 Green 0;32 Light Green 1;32 Brown/Orange 0;33 Yellow 1;33 Blue 0;34 Light Blue 1;34 Purple 0;35 Light Purple 1;35 Cyan 0;36 Light Cyan 1;36 Light Gray 0;37 White 1;37 Code example:\n#!/bin/bash  RED=\u0026#39;\\033[0;31m\u0026#39; GREEN=\u0026#39;\\033[0;32m\u0026#39; YELLOW=\u0026#39;\\033[1;33m\u0026#39; BLUE=\u0026#39;\\033[0;34m\u0026#39; CYAN=\u0026#39;\\033[0;36m\u0026#39; NC=\u0026#39;\\033[0m\u0026#39; # No Color echo -e \u0026#34;${YELLOW}HELLO, YELLOW${NC}\u0026#34; echo -e \u0026#34;${GREEN}HELLO, GREEN${NC}\u0026#34; echo -e \u0026#34;${RED}HELLO, RED${NC}\u0026#34; echo -e \u0026#34;${BLUE}HELLO, BLUE${NC}\u0026#34; echo -e \u0026#34;${CYAN}HELLO, CYAN${NC}\u0026#34; ######################################################### # generic functions ##################################### function ERROR(){ echo -e \u0026#34;${RED}[error] $*${NC}\u0026#34;; exit 1 } function INFO { echo -e \u0026#34;${BLUE}[info] $*${NC}\u0026#34;; } function WARN { echo -e \u0026#34;${YELLOW}[warn] $*${NC}\u0026#34;; } function LOG { echo -e \u0026#34;${GREEN}[log] $*${NC}\u0026#34; \u0026gt;\u0026gt; $LOG } INFO \u0026#34;This is an infomation\u0026#34; WARN \u0026#34;This is a log\u0026#34; ","date":"2022-07-20T11:54:13+08:00","permalink":"https://wangloo.github.io/posts/tools/shell/","section":"posts","tags":["Shellscript"],"title":"Shell 命令技巧"},{"categories":["C Language"],"contents":"连续内存取n bit #include \u0026lt;stdio.h\u0026gt;#include \u0026lt;stdint.h\u0026gt;#include \u0026lt;assert.h\u0026gt; #define bitmask(n) ((1ul \u0026lt;\u0026lt; (n)) - 1)  /* * 从ptr指向的内存开始，抽取第start个bit开始的连续n个bit * 限制: n \u0026lt; 32 */ uint32_t extract_bits(uint8_t *ptr, uint32_t start, uint32_t n) { uint32_t start_byte = start / 8; uint32_t start_offset = start % 8; uint32_t *pstart = (uint32_t *)(ptr + start_byte); uint32_t end = start + n - 1; uint32_t end_byte = end / 8; uint32_t end_offset = end % 8; uint32_t *pend = (uint32_t *)(ptr + end_byte); uint32_t data = *pstart \u0026gt;\u0026gt; start_offset; if (n \u0026gt; 32 - start_offset) { /* 由于n \u0026lt; 32, 所以补齐*pend一定就够了， * end_offset对齐到最后一位(n-1). * * 严谨性证明: n 一定\u0026gt; end_offset + 1 * 因为n \u0026gt; 32-start_offset ==\u0026gt; n \u0026gt; 25, * 且end_offset + 1 \u0026lt; 9, 故得证 */ data |= *pend \u0026lt;\u0026lt; (n - end_offset - 1); } return data \u0026amp; bitmask(n); } void test_val(uint32_t val, uint32_t expect) { if (val != expect) { printf(\u0026#34;error: val: 0x%x, expect: 0x%x\\n\u0026#34;, val, expect); } assert(val == expect); } int main(void) { uint32_t vals[] = {0x11223344, 0x11223344}; uint32_t ret; ret = extract_bits((uint8_t *)vals, 31, 30); test_val(ret, 0x22446688); printf(\u0026#34;Test Passed!\\n\u0026#34;); return 0; } 一个数取连续n bit /* * 从一个数中取第start个bit开始的连续n个bit */ uint32_t extract_bits (uint32_t val, uint32_t start, uint32_t n) { return (val \u0026gt;\u0026gt; start) \u0026amp; bitmask(n); } 判断一个数是否为2的幂 unsigned int v; if ((v \u0026amp; (v - 1)) == 0) printf(\u0026#34;v is a power of 2\\n\u0026#34;); else printf(\u0026#34;v is not a power of 2\\n\u0026#34;);  统计一个数的二进制中1的数量 依然是利用v \u0026amp; (v -1)的运算结果会将v的最低位的1(如果有的话)置0.\n循环执行此操作就可统计v中1的数量.\nint numberof1(int v) { int count = 0; while(v) { count++; v = v \u0026amp; (v -1); } return count; }  将一个数向上取整为2的幂 用一个1一直左移, 直到比这个数大为止.\nuint32_t roundup_pow_of_two(const uint32_t x) { uint32_t ret = 1; while (ret \u0026lt; x) { ret = ret \u0026lt;\u0026lt; 1; } return ret; } Linux内核中使用了一种更快的方案, amazing!!!\nstatic __inline__ int generic_fls(int x) { int r = 32; if (!x) return 0; if (!(x \u0026amp; 0xffff0000u)) { x \u0026lt;\u0026lt;= 16; r -= 16; } if (!(x \u0026amp; 0xff000000u)) { x \u0026lt;\u0026lt;= 8; r -= 8; } if (!(x \u0026amp; 0xf0000000u)) { x \u0026lt;\u0026lt;= 4; r -= 4; } if (!(x \u0026amp; 0xc0000000u)) { x \u0026lt;\u0026lt;= 2; r -= 2; } if (!(x \u0026amp; 0x80000000u)) { x \u0026lt;\u0026lt;= 1; r -= 1;1 } return r; } static inline unsigned long __attribute_const__ roundup_pow_of_two(unsigned long x) { return (1UL \u0026lt;\u0026lt; generic_fls(x - 1)); }  向上/向下对齐, 检查是否对齐 /* uintptr_t 代表指针的位数 * 加uintptr_t转换的原因是: (void *)不能进行运算 */ #define IS_ALIGNED(X, align) (((uintptr_t)(const void *)(X)) % (align) == 0) #define ALIGN_UP(X, align) (((X) + ((align) - 1)) \u0026amp; ~((align) - 1)) #define ALIGN_DOWN(x, align) ((X) \u0026amp; ~((align) - 1))  #define X (0x12345675) #define align (1 \u0026lt;\u0026lt; 2)  int main() { int v = IS_ALIGNED(X, align); if (0 == v) { printf(\u0026#34;Given X(0x%x) is not align to 0x%08x\\n\u0026#34;, X, align); printf(\u0026#34;After align up, new X = 0x%x\\n\u0026#34;, ALIGN_UP(X, align)); printf(\u0026#34;After align down, new X = 0x%x\\n\u0026#34;, ALIGN_DOWN(X, align)); } else { printf(\u0026#34;Give X(0x%x) is aligned to 0x%08x\\n\u0026#34;, X, align); printf(\u0026#34;After align up, new X = 0x%x\\n\u0026#34;, ALIGN_UP(X, align)); printf(\u0026#34;After align down, new X = 0x%x\\n\u0026#34;, ALIGN_DOWN(X, align)); } return 0; }  检查两个有符号数是否异号 int x,y; if ((x ^ y) \u0026lt; 0) printf(\u0026#34;They have opposite signs\\n\u0026#34;); else printf(\u0026#34;They have same signs\\n\u0026#34;);  大小端转换  对某个位的get/set/clear操作 #define GET_BIT(x, bit) ( ((x) \u0026amp; (1ULL \u0026lt;\u0026lt; (bit))) \u0026gt;\u0026gt; (bit) ) #define SET_BIT(x, bit) ( (x) |= (1ULL \u0026lt;\u0026lt; (bit)) ) #define CLEAR_BIT(x, bit) ( (x) \u0026amp;= ~(1ULL \u0026lt;\u0026lt; (bit)) )  Release note:\n 添加对unsigned long long长度的支持    Sign extending from a varaiable bit-width int bits = 2 * 8; // number of bits representing the number in x  int x = 0xFFC1; // ready to get sign-extended  int rst; // resulting sign-extended number  int const mask = 1U \u0026lt;\u0026lt; (bits - 1); // mask can be pre-computed if bits if fixed.  x = x \u0026amp; ((1U \u0026lt;\u0026lt; bits) - 1); // cut x if it holds more bits  rst = (x ^ mask) - mask; // excellent trick!  printf(\u0026#34;INPUT: 0x%x, RESULT: 0x%x\\n\u0026#34;, x, rst);  字符/字符数组的大小写转换 #define TO_LOWER(c) (unsigned char)((c \u0026gt;= \u0026#39;A\u0026#39; \u0026amp;\u0026amp; c \u0026lt;= \u0026#39;Z\u0026#39;) ? (c | 0x20) : c) #define TO_UPPER(c) (unsigned char)((c \u0026gt;= \u0026#39;a\u0026#39; \u0026amp;\u0026amp; c \u0026lt;= \u0026#39;z\u0026#39;) ? (c \u0026amp; ~0x20) : c)  #define TO_LOWER_STR(s, len) { \\ for (int i = 0; i \u0026lt; len \u0026amp;\u0026amp; s[i] != \u0026#39;\\0\u0026#39;; i++) { \\ s[i] = TO_LOWER(s[i]); \\ } \\ }  #define TO_UPPER_STR(s, len) {\\ for (int i = 0; i \u0026lt; len \u0026amp;\u0026amp; s[i] != \u0026#39;\\0\u0026#39;; i++) { \\ s[i] = TO_UPPER(s[i]); \\ } \\ } ","date":"2022-07-03T09:44:13+08:00","permalink":"https://wangloo.github.io/posts/c/bitops/","section":"posts","tags":["c"],"title":"C 语言位操作技巧"},{"categories":null,"contents":" 堆的含义 我们都知道malloc动态申请的变量是存放在堆中. 所以相比栈来说, 堆是动态的.\n堆占据进程虚拟地址空间的大部分, 我们可能通过堆来申请1GB的数组, 但是栈通常不行 , 大多也就几兆的空间.\n 堆空间的管理 进程中堆空间的管理是运行库负责的, 在Linux中是GLIBC.\n运行库在初始化时会像操作系统申请一大块的堆空间, 再为每个进行分别分配需求. 当然, 如果某些程序的需求过大, 运行库也可以使用mmap系统调用直接向操作系统申请, 然后 返回给用户进程.\n GLIBC的malloc函数的处理方式是: 对于小于128KB的申请, 会从运行库\u0026quot;批发的\u0026quot;堆空间 里分出一块来; 但若申请的空间过大, 则使用mmap系统调用来创建匿名空间分配给用户.\n  Linux中虚拟地址块(VMA)的管理使用了红黑树, 可以用于运行库管理自己向操作系统 \u0026ldquo;批发\u0026quot;的堆空间. 使得用户程序动态申请和释放内存性能提高.\n ","date":"2022-06-28T16:41:54+08:00","permalink":"https://wangloo.github.io/posts/os/stack-and-heap/","section":"posts","tags":["Operating system","Virtual memory"],"title":"Stack and Heap"},{"categories":["Operating System"],"contents":"静态链接带来的问题   像是libc这种几乎每个程序都要用到的库, 如果是静态的, 那么不仅意外着每个程序的 可执行文件很大, 浪费磁盘空间. 并且当程序加载到内存时, 可能许多程序都会用到printf , 使得内存中会存在好多份的printf源码.\n  维护和更新难. 一旦静态链接的其中一个目标文件更新, 所有的可执行程序都要重新链接.\n  不满足局部性原理. 上面提到, 内存中同时存在多份的printf源码会破坏局部性原理的. 显然如果所有的程序共享一份printf源码的想法更好. 即动态加载.\n  可移植性差. 静态链接, 只要有一个依赖目标文件的实现不同, 软件厂商就得专门发布一个 版本. 而动态链接则信赖客户电脑上的动态库, 相当于一个中间层.\n  动态链接的过程 对比静态链接使用ld链接器在编译后即执行链接, 动态链接则是将链接过程推迟到运行时, 即装载到内存时.\n这样, 链接器在链接产生可执行文件时就有两种做法:\n 对于静态符号, 按照静态链接的规则进行地址引用重定位 对于动态符号, 链接器则仅标记其为动态链接中的符号, 不进行处理. 而是等到装载时由 专门的动态链接器来完成动态符号的链接工作.  ⁉️ 链接器如何确定一个符号是静态的 or 动态的?\n在动态共享对象(.so)中保存了完整的动态符号表*, 表中存在的符号即为动态的, 否则为静态.\n Linux 的 C 语言运行库glib的动态链接版本叫libc.so. 它在外存上只保存一份, 所有的程序 都可以在运行时使用它. 所以千万不要删掉它.\n  动态链接有一定的性能损失, 因为每次运行程序时都要重新链接, 并不像静态链接是一劳永逸的. 也有例如延迟绑定对性能进行优化的方法, 大概仅有 5%的损耗, 与带来的便利相比可以忽略不计.\n 地址无关代码 PIC GCC 生成动态库时需要添加参数-fPIC, 含义就是生成地址无关码\n地址无关码的含义是代码中不包含任何的绝对地址引用, 全都是相对地址.\n 对于模块内的跳转/数据引用, 使用相对的跳转/加载指令. 例如 ARM 指令集中的B, ADR, 经过汇编器之后, 目标的地址都会转为相对于该指令(PC)的偏移. 对于模块间的跳转/数据引用, 借用GOT 表来间接实现地址无关.  而如果该动态库中全部使用相对地址, 那么加载时也就不需要进行重定位, 即所有的程序都可以 共享这些地址无关代码.\n 上面说 PIC 的动态库不需要重定位其实是错误的, 只不过它的重定位过程不需要修改代码段, 而是设置了一个放置在数据段的GOT表来实现代码段部分的地址无关特性.\n  现在貌似 GCC ARM 版本在编译动态库时强制使用-fPIC 选项, 否则会报错. 对此我不是 非常确定!\n  一般来说, 不将主程序编译为地址无关码. 因为主程序不需要共享, 而且地址无关码的调用 需要两个指令: 计算地址 + 跳转. 多了一步根据偏移得到绝对地址.\n 动态加载 上面说的，有了动态链接之后，库文件的重定位到运行时。运行时一定是库加载到内存时候吗？ 看你怎么理解“运行时”，是主程序运行的时刻，还是库中的代码运行的时刻。所以我可以回答的是： 主程序运行时，动态库不一定立马加载到内存，也就不一定发生动态链接。\n动态加载这种思想类似于 COW，可以提升主程序启动的速度，启动消耗的内存更小。 缺点就是第一次调用库的速度变慢，因为加载、重定位都需要发生。\n有一个需要注意的点，一般的动态链接过程（不考虑动态加载）就是所有的库一股脑加载到内存， 然后进行重定位工作。重定位完所有符号后，会将主程序的 GOT 表设置为只读，避免 got 表被恶意修改， 这个过程是动态链接器ld.so做的。\n 这个说法可以通过看 elf 的 section 布局确定，got 表都会和一些其他的只读 section 放在一起， 而与总是 RW 的 section 分开，这样布局以后设置 got 只读的时候更加方便。  这里图中的 got 虽然是可写入的，只是为了可以被重定位修改，改完之后由 ld.so 重映射为只读。\n 加入动态加载之后，其实 got 表不能在主程序加载完后就设为只读，因为链接延后到了动态库加载到内存时， 现在的做法时，将 got 表进行拆分==\u0026gt; .got 和.got.plt, .got.plt 保存的是以后运行中随时需要重定位的符号， 就不能被设为只读，而为了兼容，.got 就会在主程序加载后被设为只读，因为里面没有需要执行时重定位的符号了。\n 主程序编译时添加选项 -Wl,-z,lazy 启用动态加载\n    动态链接和动态加载关系 动态加载和动态链接并不进行绑定\n 静态链接-动态加载：因为是静态链接，所以库的地址已经确定，但加载时只分配虚拟地址空间 动态链接-动态加载：用到库时才加载到内存，此时才进行动态重定位 动态链接-静态加载：运行主程序时库同时被加载到内存，然后立马执行动态重定位  ","date":"2022-06-26T19:50:45+08:00","permalink":"https://wangloo.github.io/posts/os/dynamic-link/","section":"posts","tags":["Operating System"],"title":"操作系统：动态链接/动态加载"},{"categories":["Binary"],"contents":"ELF是什么 ELF（Executable Linkable Format）可执行文件格式不止是单指“可以被执行的文件”， 动态链接库、静态链接库都按照可执行文件格式来存储。\nELF标准里把采用ELF格式的文件分为四类：\n   Type description 实例     Relocatable File 这些文件包含了代码和data, 可以被用来链接成可执行文件或共享目标文件. .o, .a   Executable File 直接可执行的文件 /bin/ls   Shared Object File Including code and data. 链接器可将其与其他Relocatable File或Shared Object File结合, 生成新的目标文件. 动态链接器可将其与Executable File结合, 作为进程映像的一部分来运行. .so   Core Dump File Restore critical infomation when process is terminated unexpectedly core dump     📌 file command in Linux can output the format of a file.\n 关于静态库 一个静态库可以简单的看作是 a set of object file.\n这些 object file 可能包括: 输入输出相关的printf.o, scanf.o, 日期时间相关的time.o, date.o等.\n❓ 为什么不直接提供这些目标文件呢?\n这些零散的文件若直接提供给使用者, 很大程度上造成文件传输, 管理等方面的不便.\n于是人们通常使用ar压缩程序将这些目标文件压缩到一起.\n❓ 如何查看一个静态库是由哪些object file压缩到一起的?\nShell commandar -t libc.a 可以查看libc.a中包含的所有object files.\nELF 文件组成的结构 知道了ELF文件是什么，接下来就看看其内部的结构。\n+---------------------------------+ | ELF Header | 包含描述整个ELF的基本信息, 如版本, 入口地址... +---------------------------------+ | .text | +---------------------------------+ | .data | +---------------------------------+ 紧接着是各个段 | .bss | +---------------------------------+ | ... | | other sections | +---------------------------------+ | | 与section相关最重要的结构 | Section Header table | 描述了每个section的名称,长度,权限... | | +---------------------------------+ | | 与segment相关最重要的结构 | Program Header table | 描述了每个segment的位置、属性(RWX)、size... | | +---------------------------------+ | String tables | | Symbol tables | +---------------------------------+ ELF Header    字段 含义     e_machine 目标架构   e_entry 入口地址   e_machine 目标架构   e_phnum number of entries in the program header table   e_shnum number of entries in the section header table   e_shoff offset, in bytes, of the section header table   e_phoff offset, in bytes, of the program header table   e_machine 目标架构   e_machine 目标架构    Program Header Table 每个表项对应一个segment，表明其位置、属性(LOAD?动态链接用?)、memory size和file size，权限(RWX)等。\n Memory Size \u0026gt;= Segment Size, 因为有BSS段存在。\n Section Header Table 相应地，每个表项指定一个section的信息，包括名字、大小、地址等。\n如何生成一个ELF可执行文件 参考：The compiler, assembler, linker, loader and process address space tutorial\n从一个C文件到一个ELF可执行文件包括编译、链接两个步骤，具体来说，共包含4个步骤：\n 预编译 gcc –E hello.c –o hello.i 预编译过程主要处理那些源代码文件中的以“#”开始的预编译指令。比如 “#include”、“#define ”等\n 将所有的 “#define ”删除，并且展开所有的宏定义。 处 理 所 有 条 件 预 编 译 指 令， 比 如 “#if”、“#ifdef”、“#elif”、“#else”、“#endif ”。 处理 “#include ”预编译指令，将被包含的文件插入到该预编译指令的位 置。注意，这个过程是递归进行的，也就是说被包含的文件可能还包含其 他文件。 删除所有的注释“//”和“/* */”。 添加行号和文件名标识，比如#2“hello.c”2，以便于编译时编译器产生调 试用的行号信息及用于编译时产生编译错误或警告时能够显示行号。 保留所有的 #pragma 编译器指令，因为编译器须要使用它们。  编译 gcc –S hello.i –o hello.s # or gcc –S hello.c –o hello.s 编译过程就是把预处理完的文件进行一系列词法分析、语法分析、语义分析及优化后生产相应的汇编代码文件\n汇编 as hello.s –o hello.o # or gcc –c hello.c –o hello.o 汇编器是将汇编代码转变成机器可以执行的指令，每一个汇编语句几乎都 对应一条机器指令。所以汇编器的汇编过程相对于编译器来讲比较简单， 它没有复杂的语法，也没有语义，也不需要做指令优化，只是根据汇编指 令和机器指令的对照表一一翻译就可以了\n链接 一个可执行文件可能需要用到许多个目标文件，例如C库、pthread库、自己写的库等。 链接的过程就是把他们组合在一起，生成最终的可执行文件。\n仅编译过程中，如果对于外部的函数，编译器无法确定实际跳转的地址， 只能先写0，链接过程会对这个值进行修改。\n主要包含两个过程：（1）地址空间分配（2）重定位\n 地址空间分配：这么多.o，这么多section，他们结合为可执行文件后地址怎么规划呢？是不是有的 section 可以合并，比如多个代码段。 重定位：对于外部调用的函数，这些实际的值也需要更正，或者采用别的方法来间接寻址（动态链接）  静态链接 重定位\n合并后的每个section都有一个重定位表.rel.xx， 里面的内容大概是:\nRELOCATION RECORDS FOR [.text]: OFFSET TYPE VALUE 0000001c R_386_32 shared 00000027 R_386_PC32 swap 对于每个需要重定位的指令，都会在这里表里对应到，所以链接时需要遍历它，填充上真正的地址。\n动态链接 静态链接的做法就决定了，程序A和B不能共享同一份库，浪费内存。库编进了可执行文件中，所以生成的可执行文件就很大， 另外这样如果要修改库的话就需要对所有依赖的A和B都重新编译。\n动态链接是目的是解决上面的问题，也就是说，库不编到ELF里，ELF在运行的时候能找到它就行。 这样一个程序编译链接后其实不能确定库的地址, 而是将这个过程推迟到运行时的某个时间。\n 详细可见动态链接\n ELF 加载  废了半天劲编译生成的ELF文件, 想要最终跑起来则包含的instruction and data必须要在内存中.\n 我们能想到的最简单的办法是: 把整个ELF的所有指令和数据在运行之前就全部load到内存中. 这就是静态加载.\n更加高效的做法是: 充分利用局部性原理, 将指令和数据划分为模块, 只有当该模块被使用时, 才load进内存, 否则就在外存中老老实实呆着. 这就是动态加载.\n静态加载  读取ELF header, 校验magic number和架构是否正确 根据ELF header中指定的 program header table地址去读 segments 加载segments 中属性为LOAD的segment, 先要分配对应的虚拟空间, 根据ELF的LMA 加载程序为ELF分配栈空间，并填充argc, argv，env等。  参数、环境变量怎么填充需要参考体系结构的ABI手册\n  将PC设置为ELF header中entry point, 返回到用户态开始执行  动态加载  详细可见动态加载\n 其他问题汇总 为什么要区分section和segment ELF文件提供了两个视角来组织一个可执行文件, 一个是面向链接过程的section视角, 这个视角提供了用于链接与重定位的信息(例如符号表); 另一个是面向执行的segment视角, 这个视角提供了用于加载可执行文件的信息.\n我们还可以看到section和segment之间的映射关系: 一个segment可能由0个或多个section组成, 但一个section可能不被包含于任何segment中\n 多个地址相连、属性类似的section可组合称为一个segment, 程序运行时加载器只按照segment去加载即可。 而链接时, 链接器会对每个section进行重定位, 同时也需要 .rel* section来完成重定位。 调试信息也是按照section进行存储的，调试器依赖他们得到符号信息。  每个segment有filesize和memsize，有什么区别？  filesize是segment真实的大小 memsize是加上满足内存对齐原则的padding后，在内存中呈现的额大小  +-------+---------------+-----------------------+ | |...............| | | |...............| | ELF file | |...............| | +-------+---------------+-----------------------+ 0 ^ | |\u0026lt;------+------\u0026gt;| | | | | | | +----------------------------+ | | Type | Offset VirtAddr PhysAddr |FileSiz MemSiz Flg Align LOAD +-- 0x001000 0x03000000 0x03000000 +0x1d600 0x27240 RWE 0x1000 | | | | +-------------------+ | | | | | | | | | | | | | | | | +-----------+ --- | | | |00000000000| ^ | | | --- |00000000000| | | | | ^ |...........| | | | | | |...........| +------+ | +--+ |...........| | | | |...........| | | v |...........| v +-------\u0026gt; +-----------+ --- | | | | Memory 为什么目标文件中代码和数据要分开放? 一方面, 程序被加载进内存后, 代码段和数据段分别被映射到两个virtual memory region. 通过MMU的支持, 可以将代码段的区域设置为只读, 防止恶意篡改.\n另一方面, 当下CPU Cache多划分为Instruction Cache和Data Cache, 再配合互相独立的 地址区域能够提高局部性原理的效果.\n最后, 代码段可以被多个进程共享(例如都调用同一外部函数), 节省内存空间.\n 针对嵌入式设备, 如果内存空间不够大, 只读的代码段可存放在ROM中\n 段地址对齐技术  由前面动态加载的步骤可知, ELF文件中的代码和数据被按page划分. 并只有在用到时才被加载到内存, 并建立虚拟内存-物理内存的映射.\n 假设一个ELF有三个段需要被LOAD, ELF段表如下:\n   Segment Length offset     SEG 0 127 B 34 B   SEG 1 9899 B 164 B   SEG 2 1988 B 0 B    ❓ 这三个段在ELF文件中的布局如何? 根据前面ELF文件格式的介绍, 这三个段必然是挨着的(简单考虑, ELF中仅有这三个段).\n❓ 这三个段在物理内存中的布局? 发生page fault之后, OS会为页面分配合适的物理页面, 如利用buddy system等.\n可以保证段内的连续, 不能保证段与段是连续的.\n 未使用段对齐技术之前, SEG0的长度不足一页, 但是也给它分配一页的空间. 同理为SEG1分配两页, SEG2分配一页. 总共占用 1+2+1=5个物理页.\n ❓ 这三个段在用户virtual addrspace下的布局如何? todo\n❓ 何为段地址对齐技术? 上面说了, 在为这三个段分配物理内存时, 虽然他们的真实大小远小于5个页面, 但由于简单采用: 每个段的开头必须是page align, 导致实际上产生了巨大的内部碎片.\n段地址对齐实际上就是在为ELF文件中的段分配物理内存时, 不考虑其段的独立性, 强制按照page来划分. 划分的行为如下图所示. 结果就是仅需占用3个物理页面.\n+---+---------------+ | P | SEG0 | | A +---------------+ | G | | | E | | +---+ | | P | SEG1 | | A | | | G | | | E | | +---+ | | P +---------------+ | A | | | G | SEG2 | | E | | +---+---------------+  目前, gcc(更准确是说是GUN ld)默认启用段对齐技术. 各个段的虚拟地址并不是page align.\n  🍀 物理页面到虚拟页面的映射阶段, 那些同时包含两个段的页面会被映射两次, 即一个物理页面对应两个 虚拟页.\n原因是: 在一个页面的不同段可能权限不同, 所以不能使用同一映射.\n ","date":"2022-06-20T16:21:27+08:00","permalink":"https://wangloo.github.io/posts/binary/elf-format/","section":"posts","tags":["Binary"],"title":"Elf 文件的链接与加载"},{"categories":["C Language"],"contents":"添加更多的编译选项(comiler options)来防止bug 对于我常用的GCC, 推荐开启一下的compiler options:\n  -Wall: enable a lot of common warnings\n  -Wno-format-truncation: warns about the snprintf output buffer not being large enough for a corresponding “%s” in the format string.\n  -Werror: turn warnings into errors.\n   动态申请的空间到底要不要释放 When using a barebones embedded OS, you absolutely need to tightly manage your memory.\n但是, 如果你是写应用业务的代码, 特别是在内存足够的场景下. 最好不要手动释放内存, 因为当线程/进程退出时, 操作系统会自动帮我们释放. 某些情况下, 释放内存的操作会很大程度上增加逻辑的复杂度.\n 如果你是一个内核程序员, 则必须手动的释放. 不用怀疑.\n  尽可能在创建变量时赋初值 放置某些变量创建后是 magic value. 而使用这些变量可能不会立马导致错误, 但是这是一个隐患.\n但这会产生一个问题, 有时我们定义变量之后的不久之后就会对其赋予正确的值, 这时候初值就是 多余的. 而且维护者可能认为这个值是meaningful, 这就要求我们如果要赋初值, 就要说明这个值 仅仅是无意义的初值.\n 使用#define, enum 对于代码在不同地方使用的同一个值, 应使用#define来声明使得代码maintainable.\n如果这些值有多个且能规划为同一类别, 则还可将#define的方式换为enum. 这会使代码更加meaningful\n 使用enum使还要注意其所占内存空间在不同架构中可能不同的问题, see enum的优势和漏洞\n  使用typedef优化function pointer  重定义一套自己的类型 在开发大项目时, 需要考虑可移植性的情况下, 最好利用typedef对类型进行重定义.\n#if SYSTEM1  typedef int INT32; ... #else  typedef long INT32; ... #endif 如上, 对于某些架构int类型可能不是32bit, 此时就要使用long. 这种定义的方式会保证我们的系统 在任何架构中都不会出现类型的bug. 而且也增加了代码的readability.\n 善用~0 在做嵌入式编程时, 有时在设置掩码(mask)或者其他情况会要用到全1的变量值, 你是否经常这样声明?\nint mask = 0xffff; 暂且不谈int类型到底占多少字节的问题. 就像上面一样, 我们程序员经常忘记某个类型的大小, 而少添加了f. 会导致变量mask的值不是全1(32位情况下).\n这是要变换一下思维, 使用~0的定义方法就可轻松化解, 无需管变量的类型是什么.\nint mask = ~0;  合理的使用goto语句 在大学课堂中, 我们老师说过禁止使用goto语句, 但却没有给出明确的原因.\n实际上, 合理的使用goto能够极大的减少程序的冗余度.\ngoto语句常用于程序出现错误要退出时, 可能有多个情况会使用重复的代码处理, 例如释放一些allocated memory. 相较于使用flag, 使用goto显然更加clearly and readability.\n所以, 在面对重复的错误处理代码时, 想想能不能用goto进行优化. 当然, 避免过早优化.\n 注意, goto出现的场景其实很受限. Never use a backward goto or jump into control statements.\n  定义合理, 正确的结构体 结构体是C语言编程应用中常用的数据结构, 关于结构体也有许多要注意的点.\n#1 Flexible Array Member C99开始支持Flexible Array Member. 且看我lstring库的结构体定义:\nstruct str { int length; int size; char data[]; // Flexible array member - C99 only }; 对于这种不定长的数组元素, 我之前都是定义一个指针, 占用一个sizeof(char *)的空间. 而Flexible Array Member本身不占用空间. 需要在malloc时为他单独声明空间.\nint n = 100 struct str *s = malloc(sizeof(struct str) + sizeof(char[n]));  这里也有一个小trick, 使用sizeof(char[n]) 比 sizeof(char) * n 更简洁!\n # 2 Padding and Packed 有关结构体的大小, 和地址对齐的问题. 假设我有一个结构体如下:\nstruct mystruct_A { char a; int b; char c; } x; Padding是编译器对结构体默认做的事情. 它会在成员之间插入一些 gap 来保证地址对齐:\nstruct mystruct_A { char a; char gap_0[3]; /* inserted by compiler: for alignment of b */ int b; /* int 在32位上其地址是4字节对齐的 */ char c; char gap_1[3]; /* -\u0026#34;-: for alignment of the whole struct in an array */ } x;  除了保证每个成员的地址是对齐的, 整个结构体的地址也是按照其最大的成员类型来对齐, 即对齐到int(4字节).\n 如果你不想要这些 gap, 那么可以对结构体声明使用 __attribute__((__packed__))关键字. 整个结构体大小仅为6个字节.\nstruct __attribute__((__packed__)) mystruct_A { char a; int b; char c; };  永远为你的函数设置error return value 一旦你的函数可能被其他人调用, 那么养成设置return value的习惯. 即便你现在的实现 并不会产生任何错误, 也请返回success.\n这样做的原因是, caller可以根据你的定义做错误判断, 即便以后你的实现加上了出错情况, 上层的代码也不需要修改.\n 变量类型的选择  名字, 特定不变的字符串使用const char *, 甚至const char const* 长度使用size_t 表示类型的参数尽可能使用enum 循环变量i使用signed, 避免溢出后出错   Reference How I Improve My (C) Code Quality\nTen Fallacies of Good C Code\n","date":"2022-06-14T17:59:22+08:00","permalink":"https://wangloo.github.io/posts/c/improve_quality/","section":"posts","tags":["c"],"title":"写高质量的C语言工程的规范"},{"categories":["Operating System"],"contents":"seL4 Capabilities In seL4, capabilities are stored in C-space. C-space is a hierarchical data structure very similar to page table.\n page table is a mapping from virtual address to physical address. C-space is a mapping from object ID to capability. Kernel object is made up of several C-nodes, just like a page table made up of individual page tables. Each C-nodes is an array of cap slots, which contain capability.  Inaccessible to userland, you can never hold an actual capability\n You can only hold a reference to capability, which pointers into C-space(slot addresses) These C-space addresses are called CPTRs   You don\u0026rsquo;t need to do the transform, because this is typically extracted in some libs.\n Capabilities convey specific privilege (acces rights)\n Read, Write, Execute, GrantReply(call), Grant(cap transfer)  Main operations on capabilities:\n Invokeperform operation on object referred to by cap.  For example, map some frame into memory. You need to have capabilities to both the frame and address space.   Copy|Mint|Grant: create copy of cap with same/lesser privilege. Move|Mutate: transfer to different address with same/lesser privilege.  Between C-space or within C-space.   Delete: invalidate slot(cleans up object if this is the only cap to it) Revoke: delete any derived(eg. copied or minted) caps  Capability Derivation MINT OPERATION The Mint operation creates a new, less powerful cap\n Can add badge Can strip access rights, eg RW-\u0026gt;RO  mint(dest, src, rights, badge)  The first two arguement are capability pointers(CPTR) to a C-space(represented by C-node), which are references inside C-node. The destination C-node cap must allow modification Then you have the rights and the batch of the new cap.  📌 This is an alternative of sending addressed capabilities by IPC operation. That is what operating system do to set up protection domains for user level process.\nCOPY OPERATION  Copy as a version of Mint.\n  seL4 Kernel Objects In file libsel4\\include\\sel4\\objecttype.h\ntypedef enum api_object { seL4_UntypedObject, seL4_TCBObject, seL4_EndpointObject, seL4_NotificationObject, seL4_CapTableObject, #ifdef CONFIG_KERNEL_MCS  seL4_SchedContextObject, seL4_ReplyObject, #endif  seL4_NonArchObjectTypeCount, } seL4_ObjectType;  seL4 System Calls seL4 has 11 syscalls:\nYield(): invokes scheduler\n does NOT require a capability!  Send(),Recv() and variants/combinations thereof: IPC operations\n Call(),ReplyRecv(): usually invokes by client/server Send(), NBSend(): send-only and non-blocking version of it. Recv(), NBRecv(), NBSendRecv() Wait(), NBWait(), NBSendWait()   We just use Call() normally, the others are only for bootstrapping protocols and exception handling.\n Call() is atomic Send() + reply-object setup + Wait()\n cannot be simulated with one-way operations!  ReplyRecv() is NBSend() + Recv()\nDifferent object support different operations ENDPOINTS Endpoints support all 10 IPC variants.\nNOTIFICATIONS Notifications support:\n NBSend() - aliased as Signal() Wait() NBWait() - aliased as Poll()  OTHER OBJECTS Other objects only supports Call() operation.\n Appear as (kernel-implemented) servers. If you invoking a method on an object, this is done by treating the object as a kernel-implemented server. And you invoke it with a call() operation just as you do a normal server invocation. Each of these kernel objects has a different kernel-defined protocol  operations encoded in message tag parameters passed in message words   Mostly hidden behind syscall wrappers, user do not need to know this details.   seL4 IPC  IPC in seL4 is a way to realize cross-domain invocation.\n seL4 IPC is not a mechanism for shipping data. Transfering data is axillary but not the primary purpose.\nseL4 IPC is a protected procedure call, a user-controlled context switch(from clients context into server context).\n seL4 Threads Creating a thread  Obtain a TCB object Set attributes: V-space, C-space, fault endpoint, IPC buffer Set Scheduling parameters:  priority, scheduling context, timeout endpoint(maybe MCP)   Set architecture-related registers  Threads and Stacks Stacks are completely user-managed, kernel doesn\u0026rsquo;t care!\n Kernel only preserves SP.. on context switch\n Stack location, allocation, size must be managed by userland.\nKernel beware of stack overflow\n","date":"2022-06-04T11:52:51+08:00","permalink":"https://wangloo.github.io/posts/os/sel4/","section":"posts","tags":null,"title":"操作系统：SeL4 基础概念"},{"categories":["Hugo"],"contents":"本章将解答Hugo是什么, 以及Hugo是如何工作的. 只有了解Hugo的工作机制之后, 才能发挥想象力进行DIY.\n本章内容大多来自官方手册或者搜索引擎提供的结果.\nHugo 项目结构 一个hugo 项目通常包含以下内容:\n. ├── archetypes ├── config.toml ├── content ├── data ├── layouts ├── public ├── static └── themes 这里面有些是必须的, 有些是可选的.\narchetypes\n定义新创建post时, header的格式.\nasserts\n Note: assets directory is not created by default.\n config\nHugo uses the config.toml, config.yaml, or config.json (if found in the site root) as the default site config file.\nThe user can choose to override that default with one or more site config files using the command-line --config switch.\nhugo --config debugconfig.toml hugo --config a.toml,b.toml,c.toml  Config directory is not created by default.\n content\n显然, 存储所有的post.\ndata\nThis directory is used to store configuration files that can be used by Hugo when generating your website.\n像是你 website 的一个mini 数据库, 你可以放置 toml, yaml, json格式的文件.\nlayouts\nStores templates in the form of .html files that specify how views of your content will be rendered into a static website. Templates include list pages, your homepage, taxonomy templates, partials, single page templates, and more.\npublic\n保存build生成的站点. 当运行hugo [flag]时生成.\n拷贝该目录下的内容, 可以部署到web 服务器上了.\nstatic\nStores all the static content: images, CSS, JavaScript, etc. 当Hugo构建您的站点时，静态目录中的所有资源都会按原样复制。\n即当构建website时, static/下的所有文件都会复制到 public/下.\nThe static files are served on the site root path (eg. if you have the file static/image.png you can access it using http://{server-url}/image.png, to include it in a document you can use ![Example image](/image.png) ).\nresources\n一些缓存文件\n resources directory is not created by default.\n Hugo Cli Command hugo 支持的所有命令可以通过 hugo help 命令来查看. 每一条命令的具体用法, 可以执行 hugo [command] help 来查看\nUsage: hugo [flags] hugo [command] hugo completion\n用来配置补全 hugo command 和 flag 的. 该命令会输出一段脚本, 将该脚本复制到你的 shell 的配置文件中就可以使用 hugo tab 补全了.\nhugo config\n打印hugo的配置文件, 即根目录下的 config.toml.\nhugo env\n打印 hugo 的版本和环境信息\nhugo list\n打印所有post的info, 包含标题, 发布日志, 链接等.\nhugo new\n非常重要的命令, 可以用来新建一个 website, 主题, 或者一篇post(常用). 带有许多 flag可以使用.\nhugo server\n执行hugo server之后, 首先构建了你的网站(但是默认并不在本地创建文件, 而是放在内存), 然后启动hugo 自带的 web服务器让我们能看见网站的效果.\n.notice { --root-color: #444; --root-background: #eff; --title-color: #fff; --title-background: #7bd; --warning-title: #c33; --warning-content: #fee; --info-title: #fb7; --info-content: #fec; --note-title: #6be; --note-content: #e7f2fa; --tip-title: #5a5; --tip-content: #efe } @media (prefers-color-scheme:dark) { .notice { --root-color: #ddd; --root-background: #eff; --title-color: #fff; --title-background: #7bd; --warning-title: #800; --warning-content: #400; --info-title: #a50; --info-content: #420; --note-title: #069; --note-content: #023; --tip-title: #363; --tip-content: #121 } } body.dark .notice { --root-color: #ddd; --root-background: #eff; --title-color: #fff; --title-background: #7bd; --warning-title: #800; --warning-content: #400; --info-title: #a50; --info-content: #420; --note-title: #069; --note-content: #023; --tip-title: #363; --tip-content: #121 } .notice { padding: 18px; line-height: 24px; margin-bottom: 24px; border-radius: 4px; color: var(--root-color); background: var(--root-background) } .notice p:last-child { margin-bottom: 0 } .notice-title { margin: -18px -18px 12px; padding: 4px 18px; border-radius: 4px 4px 0 0; font-weight: 700; color: var(--title-color); background: var(--title-background) } .notice.warning .notice-title { background: var(--warning-title) } .notice.warning { background: var(--warning-content) } .notice.info .notice-title { background: var(--info-title) } .notice.info { background: var(--info-content) } .notice.note .notice-title { background: var(--note-title) } .notice.note { background: var(--note-content) } .notice.tip .notice-title { background: var(--tip-title) } .notice.tip { background: var(--tip-content) } .icon-notice { display: inline-flex; align-self: center; margin-right: 8px } .icon-notice img, .icon-notice svg { height: 1em; width: 1em; fill: currentColor } .icon-notice img, .icon-notice.baseline svg { top: .125em; position: relative }     不知道从哪个版本开始，反正在hugo v0.124.1下，默认是直接生成文件，如果还是希望放在内存，需要手动添加参数： --renderToMemory。 （PS：搞不懂为什么要做这个改动！？\n 同时, 默认情况下, server 会同步你的本地更改, 然后实时的reload你的页面. 这样你就能同时看到修改的效果.\nhugo server 的常用flag:\n-D 包含标记为草稿的post（默认不构建草稿） --theme strings 使用[strings]主题进行构建 --disableFastRender 强制刷新页面，不使用缓存 hugo [flags]\nhugo 自身就是一个命令, 用于build website, 放到 public/目录下.\n常用 Flag(All supported flags):\n--gc 在build后会清除一些cache文件. 与 resource/有关 --minify minify any supported output format (HTML, XML etc.)  hugo 命令不会删除之前的文件. 而是仅新增改动. 所以每次build时需要你手动删除 public/ 目录.\n Hugo 内容管理 hugo build 后的website页面的布局和你源文件的布局相同, 所有源文件都放置在 content/ 目录下.\n└── content ├── _index.md // \u0026lt;- https://example.com | ├── about | └── index.md // \u0026lt;- https://example.com/about/ ├── posts | ├── _index.md // https://example.com/posts/ | ├── firstpost.md // \u0026lt;- https://example.com/posts/firstpost/ | ├── happy | | └── ness.md // \u0026lt;- https://example.com/posts/happy/ness/ | └── secondpost.md // \u0026lt;- https://example.com/posts/secondpost/ └── quote ├── first.md // \u0026lt;- https://example.com/quote/first/ └── second.md // \u0026lt;- https://example.com/quote/second/  hugo 将content/ 下的那级目录(例如 content/posts)特殊看待, 称为 section.\n 页面资源(Page Resources) 页面资源指每个页面私有的图片, 文档等静态资源. 与static/ 中全局的资源不同.\n页面资源放在content/下的任意位置, 但不是所有页面都能访问. page bundles 中的index.md or _index.md 能够访问该 bundles 下的资源.\ncontent └── post ├── first-post │ ├── images │ │ ├── a.jpg │ │ ├── b.jpg │ │ └── c.jpg │ ├── index.md (root of page bundle, 能够访问first-post/下的所有资源) │ ├── notice.md 不能访问任何资源, 但其自身作为一个资源可被index.md访问 │ ├── office.mp3 │ ├── pocket.mp4 │ ├── rating.pdf │ └── safety.txt └── second-post └── index.md (root of page bundle, 但不能访问first-post/下的资源) 内容分类(Taxonomy) Taxonomy: How to group the content together. Two default taxonomies are tags and categories.\n代码高亮(Syntax Highlight) 代码高亮的配置(in config.toml):\nHugo 使用chroma来执行代码高亮。\n Example of all style: https://xyproto.github.io/splash/docs/index.html  页面分类 从布局上来看, 页面可以分为两类: List page 和 single page.\n显而易见, list page比较特殊, 它负责列出当前目录下的所有post. 所以一个目录地址必然是一个list page.\n在下面的例子中, https://example.com , https://example.com/posts/happy/ 都可以叫做 list page.\n  https://example.com/posts/happy/ 是list page, 目录下的_index.md 不是必须的, hugo 会默认仅显示所有post的title. 详见\n  https://example.com/about/ 不是list page, 因为其目录下有index.md, 强制表明这是一个 single page. 详见\n  └── content ├── _index.md // \u0026lt;- https://example.com | ├── about | └── index.md // \u0026lt;- https://example.com/about/ └── posts ├── _index.md // https://example.com/posts/ ├── firstpost.md // \u0026lt;- https://example.com/posts/firstpost/ ├── happy | └── ness.md // \u0026lt;- https://example.com/posts/happy/ness/ └── secondpost.md // \u0026lt;- https://example.com/posts/secondpost/  Homepage 和 section page 都属于特殊的 list page.\n homepage 特指 content/_index.md section page 特指 content/[section]/_index.md   shortcodes shortcode 可以理解为 hugo 为了封装了一些代码块, 通过 shortcode 来调用.\n模板(Template) 模板是hugo的一个高级用法, 用来定义你网站的style. 模板不等同与主题(themes), 可以理解为主题是一套模板的集合. 我们可以在使用模板的同时添加DIY的 style. 😎 Hugo 会有优先级的判断.\n不同的页面类型需要定义不同的模板. List page 的模板称为 List template, single page 的模板称为 single template. 同理还有 homepage template, section template.\n存储模板的目录为layout/, 上面介绍hugo的目录结构时已经说过. 如果你使用了一个 theme, 那么themes/[your-theme]/layout/就是该theme的模板.\nhomepage 模板 Base 模板 对应layouts/_default/baseof.html\nbase 模板是整个website的核心. 所有的模板包括 list template, single template, homepage template\u0026hellip; 都是独立的, base template 将其他的模板联系到一起.\n分页模板 对于条数过多的场景（比如所有的post list，某个tag的post list），可以构建一个分页器，用【上一页】【下一页】来使单个页面简洁一点，避免滑不到头的情况 :X\n不过对于目前，我还没有那么多条目看不过来，所以暂且没细看。\nPagination模板 官方说明\npartial 模板 包含网站的许多元素, 增加模块化. 我可以为网站的 header 或者 footer 写一个模板(html), 这些HTML可以嵌入其他的模板.\n模板优先级 既然同一种页面的模板可以定义在多个位置, 如果他们同时存在时, 优先级规则必然存在. 常见的情况比如我们使用了某个模板, 然而, 我们对模板中的一些布局不满意, 直接修改模板中的文件显然不是一个好方法, 那么该怎么做呢?\n一般来说, 如果你只想重写theme中的某个模板, 例如section template. 那么你只需要新建 layout/_default/section.html 即可, hugo 构建你的网站时, 如果检测到本地和theme的layout/_default下都有 section.html, 它会使用我们自己定义的那个.\n 完整的, 多级的优先级规则: Hugo\u0026rsquo;s Lookup Order | Hugo (gohugo.io)\n 变量(Variables) ❗ Hugo 变量仅设计给模板使用, 即在layouts/下的html文件.\nPage Variables 与post相关的变量, 定义在post 的 front matter中.\n// Define Page variables in front matter of post ---------------- title: \u0026#34;使用 HuGo 搭建个人网站\u0026#34; description: 学习正确的 Hugo 食用方式, DIY 属于自己的 website~ Myvar: \u0026#34;my value\u0026#34; ---------------- // Use Page Variables {{.Description}} // Get the description of the post {{.Params.Myvar}} // Get the value of Myvar, that is, \u0026#34;my value\u0026#34; Site Variables 站点层面的变量大部分是网站配置相关.\n函数(Functions) 函数是hugo为你封装的一些方法你可以直接调用.\n❗ Hugo 函数仅设计给模板使用, 即在layouts/下的html文件. Same as variables.\nHugo pipes Hugo相关参考  https://lewky233.top/categories/hugo%E7%B3%BB%E5%88%97/ 一系列的hugo配置和美化记录 https://github.com/heartnn/hugo-theme-test/blob/master/README.md hugo基础知识  支持 Emoji Adding emoji tutorial\nEmoji chart\n","date":"2022-05-21T17:39:42+08:00","permalink":"https://wangloo.github.io/posts/hugo/basic/","section":"posts","tags":["hugo"],"title":"Hugo 基础概念"},{"categories":null,"contents":"Content Fourteen years ago, Steve stood on this stage and told your predecessors \u0026ldquo;Your time is limited. So don\u0026rsquo;t waste is living someone else\u0026rsquo;s life.\u0026rdquo;\nSo what is true then is true now. Don\u0026rsquo;t waste your time living someone else\u0026rsquo;s life. Don\u0026rsquo;t try to emulate the people who came before you to the exclusion of everything else, contorting into a shape that doesn\u0026rsquo;t fit.\nGraduates, the fact is, when your time comes, and it will, you will never be ready. But you\u0026rsquo;re not suppposed to be. Find the hope in the unexpected. Find the hope int the challenge. Find your vision on the solitary road. Don\u0026rsquo;t get distracted. There are too many people who want credit without responsibility. Too many who show up for the ribbon cutting without building anything worth a damn.\nBe different. Leave something worthy. And always remember that you can\u0026rsquo;t take it with you. You\u0026rsquo;re going to have to pass it on.\nThank you very much. And Congratulations to the Class of 2019!\nYouTube vidio\n","date":"2022-05-18T19:32:38+08:00","permalink":"https://wangloo.github.io/posts/motivation/2019-stanford-commencement-timcook/","section":"posts","tags":["tim cook","address"],"title":"2019 Stanford Commencement Timcook"},{"categories":["HTML/CSS"],"contents":"Get start What is HTML\u0026amp;CSS?   HTML is resonsible for the content of the page. That\u0026rsquo;s the text, images, buttons, etc.\n  CSS is resonsible for the presentation of the content. That\u0026rsquo;s the color, layout, etc.\n  Web designers create the overall look and fell of a website.\n  Web developers implement the design using HTML, CSS and JavaScript code.\n  Configure VIM as HTML code-editor  Finally in the arms of vscode 🙉\n Add vim plugin:\n emmet: Coding HTML faster.  CSS autocomplete key: \u0026lt;C-x\u0026gt; \u0026lt;C-o\u0026gt;\nHTML and CSS live previes plugin: bracey\n urlopen error solution   HTML Fundamentals Anatomy of an HTML element \u0026lt;p\u0026gt; THML is a markup language\u0026lt;/p\u0026gt; The HTML element is composed of opening tag, content, closing tag.\nHTML good styles  \u0026lt;img/\u0026gt; element should add alt attritube at all time, for the convenience of the blind. An important principle in web design is making the HTML elements meaningful. That is semantic HTML.   CSS Fundamentals CSS describes the visual style and presentation of the contend in HTML.\nAnatomy of an HTML element h1 { color: blue; text-align: center; font-size: 20px; } h1 is Seletor, every style has proporty and value.\nCSS good styles  Class selector is more commonly used than ID selector, as ID is unique in HTML. For scalability, remember always using class selector. We should always specify all the four state of \u0026lt;a\u0026gt; element in order, which including link, visited, hover and active.  Priority conflicts between selectors CSS style priority from high to low:\n Inline style(style attribute in HTML) ID selector class or pseudo-class selector element selector universal element selector   The CSS box model The box model defines how elements are displayed on a webpage and how they are sized.\nIn the box model, every element on a webpage can be seen as a rectangular box.\n Universal element \u0026amp; \u0026lt;body\u0026gt; element Styles in \u0026lt;body\u0026gt; selector take effect because of inheritance. But the text-independent elements do not support inheritance.\nThat is where universal element selector is needed. It\u0026rsquo;s styles take effect on all element.\nWhen we want to set padding and margin of all elements to 0. Must put the code in universal element selector.\n Inline elements \u0026amp; Block elements Inline elements:\n Occupies only the space necessary for its content. Box model applies in different way: heights and widths do no apply. Paddings and margins are applied only horizontally(left and right).  Block elements:\n 100% of parent\u0026rsquo;s width vertivally, one after another  Inline-Block elements:\n Good example is \u0026lt;img\u0026gt;.   The 3 ways of building layouts with CSS Float Layouts: The old way of building layouts, using the float CSS property. Still used, but getting outdated fase.\n Element is removed from the normal flow: out of flow. Like absolutely positioning. Text and inline elements will wrap around the floated elements. Different from absolutely elements. The container will NOT adjust its height to the elements.  FlexBox: Modern way of laying out elements in a 1-dimensional row without using floats. Prefect for component layouts.\n One of its most useful applications is vertical centering. Flex container property:  gap: To create space between items. justify-content: To align items along main axis(horizontally, by default) align-items: To align items along cross axis(vertically, by dedauly) flex-wrap: To allow items to wrap into a new line if they are too large align-content: Only applies when there are multiple lines(flex-wrap: wrap)   Flex Items property:  align-self: To overwrite align-items for individual flex items. flex-grow: To allow an element to grow. flex-shrink: To allow an element to shrink. flex-basis: To define an item\u0026rsquo;s width, instead of the width property. flex: Recommended shorthand for flex-grow, -shrink, -basis.    CSS Grid: For laying out elements in a fully-fledged 2-dimensional grid. Perfect for page layouts and complex components.\n  CSS grid is a set of CSS properties for building 2-dimensional layouts\n  The main idea behind CSS Grid is that we divide a container element into rows and columns that can be filled with its child elements\n  CSS grid is not meant to replace flexbox!. Instead, they work perfectly together. Need a 1D layouts? Use flexbox. Need a 2D layout? Use CSS grid\n  Grid container\n grid-template-rows/grid-template-columns: To establish the grid row and column tracks. One length uniit for each track. Any unit can be used, new fr fills unused space row-gap/colum-gap: To create empty space between tracks justify-items/align-items: To align items inside rows/columns(horizontally/vertically)    Grid items\n grid-column/grid-row: To place a grid item into a specific cell, based on line numbers. span keyword can be used to span an item across more cells justify-self/align-self: To overwrite justify-items/align-items for single items    ","date":"2022-05-17T11:02:04+08:00","permalink":"https://wangloo.github.io/posts/html-css/0/","section":"posts","tags":["html","css"],"title":"Html Css Learning note (0)"},{"categories":["Vim"],"contents":"Search a word quickly: put cursor on the word, press / and press \u0026lt;C-R\u0026gt; \u0026lt;C-W\u0026gt;.\n Vim 启动参数  view \u0026lt;file\u0026gt; 只读方式打开 vim -u NONE -N 可以不加载vim配置和插件打开vim vim --startuptime vim.log 生成vim启动的log  缩写的含义(Meaning of abbreviations) Operation\n d - delete y - yank(copy, 因为c被占了) c - change r - replace v - visual select  Scope or location\n i - inside a - around f - forward t - to  Object\n w - word s - sentence p - paragraph  基础操作 删除命令 d # 删除当前行 dd # 从当前行开始，向下删除4行 d4j # 从当前行开始，向上删除4行 d4k # 删除到某一行，无论向上或是向下 d10G 窗口  \u0026lt;c-w\u0026gt;w 切换到下一个窗口 \u0026lt;c-w\u0026gt;+ 当前窗口大小增加一行 \u0026lt;c-w\u0026gt;- 当前窗口大小减少一行 2\u0026lt;c-w\u0026gt;+ 当前窗口大小增加两行  书签: Bookmark ma: create bookmark a inside file.\nmA: create global bookmark A.\n`a: jump to bookmark a.\n:marks: display all bookmarks\ntag 目前用的生成tags文件工具是 ctag, 感觉还可以。\nta \u0026lt;tag\u0026gt; \u0026#34; 跳转到一个tag，如果有多个应该是随机一个 CTRL-] \u0026#34; 快捷键跳转到当前光标下的tag ts \u0026lt;tag\u0026gt; \u0026#34; 多个tag时，可以选择跳转到哪一个 help tag \u0026#34; 查看更多帮助 缩进: indent   \u0026gt;: increase indent , \u0026lt;: decrease indent ,=: auto indent\n  \u0026gt;\u0026gt;: 增加当前行的缩进\n  gg=G: 缩进全文, 无论当前光标在哪\n   以上命令都可以配合visual mode使用\n 自动缩进的规则 主要有四种可用缩进的方式, 分别是:\n\u0026#39;autoindent\u0026#39; 沿用上一行的缩进。 \u0026#39;smartindent\u0026#39; 类似 \u0026#39;autoindent\u0026#39;，但是可以识别一些 C 语法以能在合适的地方 增加 / 减少缩进。 \u0026#39;cindent\u0026#39; 比上面两个更聪明；可以设置不同的缩进风格。 \u0026#39;indentexpr\u0026#39; 最灵活的一个: 根据表达式来计算缩进。若此选项非空，则优先于其它 选项覆盖。参见 indent-expression 。 自定义的快速命令:\ncommand IndentOff setl noai nocin nosi indentexpr=\u0026#34;\u0026#34;command IndentOn setl ai cin si \u0026#34;indentexpr can\u0026#39;t be re-enabled.command IndentStatus set ai? si? cin? indentexpr? cindent 不一定对所有的语言都有效果. 只是 C-like 风格, 其中一个要求是顶层函数必须在第一列中含有 {.\n  只有当indentexpr计算不出当前需要缩进几格时(return -1), 才使用上面的三个规则. 它是优先级最高的.\n Find and Tail f(: 从当前cursor处向右查找下一个(, 并将光标移动到(处.\nF(: Like f(, but 向左查找.\nt(: Like f(, but 将cursor移动到(的前一个.\nT(: You can guess.\nTrick vt(c: With visual, 删除当前光标到下一个(前的所有内容.\n;/,: 查找下一个/上一个 f/F/t/T 的内容.\n Substitute and Global  See: :help :s and :help :g\n 这两个都属于vim的命令. vim 的替换和sed 的s命令使用方式基本一致. 就不多介绍了.\n而 vim 的 global 命令和sed有些许差别. 使用Sed删除包含个字符串的行的指令为: sed '/STRING/d' input_file, 而在vim中则多了一个g前缀, :g/STRING/d.\nglobal 可以和 substitute 结合使用, 例如想要在包含某个字符串的行中替换good为excellent\n:g/STRING/s/good/excellent/  TODO:\n More [cmd] in global. Power of g | Vim Tips Wiki | Fandom vim subtitute使用的正则表达式集包含 \\zs和\\ze, 然而 sed 没有(Sed 为 POSIX Basic Regular Expression).    大小写转换    cmd description     g~ 翻转大小写   gu 转换为小写   gU 转换为大写    以上命令(严格来说叫操作符)需要配合动作命令来使用.\n gUaw: 将光标所在位置的单词转为大写 gUap: 将光标所在位置的段落转为大写   Search and replace case 1: search and convert to uppercase/lowercase 我直觉想到的方式是%s/html/HTML/gc\n这种方式在简单情况下也行, 比较灵活且直观, 但是对于复杂文件不够通用且容易出错\n还有一种方式是先搜索, 然后一步步替换\n 搜索: /\\vhtml\\C 替换: 执行命令gUgn, 然后使用n和.来重复操作下一个选中项.   gn命令进对于sreach的匹配项使用, 类似于n, 但会将下一个匹配项(若光标停在match上, 那则选中当前匹配项) 转为visual模式选中的状态.\n  其实对于简单的文本, n和.也可以简化为.. 唯一的坏处就是如果两个匹配的距离太大, 你不能确认是否search了你想要的内容.\n case 2: search the text seleted in visual mode  vim 本身并未提供这个功能, 需要借助一个脚本来完成\n search the text selected in visual mode\n Visual Block 模式   选中后, 编辑所有行: I(captial i), 编辑完成后按两次ESC\n  重复visual 选中上次的 block: Normal模式下gv即可.\n   单词间跳转 w: Move cursor to begin of next word.\nb: Move cursor to begin of last word.\ne: Move cursor to end of next word.\nTrick w/b配合ce使用可达到在某一行中快速移动到某个单词, 然后删除该单词开始edit.\ndaw: 即 Delete A Word, 可以删除一个完整的单词, 无论当前光标的位置在哪.\n 编辑二进制/十六进制文件 可以使用xxd命令将一个文件中的文本转换为hex格式显示. 在vim中键入:%!xxd 即可. 得到的效果如下:\n0000000: 5468 6973 2069 7320 6120 7465 7374 0a41 This is a test.A 0000010: 6e6f 7468 6572 206c 696e 650a 416e 6420 nother line.And 0000020: 7965 7420 616e 6f74 6865 720a yet another. 后面的对应文本是自动生成的, 仅需要修改十六进制的部分即可. 修改完成后, 要返回原本的模式, 键入:%!xxd -r.\n 可通过设置文本格式对十六进制内存高亮显示 set ft=xxd.\n  删除光标前/后的所有字符  d^ \u0026ndash; delete to first non-whitespace character in the line d0 \u0026ndash; delete to beginning of the line c-u in insert mode. Same as bash command shortkeys, see here   文件恢复/swp文件 正确对待swp文件的姿势:\n vim 打开原文件, 此时会提示Found a swap file the name .xxx.swp, 显然选择(R)ecover 来恢复未保存的内容. 使用:w将恢复的内容保存下来 但是此时原本的swp文件还是存在, 此时我们执行:e刷新一下当前bufffer, 仍然会提示恢复的选项, 但此时文件内容已经恢复, 选择(D)elete 就可将对应的swp文件删除了   删除当前目录中所有swp file的脚本?\n需要确保:\n 所有文件内容已恢复 当前窗口或者其他窗口没有vim正在打开文件(会生成swp file)  find . -type f -name \u0026#34;.*.sw[klmnop]\u0026#34; -delete  How to handle swapfiles in Vim (longwood.edu)\n智能补全 目前采用coc.vim插件做补全，安装方法请看【我的开发环境部署】，其中有介绍。这里想说明的是coc.vim插件的使用方法。\n安装完成后，You have to install coc extensions or configure language servers for LSP support.\n# C/C++补全用coc-clangd插件，安装coc-json的原因是后续打开coc-setting.json方便修改 :CocInstall coc-clangd coc-json 安装好coc-clangd的插件，还需要配置clangd服务端的位置，使coc能找到。 配置Coc使用 :CocConfig 命令， :CocConfig opens your global coc-settings.json. :CocLocalConfig opens local configuration for your project ($PROJECTROOT/.vim/coc-settings.json)。不同语言的配置写法可以看这里：https://github.com/neoclide/coc.nvim/wiki/Language-servers。\n 一般我用的clangd服务端是clangd-xx，还有一个是coc-clangd是另一种可选的方案。如果你只在vim里用clangd，可以直接安装coc-clangd，貌似是比较方便。\n Debug VIM key mapping https://vi.stackexchange.com/a/7723/43494\n如何同步 VIM Dotfiles vim 的 dotfiles 主要包含.vimrc和.vim/中的插件.\n  对于.vimrc, 我选择使用mackup 软件和其他system dotfiles 一起备份. Git repo 一个单独的vimrc太大，将其分成多个子文件，所以就没用mackup， 而是一个单独的仓库进行管理。wangloo/myvimrcs: My vimrcs\n  对于 plugins, 传统的管理插件的方式(使用vim-plug), 也就是放在~/.vim/plugged/目录中的, 可以通过:PlugInstall命令在新机器上重新从网上克隆. 能够保证使用的是新版本. VIM 8.0 之后, 引入 pack system 新的插件管理方式。 wangloo/myvimpack: My Vim8 plugins 使用方法见README.\n  插件  优秀的vimrc配置: The Ultimate vimrc\n LeaderF 介绍使用方法和配置的BLOG：vim plugin介绍之LeaderF | Mingjian\u0026rsquo;s Blog\nLeaderF LeaderF可实现模糊查找文件，Tag。Github\nLeaderF结合rg实现文件内容的模糊搜索，类似grep命令。vim的grep插件Leaderf rg：grep和模糊匹配的完美结合 - 知乎\n 安装rg的命令：\nsudo apt install ripgrep  模糊搜索的使用，:Leaderf rg ，执行后是输入模式，如果想在选项中上下选择，按Tab键。\nInstalled NERD Commneter - 快速注释\nNERD Tree - 目录树\nOpen File Under Cursor - 打开光标处的文件目录\n 不支持vim-plug安装. 直接clone源码到plugged目录即可. Usage: gf: 在当前window打开文件. \u0026lt;C-w\u0026gt;\u0026lt;C-f\u0026gt;: new vertical windows中打开文件.  Ack.vim - 快速定位内容\nbarbaric - normal模式切换英文输入法\n Helpful script search text selected in visual mode xnoremap * :\u0026lt;C-u\u0026gt;call \u0026lt;SID\u0026gt;VSetSearch(\u0026#39;/\u0026#39;)\u0026lt;CR\u0026gt;/\u0026lt;C-R\u0026gt;=@/\u0026lt;CR\u0026gt;\u0026lt;CR\u0026gt;xnoremap # :\u0026lt;C-u\u0026gt;call \u0026lt;SID\u0026gt;VSetSearch(\u0026#39;?\u0026#39;)\u0026lt;CR\u0026gt;?\u0026lt;C-R\u0026gt;=@/\u0026lt;CR\u0026gt;\u0026lt;CR\u0026gt;function! s:VSetSearch(cmdtype)let temp = @snorm! gv\u0026#34;sylet @/ = \u0026#39;\\V\u0026#39; . substitute(escape(@s, a:cmdtype.\u0026#39;\\\u0026#39;), \u0026#39;\\n\u0026#39;, \u0026#39;\\\\n\u0026#39;, \u0026#39;g\u0026#39;)let @s = tempendfunction","date":"2022-05-09T19:28:12+08:00","permalink":"https://wangloo.github.io/posts/tools/vim/basic/","section":"posts","tags":["Vim"],"title":"我的 vim 调教随笔"},{"categories":null,"contents":"Change code theme Default use monokai.css. see 官方文档\n修改需要下载新的css放到plugin/highlight/目录下.\n其他可用的css在highlight.js仓库中下载.\nAlign Slide Align 取消center对齐方式:\nReveal.initialize({ ... center: false, ... }) 所有slide左对齐: https://github.com/hakimel/reveal.js/issues/1897\n用markdown写的方式下使某一幻灯片左对齐: https://github.com/hakimel/reveal.js/issues/890#issuecomment-129735291\n","date":"2022-05-08T19:34:44+08:00","permalink":"https://wangloo.github.io/posts/revealjs/","section":"posts","tags":null,"title":"reveal.js Tutorial"},{"categories":["Architecture"],"contents":"Load/Store 指令 寻址模式 Base register - w0=[x1]\nldr w0, [x1] Offset addressing mode - w0=[x1+12]\nldr w0, [x1, 12] Pre-index addressing mode - x1+=12; w0=[x1]\nldr w0, [x1, 12]! Post-index addressing mode - w0=[x1]; x1+=12\nldr w0, [x1], 12 更多示例 // load a byte from x1 ldrb w0, [x1] // load a signed byte from x1 ldrsb w0, [x1] // store a 32-bit word to address in x1 str w0, [x1] // load two 32-bit words from stack, then add 8-byte to sp ldp w0, w1, [sp], 8 // Store two 64-bit regs in [sp-96] and subtract 96-byte from sp. // ==\u0026gt; [sp]=x1, [sp+8]=x2 stp x1, x2, [sp, -16]! // LDR伪指令. load 32-bit immediate from literal pool(addr: 0x12345678) ldr w0, =0x12345678 数据处理指令 Bitfield 操作指令 Bitfield 指令常用于设置/提取寄存器的某个字段.\n;BFI(Bit Field Insert) BFI w0, w0, #9, #6 ;w0[0, 5] = w0[9, 14] ;BFC(Bit Field Clear) BFC w0, #4, #2 ;w0[4, 5] = 0 ;UBFX(Unsigned Bit Field Extract) UBFX w1, w0, #18, #7 ;w1=w0[18, 24]  与 UBFX 相对的是 SBFX, 若提取后的字段高位为 1, 会进行符号扩展\n 分支/控制指令 获得地址的相关指令 写汇编中，常常会获取一个变量或者函数(label)的地址，A64 中一共有几种获取地址的指令， 包括adr, adrp, adrl, ldr等，下面我就对这些指令进行介绍。\nADR 首先是 adr，它的作用是加载 PC 相对地址。PC相对的另一层含义就是物理地址， 而不一定是编译后指令的VMA，仅仅取决于当前的PC在哪，返回的就是偏移后的结果。\n 我们都知道，指令正常运行不一定PC对应的指令一等等于其在可执行文件中的VMA， 就拿bring-up代码做参考即可。这时候指令能正常执行的原因是：取指动作永远都是简单的PC+1， 仅仅与PC有关而已。\n adr 指令的格式是:\nadr reg, offset 输入一个 offset，输出 PC+offset 的值，但我们常用的是 offset 填某一个 label，例如函数 或者变量，此时 reg 中存的就是此函数的地址了。例如，\nadr x0, a_func # x0 = addr(a_func) adr 指令中留给 offset 的位数是 21，所以最大的寻址范围为+-1MB。\nADRP adrp 的指令格式与 adr 相同，不同点是会将计算的结果向下对齐到 4k，但这样直接计算的 地址结果往往是不正确的，因为少了页内的偏移。需要一个额外的 add 指令进行纠正，一般来说 是组合起来用的：\nadrp x0, a_func add x0, x0, :lo12:a_func 显然 adrp 这样做是为了更大的寻址空间，能到+-4GB。\nLDR 伪指令 一般通用的ldr指令都是用来加载内存中的值，比如常见的 ldr x0, [x1]。 或者说容易混淆的加载label处内存的值: ldr x0, label。\n如果 ldr 指令的参数是=\u0026lt;label\u0026gt;，那就代表伪指令，作用是加载 label 的绝对地址， 注意不是内存的值，而是地址, 拿到的地址是绝对地址，即VMA。 好处是可以获取到一个位于任意 label 的地址，不受寻址空间的约束。\n 简单说下ldr和ldr伪指令的区别\nlabel_1: // assmue VMA of label_1 = 0x12345678 .word 0xabcdabcd ldr x0, addr // x0 = 0xabcdabcd ldr x0, =addr // x0 = 0x12345678   当目前指令执行地址不等于它们的虚拟地址时，比如当 MMU 未开始时通过 uboot 加载到内存 中直接运行的那段程序，此时用adr/adrp这些加载 pc 相对地址的指令就会正确的返回 label 的实际运行地址；而ldr则是永远返回其编译链接后绑定的虚拟地址。这种情况下 如果寻址范围允许，用adr*指令更方便。\n Hint 指令  yield指令属于Hint指令的一种，其预留是为了通知处理器当前线程是“不重要的”，处理器可以切换到其他线程去执行。！！注意这个地方的线程指的是硬件线程，而目前所有的ARM处理器都是单硬件线程的，所以 yield 在所有ARM处理器上实现为 nop。  有趣特性/常见误区 \u0026lsquo;#\u0026rsquo; before the immediate value  A64 assembly language does not require the # to introduce constant immediate value. But the assembler can also indentify the #. In armv7, there must be a # or $ before other than using .syntax unified. About syntax unified.   Agreed Recommendation\nUse .syntax unified in v7 code, and never use # on any literal on either v7 or v8. Unified syntax is newer and better, and those # and $ signs are just more code noise.\n ","date":"2022-05-07T21:19:01+08:00","permalink":"https://wangloo.github.io/posts/arch/armv8/a64/","section":"posts","tags":["arm64"],"title":"A64 指令集"},{"categories":["Math"],"contents":"考试大纲 🎯 To Reader:\nThis blog is JUST FOR EXAMINATION! If you are interested in numberical analysis, please quit this web. I try to sort out the knowledge points of the course, just to pass the exam.\nBased on the course of Professor Zhong Erjie of UESTC.\n💢 I hate mathematics!\n 第二章 非线性方程/方程组的求解 1. 二分法及迭代  二分法误差估计定理  2. 不动点迭代  不动点及不动点迭代的概念 迭代格式的选择? 是否收敛? 迭代的初值是否合适?  3. 牛顿法解非线性方程  背景: 如果函数f(x)是线性的, 那么它的求根问题就会简化. 牛顿法实质上是一种线性化方法, 将非线性方程逐步归结为某种线性方程来求解.\n 牛顿法的迭代格式: $$ x^{k+1} = x^k - \\frac{f(x^k)}{f^\u0026rsquo;(x^k)} $$\n4. 弦截法  背景: 弦截法是牛顿法的一个改进. 牛顿法求根时需要计算f'(x), 而导数的计算往往困难. 弦截法使用差商来回避导数的计算.\n 5. 收敛阶 6. 非线性方程组的牛顿迭代格式  雅可比矩阵是什么?   第三章 直接法解线性方程组 1. Gauss消元法 求解过程的算法复杂度为O(n^2), 消元过程的算法复杂度为O(n^3).\n2. 直接三角分解法(Doolittle分解法)  背景: 直接意味着可以由A的元素直接计算L和U, 不需要任何的中间步骤.\n 一旦L和U得到, 求解Ax=b就可以等价表示为求解两个三角形方程组:\n Ly=b, 求y Ux=y. 求x   第四章 迭代法解线性方程组  背景: 对于线性方程组Ax=b, 当A为低阶稠密矩阵时, [选主元消去法]是求解的有效方法.\n但是实际情况中A大都是巨型的稀疏矩阵, 这是采用迭代法来求解是合适的. 迭代法可以利用A中有大量零元素的特点.\n  迭代法不一定最终能够逼近方程组的解, 认识误差向量的概念.  1. Jacobi迭代 雅可比迭代格式和收敛性的判别\n快速计算Bj的特征值\nJacobi迭代由A直接看出Bj\n2. Seidel迭代 Seidel迭代收敛格式和收敛性的判别\nSeidel迭代独有的判断收敛性的方式: 若A为对称阵, 且A正定, 那么迭代收敛.\n 第五章 插值法 1. 插值方法与插值问题  背景: 仅已知某些点和该点的函数值的情况下, 如何模拟一个插值函数P(x), 使得误差最小.\n  什么是插值函数P(x)? 被插函数? 插值节点? 插值余项?  2. 多项式插值  可证明多项式P(x)存在唯一. 多项式插值通过解方程组就能得到解(a0, a1,..., an).  3. 拉格朗日插值公式  背景: 虽然上面的多项式插值能否解决n+1个点的光滑函数, 且解是唯一的. 但是解方程组是很麻烦的.\n 拉格朗日插值公式: $$ L_n(x) = l_0(x)y_0 + l_1(x)y_1 + \\dots + l_n(x)y_n $$ 插值基函数:\n插值条件(插值系数): $$ y_0 = f(x_0), y_1 = f(x_1), \\dots,y_n = f(x_n) $$\n误差余项Rn(x)\n4. 牛顿插值公式  背景: 给定5个插值节点及其函数值, 可以得到L4(x); 由于某种原因, 需要加入一个新的插值节点. Lagrange插值法之前的计算结果(l)均失效, 需要重新计算. 非常的不方便.\n  牛顿法是基于差商的概念. 导数是差商的极限. 差商的差商是高阶差商.  牛顿插值法的插值函数(以二次插值举例): $$ P(x) = a_0 + a_1(x-x_0) + a_2(x-x_0)(x-x_1) $$ 需要做的就是解出系数a0,a1,....\n所以引入差商的符号: $$ a_1=f[x_0,x_1]=\\frac{f(x_1)-f(x_0)}{x_1-x_0} $$ $$ a_2=f[x_0,x_1,x_2]=\\frac{f[x_1,x_2]-f[x_0,x_1]}{x_2-x_0} $$\n5. Hermite插值  背景: 有时我们已知的条件不都是函数值, 也有导数值. 例如已知两个点的函数值和两个点的导数值, 可以应用Heimite插值法得到三次多项式.\n 求Hermite插值函数的方法: 构造差商表, 重复节点特殊处理.\nHermite插值方法的余项证明与Langrange插值法相同.\n6. 分段低次插值  背景: 次数太高的多项式插值的效果不好. 比如龙格现象.\n  分段: 把被插值函数所在的大区间分成一个个的小区间. 低次: 每个小区间上用次数不超过3的函数来逼近  6.1 分段线性插值 就是分段折线\n分段线性插值的优点:\n 简单 当二阶导数趋近0时, 一定收敛  分段线性插值的缺点:\n 分段折线不光滑, 分段点处不能求导.  6.2 分段Hermite插值  背景: 为了解决分段线性插值的缺点(存在尖点).\n 已知函数在(n+1)个点的函数值值以及其导数值, 去构造一阶连续可导函数.\n分段Hermite插值根据(n+1)个已知点划分为(n+1)个区间. 这样在每个小区间上都已知4个条件, 可以使用3次Hermite插值.\n结论: 已知(2n+2)个条件的情况下, 居然只得到一阶连续可微函数. 结论太差!\n 第六章 拟合 🔍 插值, 拟合, 逼近的区别\n1. 最佳平方逼近 2. 最小二乘法  背景: 已知不共线的三点, 如何确定一条可信的直线.\n 三个点可以用插值来模拟二次多项式, 但题目要求了用一次多项式, 这是插值无法做到的.\n不共线的三点不可能同时经过一条直线, 所以要用逼近的思想. 找一条近似的直线, 使得误差最小.\n 与插值的区别: 插值是明确给出n+1个插值条件, 得到n次多项式. 如何定义误差最小?: 函数间的距离.  1. 线性拟合 拟合的函数是n次多项式, 可转化为超定方程GX.\n 其中规定G为系数矩阵, X为变量的列向量. 同时定义列向量F为给出的函数值. GX=F是超定方程组, 没有准确解. 得到残差最小的解的方法即最小二乘法.  所以线性拟合的残差r = |GX - F|, 而找到目标函数的宗旨就是使r最小. 使用初等变分原理将这个问题转化为正规方程组求解的问题.\n 第七章 数值积分  背景: 定积分的计算中可能无法找到原函数的情况. 考虑定积分的本质是一句具体的数, 我们的目标就是找到这个数的近似值, 越接近越好.\n 解决的两种思路: 积分中值定理 和 插值型求积公式(近似被积函数).\n1. 积分中值定理 基本的积分中值定理: $$ \\int_{a}^{b}f(x)dx = f(\\xi)(b-a) $$\n将一个区域的面积转化为矩形的面积. 如何确定矩形的高呢? 左矩阵, 右矩阵, 中间矩阵, 梯形公式.\n更常用的积分公式是 在乘积函数积分中, 如果g(x)不变号, 则有: $$ \\int_{a}^{b}g(x)f(x)dx =f(\\xi)\\int_{a}^{b}g(x)dx $$\n2. 插值型求积公式 在被积函数很复杂的情况下, 可以对其进行近似处理, 例如使用Lagrange插值法.\n二次插值: Simpson公式 取二次插值的步长h=(b-a)/2, 即增加一个插值节点(b-a)/2, Simpson公式化简的结果为: $$ \\int_{a}^{b}f(x)dx = \\frac{b-a}{6}[f(a)+4f(\\frac{a+b}{2})+f(b)]+R[f] $$\n📌 Simpson公式满足3阶代数精度. 虽然它只是二次插值得到的.\n3. 余项  插值型求积公式的余项, 即对应的插值方法(如Lagrange, Newton)的余项在区间上的积分. 梯形公式方法的余项可以用积分中值定理来优化. Simpson公式的余项不能使用积分中值定理来优化, 因为不满足保号的条件.  4. 衡量求积公式的好坏 代数精度: 不是一种误差, 而是对误差的描述.\n如何得知某个公式的代数精度: 只要带入一个m次多项式验证余项是否为0即可.\n5.复合求积公式 为了提高精度通常把积分区间分为若干个子区间, 再在每个子区间上应用低阶求积公式.\n 复合梯形公式: 将区间等分. 复合simpson公式: 将区间偶数等分.   第八章 常微分方程初值问题数值解法 将研究的内容进一步限定为: 一阶初值问题, 单步法.\n 背景: 在无法给出解析表达式时如果利用数值方法求出y的近似解?\n 1. 简单的数值方法 1.1 Euler公式 使用一阶向前差商近似替代y'. 得到递推的数列表达式: $$ y_{n+1} = y_{n} + hf(x_n,y_n), n=0,1,2,\u0026hellip; $$\n误差: Euler法使用的近似代替只有一阶精度, 所以误差很大. 此时有两种解决方案:\n 加细步长h, 若不行再加细. 总是能得到正确的, 如果你不嫌弃带来的计算变得缓慢的问题. 换方法.  1.2 梯形公式  背景:为得到比Euler法精度更高的计算公式. 梯形公式具有二阶精度.\n 对y' = f(x,y)的两端进行局部的积分, 然后用梯形公式近似计算右边.\n1.3 改进Euler公式 先用欧拉公式求得一个近似的yn+1, 带入梯形公式, 得到矫正的yn+1.\n","date":"2022-05-07T18:04:58+08:00","permalink":"https://wangloo.github.io/posts/numberical-analysis/","section":"posts","tags":["Math","Examination"],"title":"Numberical Analysis Exam"},{"categories":["Vim"],"contents":"Use plugin vimtex Vim build-in support of LaTeX files is just OK. When we need more excellent exprience, good plugins is very recommended.\nvimtex is a nice and modern vim plugin for LaTeX files.\nUseful Futures of vimtex IMO\n \u0026lt;leader\u0026gt;ll Complier. By default, it will auto-complier when you type :w. \u0026lt;leader\u0026gt;lt Open content tree as a sidebar. \u0026lt;leader\u0026gt;lv View PDF with configured PDF viewer. \u0026lt;leader\u0026gt;li File information. cse Change surrounding \\begin \\end environment. tse Exchange between \\begin{env} and \\begin{env*}. tsc Exchange between \\command{} and \\command*{}.   Add Support of Simplified Chinese Install xetex I use xetex to add supports for Chinese fonts in LaTex files. Actually the magician is amacro package of xetex named xeCJK.\nAnd xetex is included intexlive. so we install it from source:\nsudo apt install texlive-xetex Install Chinese Font If there is no Chinese font in your system, you must install one. I choose WinQingYuan microhei as a instance.\nsudo apt install ttf-wqy Excute fc-list to check if install successfully, here is excepted output:\nfc-list | grep wqy /usr/share/fonts/truetype/wqy/wqy-microhei.ttc: WenQuanYi Micro Hei,文泉驛微米黑,文泉驿微米黑:style=Regular /usr/share/fonts/truetype/wqy/wqy-microhei.ttc: WenQuanYi Micro Hei Mono,文泉驛等寬微米黑,文泉驿等宽微米黑:style=Regular Configure your tex file \\documentclass {article} \\usepackage{xeCJK} \\setCJKmainfont{WenQuanYi Micro Hei} \\begin{document} Hello, LaTeX! 你好, LaTex! \\end{document} Complier it and see, the Chinese font is displayed!\n Confusing Tools Difference between {pdf,lua,xe}Tex and {pdf,lua,xe}LaTeX If a .texfile starts with \\documentclass, it\u0026rsquo;s a LaTex format file rather than the Plain Tex format file.\nThe LaTeX format file has some specific macro like \\documentclass that cannot be compliered by [pdf]Tex, so that\u0026rsquo;s the job of [pdf]LaTeX. Same goes for other engines.\nWhat is xetex/xelatex? xetex/xelatex is one of the TeX/LaTeX engines. Others are pdfTex, LuaTex, etc. Wiki\nxetex/xelatex add fonts and character sets support for TeX/LaTeX file.\n Treat input as Unicode Allow us to use many system fonts in LaTeX file easily  What is latexmk? LaTeXmk 是一个集成化的命令行工具, it must work with one LaTeX engine.\nThe fundamental issue that latexmk solves is that the number of runs of [pdf]latex is highly dynamically dependent on the document and the class file used. latex just need to be run once a time.\nDifferent between CTeX/MiKTeX/TeXlive ? They are all 包含与.tex文件关联的各种编辑、查看工具、常用宏包及文档.\nCTex packages add complete Chinese support based on MiKTeX.\n CTex is only avilable in windows.  ","date":"2022-05-04T17:07:51+08:00","permalink":"https://wangloo.github.io/posts/tools/vim/latex_vim/","section":"posts","tags":["Vim"],"title":"LaTeX Vim Tutorial"},{"categories":null,"contents":"When reading C standard documents, we usually see phrases like \u0026ldquo;Implementation-defined\u0026rdquo;, \u0026ldquo;Unspecified\u0026rdquo;,.etc.\nSo, what do they really mean?\n术语 我们将这些难以直接理解的词汇称为术语，在ANSI C中，术语可以分为描述不可移植代码(unportable), 坏代码(bad), 可移植的代码(portable)三类.\nunportable code Implementation-defined\n需要由编译器设计者决定采取何种行为，他们可能不同，但都不能说是错误的.\n例如：当整型数右移时，是否需要扩展符号位. 右移代替除法可能导致的灾难.\nunspecified\n在某些正确情况下的做法，标准并未明确规定应该怎样做.\n例如：参数求值的顺序.\nbad code undefined\n在某些不正确情况下的做法，但标准并未规定应该怎样做。意味着你可以采取任何行动，可以什么都不做，也可以发出一条警告信息, 或者终止CPU重启等等. 你甚至可以发射核导弹(只要你安装了能发射核导弹的硬件系统).\n例如：当一个有符号整数溢出时该采取什么行动.\nconstraint\n这是一个必须遵守的限制或要求. 如果你不遵守, 那么你的程序的行为就会变成如上所说的undefined. 这出现了一种很有意思的情况: 分辨某种东西是否是一个constaint是很容易的, 因为每个标准的主题都附有一个constraint小节, 列出了所有的约束条件。\n例如: %操作符的操作数必须为整型. 所以,在非整型数据上使用%操作符肯定会导致undefined.\nportable code strictly conforming\n严格遵守标准的. 符合该条件的程序应当是:\n 只使用已确定的特性 不突破任何由编译器实现(Implementation-defined)的限制. 不使用unspecified和undefined特性  这样规定的目的是最大程序保证代码的可移植性. 但符合该术语的代码并不常见, 例如INT_MAX的值在不同架构的机器上结果可能不同.\ncomforming\n遵循标准的; 一个遵循标准的程序可以依赖一些对于某种编译器特有的不可移植的特性. 这样一个程序对于某个编译器可能是遵循标准的, 但对于另外一个编译器又是不遵循标准的.\n","date":"2022-05-01T16:41:35+08:00","permalink":"https://wangloo.github.io/posts/reading-notes/expert_c_programming/portability_issues/","section":"posts","tags":null,"title":"Portability Issues"},{"categories":null,"contents":"","date":"2022-05-01T16:41:35+08:00","permalink":"https://wangloo.github.io/posts/third-blog/","section":"posts","tags":null,"title":"Third Blog"},{"categories":["Makefile"],"contents":"As we all know, there are huge number of parameters for GCC. With them, we can make many things possible. Now we talk about -M and related ones. After reading this article, you will know the meaning of there magic parameters. And I will put some little demos follows. Finally, we will see what can they do in really project. Let\u0026rsquo;s go ahead.\n实例规则 以下的分析都是基于这样一个生成目标文件的规则, 应该来说具有一定的通用性。\nbuild/obj/main.o: src/main.c $(CC) $(CFLAGS) $(INCLUDES) -c $\u0026lt; -o $@ main.c中的内容：\n/* File: main.c */ #include \u0026lt;stdio.h\u0026gt; // system header file#include \u0026#34;header.h\u0026#34; // user defined header fileint main() { return 0; } -M Output the dependencies of the input source file. Incluing the names of itself and all included files.\n-M(and 下面的-MM)和-o 不能同时使用，因为都隐含-E。 假设我们只想输出依赖文件，我们可以将示例中的规则如此改造：\nbuild/obj/main.o: src/main.c $(CC) $(CFLAGS) $(INCLUDES) -c $\u0026lt; -M We will get messy output like following. Notice that the first two words is object filename and a colon.\nmain.o: src/main.c /usr/include/stdc-predef.h /usr/include/stdio.h \\  /usr/include/x86_64-linux-gnu/bits/libc-header-start.h \\  /usr/include/features.h /usr/include/x86_64-linux-gnu/sys/cdefs.h \\  /usr/include/x86_64-linux-gnu/bits/wordsize.h \\  /usr/include/x86_64-linux-gnu/bits/long-double.h \\  /usr/include/x86_64-linux-gnu/gnu/stubs.h \\  /usr/include/x86_64-linux-gnu/gnu/stubs-64.h \\  /usr/lib/gcc/x86_64-linux-gnu/9/include/stddef.h \\  /usr/lib/gcc/x86_64-linux-gnu/9/include/stdarg.h \\  /usr/include/x86_64-linux-gnu/bits/types.h \\  /usr/include/x86_64-linux-gnu/bits/timesize.h \\  /usr/include/x86_64-linux-gnu/bits/typesizes.h \\  /usr/include/x86_64-linux-gnu/bits/time64.h \\  /usr/include/x86_64-linux-gnu/bits/types/__fpos_t.h \\  /usr/include/x86_64-linux-gnu/bits/types/__mbstate_t.h \\  /usr/include/x86_64-linux-gnu/bits/types/__fpos64_t.h \\  /usr/include/x86_64-linux-gnu/bits/types/__FILE.h \\  /usr/include/x86_64-linux-gnu/bits/types/FILE.h \\  /usr/include/x86_64-linux-gnu/bits/types/struct_FILE.h \\  /usr/include/x86_64-linux-gnu/bits/stdio_lim.h \\  /usr/include/x86_64-linux-gnu/bits/sys_errlist.h src/header.h -MM Like -M but do NOT output system header files.\nmain.o: src/main.c src/header.h -MF \u0026lt;file\u0026gt; Use with -M or -MM. Specify output dependencies to file instead of STDOUT.\n注意，只要使用追加上-MF，就可以和-o选项并存了，可以写在一条语句中\n-MD -MD is same as -M -MF \u0026lt;file\u0026gt;. But the filename is basd on the object file but replacing .o with .d.\n如果将示例中的代码换成：\nbuild/obj/main.o: src/main.c FORCE $(CC) $(CFLAGS) $(INCLUDES) -c $\u0026lt; -o $@ -MD $ ll build/obj/ total 16 drwxrwxr-x 2 soben soben 4096 3月 23 20:45 ./ drwxrwxr-x 3 soben soben 4096 3月 23 20:35 ../ -rw-rw-r-- 1 soben soben 1144 3月 23 20:45 main.d -rw-rw-r-- 1 soben soben 1368 3月 23 20:45 main.o  Note: -MD and -MMD 因为有-MT，也不隐含 -E.\n -MMD -MMD is same as -MM -MF \u0026lt;file\u0026gt;. Also named on object file but replacing .o with .d.\n-MT \u0026lt;target\u0026gt; MT 是一个单独的选项，不与上面的冲突。作用是改变生成依赖规则的目标格式。在此之前，默认的格式是文件名.o，去除任何前缀目录。\n而使用-MT之后可以自定义规则中目标的格式， 由\u0026lt;target\u0026gt;指定。\n例如，对于前面的选项，依赖规则目前总是main.o，很多使用，我们需要的是其编译规则中目标的形式，包含路径，并不仅仅是文件名本身。这时我们就需要使用-MT，可以将示例中的规则做如下修改:\nbuild/obj/main.o: src/main.c FORCE $(CC) $(CFLAGS) $(INCLUDES) -c $\u0026lt; -o $@ -MMD -MT $@ 依赖文件的内容就变为:\nbuild/obj/main.o: src/main.c src/header.h  实际上，从我的开发经验来看，大项目中编译规则的目标并不直接是目标文件，总有一个路径前缀，例如：$(objdir)/%.o: $(srcdir)/%c, 这时如果 include 的依赖文件的目标只是一个文件名，其实没什么意义。 所以 -MT 应该是在开发大型项目中很常见的。\n -MQ \u0026lt;target\u0026gt; 与MT类似，而且我没有验证成功官网说出的和 MT 的区别. 所以，这是一个 TODO。\nApplication Here is an important question you may ask me: Why do we struggle to get the dependencies formats? What can they do?\nIf you are familiar with make and Makefile, aha, that\u0026rsquo;s it! With the help of M-related parameters, you can easily handle the problem of tracing header files.\nGive you a little demo about my point.\n-include *.d %.o:%.c $(CC) $(CFLAGS) $(INCLUDES) $\u0026lt; -c -MMD -o $@ Actually, we do two things in order:\n When complieing source files, we generate dependency files xxx.d at the same time. After geting xxx.d, we include them in makefile. As its format is exactly the dependency format required by makefile.  Summary Hope this article can give you a clear understanding of M-related parameters in GCC. We can sometimes find them in large projects\u0026rsquo; makefile. It\u0026rsquo;s very useful to automatic build dependency for header files. So try to use them in your current or next project.\nReference  GNU GCC options GCC -M, -MM, -MMD, -MF, -MT  ","date":"2022-04-26T19:08:22+08:00","permalink":"https://wangloo.github.io/posts/c/make/gcc_-m_related/","section":"posts","tags":["c","makefile"],"title":"\"GCC -M\" 选项在Makefile中的使用"},{"categories":null,"contents":"This is my second blog.\n Wish you have a good life.\n  happy smile   sunset   ","date":"2022-04-26T15:32:11+08:00","permalink":"https://wangloo.github.io/posts/second-blog/second-blog/","section":"posts","tags":null,"title":"Second Blog"},{"categories":null,"contents":"This is my first blog. This is my first blog. This is my first blog. This is my first blog. This is my first blog. This is my first blog. This is my first blog. This is my first blog. This is my first blog. This is my first blog. This is my first blog. This is my first blog. This is my first blog. This is my first blog. This is my first blog. This is my first blog. This is my first blog.\n#include \u0026lt;stdio.h\u0026gt; int main(void) { printf(\u0026#34;hello, hugo\\n\u0026#34;); return 0; } ","date":"2022-04-26T15:13:07+08:00","permalink":"https://wangloo.github.io/posts/first-blog/first-blog/","section":"posts","tags":null,"title":"First Blog"},{"categories":null,"contents":"Reference  Measuring Function Duration with Ftrace  Finding Origins of Latencies Using Ftrace Slides: Ftrace Slides: Ftrace Kernel Hooks:More than just tracing  介绍 ftrace功能 ：帮助了解Linux内核的运行时行为，可以查看系统调用情况，以及某个函数的调用流程。 2.6内核之后引入内核的。以便进行故障调试或性能分析。\nFtrace 跟踪工具由性能分析器（profiler）和跟踪器（tracer）两部分组成，\n性能分析器：用来提供追踪数据的解析和图形化作战时（需要 CONFIG_FUNCTION_PROFILER=y）\n 函数性能分析 直方图  跟踪器：负责不同追踪事件的实现，数据的来源\n 函数跟踪（function） 点跟踪（tracepoint） kprobe uprobe 函数调用关系（function_graph） hwlat等  Debugfs提供用户层控制接口 ftrace的目录：/sys/kernel/debug/tracing/ ，常用文件介绍：\n dynamic tracing，动态trace进行过滤的接口，是需要在编译时支持该功能，需要打开对应的宏开关： available_events available_filter_functions: 可追对函数的完整列表 available_tracers，当前内核中可用的插件追踪器。 buffer_size_kb，以KB为单位指定各个CPU追踪缓冲区的大小。系统追踪缓冲区的总大小就是这个值乘以CPU的数量。设置buffer_size_kb时，必须设置current_tracer为nop追踪器。 buffer_total_size_kb current_tracer，通过该接口指定当前ftrace要使用的tracer，也就是要追踪的函数/时间。 dyn_ftrace_total_info: enabled_functions: max_graph_depth: printk_formats: saved_cmdlines: saved_cmdlines_size: set_event: set_event_pid: set_ftrace_filter，指定要追踪的函数名称，函数名称仅可以包含一个通配符。 set_ftrace_notrace，指定不要追踪的函数名称。 set_ftrace_pid，指定作为追踪对象的进程的PID号。 set_graph_function: set_graph_notrace: trace，以文本格式输出内核中追踪缓冲区的内容，是查看trace日志的接口。 trace_clock: trace_marker: trace_marker_raw: trace_options: trace_pipe，与trace相同，但是运行时像管道一样，可以在每次事件发生时读出追踪信息，但是读出的内容不能再次读出 tracing_cpumask，以十六进制的位掩码指定要作为追踪对象的处理器，例如，指定0xb时仅在处理器0、1、3上进行追踪。 tracing_on，启用/禁用向追踪缓冲区写入功能。1为启用，0为禁用。 tracing_thresh: uprobe_events: uprobe_profile:   支持的tracer包括:\n nop，不执行任何操作。不使用插件追踪器时指定。 function，函数调用追踪器，可以看出哪个函数何时调用。 function_graph，函数调用图表追踪器，可以看出哪个函数被哪个函数调用，何时返回。 mmiotrace，MMIO( Memory MappedI/O)追踪器，用于Nouveau驱动程序等逆向工程。 blk，block I/O追踪器。 wakeup，进程调度延迟追踪器。 wakeup_rt，与wakeup相同，但以实时进程为对象。 irqsoff，当中断被禁止时，系统无法响应外部事件，造成系统响应延迟，irqsoff跟踪并记录内核中哪些函数禁止了中断，对于其中禁止中断时间最长的，irqsoff将在log文件的第一行标示出来，从而可以迅速定位造成系统响应延迟的原因。 preemptoff，追踪并记录禁止内核抢占的函数，并清晰显示出禁止内核抢占时间最长的函数。 preemptirqsoff，追踪并记录禁止内核抢占和中断时间最长的函数 sched_switch，进行上下文切换的追踪，可以得知从哪个进程切换到了哪个进程。  ftrace有两种主要跟踪机制可以往缓冲区中写数据，一种是函数，一种是事件。前者比较酷，很多教程都会先讲前者。但对我来说，后者才比较可靠实用，所以我先讲后者。\n事件是固定插入到内核中的跟踪点，我们看Linux代码的时候，经常看到这种trace_开头的函数调用：\nif (likely(prev != next)) { rq-\u0026gt;nr_switches++; rq-\u0026gt;curr = next; ++*switch_count; trace_sched_switch(preempt, prev, next); rq = context_switch(rq, prev, next, cookie); /* unlocks the rq */ } else { lockdep_unpin_lock(\u0026amp;rq-\u0026gt;lock, cookie); raw_spin_unlock_irq(\u0026amp;rq-\u0026gt;lock); } 实验 使用ftrace：分为三步\n 设置tracer类型 设置tracer参数 使能tracer  内核函数跟踪 cd /sys/kernel/debug/tracing # Set tracer  echo function \u0026gt; current_tracer # Set function filter echo vma_link \u0026gt; set_ftrace_filter # Enable selected tracer echo 1 \u0026gt; tracing_on # See trace result cat trace 应用的场景不多，只限于想看某几类函数的调用事件。 但是有些场景我们更可能希望获取调用该内核函数的流程（即该函数是在何处被调用）， 这需要通过设置 options/func_stack_trace 选项实现。\n#先关闭跟踪 echo 0 \u0026gt; tracing_on # Set tracer  echo function \u0026gt; current_tracer # Set function filter echo vma_link \u0026gt; set_ftrace_filter #开启跟踪函数的调用栈 echo 1 \u0026gt; options/func_stack_trace # Enable selected tracer echo 1 \u0026gt; tracing_on # See trace result cat trace 如果想要分析内核函数调用的子流程（即本函数调用了哪些子函数，处理的流程如何）， 这时需要用到 function_graph 跟踪器，从字面意思就可看出这是函数调用关系跟踪。\necho function_graph \u0026gt; current_tracer echo *vfs* \u0026gt; set_ftrace_filter echo 1 \u0026gt; tracing_on cat trace 事件 可基于 ftrace 跟踪内核静态跟踪点，可跟踪的完整列表可通过 available_events 查看。\n1小时掌握ftrace内核跟踪技术 - 知乎\n高效调试与分析：利用ftrace进行Linux内核追踪 - 知乎\nPerf性能分析 Wsl2编译安装Perf apt工具总是提示找不到，所以就手动编译安装。\ngit clone https://github.com/microsoft/WSL2-Linux-Kernel --depth 1 cd WSL2-Linux-Kernel/tools/perf make -j8 sudo cp perf /usr/local/bin ","date":"0001-01-01T00:00:00Z","permalink":"https://wangloo.github.io/posts/os/linux/trace/ftrace/","section":"posts","tags":null,"title":""},{"categories":null,"contents":"名词解释 probe 一个probe是一个位置或者活动, 动态追踪工具可以在probe上绑定一些action. 例如记录栈帧位置, 查看参数等.\nprobe就像是一个可编程的传感器, 你可以为他设定触发的事件或者指令. 当probe 触发时, 可以执行你提前绑定的函数, 了解此时系统的状态\n","date":"0001-01-01T00:00:00Z","permalink":"https://wangloo.github.io/posts/os/trace/","section":"posts","tags":null,"title":""},{"categories":null,"contents":"涉猎要广 要摄影, 其他的方面也要广泛涉猎.\n 安塞尔·亚当斯（Ansel Adams）曾经说过：“我们不只是用相机在拍照，我们带到摄影中去的是所有我们读过的书、看过的电影、听过的音乐、爱过的人。”\n 拍出来的照片跟你的经历有非常大的关系, 不要拍不在自己经历范畴之内的东西.\n 能够说明拍照与后期的关系的电影: 再次出发之纽约遇见你 (豆瓣) (douban.com)\n ","date":"0001-01-01T00:00:00Z","permalink":"https://wangloo.github.io/posts/photo/50%E8%AE%B2/","section":"posts","tags":null,"title":""},{"categories":null,"contents":"源文件 模拟了一个调度器的行为，支持输入多个进程，每个进程可以包含一部分CPU计算指令和IO指令，IO指令可以设置等待时间。\nhttp://pages.cs.wisc.edu/~remzi/OSTEP/Homework/HW-CPU-Intro.tgz\n运行参数解析 利用python OptionParser 模块\nfrom optparse import OptionParser 生成实例，添加支持的参数列表：\nparser = OptionParser() # -s ==\u0026gt; 短参数 # --seed ==\u0026gt; 长参数 # default ==\u0026gt; 默认值 # type ==\u0026gt; type of option value # action=\u0026#39;store\u0026#39; ==\u0026gt; store option value to dest # action=\u0026#39;store_true\u0026#39; ==\u0026gt; 无需携带参数，只要出现就认为True # dest ==\u0026gt; member of parser for storing value # help ==\u0026gt; description of this option, -h时会输出 parser.add_option(\u0026#39;-s\u0026#39;, \u0026#39;--seed\u0026#39;, default=0, help=\u0026#39;the random seed\u0026#39;, action=\u0026#39;store\u0026#39;, type=\u0026#39;int\u0026#39;, dest=\u0026#39;seed\u0026#39;) parser.add_option(\u0026#39;-l\u0026#39;, \u0026#39;--processlist\u0026#39;, default=\u0026#39;\u0026#39;, help=\u0026#39;a comma-separated list of processes to run, in the form X1:Y1,X2:Y2,... where X is the number of instructions that process should run, and Y the chances (from 0 to 100) that an instruction will use the CPU or issue an IO\u0026#39;, action=\u0026#39;store\u0026#39;, type=\u0026#39;string\u0026#39;, dest=\u0026#39;process_list\u0026#39;) parser.add_option(\u0026#39;-L\u0026#39;, \u0026#39;--iolength\u0026#39;, default=5, help=\u0026#39;how long an IO takes\u0026#39;, action=\u0026#39;store\u0026#39;, type=\u0026#39;int\u0026#39;, dest=\u0026#39;io_length\u0026#39;) parser.add_option(\u0026#39;-S\u0026#39;, \u0026#39;--switch\u0026#39;, default=\u0026#39;SWITCH_ON_IO\u0026#39;, help=\u0026#39;when to switch between processes: SWITCH_ON_IO, SWITCH_ON_END\u0026#39;, action=\u0026#39;store\u0026#39;, type=\u0026#39;string\u0026#39;, dest=\u0026#39;process_switch_behavior\u0026#39;) parser.add_option(\u0026#39;-I\u0026#39;, \u0026#39;--iodone\u0026#39;, default=\u0026#39;IO_RUN_LATER\u0026#39;, help=\u0026#39;type of behavior when IO ends: IO_RUN_LATER, IO_RUN_IMMEDIATE\u0026#39;, action=\u0026#39;store\u0026#39;, type=\u0026#39;string\u0026#39;, dest=\u0026#39;io_done_behavior\u0026#39;) parser.add_option(\u0026#39;-c\u0026#39;, help=\u0026#39;compute answers for me\u0026#39;, action=\u0026#39;store_true\u0026#39;, default=False, dest=\u0026#39;solve\u0026#39;) parser.add_option(\u0026#39;-p\u0026#39;, \u0026#39;--printstats\u0026#39;, help=\u0026#39;print statistics at end; only useful with -c flag (otherwise stats are not printed)\u0026#39;, action=\u0026#39;store_true\u0026#39;, default=False, dest=\u0026#39;print_stats\u0026#39;) 根据以上定义的规则，解析本次传入的参数列表。返回两个变量：\n options: \u0026lt;dest,value\u0026gt;的键值对。options.seed 访问seed参数的值 args: 按照规则解析后残余的参数list  (options, args) = parser.parse_args() 运行 输出我们给定的策略，包括每个进程的指令流，调度器的任务切换逻辑。\nif options.solve == False: print \u0026#39;Produce a trace of what would happen when you run these processes:\u0026#39; for pid in range(s.get_num_processes()): print \u0026#39;Process %d\u0026#39; % pid for inst in range(s.get_num_instructions(pid)): print \u0026#39; %s\u0026#39; % s.get_instruction(pid, inst) print \u0026#39;\u0026#39; print \u0026#39;Important behaviors:\u0026#39; print \u0026#39; System will switch when\u0026#39;, if options.process_switch_behavior == SCHED_SWITCH_ON_IO: print \u0026#39;the current process is FINISHED or ISSUES AN IO\u0026#39; else: print \u0026#39;the current process is FINISHED\u0026#39; print \u0026#39; After IOs, the process issuing the IO will\u0026#39;, if options.io_done_behavior == IO_RUN_IMMEDIATE: print \u0026#39;run IMMEDIATELY\u0026#39; else: print \u0026#39;run LATER (when it is its turn)\u0026#39; print \u0026#39;\u0026#39; exit(0) ","date":"0001-01-01T00:00:00Z","permalink":"https://wangloo.github.io/posts/python/process-run.py/","section":"posts","tags":null,"title":""},{"categories":null,"contents":"Clang是个啥 Clang与LLVM llvm有两种含义：llvm框架和llvm Core\n llvm框架定义了一个编译器的组成架构，此时Clang可以作为框架中针对C/C++语言的前端。 当然llvm框架也并不只是包含这一个前端，也可以有其他的前端。 llvm Core是除了前端之外的其他构成编译器的部分，包括中端优化和后端。  Clang与Gcc  Clang是一个编译器前端，Clang+llvm Core=编译器，Gcc也是一个编译器 Clang的代码结构更好，扩展性强  Clangd clangd是llvm项目推出的C/C++语言服务器，通过LSP(Language Server Protocal)协议向编辑器如vscode/vim/emacs提供语法补全、错误检测、跳转、格式化等等功能。C++的LSP曾经是cquery, ccls, clangd三足鼎立。但是clangd支持clang-tidy实时检查的功能是另外两者不具备的，而且cquery和ccls都是单个开发者主导的项目，clangd背后则是有llvm的背书。\n一般写C代码，在vscode中用C/C++这个插件来进行自动补全，这类插件在复杂工程中效果不太好因为它是基于代码进行分析，理论上不能准确的区别同名函数到底是调用谁的情况。而且在实践中也经常产生莫名其妙找不到定义的情况。\n而Clangd则是支持基于编译的分析做代码补全， 通过解析一个调用数据库文件compile_commands.json 来提供错误检查和补全等功能。\n生成 compile_commands.json 一般采用make工具构建的工程，通过bear工具可以在编译中自动分析并生成compile_commands.json。\n特别对于Linux kernel，有专门的工具scripts/clang-tools/gen_compile_commands.py，在编译后执行该脚本即可在根目录生成compile_commands.json。\nVSCode配置Clangd补全  安装clangd插件 clangd插件与c/c++插件冲突，目前的方法时禁用C/C++插件。 配置clangd服务的路径，可以在User或者Workspace。 如果有其他参数需求，可以按需添加。  .notice { --root-color: #444; --root-background: #eff; --title-color: #fff; --title-background: #7bd; --warning-title: #c33; --warning-content: #fee; --info-title: #fb7; --info-content: #fec; --note-title: #6be; --note-content: #e7f2fa; --tip-title: #5a5; --tip-content: #efe } @media (prefers-color-scheme:dark) { .notice { --root-color: #ddd; --root-background: #eff; --title-color: #fff; --title-background: #7bd; --warning-title: #800; --warning-content: #400; --info-title: #a50; --info-content: #420; --note-title: #069; --note-content: #023; --tip-title: #363; --tip-content: #121 } } body.dark .notice { --root-color: #ddd; --root-background: #eff; --title-color: #fff; --title-background: #7bd; --warning-title: #800; --warning-content: #400; --info-title: #a50; --info-content: #420; --note-title: #069; --note-content: #023; --tip-title: #363; --tip-content: #121 } .notice { padding: 18px; line-height: 24px; margin-bottom: 24px; border-radius: 4px; color: var(--root-color); background: var(--root-background) } .notice p:last-child { margin-bottom: 0 } .notice-title { margin: -18px -18px 12px; padding: 4px 18px; border-radius: 4px 4px 0 0; font-weight: 700; color: var(--title-color); background: var(--title-background) } .notice.warning .notice-title { background: var(--warning-title) } .notice.warning { background: var(--warning-content) } .notice.info .notice-title { background: var(--info-title) } .notice.info { background: var(--info-content) } .notice.note .notice-title { background: var(--note-title) } .notice.note { background: var(--note-content) } .notice.tip .notice-title { background: var(--tip-title) } .notice.tip { background: var(--tip-content) } .icon-notice { display: inline-flex; align-self: center; margin-right: 8px } .icon-notice img, .icon-notice svg { height: 1em; width: 1em; fill: currentColor } .icon-notice img, .icon-notice.baseline svg { top: .125em; position: relative }     不生效的排查方法\nclangd服务会输出一些日志，当你切换文件或者鼠标悬浮在代码上时会输出解析的日志，如果有Error可以在这里排查。比如vscode使用clangd报error: invalid AST错误-CSDN博客。\n Vim配置Clangd补全 我目前使用coc-nvim插件来调用Clangd进行补全。\nClangd配置文件`.clangd. Clangd支持的所有配置项：https://clangd.llvm.org/config.html\n有两种方式对Clangd的配置进行设定：\n 全局配置 ~/.config/clangd/config.yaml 工程内部 .clangd 仅在工程目录内生效  以上两个都是YAML类型的文件，我目前使用到了忽略一些编译参数:\nCompileFlags:Remove:[-march=armv8-a, -march=armv7-a]# invalid target CPU values in clangd-15Clang-format 代码格式化工具\nReference  Clangd config   ","date":"0001-01-01T00:00:00Z","permalink":"https://wangloo.github.io/posts/tools/clang/","section":"posts","tags":null,"title":""},{"categories":null,"contents":"Googletest 移植 Arm64 交叉编译 Download source code\ngit clone https://github.com/google/googletest.git -b v1.14.0 编写适用于Arm64平台的规则，指定交叉编译器的位置。此文件放在项目的根目录下。\nset(CMAKE_CROSSCOMPILING TRUE)set(CMAKE_FIND_ROOT_PATH ~/tools/gcc-arm-10.3-2021.07-x86_64-aarch64-none-linux-gnu/)# Cross compiler SET(CMAKE_C_COMPILER aarch64-none-linux-gnu-gcc)SET(CMAKE_CXX_COMPILER aarch64-none-linux-gnu-g++)set(CMAKE_LIBRARY_ARCHITECTURE aarch64-none-linux-gnu)# Search for programs in the build host directories SET(CMAKE_FIND_ROOT_PATH_MODE_PROGRAM NEVER)# Libraries and headers in the target directories set(CMAKE_FIND_ROOT_PATH_MODE_LIBRARY ONLY)set(CMAKE_FIND_ROOT_PATH_MODE_INCLUDE ONLY)set(CMAKE_FIND_ROOT_PATH_MODE_PACKAGE ONLY)编译，这里没有编译Googlemock\n#!/bin/bash  rm -rf build mkdir build \u0026amp;\u0026amp; cd build cmake .. -DCMAKE_TOOLCHAIN_FILE=../toolchain_arm64.cmake -DGTEST_HAS_PTHREAD=0 -DBUILD_GMOCK=OFF # check file: lib/libgtest_main.a and lib/libgtest.a ","date":"0001-01-01T00:00:00Z","permalink":"https://wangloo.github.io/posts/tools/gtest/","section":"posts","tags":null,"title":""},{"categories":null,"contents":"正则表达式常用:\n 匹配一个或多个以上的空格: [ \\t]{1,}  ","date":"0001-01-01T00:00:00Z","permalink":"https://wangloo.github.io/posts/tools/regex/","section":"posts","tags":null,"title":""}]